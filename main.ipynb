{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from Stock_Dataset.ipynb\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "import sys\n",
    "sys.path.append('C:\\\\Users\\\\USER\\\\JupyterProjects\\conv_biLSTM_attention_ti')\n",
    "from Stock_Dataset import StockDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from CONV_Att_BILSTM.ipynb\n",
      "importing Jupyter notebook from attention.ipynb\n",
      "importing Jupyter notebook from metric.ipynb\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import argparse\n",
    "from CONV_Att_BILSTM import Conv_attLSTM\n",
    "import numpy as np\n",
    "import time\n",
    "from metric import metric_acc as ACC\n",
    "from metric import metric_mcc as MCC\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import os\n",
    "from Stock_dataloader_csv_ti import stock_csv_read\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train(conv_attLSTM, lstm_optimizer,Partition, args): ## Data, loss function, argument\n",
    "    trainloader = DataLoader(Partition['train'],\n",
    "                             batch_size = args.batch_size,\n",
    "                             shuffle=False, drop_last=True)\n",
    "    conv_attLSTM.train()\n",
    "\n",
    "    train_loss = 0.0\n",
    "    for i, (x,y) in enumerate(trainloader):\n",
    "        \n",
    "        lstm_optimizer.zero_grad()\n",
    "        true_y = y.squeeze().float().to(args.device)\n",
    "        x = x.to(args.device)\n",
    "        \n",
    "        conv_attLSTM.hidden = [hidden.to(args.device) for hidden in conv_attLSTM.init_hidden()]\n",
    "        \n",
    "        yhat, attention_weight, attn_applied = conv_attLSTM(x)\n",
    "        # print(es.size()) [128, 20]\n",
    "        \n",
    "\n",
    "        loss = args.loss_fn(yhat, true_y)\n",
    "        loss.backward()\n",
    "\n",
    "\n",
    "        lstm_optimizer.step()## parameter 갱신\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    train_loss = train_loss / len(trainloader)\n",
    "    return conv_attLSTM, train_loss\n",
    "\n",
    "\n",
    "def validation(conv_attLSTM, partition, args):\n",
    "    valloader = DataLoader(partition['val'], \n",
    "                           batch_size=args.batch_size,\n",
    "                           shuffle=False, drop_last=True)\n",
    "    conv_attLSTM.eval()\n",
    "    \n",
    "    val_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (x, y) in enumerate(valloader):\n",
    "\n",
    "            true_y = y.squeeze().float().to(args.device)\n",
    "            x = x.to(args.device)\n",
    "\n",
    "            conv_attLSTM.hidden = [conv_attLSTM.to(args.device) for hidden in conv_attLSTM.init_hidden()]\n",
    "\n",
    "            yhat, attention_weight, attn_applied = conv_attLSTM(x)\n",
    "\n",
    "\n",
    "            # output_ = torch.where(output1 >= 0.5, 1.0, 0.0)\n",
    "            # output_.requires_grad=True\n",
    "\n",
    "            loss = args.loss_fn(yhat, true_y)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "\n",
    "        val_loss = val_loss / len(valloader)\n",
    "        return conv_attLSTM, val_loss\n",
    "\n",
    "\n",
    "def test(conv_attLSTM,partition, args):\n",
    "    testloader = DataLoader(partition['test'],\n",
    "                           batch_size=args.batch_size,\n",
    "                           shuffle=False, drop_last=True)\n",
    "    conv_attLSTM.eval()\n",
    "\n",
    "    ACC_metric = 0.0\n",
    "    MCC_metric = 0.0\n",
    "    with torch.no_grad():\n",
    "        for i, (x, y) in enumerate(testloader):\n",
    "\n",
    "            # feature transform\n",
    "            true_y = y.squeeze().float().to(args.device)\n",
    "            x = x.to(args.device)\n",
    "\n",
    "            conv_attLSTM.hidden = [hidden.to(args.device) for hidden in conv_attLSTM.init_hidden()]\n",
    "\n",
    "            yhat, attention_weight, attn_applied = conv_attLSTM(x)\n",
    "\n",
    "            output_ = torch.where(yhat >= 0.5, 1.0, 0.0)\n",
    "\n",
    "            output_.requires_grad = True\n",
    "\n",
    "            ACC_metric += ACC(output_, true_y)\n",
    "            MCC_metric += MCC(output_, true_y)\n",
    "\n",
    "        ACC_metric = ACC_metric / len(testloader)\n",
    "        MCC_metric = MCC_metric / len(testloader)\n",
    "\n",
    "        return ACC_metric, MCC_metric\n",
    "\n",
    "\n",
    "\n",
    "def experiment(partition, args):\n",
    "    conv_attLSTM = args.Conv_attLSTM(args.input_dim, args.hid_dim, args.output_dim, args.num_layers, args.batch_size,\n",
    "                                args.dropout, args.use_bn, args.attention_head, args.attn_size,activation=\"ReLU\")\n",
    "\n",
    "    conv_attLSTM.to(args.device)\n",
    "\n",
    "\n",
    "    if args.optim == 'SGD':\n",
    "        lstm_optimizer = optim.SGD(conv_attLSTM.parameters(), lr=args.lr, weight_decay=args.l2)\n",
    "    elif args.optim == 'RMSprop':\n",
    "        lstm_optimizer = optim.RMSprop(conv_attLSTM.parameters(), lr=args.lr, weight_decay=args.l2)\n",
    "    elif args.optim == 'Adam':\n",
    "        lstm_optimizer = optim.Adam(conv_attLSTM.parameters(), lr=args.lr, weight_decay=args.l2)\n",
    "    else:\n",
    "        raise ValueError('In-valid optimizer choice')\n",
    "\n",
    "    # ===== List for epoch-wise data ====== #\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    # ===================================== #\n",
    "    for epoch in range(args.epoch):\n",
    "        ts = time.time()\n",
    "        conv_attLSTM, train_loss = train(conv_attLSTM, lstm_optimizer, partition, args)\n",
    "\n",
    "        conv_attLSTM, val_loss = validation(conv_attLSTM, partition, args)\n",
    "\n",
    "        te = time.time()\n",
    "\n",
    "        ## 각 에폭마다 모델을 저장하기 위한 코드\n",
    "        if len(val_losses) == 0:\n",
    "            torch.save(conv_attLSTM.state_dict(), args.split_file_path + '\\\\' + str(epoch) +'conv_attLSTM' +'.pt')\n",
    "        elif min(val_losses) > val_loss:\n",
    "            torch.save(conv_attLSTM.state_dict(), args.split_file_path + '\\\\' + str(epoch) +'conv_attLSTM' +'.pt')\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        print('Epoch {}, Loss(train/val) {:2.5f}/{:2.5f}. Took {:2.2f} sec'\n",
    "              .format(epoch, train_loss, val_loss, te - ts))\n",
    "\n",
    "    ## val_losses에서 가장 값이 최소인 위치를 저장함\n",
    "    site_val_losses = val_losses.index(min(val_losses)) ## 10 epoch일 경우 0번째~9번째 까지로 나옴\n",
    "    conv_attLSTM = args.Conv_attLSTM(args.input_dim, args.hid_dim, args.output_dim, args.num_layers, args.batch_size,\n",
    "                                     args.dropout, args.use_bn, args.attention_head, args.attn_size, activation=\"ReLU\")\n",
    "\n",
    "    conv_attLSTM.to(args.device)\n",
    "\n",
    "\n",
    "    conv_attLSTM.load_state_dict(torch.load(args.split_file_path + '\\\\' + str(site_val_losses) +'conv_attLSTM'+ '.pt'))\n",
    "\n",
    "    ACC, MCC = test(conv_attLSTM, partition, args)\n",
    "    print('ACC: {}, MCC: {}'.format(ACC, MCC))\n",
    "\n",
    "    with open(args.split_file_path + '\\\\'+ str(site_val_losses)+'Epoch_test_metric' +'.csv', 'w') as fd:\n",
    "        print('ACC: {}, MCC: {}'.format(ACC, MCC), file=fd)\n",
    "\n",
    "    result = {}\n",
    "\n",
    "    result['train_losses'] = train_losses\n",
    "    result['val_losses'] = val_losses\n",
    "    result['ACC'] = ACC\n",
    "    result['MCC'] = MCC\n",
    "\n",
    "    return vars(args), result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ====== Random Seed Initialization ====== #\n",
    "seed = 666\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# ========= experiment setting ========== #\n",
    "parser = argparse.ArgumentParser()\n",
    "args = parser.parse_args(\"\")\n",
    "args.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "args.save_file_path = \"C:\\\\Users\\\\USER\\\\JupyterProjects\\\\conv_biLSTM_attention_ti\\\\results\"\n",
    "\n",
    "# ====== hyperparameter ======= #\n",
    "args.batch_size = 64\n",
    "\n",
    "args.dropout = 0.2\n",
    "args.use_bn = True\n",
    "args.loss_fn = nn.L1Loss()  ## loss function for classification : cross entropy\n",
    "args.optim = 'Adam'\n",
    "args.lr = 0.0005\n",
    "args.l2 = 0.00001 #?\n",
    "args.epoch = 100\n",
    "# ============= model ================== #\n",
    "args.Conv_attLSTM = Conv_attLSTM\n",
    "\n",
    "# ====== att_lstm hyperparameter ======= #\n",
    "args.x_frames = 10\n",
    "args.y_frames = 1\n",
    "\n",
    "args.input_dim = 64\n",
    "args.hid_dim = 64\n",
    "args.output_dim = 1\n",
    "\n",
    "args.attention_head = 1\n",
    "args.attn_size = 10\n",
    "args.num_layers = 1\n",
    "args.attLSTM_x_frames = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss(train/val) 0.49051/0.47593. Took 0.37 sec\n",
      "Epoch 1, Loss(train/val) 0.46401/0.43318. Took 0.15 sec\n",
      "Epoch 2, Loss(train/val) 0.41957/0.38714. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.39127/0.36715. Took 0.16 sec\n",
      "Epoch 4, Loss(train/val) 0.37687/0.35980. Took 0.15 sec\n",
      "Epoch 5, Loss(train/val) 0.37034/0.35880. Took 0.15 sec\n",
      "Epoch 6, Loss(train/val) 0.36335/0.35012. Took 0.15 sec\n",
      "Epoch 7, Loss(train/val) 0.35944/0.34742. Took 0.15 sec\n",
      "Epoch 8, Loss(train/val) 0.35358/0.34127. Took 0.16 sec\n",
      "Epoch 9, Loss(train/val) 0.34399/0.34907. Took 0.15 sec\n",
      "Epoch 10, Loss(train/val) 0.34257/0.33480. Took 0.15 sec\n",
      "Epoch 11, Loss(train/val) 0.33294/0.35236. Took 0.16 sec\n",
      "Epoch 12, Loss(train/val) 0.32961/0.31535. Took 0.16 sec\n",
      "Epoch 13, Loss(train/val) 0.32222/0.32274. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.30852/0.34716. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.30784/0.34569. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.29553/0.31743. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.29351/0.32537. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.29130/0.32785. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.28943/0.32333. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.28811/0.33717. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.28577/0.27816. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.28440/0.33450. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.28642/0.27747. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.28206/0.30524. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.27936/0.31364. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.27094/0.30287. Took 0.13 sec\n",
      "Epoch 27, Loss(train/val) 0.26468/0.31581. Took 0.13 sec\n",
      "Epoch 28, Loss(train/val) 0.26553/0.30165. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.25329/0.29441. Took 0.13 sec\n",
      "Epoch 30, Loss(train/val) 0.26391/0.29918. Took 0.13 sec\n",
      "Epoch 31, Loss(train/val) 0.27277/0.28628. Took 0.13 sec\n",
      "Epoch 32, Loss(train/val) 0.25382/0.30840. Took 0.13 sec\n",
      "Epoch 33, Loss(train/val) 0.25287/0.30138. Took 0.13 sec\n",
      "Epoch 34, Loss(train/val) 0.25463/0.28595. Took 0.13 sec\n",
      "Epoch 35, Loss(train/val) 0.24768/0.30394. Took 0.13 sec\n",
      "Epoch 36, Loss(train/val) 0.24713/0.31242. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.25445/0.31355. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.25494/0.25853. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.25320/0.26737. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.23905/0.30264. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.23502/0.27932. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.23776/0.28173. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.23018/0.32974. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.24426/0.31778. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.23447/0.31326. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.23739/0.32042. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.22934/0.31324. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.22171/0.32775. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.22967/0.31612. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.21614/0.33132. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.22204/0.31885. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.22255/0.28525. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.22530/0.32388. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.21525/0.30806. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.22295/0.33124. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.22091/0.27863. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.21783/0.35578. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.21089/0.34924. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.22432/0.34470. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.20638/0.34777. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.19986/0.32663. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.20904/0.36493. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.20000/0.34551. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.20087/0.34501. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.19225/0.32445. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.19846/0.33332. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.19199/0.33655. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.19410/0.35719. Took 0.14 sec\n",
      "Epoch 69, Loss(train/val) 0.19947/0.33791. Took 0.12 sec\n",
      "Epoch 70, Loss(train/val) 0.18943/0.33955. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.19691/0.29008. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.19405/0.31542. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.19576/0.32950. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.18323/0.29679. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.18491/0.33743. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.17834/0.33128. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.18485/0.31849. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.17291/0.32048. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.18968/0.31876. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.17948/0.33980. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.16940/0.37765. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.17339/0.34778. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.17554/0.37259. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.16713/0.32975. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.15921/0.37737. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.16131/0.36455. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.16527/0.36357. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.16449/0.36361. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.16744/0.33393. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.16014/0.34222. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.16695/0.33293. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.16024/0.36678. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.14955/0.33942. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.15723/0.33874. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.15111/0.34555. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.15758/0.33518. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.15691/0.36666. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.15343/0.32717. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.15306/0.33973. Took 0.13 sec\n",
      "ACC: 0.6875, MCC: 0.2868600772746187\n",
      "Epoch 0, Loss(train/val) 0.49292/0.46479. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.47012/0.40613. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.43184/0.36333. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.39888/0.34735. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.38480/0.34288. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.37845/0.33845. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.36682/0.33643. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.36105/0.33665. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.35289/0.33835. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.34388/0.34151. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.33285/0.34335. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.32768/0.34455. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.31416/0.34340. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.30822/0.37109. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.30006/0.33202. Took 0.15 sec\n",
      "Epoch 15, Loss(train/val) 0.30137/0.33085. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.29072/0.32884. Took 0.15 sec\n",
      "Epoch 17, Loss(train/val) 0.28716/0.32807. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.27847/0.31981. Took 0.15 sec\n",
      "Epoch 19, Loss(train/val) 0.27488/0.34676. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.26140/0.34929. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.27076/0.37222. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.29208/0.35605. Took 0.16 sec\n",
      "Epoch 23, Loss(train/val) 0.27374/0.35439. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.26057/0.34796. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.26233/0.33628. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.26198/0.35211. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.24903/0.34043. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.25453/0.37462. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.24037/0.37294. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.24120/0.39319. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.24242/0.35868. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.23527/0.32201. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.23147/0.36581. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.24039/0.31452. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.23635/0.33947. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.21674/0.37950. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.22188/0.31102. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.22315/0.38298. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.21426/0.35004. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.21751/0.36968. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.21241/0.36492. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.21768/0.32209. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.20535/0.36198. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.20177/0.32557. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.20843/0.32590. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.19290/0.34478. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.20365/0.35838. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.19931/0.32527. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.19293/0.32267. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.18733/0.31797. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.19085/0.34110. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.20361/0.33518. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.18460/0.32995. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.18502/0.36133. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.18513/0.34279. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.19382/0.34944. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.18186/0.34344. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.18325/0.37268. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.16670/0.35159. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.17891/0.36519. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.17492/0.35136. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.17679/0.36975. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.17237/0.34934. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.17765/0.35507. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.17699/0.34980. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.17597/0.35633. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.16364/0.34465. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.16927/0.35687. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.16783/0.36939. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.15502/0.37596. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.16285/0.33651. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.16656/0.36112. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.15024/0.37107. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.16441/0.35436. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.15383/0.34582. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.15466/0.32909. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.16508/0.33802. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.15588/0.33324. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.14703/0.35607. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.15265/0.32996. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.16253/0.34145. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.14995/0.35865. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.15212/0.35612. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.14736/0.33197. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.14268/0.33951. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.14943/0.36906. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.14000/0.34341. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.14672/0.33616. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.13512/0.33902. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.13754/0.33135. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.13456/0.35225. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.13017/0.36208. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.13785/0.33535. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.12758/0.34693. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.13386/0.35114. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.14015/0.34380. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.13845/0.38906. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.12871/0.35867. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.12797/0.33459. Took 0.13 sec\n",
      "ACC: 0.671875, MCC: 0.3979656730604679\n",
      "Epoch 0, Loss(train/val) 0.49150/0.46764. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.46607/0.40593. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.42293/0.32656. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.38560/0.28659. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.36549/0.27890. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.35616/0.26535. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.34800/0.26725. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.34298/0.25079. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.33854/0.24942. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.33160/0.26017. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.32720/0.24473. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.31871/0.24352. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.31689/0.25991. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.31918/0.19848. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.30808/0.22670. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.29858/0.21811. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.29675/0.21450. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.29312/0.22334. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.28899/0.24265. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.28650/0.20569. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.28754/0.24007. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.28199/0.21592. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.27874/0.24563. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.27847/0.22049. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.26918/0.24259. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.26981/0.23949. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.26670/0.24446. Took 0.13 sec\n",
      "Epoch 27, Loss(train/val) 0.26094/0.23475. Took 0.13 sec\n",
      "Epoch 28, Loss(train/val) 0.25823/0.22589. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.24974/0.23730. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.23702/0.21978. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.23721/0.22545. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.23939/0.22255. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.23633/0.21013. Took 0.13 sec\n",
      "Epoch 34, Loss(train/val) 0.23602/0.20104. Took 0.13 sec\n",
      "Epoch 35, Loss(train/val) 0.23478/0.23029. Took 0.13 sec\n",
      "Epoch 36, Loss(train/val) 0.23925/0.22439. Took 0.13 sec\n",
      "Epoch 37, Loss(train/val) 0.21810/0.23569. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.22459/0.21549. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.23027/0.21690. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.22711/0.20494. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.21579/0.21407. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.20700/0.21885. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.21523/0.26949. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.20853/0.22736. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.21197/0.23771. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.20481/0.24349. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.20522/0.25798. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.20566/0.25330. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.21049/0.23682. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.20631/0.23533. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.20225/0.22559. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.19586/0.22538. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.19912/0.26275. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.20326/0.25903. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.19237/0.26596. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.19487/0.26184. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.19253/0.24212. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.18852/0.26473. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.18290/0.26573. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.17805/0.23921. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.18548/0.25508. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.18451/0.24526. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.18109/0.24541. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.17624/0.24701. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.17950/0.24233. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.17932/0.24502. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.17876/0.23667. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.18273/0.24692. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.17517/0.25701. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.16918/0.24870. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.17485/0.26876. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.17798/0.24986. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.17452/0.24126. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.16719/0.23942. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.17171/0.23056. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.16631/0.24469. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.16553/0.24893. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.15969/0.24474. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.15622/0.25217. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.15768/0.23267. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.16411/0.25758. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.15611/0.24883. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.16306/0.23923. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.16745/0.24142. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.16100/0.24133. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.15719/0.24762. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.16252/0.24994. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.15663/0.24887. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.14690/0.24044. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.15258/0.25179. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.14446/0.25437. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.14711/0.24853. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.13736/0.25098. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.15237/0.25544. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.14638/0.25128. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.13540/0.25078. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.14274/0.24678. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.15222/0.24216. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.13974/0.24620. Took 0.13 sec\n",
      "ACC: 0.65625, MCC: 0.2721190148800421\n",
      "Epoch 0, Loss(train/val) 0.49234/0.48806. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.46276/0.46231. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.41626/0.43234. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.38197/0.40635. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.36789/0.37586. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.35968/0.35903. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.35162/0.35927. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.34417/0.34843. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.34714/0.34960. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.33130/0.34469. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.32144/0.33679. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.31699/0.33321. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.31072/0.32627. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.30113/0.32825. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.30792/0.32360. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.30253/0.32955. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.29680/0.33017. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.29445/0.33837. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.29859/0.34313. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.29227/0.32770. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.27768/0.32172. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.27455/0.32035. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.26872/0.32202. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.27357/0.33246. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.27761/0.32495. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.27466/0.32177. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.26373/0.32047. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.25582/0.31696. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.26129/0.31267. Took 0.17 sec\n",
      "Epoch 29, Loss(train/val) 0.27029/0.31055. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.26264/0.32564. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.26684/0.31996. Took 0.13 sec\n",
      "Epoch 32, Loss(train/val) 0.24894/0.31849. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.25371/0.31861. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.24213/0.29953. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.24473/0.31499. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.24321/0.31818. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.24082/0.31157. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.25087/0.29826. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.24387/0.32675. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.23275/0.29975. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.23603/0.30708. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.22492/0.31651. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.22531/0.29496. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.22306/0.30850. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) 0.21116/0.30225. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.22281/0.31259. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.22021/0.30764. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.21179/0.31041. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.21360/0.30350. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.21958/0.31264. Took 0.14 sec\n",
      "Epoch 51, Loss(train/val) 0.22790/0.31246. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.21263/0.30647. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) 0.20219/0.31705. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.20520/0.31355. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.19718/0.30604. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.19473/0.31160. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.20034/0.32017. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.19589/0.31434. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.19811/0.31718. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.20401/0.31323. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.19744/0.31055. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.19490/0.32508. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.18533/0.31211. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.20051/0.31447. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.18609/0.30343. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.18918/0.31000. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.18179/0.31397. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.18125/0.31221. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.18214/0.31459. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.18777/0.32052. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.18311/0.31316. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.18176/0.32129. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.18366/0.32045. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.18080/0.31087. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.18063/0.31303. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.17534/0.31211. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.18059/0.30872. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.17277/0.31173. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.17474/0.31158. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.17239/0.31279. Took 0.14 sec\n",
      "Epoch 81, Loss(train/val) 0.17150/0.31389. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.18139/0.31553. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.18084/0.30803. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.18111/0.30967. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.17630/0.31269. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.17285/0.32855. Took 0.15 sec\n",
      "Epoch 87, Loss(train/val) 0.18265/0.32977. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.18149/0.31523. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.18693/0.31077. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.16885/0.31291. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.17150/0.33864. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.16919/0.31249. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.16718/0.31381. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.17674/0.32050. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.16950/0.31262. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.18509/0.31875. Took 0.14 sec\n",
      "Epoch 97, Loss(train/val) 0.17394/0.33963. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.16570/0.31460. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.15373/0.33962. Took 0.13 sec\n",
      "ACC: 0.6875, MCC: 0.4431985015711704\n",
      "Epoch 0, Loss(train/val) 0.48907/0.47152. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.45737/0.41734. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.41188/0.36411. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.37902/0.34754. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.36175/0.34924. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.34655/0.35068. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.34265/0.34641. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.34001/0.34621. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.33264/0.34046. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.33129/0.35469. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.32982/0.34736. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.32395/0.33937. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.32064/0.34642. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.31227/0.33862. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.30997/0.33562. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.31162/0.33419. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.31296/0.35050. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.30349/0.34459. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.29649/0.33761. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.29650/0.34634. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.28914/0.35112. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.29861/0.35121. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.28291/0.35706. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.27578/0.35748. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.27339/0.35550. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.26872/0.35679. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.25718/0.35219. Took 0.15 sec\n",
      "Epoch 27, Loss(train/val) 0.25490/0.35529. Took 0.13 sec\n",
      "Epoch 28, Loss(train/val) 0.25061/0.35961. Took 0.13 sec\n",
      "Epoch 29, Loss(train/val) 0.24356/0.35639. Took 0.13 sec\n",
      "Epoch 30, Loss(train/val) 0.23787/0.35206. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.22693/0.35368. Took 0.13 sec\n",
      "Epoch 32, Loss(train/val) 0.22779/0.34711. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.22467/0.34767. Took 0.13 sec\n",
      "Epoch 34, Loss(train/val) 0.21653/0.34428. Took 0.13 sec\n",
      "Epoch 35, Loss(train/val) 0.21966/0.33910. Took 0.13 sec\n",
      "Epoch 36, Loss(train/val) 0.21922/0.33481. Took 0.13 sec\n",
      "Epoch 37, Loss(train/val) 0.21342/0.33569. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.20575/0.32957. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.19976/0.33318. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.19267/0.33702. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.19106/0.34936. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.19144/0.34952. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.18886/0.36330. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.20104/0.34614. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.19301/0.31553. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.18731/0.33376. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.18143/0.34892. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.17955/0.34995. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.17740/0.32756. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.17412/0.34244. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.16779/0.33563. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.16889/0.33396. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.16661/0.36002. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.16904/0.33549. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.15708/0.35291. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.16494/0.32807. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.16269/0.34962. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.15618/0.35496. Took 0.14 sec\n",
      "Epoch 59, Loss(train/val) 0.15382/0.36979. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.15673/0.32635. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.15313/0.39027. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.15649/0.37316. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.15834/0.34548. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.15516/0.33483. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.15241/0.36251. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.15669/0.34664. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.15743/0.38562. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.15820/0.37816. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.15009/0.33278. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.14407/0.33895. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.14136/0.35109. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.14116/0.40059. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.15223/0.34181. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.14991/0.37109. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.13652/0.37126. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.13546/0.38032. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.13619/0.36816. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.13440/0.37740. Took 0.14 sec\n",
      "Epoch 79, Loss(train/val) 0.14103/0.38432. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.13576/0.36616. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.14143/0.34657. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.15229/0.40132. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) 0.14166/0.36505. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.14311/0.40365. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.14433/0.37868. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.13042/0.37262. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.13772/0.42669. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.12696/0.40936. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.13587/0.41601. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.13289/0.38028. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.12636/0.43095. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.12995/0.43105. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.12487/0.40263. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.12909/0.38060. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.12851/0.41006. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.13149/0.40950. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.12267/0.39888. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.12457/0.43888. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.11993/0.44337. Took 0.13 sec\n",
      "ACC: 0.640625, MCC: 0.21449154984286298\n",
      "Epoch 0, Loss(train/val) 0.49095/0.48696. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.46210/0.44770. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.41262/0.39333. Took 0.15 sec\n",
      "Epoch 3, Loss(train/val) 0.37731/0.37336. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.36271/0.36108. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.35078/0.36208. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.34399/0.35636. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.33867/0.35810. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.33122/0.35684. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.32314/0.36052. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.31522/0.36259. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.31530/0.37515. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.30649/0.38201. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.29581/0.38688. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.29783/0.38739. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.29286/0.37988. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.28471/0.37625. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.27883/0.37765. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.27375/0.37572. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.27146/0.37443. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.26565/0.37512. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.26117/0.37718. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.25644/0.38348. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.25480/0.37395. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.26460/0.38127. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.25473/0.36993. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.25061/0.35786. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.24362/0.36555. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.23774/0.35773. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.23048/0.35949. Took 0.13 sec\n",
      "Epoch 30, Loss(train/val) 0.23315/0.35532. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.23144/0.35450. Took 0.13 sec\n",
      "Epoch 32, Loss(train/val) 0.22521/0.36729. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.22219/0.36204. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.22001/0.35756. Took 0.13 sec\n",
      "Epoch 35, Loss(train/val) 0.21750/0.35829. Took 0.13 sec\n",
      "Epoch 36, Loss(train/val) 0.22054/0.35982. Took 0.13 sec\n",
      "Epoch 37, Loss(train/val) 0.21734/0.36110. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.20776/0.36134. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.20106/0.35270. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.20908/0.36228. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.20781/0.36964. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.21938/0.36651. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.19678/0.35197. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.19280/0.36129. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) 0.19207/0.35323. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.19457/0.36844. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.18623/0.35039. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.17980/0.36883. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.17943/0.34640. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.18213/0.35459. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.17615/0.34576. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.16912/0.36493. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.17609/0.35544. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.17202/0.35709. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.16171/0.36984. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.16792/0.36226. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.16857/0.34579. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.17176/0.36539. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.15952/0.35362. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.15488/0.34549. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.15054/0.32973. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.14224/0.33948. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.15176/0.35767. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.15658/0.35453. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.15599/0.32327. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.15069/0.36410. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.14971/0.36088. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.14700/0.37001. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.14677/0.35530. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.14059/0.34596. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.14892/0.35783. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.13982/0.36730. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.14375/0.35284. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.13358/0.36843. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.13667/0.34971. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.13017/0.35934. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.13231/0.35396. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.12978/0.36689. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.12807/0.34690. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.13907/0.36850. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.12828/0.36928. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.13568/0.35288. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.13154/0.36008. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.12633/0.35799. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.12426/0.36195. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.12076/0.33284. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.11744/0.36688. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.12522/0.35570. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.11892/0.35619. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.11595/0.36300. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.10679/0.34431. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.12184/0.33840. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.11488/0.34914. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.11210/0.35818. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.11188/0.35007. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.10946/0.34645. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.10380/0.33604. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.10674/0.36673. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.10959/0.35407. Took 0.13 sec\n",
      "ACC: 0.609375, MCC: 0.2254091596030085\n",
      "Epoch 0, Loss(train/val) 0.49133/0.48260. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.46272/0.44998. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.41881/0.41571. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.37825/0.39521. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.35853/0.37528. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.34422/0.36180. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.33316/0.34658. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.32741/0.35225. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.32096/0.35178. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.31649/0.35211. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.30146/0.32858. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.30185/0.33946. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.29611/0.33467. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.29360/0.32031. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.28642/0.33218. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.28431/0.34229. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.27428/0.33861. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.27371/0.33076. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.27329/0.32273. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.26408/0.33297. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.26366/0.33215. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.26078/0.33015. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.26466/0.33034. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.26397/0.31752. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.26211/0.31329. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.25243/0.29683. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.25643/0.31788. Took 0.15 sec\n",
      "Epoch 27, Loss(train/val) 0.24682/0.32864. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.24273/0.30563. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.24544/0.31672. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.23729/0.30432. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.23529/0.30719. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.23507/0.30516. Took 0.13 sec\n",
      "Epoch 33, Loss(train/val) 0.23247/0.31178. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.23462/0.29834. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.22947/0.32015. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.23189/0.29998. Took 0.13 sec\n",
      "Epoch 37, Loss(train/val) 0.22744/0.31585. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.22126/0.31041. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.21885/0.33128. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.22675/0.34492. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.22523/0.34790. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.22859/0.33548. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.21740/0.33632. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.21998/0.33616. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.21794/0.34409. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.21531/0.34287. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.20817/0.34012. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.21668/0.34115. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.21673/0.33400. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.21096/0.31119. Took 0.14 sec\n",
      "Epoch 51, Loss(train/val) 0.21674/0.32813. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.20982/0.32312. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.20234/0.33898. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.20627/0.33991. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.20580/0.33325. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.20568/0.33455. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.20505/0.33942. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.20291/0.33744. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.20189/0.33499. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.20296/0.34131. Took 0.15 sec\n",
      "Epoch 61, Loss(train/val) 0.19986/0.32849. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.20224/0.33264. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.19915/0.32341. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.19934/0.33084. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.19527/0.33718. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.19397/0.32163. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.19445/0.33122. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.19493/0.33036. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.19075/0.33150. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.18711/0.32308. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.18932/0.34310. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.19178/0.31917. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.19545/0.32197. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.18863/0.31994. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.18659/0.32561. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.19001/0.30949. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.18944/0.32318. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.18645/0.30922. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.18455/0.30510. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.18100/0.32284. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.18444/0.30335. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.18152/0.31917. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.18136/0.30379. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.18963/0.31074. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.18876/0.32060. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.18103/0.31986. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.18325/0.31870. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.17652/0.32436. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.18249/0.33305. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.18914/0.30943. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.18123/0.30131. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.18068/0.30624. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.17972/0.31740. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.17618/0.31126. Took 0.14 sec\n",
      "Epoch 95, Loss(train/val) 0.17599/0.28607. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.18108/0.29489. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.17137/0.32622. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.17481/0.32703. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.17476/0.31990. Took 0.14 sec\n",
      "ACC: 0.6875, MCC: 0.37389885714349824\n",
      "Epoch 0, Loss(train/val) 0.49017/0.48587. Took 0.13 sec\n",
      "Epoch 1, Loss(train/val) 0.45100/0.44622. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.39731/0.42441. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.35639/0.41584. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.33943/0.39168. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.32879/0.41615. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.32488/0.40103. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.32121/0.40737. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.31716/0.38852. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.31459/0.38927. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.31474/0.37713. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.31150/0.38407. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.30606/0.37713. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.30575/0.37307. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.30115/0.37677. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.29946/0.37975. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.29200/0.37811. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.28975/0.40429. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.28482/0.38437. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.28138/0.39321. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.27910/0.39685. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.27869/0.38491. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.27030/0.38507. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.26847/0.38383. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.27360/0.38063. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.26156/0.39235. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.25664/0.38502. Took 0.15 sec\n",
      "Epoch 27, Loss(train/val) 0.25667/0.33526. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.24433/0.33842. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.25028/0.37752. Took 0.13 sec\n",
      "Epoch 30, Loss(train/val) 0.24590/0.33946. Took 0.13 sec\n",
      "Epoch 31, Loss(train/val) 0.23803/0.35528. Took 0.13 sec\n",
      "Epoch 32, Loss(train/val) 0.23828/0.32969. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.23660/0.33276. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.23952/0.36613. Took 0.13 sec\n",
      "Epoch 35, Loss(train/val) 0.23587/0.33682. Took 0.13 sec\n",
      "Epoch 36, Loss(train/val) 0.23113/0.33567. Took 0.13 sec\n",
      "Epoch 37, Loss(train/val) 0.22812/0.33417. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.23283/0.34355. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.23059/0.34288. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.22515/0.33357. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.23491/0.39894. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.23074/0.34955. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.23095/0.35698. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.22084/0.36244. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.21735/0.35444. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.21788/0.33655. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.21497/0.33492. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.21539/0.32912. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.22143/0.35826. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.20794/0.34168. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.21009/0.34618. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.20453/0.35034. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.21017/0.34519. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.20321/0.33461. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.20715/0.36621. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.20923/0.34200. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.20229/0.34597. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.20452/0.34190. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.20334/0.34925. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.19359/0.32743. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.20052/0.34849. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.20220/0.33517. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.18940/0.33428. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.20006/0.34199. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.19772/0.34766. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.19238/0.33910. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.19049/0.33853. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.18597/0.34067. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.18828/0.34598. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.18400/0.32812. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.18740/0.34881. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.18596/0.31423. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.19280/0.33597. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.17734/0.32525. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.19077/0.35170. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.19399/0.36317. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.18502/0.32354. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.18150/0.39270. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.17728/0.39770. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.17588/0.39706. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.16802/0.35922. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.18008/0.40468. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.17050/0.40891. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.16889/0.36167. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.16316/0.42239. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.17177/0.40889. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.16812/0.44875. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.15743/0.42266. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.17254/0.43490. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.15961/0.43117. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.15468/0.46579. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.15522/0.43708. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.15960/0.46328. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.15929/0.43395. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.16343/0.48398. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.16371/0.48411. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.15885/0.37612. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.15462/0.42736. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.15529/0.43535. Took 0.13 sec\n",
      "ACC: 0.625, MCC: 0.2519763153394848\n",
      "Epoch 0, Loss(train/val) 0.47976/0.49058. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.44079/0.47551. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.39755/0.45528. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.36779/0.44775. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.35192/0.43850. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.33740/0.43265. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.33195/0.42997. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.32506/0.43353. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.32307/0.42992. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.32381/0.42617. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.31698/0.42130. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.31561/0.42586. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.31396/0.42130. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.31093/0.42150. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.30463/0.41637. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.29981/0.40865. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.30150/0.41325. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.29426/0.41047. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.29532/0.41157. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.29439/0.41035. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.28937/0.40769. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.28330/0.40488. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.27613/0.41421. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.27525/0.40793. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.27276/0.40975. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.27392/0.39901. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.27069/0.40595. Took 0.15 sec\n",
      "Epoch 27, Loss(train/val) 0.26926/0.41818. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.27000/0.42211. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.26640/0.42130. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.25891/0.42003. Took 0.13 sec\n",
      "Epoch 31, Loss(train/val) 0.26260/0.41369. Took 0.13 sec\n",
      "Epoch 32, Loss(train/val) 0.25827/0.41781. Took 0.13 sec\n",
      "Epoch 33, Loss(train/val) 0.25255/0.40914. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.25149/0.41570. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.24325/0.39172. Took 0.13 sec\n",
      "Epoch 36, Loss(train/val) 0.24136/0.40092. Took 0.13 sec\n",
      "Epoch 37, Loss(train/val) 0.24135/0.38592. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.24289/0.39128. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.23090/0.39096. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.23367/0.39552. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.23096/0.38979. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.23433/0.37675. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.22176/0.39355. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.21675/0.39462. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.22011/0.39904. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.21308/0.38729. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.21157/0.37471. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.21463/0.38071. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.20294/0.39201. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.19963/0.38798. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.20142/0.38745. Took 0.12 sec\n",
      "Epoch 52, Loss(train/val) 0.19611/0.40351. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.19711/0.40916. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.19587/0.40148. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.18380/0.40646. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.19352/0.38727. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.19128/0.39421. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.18707/0.42190. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.19050/0.39775. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.17833/0.39512. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.17853/0.40172. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.18155/0.41218. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.16871/0.38944. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.17628/0.38862. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.16941/0.40701. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.17971/0.40671. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.17033/0.40143. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.15945/0.39972. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.16366/0.40391. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.15687/0.40852. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.15804/0.39561. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.14969/0.39063. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.15548/0.39788. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.14585/0.39770. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.15419/0.41547. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.14251/0.40253. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.14548/0.40197. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.13832/0.38438. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.14802/0.37270. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.15181/0.38097. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.13865/0.37986. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.13384/0.38374. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) 0.12882/0.40632. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.13181/0.40100. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.13377/0.39947. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.12940/0.36284. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.13867/0.40505. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.12647/0.40813. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.12088/0.39736. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.12960/0.39668. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.13062/0.35621. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.12474/0.38655. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.12286/0.36754. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.12036/0.37913. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.11798/0.40497. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.11779/0.38236. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.12683/0.40212. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.12016/0.38170. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.12208/0.37166. Took 0.13 sec\n",
      "ACC: 0.625, MCC: 0.25\n",
      "Epoch 0, Loss(train/val) 0.48736/0.48373. Took 0.34 sec\n",
      "Epoch 1, Loss(train/val) 0.45289/0.45057. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.41023/0.40175. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.37220/0.36882. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.35226/0.35242. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.33611/0.34231. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.32983/0.35596. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.32821/0.34831. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.32207/0.34816. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.31563/0.35618. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.31520/0.35073. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.30578/0.36060. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.30695/0.34491. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.29507/0.34837. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.28583/0.34628. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.28838/0.35507. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.27946/0.35146. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.27252/0.35373. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.27413/0.34855. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.26555/0.34904. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.26494/0.34322. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.25883/0.34590. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.26103/0.34117. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.24814/0.33910. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.24443/0.30799. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.24480/0.34257. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.24252/0.33723. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.23817/0.32266. Took 0.13 sec\n",
      "Epoch 28, Loss(train/val) 0.22913/0.32061. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.22337/0.31886. Took 0.13 sec\n",
      "Epoch 30, Loss(train/val) 0.22711/0.30706. Took 0.13 sec\n",
      "Epoch 31, Loss(train/val) 0.22673/0.31773. Took 0.13 sec\n",
      "Epoch 32, Loss(train/val) 0.22459/0.30534. Took 0.13 sec\n",
      "Epoch 33, Loss(train/val) 0.21942/0.30572. Took 0.13 sec\n",
      "Epoch 34, Loss(train/val) 0.21828/0.32020. Took 0.13 sec\n",
      "Epoch 35, Loss(train/val) 0.21942/0.34213. Took 0.13 sec\n",
      "Epoch 36, Loss(train/val) 0.20816/0.30582. Took 0.13 sec\n",
      "Epoch 37, Loss(train/val) 0.20989/0.31373. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.21446/0.31544. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.21113/0.31209. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.20840/0.30243. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.20001/0.30883. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.19683/0.31813. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.20017/0.33489. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.20177/0.32259. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.19787/0.30461. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.19414/0.32340. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.19196/0.32281. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.19017/0.32802. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.19077/0.29908. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.18733/0.32197. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.18196/0.34198. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.18436/0.31721. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.17756/0.33396. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.18205/0.33330. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.17536/0.32941. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.18083/0.33125. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.16923/0.33683. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.16944/0.34285. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.17359/0.32907. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.17431/0.35944. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.16274/0.33825. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.16360/0.32814. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.16315/0.32982. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.16161/0.35059. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.16792/0.33418. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.16143/0.32946. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.16014/0.34596. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.15859/0.34627. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.15544/0.33443. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.15115/0.34789. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.15601/0.33986. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.15546/0.33940. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.14867/0.33718. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.15285/0.32906. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.15463/0.32228. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.14848/0.32461. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.15065/0.33253. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.15010/0.33177. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.15128/0.33430. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.14631/0.33065. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.13746/0.33763. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.14550/0.33253. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.14371/0.32812. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.13875/0.32068. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.14087/0.31033. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.13746/0.32017. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.13514/0.33557. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.13756/0.33024. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.13526/0.32746. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.14060/0.31204. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.14879/0.31478. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.13937/0.33433. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.13682/0.32340. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.13352/0.31081. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.13013/0.32351. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.13614/0.32237. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.13146/0.31992. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.13656/0.30309. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.13447/0.34676. Took 0.13 sec\n",
      "ACC: 0.703125, MCC: 0.33797354331116836\n",
      "Epoch 0, Loss(train/val) 0.49323/0.50867. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.47174/0.51559. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.44076/0.50026. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.41317/0.48055. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.39545/0.47387. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.38168/0.45354. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.37002/0.43722. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.36596/0.42214. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.34935/0.41504. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.34861/0.39786. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.34306/0.39680. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.33522/0.37301. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.35412/0.35033. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.33538/0.35602. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.34037/0.35935. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.32464/0.36844. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.30885/0.34968. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.30212/0.36257. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.30107/0.32815. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.29176/0.34246. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.29370/0.32533. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.28692/0.38698. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.28462/0.32065. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.28717/0.34843. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.27343/0.33551. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.27957/0.31979. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.26960/0.31294. Took 0.13 sec\n",
      "Epoch 27, Loss(train/val) 0.27299/0.36622. Took 0.13 sec\n",
      "Epoch 28, Loss(train/val) 0.26578/0.32697. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.26896/0.33151. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.25812/0.31426. Took 0.13 sec\n",
      "Epoch 31, Loss(train/val) 0.26117/0.32698. Took 0.13 sec\n",
      "Epoch 32, Loss(train/val) 0.27393/0.28550. Took 0.13 sec\n",
      "Epoch 33, Loss(train/val) 0.25158/0.29486. Took 0.13 sec\n",
      "Epoch 34, Loss(train/val) 0.24813/0.32645. Took 0.13 sec\n",
      "Epoch 35, Loss(train/val) 0.25458/0.30756. Took 0.13 sec\n",
      "Epoch 36, Loss(train/val) 0.25330/0.32148. Took 0.13 sec\n",
      "Epoch 37, Loss(train/val) 0.24782/0.31533. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.25573/0.30765. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.24961/0.29844. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.24196/0.33347. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.24559/0.29146. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.24602/0.32265. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.24512/0.31816. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.24484/0.34702. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) 0.25107/0.26524. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.23723/0.29424. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.23206/0.31322. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.22517/0.30102. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.22987/0.30457. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.23246/0.29348. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.23145/0.27861. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.22615/0.31095. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.22670/0.32865. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.22852/0.31062. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.21845/0.28888. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.22122/0.27681. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.21235/0.31997. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.21467/0.28194. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.21369/0.31099. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.21029/0.31038. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.20966/0.32099. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.21120/0.32884. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.20351/0.29628. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.20712/0.33597. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.20956/0.32504. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.19896/0.31882. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.19800/0.32555. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.19875/0.31434. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.18984/0.31776. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.19868/0.31716. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.20334/0.32728. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.19375/0.31777. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.19443/0.30667. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.18706/0.33644. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.18912/0.29971. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.19133/0.30586. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.18873/0.31817. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.19034/0.30804. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.18616/0.32036. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.18068/0.33590. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.18214/0.33242. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.17206/0.32747. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.17390/0.32138. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.16749/0.32169. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.17701/0.30895. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.16687/0.30873. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.16915/0.32615. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.16480/0.31093. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.16420/0.31509. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.15973/0.29768. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.16022/0.30542. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.15649/0.29538. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.15383/0.29606. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.15570/0.30793. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.15738/0.31083. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.15457/0.31991. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.15385/0.29794. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.15773/0.29090. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.16052/0.29015. Took 0.13 sec\n",
      "ACC: 0.59375, MCC: 0.38917006582288083\n",
      "Epoch 0, Loss(train/val) 0.49187/0.46257. Took 0.13 sec\n",
      "Epoch 1, Loss(train/val) 0.47269/0.42286. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.44148/0.38753. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.41370/0.36678. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.39262/0.34108. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.37244/0.33372. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.35931/0.33925. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.34544/0.33777. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.34607/0.34952. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.34013/0.33750. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.32364/0.31658. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.32781/0.32631. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.30810/0.33641. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.31285/0.31152. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.30049/0.31634. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.29882/0.31048. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.29828/0.32268. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.30941/0.30696. Took 0.16 sec\n",
      "Epoch 18, Loss(train/val) 0.29062/0.31339. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.28933/0.31043. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.29234/0.30374. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.27289/0.32366. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.27910/0.29887. Took 0.16 sec\n",
      "Epoch 23, Loss(train/val) 0.28278/0.28901. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.28148/0.27956. Took 0.16 sec\n",
      "Epoch 25, Loss(train/val) 0.27436/0.28674. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.26341/0.27106. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.25656/0.30139. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.26382/0.28363. Took 0.16 sec\n",
      "Epoch 29, Loss(train/val) 0.26694/0.29781. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.27527/0.29322. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.26504/0.28409. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.25722/0.29992. Took 0.13 sec\n",
      "Epoch 33, Loss(train/val) 0.25291/0.26894. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.25227/0.24766. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.24904/0.27561. Took 0.13 sec\n",
      "Epoch 36, Loss(train/val) 0.24578/0.26075. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.24024/0.28337. Took 0.16 sec\n",
      "Epoch 38, Loss(train/val) 0.25602/0.26220. Took 0.16 sec\n",
      "Epoch 39, Loss(train/val) 0.24072/0.28261. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.23888/0.33733. Took 0.15 sec\n",
      "Epoch 41, Loss(train/val) 0.24325/0.29711. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.23624/0.33426. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.23517/0.29110. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.23144/0.31256. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.23750/0.30393. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.23185/0.27067. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.22856/0.27790. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.22095/0.25025. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.21678/0.32945. Took 0.15 sec\n",
      "Epoch 50, Loss(train/val) 0.23419/0.25485. Took 0.15 sec\n",
      "Epoch 51, Loss(train/val) 0.23077/0.25128. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.21741/0.25659. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.21660/0.26398. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.21604/0.24460. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.22097/0.25367. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.22136/0.25633. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.22109/0.25980. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.22083/0.26422. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.21180/0.26774. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.20874/0.26148. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.21497/0.23786. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.21012/0.25642. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.21668/0.25190. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.20829/0.25924. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.20934/0.24593. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.20727/0.29793. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.19872/0.25998. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.20715/0.28574. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.20170/0.29246. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.20250/0.26718. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.20096/0.25552. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.20157/0.31364. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.20124/0.30609. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.20059/0.30613. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.20393/0.28821. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.19762/0.24697. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.18348/0.23972. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.19504/0.24536. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.18010/0.24008. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.19136/0.23647. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.20210/0.26632. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.18664/0.23835. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.19017/0.24152. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.19125/0.25921. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.19268/0.24907. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.19666/0.25100. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.18236/0.29828. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.18169/0.24442. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.18964/0.24205. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.17891/0.28133. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.17892/0.22174. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.17483/0.27140. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.17968/0.27771. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.18530/0.22787. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.17647/0.28263. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.17871/0.22759. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.18010/0.34464. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.18037/0.23445. Took 0.14 sec\n",
      "Epoch 99, Loss(train/val) 0.17488/0.24947. Took 0.13 sec\n",
      "ACC: 0.78125, MCC: 0.595610304631208\n",
      "Epoch 0, Loss(train/val) 0.49717/0.48622. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.48257/0.45977. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.45602/0.41832. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.42144/0.38587. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.40053/0.37259. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.38113/0.35532. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.37491/0.33998. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.35758/0.35061. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.34718/0.34484. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.34179/0.34522. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.32400/0.33924. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.31367/0.32634. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.31332/0.31496. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.29820/0.31211. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.28845/0.31597. Took 0.15 sec\n",
      "Epoch 15, Loss(train/val) 0.29272/0.35745. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.28656/0.29677. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.27580/0.32318. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.27989/0.31739. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.28446/0.29762. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.27030/0.28385. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.26936/0.30220. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.27779/0.27600. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.25738/0.27654. Took 0.16 sec\n",
      "Epoch 24, Loss(train/val) 0.25652/0.25946. Took 0.16 sec\n",
      "Epoch 25, Loss(train/val) 0.25010/0.26272. Took 0.16 sec\n",
      "Epoch 26, Loss(train/val) 0.25785/0.27940. Took 0.18 sec\n",
      "Epoch 27, Loss(train/val) 0.25457/0.28239. Took 0.17 sec\n",
      "Epoch 28, Loss(train/val) 0.25640/0.26420. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.25329/0.27040. Took 0.16 sec\n",
      "Epoch 30, Loss(train/val) 0.23600/0.25343. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.23953/0.28625. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.24486/0.29013. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.23982/0.29089. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.23570/0.30111. Took 0.16 sec\n",
      "Epoch 35, Loss(train/val) 0.23532/0.31371. Took 0.17 sec\n",
      "Epoch 36, Loss(train/val) 0.23492/0.28948. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.23131/0.30542. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.21903/0.30193. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.22352/0.30379. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.21471/0.29951. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.22689/0.31613. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.21735/0.30011. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.22290/0.27664. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.21152/0.28636. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.20504/0.30108. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.21079/0.28976. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.20932/0.31320. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.20166/0.28807. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.20561/0.31591. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.19857/0.30505. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.20526/0.29231. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.19372/0.28850. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.19505/0.29305. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.19635/0.30970. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.18411/0.27497. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.18768/0.32377. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.19207/0.33197. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.17761/0.31375. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.18550/0.31811. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.17188/0.30199. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.17776/0.31981. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.17652/0.33225. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.17357/0.31539. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.17251/0.31167. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.16257/0.34007. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.17537/0.28188. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.16513/0.31204. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.16786/0.31739. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.17041/0.29411. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.16299/0.29942. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.17266/0.28738. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.15784/0.30329. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.15801/0.27778. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.17286/0.37637. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.16372/0.35616. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.15368/0.33383. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.15265/0.29108. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.13676/0.29853. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.14524/0.31889. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.14883/0.28236. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.15123/0.32021. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.14974/0.27860. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) 0.14973/0.28725. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.13615/0.28360. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.13271/0.28440. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.13628/0.34906. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.13738/0.34218. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.13922/0.28117. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.12595/0.31373. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.13092/0.30009. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.13240/0.29680. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.13070/0.31947. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.13703/0.33341. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.13207/0.29319. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.14556/0.32111. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.12494/0.32632. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.12967/0.28933. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.12599/0.33287. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.12671/0.33252. Took 0.13 sec\n",
      "ACC: 0.671875, MCC: 0.33613646607466174\n",
      "Epoch 0, Loss(train/val) 0.49373/0.48353. Took 0.13 sec\n",
      "Epoch 1, Loss(train/val) 0.47645/0.44927. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.44587/0.39413. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.41488/0.37060. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.40318/0.36890. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.38732/0.36473. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.37654/0.36168. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.36231/0.34645. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.35316/0.34216. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.34263/0.34872. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.32469/0.35767. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.32079/0.35865. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.32348/0.29080. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.31162/0.27870. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.31002/0.25944. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.30433/0.32628. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.30400/0.25799. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.30266/0.27395. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.29198/0.23608. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.27553/0.23281. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.27230/0.28761. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.27012/0.29158. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.26598/0.27230. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.26526/0.31270. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.26479/0.29170. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.25336/0.28704. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.25515/0.30895. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.25350/0.30647. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.24371/0.36516. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.24516/0.30190. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.23700/0.32140. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.23057/0.32600. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.24632/0.31552. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.23366/0.31647. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.22117/0.32501. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.21786/0.30721. Took 0.13 sec\n",
      "Epoch 36, Loss(train/val) 0.22413/0.33365. Took 0.13 sec\n",
      "Epoch 37, Loss(train/val) 0.21927/0.29072. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.21402/0.33255. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.21441/0.31231. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.20832/0.31434. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.20884/0.30673. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.21148/0.30413. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.21801/0.31512. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.21041/0.29180. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.20200/0.28395. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.20098/0.29497. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.20302/0.31317. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.19501/0.29228. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.20879/0.25316. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.21469/0.32159. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.19693/0.28845. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.18538/0.29380. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.17753/0.29455. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.19925/0.28151. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.18412/0.30773. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.18307/0.28718. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.18339/0.28569. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.17964/0.31590. Took 0.15 sec\n",
      "Epoch 59, Loss(train/val) 0.17593/0.32225. Took 0.15 sec\n",
      "Epoch 60, Loss(train/val) 0.17036/0.31083. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.17372/0.31333. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.17517/0.28152. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.17021/0.28611. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.16186/0.33126. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.17611/0.32718. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.16634/0.33424. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.16936/0.31977. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.17621/0.34211. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.17430/0.31682. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.16644/0.32559. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.15834/0.36880. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.16330/0.34768. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.15838/0.34089. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.15309/0.31474. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.15683/0.33797. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.16132/0.31345. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.16573/0.34597. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.15839/0.31285. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.15658/0.33660. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.15733/0.36379. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.15901/0.36516. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.15721/0.34133. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) 0.15191/0.36941. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.15293/0.32814. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.14654/0.37895. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.13805/0.32780. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.14607/0.33003. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.14634/0.32509. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.14366/0.32637. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.13800/0.32341. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.14337/0.32445. Took 0.12 sec\n",
      "Epoch 92, Loss(train/val) 0.13760/0.34988. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.13529/0.35274. Took 0.12 sec\n",
      "Epoch 94, Loss(train/val) 0.13749/0.33435. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.13733/0.36081. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.13274/0.33794. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.13167/0.33498. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.12570/0.29874. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.13240/0.33551. Took 0.13 sec\n",
      "ACC: 0.53125, MCC: 0.2537340189666186\n",
      "Epoch 0, Loss(train/val) 0.49338/0.46582. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.47237/0.40877. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.43966/0.34934. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.41221/0.33234. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.39792/0.32751. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.38828/0.31972. Took 0.12 sec\n",
      "Epoch 6, Loss(train/val) 0.37473/0.30574. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.36408/0.29700. Took 0.12 sec\n",
      "Epoch 8, Loss(train/val) 0.34846/0.31017. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.34147/0.28589. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.32328/0.29521. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.31630/0.39271. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.31075/0.34717. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.28647/0.37565. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.28421/0.31022. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.28737/0.31901. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.29918/0.27784. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.28898/0.36756. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.27774/0.32726. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.27049/0.34161. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.26812/0.28438. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.25910/0.36831. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.27259/0.29861. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.27275/0.32882. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.26216/0.32978. Took 0.15 sec\n",
      "Epoch 25, Loss(train/val) 0.26516/0.30844. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.24798/0.31263. Took 0.15 sec\n",
      "Epoch 27, Loss(train/val) 0.25656/0.34998. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.25697/0.31581. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.24864/0.35014. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.25382/0.34933. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.23889/0.32043. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.23853/0.30446. Took 0.16 sec\n",
      "Epoch 33, Loss(train/val) 0.23420/0.34467. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.24079/0.34691. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.25371/0.34490. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.24935/0.34067. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.23526/0.30108. Took 0.15 sec\n",
      "Epoch 38, Loss(train/val) 0.23394/0.33206. Took 0.15 sec\n",
      "Epoch 39, Loss(train/val) 0.23567/0.33923. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.22713/0.33374. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.23001/0.32593. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.22355/0.31527. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.21885/0.32777. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.21561/0.34216. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.21220/0.35736. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.22559/0.31043. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.22196/0.35690. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.21850/0.33779. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.21873/0.30554. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.21386/0.37329. Took 0.14 sec\n",
      "Epoch 51, Loss(train/val) 0.21352/0.34497. Took 0.16 sec\n",
      "Epoch 52, Loss(train/val) 0.21193/0.33351. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.20907/0.37049. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.20354/0.37432. Took 0.15 sec\n",
      "Epoch 55, Loss(train/val) 0.21864/0.33322. Took 0.15 sec\n",
      "Epoch 56, Loss(train/val) 0.21219/0.35061. Took 0.15 sec\n",
      "Epoch 57, Loss(train/val) 0.19779/0.35280. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.19759/0.35564. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.18657/0.36770. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.20356/0.37168. Took 0.14 sec\n",
      "Epoch 61, Loss(train/val) 0.20131/0.34728. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.18701/0.34610. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.18891/0.34263. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.19609/0.36499. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.18252/0.35356. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.18987/0.35631. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.18470/0.37995. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.18445/0.37368. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.18110/0.36122. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.17629/0.35883. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.17122/0.40557. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.17749/0.37264. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.17427/0.37145. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.17556/0.39887. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.17000/0.38150. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.17503/0.39705. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.17519/0.39373. Took 0.12 sec\n",
      "Epoch 78, Loss(train/val) 0.17235/0.38781. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.16602/0.39820. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.16865/0.37031. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.17080/0.39243. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.17634/0.35658. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.16768/0.37673. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.17122/0.43013. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.16704/0.40876. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.14790/0.42704. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.15624/0.43100. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.16851/0.35873. Took 0.15 sec\n",
      "Epoch 89, Loss(train/val) 0.16492/0.40792. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.15682/0.38502. Took 0.14 sec\n",
      "Epoch 91, Loss(train/val) 0.16004/0.39802. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.16288/0.41102. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.15398/0.40465. Took 0.15 sec\n",
      "Epoch 94, Loss(train/val) 0.15292/0.40809. Took 0.14 sec\n",
      "Epoch 95, Loss(train/val) 0.16573/0.40025. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.15853/0.39996. Took 0.14 sec\n",
      "Epoch 97, Loss(train/val) 0.16344/0.39837. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.15321/0.39388. Took 0.14 sec\n",
      "Epoch 99, Loss(train/val) 0.14833/0.42475. Took 0.13 sec\n",
      "ACC: 0.671875, MCC: 0.4231456565780868\n",
      "Epoch 0, Loss(train/val) 0.49150/0.47528. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.46827/0.42639. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.43099/0.37091. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.39843/0.34307. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.38601/0.33528. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.37678/0.32030. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.37166/0.33399. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.36344/0.31953. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.34869/0.31695. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.33582/0.31875. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.33379/0.34435. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.32211/0.29096. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.32261/0.29882. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.29484/0.39010. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.29973/0.31206. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.27758/0.38147. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.29646/0.32717. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.28069/0.32339. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.27652/0.35432. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.27177/0.32772. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.26526/0.32457. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.26061/0.40994. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.26567/0.36117. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.26454/0.35601. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.26507/0.31679. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.26748/0.38216. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.25994/0.34259. Took 0.15 sec\n",
      "Epoch 27, Loss(train/val) 0.25261/0.34799. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.24798/0.35746. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.23509/0.33235. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.25492/0.31711. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.24254/0.31985. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.24263/0.36108. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.23861/0.30703. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.24569/0.35026. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.23867/0.35078. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.22511/0.33445. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.22199/0.32624. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.22299/0.34838. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.21936/0.35042. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.22442/0.33967. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.21292/0.36218. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.22221/0.34219. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.21430/0.34833. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.21291/0.35862. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.21823/0.35990. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.21281/0.36531. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.21627/0.35802. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.21567/0.32871. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.21134/0.32736. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.20232/0.34263. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.19496/0.33599. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.20787/0.33267. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.19855/0.36668. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.19555/0.35426. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.19242/0.35994. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.19972/0.36061. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.19393/0.38175. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.19528/0.31677. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.19419/0.37328. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.19193/0.34985. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.18496/0.37953. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.18864/0.34892. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.17057/0.37808. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.17920/0.36476. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.17711/0.38942. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.17216/0.34914. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.17711/0.38008. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.17965/0.36622. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.17642/0.35996. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.17437/0.36399. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.17803/0.37448. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.17678/0.33410. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.17447/0.37078. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.17580/0.37962. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.15812/0.38649. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.17090/0.34805. Took 0.17 sec\n",
      "Epoch 77, Loss(train/val) 0.17201/0.37539. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.17326/0.37328. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.16128/0.35575. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.16664/0.33555. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.16990/0.33683. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.16731/0.33710. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) 0.15767/0.36184. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.16517/0.39490. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.16766/0.32889. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.17379/0.32732. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.16686/0.36184. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.16471/0.30639. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.15610/0.37864. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.15829/0.35066. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.16140/0.32401. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.17251/0.36804. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.15800/0.29401. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.15254/0.32762. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.15278/0.33220. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.14775/0.34652. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.15000/0.33194. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.15630/0.35295. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.14479/0.31966. Took 0.13 sec\n",
      "ACC: 0.6875, MCC: 0.3649046088126948\n",
      "Epoch 0, Loss(train/val) 0.49062/0.47878. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.46771/0.43775. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.43015/0.38838. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.39574/0.37970. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.37703/0.36593. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.35734/0.35381. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.34874/0.33855. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.34466/0.33960. Took 0.16 sec\n",
      "Epoch 8, Loss(train/val) 0.33676/0.31329. Took 0.15 sec\n",
      "Epoch 9, Loss(train/val) 0.32919/0.31589. Took 0.15 sec\n",
      "Epoch 10, Loss(train/val) 0.32105/0.31302. Took 0.18 sec\n",
      "Epoch 11, Loss(train/val) 0.31505/0.30529. Took 0.19 sec\n",
      "Epoch 12, Loss(train/val) 0.31480/0.31082. Took 0.17 sec\n",
      "Epoch 13, Loss(train/val) 0.30183/0.30679. Took 0.16 sec\n",
      "Epoch 14, Loss(train/val) 0.31687/0.32761. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.30892/0.31466. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.29610/0.31239. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.29089/0.30575. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.28755/0.30634. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.28838/0.30664. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.28654/0.30920. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.27897/0.32699. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.27833/0.29663. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.28518/0.30796. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.27739/0.34798. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.27131/0.31487. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.26242/0.30741. Took 0.15 sec\n",
      "Epoch 27, Loss(train/val) 0.26748/0.33321. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.27978/0.33869. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.29133/0.33394. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.27979/0.30436. Took 0.16 sec\n",
      "Epoch 31, Loss(train/val) 0.26828/0.31244. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.25072/0.31748. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.25155/0.33202. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.25488/0.32684. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.24983/0.34724. Took 0.15 sec\n",
      "Epoch 36, Loss(train/val) 0.25021/0.34263. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.24194/0.32495. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.24643/0.34878. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.24026/0.32095. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.23659/0.32236. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.23510/0.34433. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.23276/0.31498. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.23147/0.34114. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.23315/0.34235. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.22871/0.33963. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.22267/0.33132. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.22259/0.34899. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.21719/0.34264. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.21360/0.35571. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.22690/0.33094. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.22344/0.34602. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.21402/0.36529. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.21623/0.34663. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.22834/0.33434. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.21750/0.34765. Took 0.12 sec\n",
      "Epoch 56, Loss(train/val) 0.21725/0.33768. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.22131/0.34158. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.21698/0.32296. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.20532/0.34637. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.20183/0.34351. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.21095/0.33037. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.19875/0.34266. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.20421/0.32939. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.20318/0.33460. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.19380/0.32256. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.19546/0.31931. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.19528/0.31193. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.19026/0.32803. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.19302/0.34717. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.21381/0.35801. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.19584/0.34679. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.20599/0.33766. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.19559/0.35136. Took 0.12 sec\n",
      "Epoch 74, Loss(train/val) 0.19320/0.35323. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.18612/0.34474. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.18527/0.35303. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.18916/0.32932. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.19789/0.33581. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.18794/0.32032. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.18440/0.33588. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.18412/0.33604. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.18258/0.29923. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.18398/0.33182. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.17386/0.31237. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.17936/0.30273. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.19186/0.31675. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.18081/0.30616. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.19553/0.32100. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.20129/0.28699. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.18103/0.32342. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.17460/0.32938. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.17080/0.29190. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.18473/0.27651. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.18657/0.29901. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.16645/0.30795. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.17263/0.28266. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.17191/0.30726. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.17102/0.29913. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.16954/0.30700. Took 0.13 sec\n",
      "ACC: 0.578125, MCC: 0.22529024816220128\n",
      "Epoch 0, Loss(train/val) 0.49364/0.48976. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.47171/0.46549. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.43736/0.43478. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.40473/0.41796. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.38092/0.41198. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.36707/0.40666. Took 0.15 sec\n",
      "Epoch 6, Loss(train/val) 0.35242/0.40389. Took 0.15 sec\n",
      "Epoch 7, Loss(train/val) 0.34338/0.40454. Took 0.15 sec\n",
      "Epoch 8, Loss(train/val) 0.32824/0.38629. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.32677/0.38887. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.31225/0.35332. Took 0.15 sec\n",
      "Epoch 11, Loss(train/val) 0.32010/0.35674. Took 0.15 sec\n",
      "Epoch 12, Loss(train/val) 0.30315/0.41057. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.31591/0.36354. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.30748/0.36328. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.30660/0.39518. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.30994/0.38814. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.29147/0.35645. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.27614/0.35924. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.28892/0.38408. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.28287/0.38488. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.25854/0.38215. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.25822/0.36515. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.25785/0.35818. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.25371/0.37611. Took 0.15 sec\n",
      "Epoch 25, Loss(train/val) 0.25032/0.38077. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.24733/0.39027. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.24005/0.34690. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.24138/0.35827. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.23597/0.38096. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.23748/0.39140. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.23284/0.38727. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.23081/0.38344. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.23078/0.39027. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.22085/0.38617. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.22426/0.36880. Took 0.13 sec\n",
      "Epoch 36, Loss(train/val) 0.23117/0.37037. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.23007/0.40147. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.22623/0.42445. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.22544/0.38305. Took 0.12 sec\n",
      "Epoch 40, Loss(train/val) 0.21230/0.39092. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.21524/0.41026. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.21380/0.41257. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.20533/0.39323. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.21039/0.42993. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.20948/0.36963. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.21015/0.39262. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.20902/0.41860. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.20159/0.39747. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.20069/0.41175. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.20588/0.40615. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.18839/0.40191. Took 0.12 sec\n",
      "Epoch 52, Loss(train/val) 0.19281/0.39098. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.18731/0.40113. Took 0.12 sec\n",
      "Epoch 54, Loss(train/val) 0.18469/0.39990. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.19556/0.39986. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.17877/0.40163. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.17752/0.39841. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.18369/0.40671. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.19352/0.42959. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.19467/0.39956. Took 0.14 sec\n",
      "Epoch 61, Loss(train/val) 0.17945/0.40142. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.17479/0.41799. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.17338/0.40440. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.17437/0.40327. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.16897/0.41083. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.17540/0.38971. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.17322/0.39684. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.17099/0.40594. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.18234/0.41462. Took 0.12 sec\n",
      "Epoch 70, Loss(train/val) 0.16706/0.42374. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.15770/0.42975. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.15847/0.43012. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.15662/0.41980. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.15712/0.43447. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.15864/0.41321. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.15622/0.40643. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.16064/0.41028. Took 0.12 sec\n",
      "Epoch 78, Loss(train/val) 0.16108/0.42796. Took 0.12 sec\n",
      "Epoch 79, Loss(train/val) 0.15782/0.41695. Took 0.12 sec\n",
      "Epoch 80, Loss(train/val) 0.15557/0.42219. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.15695/0.41255. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.14871/0.41528. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.14564/0.42192. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.14865/0.39273. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.14075/0.40168. Took 0.12 sec\n",
      "Epoch 86, Loss(train/val) 0.14485/0.40828. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.14748/0.39214. Took 0.12 sec\n",
      "Epoch 88, Loss(train/val) 0.14803/0.41519. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.14390/0.40932. Took 0.12 sec\n",
      "Epoch 90, Loss(train/val) 0.14913/0.40890. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.14166/0.38325. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.13982/0.42327. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.14703/0.39927. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.13938/0.40328. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.13854/0.42484. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.14444/0.40809. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.13673/0.41422. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.13748/0.42086. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.13635/0.40814. Took 0.13 sec\n",
      "ACC: 0.640625, MCC: 0.26744549649612553\n",
      "Epoch 0, Loss(train/val) 0.49370/0.49104. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.47217/0.48223. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.43732/0.47711. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.40526/0.46786. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.38739/0.45523. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.37348/0.45073. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.36352/0.44391. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.35661/0.43967. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.34297/0.42744. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.33800/0.41824. Took 0.15 sec\n",
      "Epoch 10, Loss(train/val) 0.33091/0.41473. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.32183/0.39210. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.31479/0.36334. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.30620/0.37524. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.30304/0.36897. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.29373/0.37452. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.27740/0.35380. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.27591/0.37712. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.26973/0.37122. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.26980/0.34382. Took 0.15 sec\n",
      "Epoch 20, Loss(train/val) 0.26611/0.36463. Took 0.15 sec\n",
      "Epoch 21, Loss(train/val) 0.26831/0.39133. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.26384/0.36011. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.25663/0.36667. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.25772/0.37818. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.26146/0.37875. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.24858/0.37896. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.24498/0.36146. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.24484/0.37365. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.24372/0.38768. Took 0.13 sec\n",
      "Epoch 30, Loss(train/val) 0.24346/0.37266. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.23142/0.39514. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.22162/0.38972. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.22584/0.37591. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.22714/0.36568. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.21921/0.38959. Took 0.15 sec\n",
      "Epoch 36, Loss(train/val) 0.21707/0.37219. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.22123/0.37737. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.21092/0.39394. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.20614/0.35416. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.20584/0.36233. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.21457/0.33362. Took 0.16 sec\n",
      "Epoch 42, Loss(train/val) 0.21318/0.32540. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.20438/0.34610. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.19682/0.35374. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) 0.19657/0.35017. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.18940/0.30476. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.19902/0.34275. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.19102/0.36339. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.18244/0.32748. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.19002/0.34471. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.18881/0.32402. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.17294/0.35991. Took 0.17 sec\n",
      "Epoch 53, Loss(train/val) 0.17897/0.33197. Took 0.15 sec\n",
      "Epoch 54, Loss(train/val) 0.17409/0.32586. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.17440/0.33613. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.17141/0.31191. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.17139/0.33795. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.16857/0.32315. Took 0.14 sec\n",
      "Epoch 59, Loss(train/val) 0.17680/0.33823. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.16745/0.31211. Took 0.15 sec\n",
      "Epoch 61, Loss(train/val) 0.16379/0.29616. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.16244/0.30240. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.16192/0.30935. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.16178/0.30879. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.16374/0.32340. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.15575/0.30647. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.16438/0.31434. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.16105/0.30243. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.15865/0.29900. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.15371/0.30829. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.15270/0.33065. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.14937/0.33433. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.16138/0.32927. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.16315/0.31971. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.14809/0.31323. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.14745/0.32397. Took 0.15 sec\n",
      "Epoch 77, Loss(train/val) 0.14569/0.31398. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.14305/0.30678. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.14408/0.31053. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.13688/0.31938. Took 0.14 sec\n",
      "Epoch 81, Loss(train/val) 0.14057/0.33760. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.14149/0.34315. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.13700/0.30920. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.14252/0.31873. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.13723/0.31278. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.13484/0.32032. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.13988/0.34262. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.13236/0.32716. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.14149/0.33699. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.13069/0.29119. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.13244/0.30726. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.12723/0.29689. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.13521/0.32379. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.12615/0.31941. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.12437/0.32361. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.12551/0.34744. Took 0.14 sec\n",
      "Epoch 97, Loss(train/val) 0.13748/0.32340. Took 0.16 sec\n",
      "Epoch 98, Loss(train/val) 0.12667/0.30335. Took 0.16 sec\n",
      "Epoch 99, Loss(train/val) 0.12747/0.31377. Took 0.14 sec\n",
      "ACC: 0.6875, MCC: 0.3779644730092272\n",
      "Epoch 0, Loss(train/val) 0.49510/0.47930. Took 0.16 sec\n",
      "Epoch 1, Loss(train/val) 0.47712/0.44034. Took 0.15 sec\n",
      "Epoch 2, Loss(train/val) 0.45147/0.39049. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.42200/0.34484. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.39925/0.32947. Took 0.15 sec\n",
      "Epoch 5, Loss(train/val) 0.38243/0.32980. Took 0.15 sec\n",
      "Epoch 6, Loss(train/val) 0.37045/0.32401. Took 0.15 sec\n",
      "Epoch 7, Loss(train/val) 0.35909/0.32009. Took 0.15 sec\n",
      "Epoch 8, Loss(train/val) 0.34572/0.31479. Took 0.15 sec\n",
      "Epoch 9, Loss(train/val) 0.33753/0.33209. Took 0.15 sec\n",
      "Epoch 10, Loss(train/val) 0.33656/0.34490. Took 0.17 sec\n",
      "Epoch 11, Loss(train/val) 0.32395/0.32248. Took 0.15 sec\n",
      "Epoch 12, Loss(train/val) 0.31435/0.33534. Took 0.17 sec\n",
      "Epoch 13, Loss(train/val) 0.31766/0.30455. Took 0.17 sec\n",
      "Epoch 14, Loss(train/val) 0.30438/0.32886. Took 0.15 sec\n",
      "Epoch 15, Loss(train/val) 0.29575/0.30755. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.29673/0.31998. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.29735/0.29761. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.28828/0.31814. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.28695/0.29229. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.28445/0.28512. Took 0.15 sec\n",
      "Epoch 21, Loss(train/val) 0.27607/0.30779. Took 0.19 sec\n",
      "Epoch 22, Loss(train/val) 0.26630/0.29408. Took 0.16 sec\n",
      "Epoch 23, Loss(train/val) 0.26108/0.29193. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.26962/0.31504. Took 0.15 sec\n",
      "Epoch 25, Loss(train/val) 0.26418/0.31029. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.26519/0.26904. Took 0.16 sec\n",
      "Epoch 27, Loss(train/val) 0.25048/0.28421. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.25469/0.29008. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.25333/0.28993. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.24606/0.28895. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.24392/0.28908. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.24333/0.28961. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.23586/0.27517. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.23457/0.27770. Took 0.13 sec\n",
      "Epoch 35, Loss(train/val) 0.24274/0.28329. Took 0.13 sec\n",
      "Epoch 36, Loss(train/val) 0.23430/0.30966. Took 0.12 sec\n",
      "Epoch 37, Loss(train/val) 0.23354/0.32541. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.23468/0.28880. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.22648/0.29180. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.22545/0.29508. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.21806/0.29525. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.22485/0.28608. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.21658/0.30239. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.22158/0.29454. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) 0.20956/0.33176. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.22473/0.29344. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.20854/0.28512. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.22009/0.30322. Took 0.12 sec\n",
      "Epoch 49, Loss(train/val) 0.20843/0.29172. Took 0.12 sec\n",
      "Epoch 50, Loss(train/val) 0.20413/0.30036. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.20566/0.28074. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.21146/0.27690. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.20334/0.27672. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.19771/0.28125. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.20566/0.26208. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.20994/0.27067. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.20450/0.28913. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.19847/0.30313. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.20484/0.30573. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.19933/0.31608. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.20884/0.29455. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.19211/0.29729. Took 0.12 sec\n",
      "Epoch 63, Loss(train/val) 0.18522/0.29115. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.19743/0.32660. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.19827/0.29592. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.19330/0.31705. Took 0.12 sec\n",
      "Epoch 67, Loss(train/val) 0.19991/0.29477. Took 0.12 sec\n",
      "Epoch 68, Loss(train/val) 0.19300/0.33210. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.18477/0.30753. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.18819/0.30721. Took 0.12 sec\n",
      "Epoch 71, Loss(train/val) 0.18788/0.29483. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.18606/0.30125. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.20637/0.28271. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.18045/0.29570. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.18208/0.31482. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.18582/0.29994. Took 0.12 sec\n",
      "Epoch 77, Loss(train/val) 0.20530/0.29083. Took 0.12 sec\n",
      "Epoch 78, Loss(train/val) 0.18472/0.30007. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.18316/0.29843. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.17284/0.30867. Took 0.12 sec\n",
      "Epoch 81, Loss(train/val) 0.17398/0.29258. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.17840/0.30437. Took 0.12 sec\n",
      "Epoch 83, Loss(train/val) 0.17633/0.31481. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.16826/0.31571. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.17375/0.31173. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.17178/0.30379. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.17423/0.30872. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.16591/0.30924. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.16997/0.29907. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.17105/0.30593. Took 0.12 sec\n",
      "Epoch 91, Loss(train/val) 0.16837/0.30816. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.16283/0.29488. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.16156/0.31121. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.15928/0.31590. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.16688/0.31342. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.17014/0.30870. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.15955/0.30541. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.17206/0.31780. Took 0.12 sec\n",
      "Epoch 99, Loss(train/val) 0.16351/0.31621. Took 0.13 sec\n",
      "ACC: 0.59375, MCC: 0.18029556650246306\n",
      "Epoch 0, Loss(train/val) 0.48851/0.48869. Took 0.16 sec\n",
      "Epoch 1, Loss(train/val) 0.46132/0.47201. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.43074/0.44844. Took 0.15 sec\n",
      "Epoch 3, Loss(train/val) 0.40105/0.42714. Took 0.15 sec\n",
      "Epoch 4, Loss(train/val) 0.38040/0.42329. Took 0.15 sec\n",
      "Epoch 5, Loss(train/val) 0.36611/0.42221. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.35667/0.41363. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.33958/0.39707. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.32500/0.39312. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.31917/0.38827. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.31212/0.38494. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.30160/0.38552. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.29228/0.37044. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.29439/0.35984. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.28759/0.35010. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.28940/0.37685. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.27837/0.37932. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.27786/0.38233. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.27921/0.37056. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.27190/0.37996. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.26800/0.38083. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.27468/0.40162. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.27265/0.36883. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.26274/0.41137. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.26166/0.37096. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.25401/0.37915. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.24617/0.37006. Took 0.13 sec\n",
      "Epoch 27, Loss(train/val) 0.24782/0.37338. Took 0.13 sec\n",
      "Epoch 28, Loss(train/val) 0.23203/0.37412. Took 0.13 sec\n",
      "Epoch 29, Loss(train/val) 0.23253/0.36734. Took 0.13 sec\n",
      "Epoch 30, Loss(train/val) 0.23385/0.36016. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.23960/0.37808. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.23921/0.36681. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.22813/0.38169. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.23393/0.40159. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.22237/0.38876. Took 0.13 sec\n",
      "Epoch 36, Loss(train/val) 0.22345/0.38036. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.20665/0.37698. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.21518/0.36921. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.21480/0.37507. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.20996/0.36831. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.20893/0.36788. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.20396/0.35989. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.19594/0.36862. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.18911/0.36898. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.19225/0.38162. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.19783/0.35921. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.19240/0.35670. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.19366/0.37552. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.18659/0.35730. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.19182/0.36187. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.18062/0.34992. Took 0.12 sec\n",
      "Epoch 52, Loss(train/val) 0.17560/0.35696. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.18638/0.35045. Took 0.12 sec\n",
      "Epoch 54, Loss(train/val) 0.17336/0.35407. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.17741/0.37002. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.16917/0.36629. Took 0.12 sec\n",
      "Epoch 57, Loss(train/val) 0.17039/0.35894. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.17159/0.36827. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.16997/0.38482. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.17112/0.38817. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.16847/0.37061. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.17554/0.37669. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.15825/0.38792. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.16512/0.36162. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.16730/0.36105. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.16477/0.39102. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.16398/0.40250. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.17105/0.36523. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.16141/0.36921. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.15955/0.37252. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.15500/0.37026. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.15425/0.38669. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.15277/0.39350. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.15148/0.38863. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.15247/0.39171. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.15488/0.37677. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.14793/0.37513. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.14016/0.37824. Took 0.14 sec\n",
      "Epoch 79, Loss(train/val) 0.15630/0.38271. Took 0.15 sec\n",
      "Epoch 80, Loss(train/val) 0.15888/0.39535. Took 0.14 sec\n",
      "Epoch 81, Loss(train/val) 0.15755/0.39458. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.14954/0.40151. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.14715/0.39527. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.14431/0.40044. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.14243/0.40206. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.14586/0.39768. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.15237/0.40608. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.14605/0.40455. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.13087/0.39936. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.13625/0.40143. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.13844/0.40075. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.13912/0.39919. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.13114/0.39786. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.14109/0.38811. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.13067/0.38383. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.13001/0.39333. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.13157/0.38053. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.12904/0.38991. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.12729/0.39492. Took 0.13 sec\n",
      "ACC: 0.609375, MCC: 0.21971768720102058\n",
      "Epoch 0, Loss(train/val) 0.49174/0.49802. Took 0.13 sec\n",
      "Epoch 1, Loss(train/val) 0.46807/0.49452. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.43208/0.46543. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.39681/0.42020. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.37311/0.40659. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.35755/0.38854. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.34537/0.37666. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.33012/0.37661. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.32674/0.35489. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.31451/0.34225. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.31352/0.33191. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.30325/0.36029. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.29597/0.31947. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.29451/0.35879. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.29081/0.31135. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.28540/0.32009. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.27832/0.33849. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.27635/0.35372. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.27841/0.35861. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.27314/0.34747. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.26602/0.31136. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.26645/0.34170. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.25953/0.31231. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.25930/0.30673. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.25598/0.31709. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.25711/0.30710. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.24637/0.32181. Took 0.13 sec\n",
      "Epoch 27, Loss(train/val) 0.24796/0.33278. Took 0.13 sec\n",
      "Epoch 28, Loss(train/val) 0.24855/0.31634. Took 0.13 sec\n",
      "Epoch 29, Loss(train/val) 0.23862/0.31986. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.24574/0.30375. Took 0.13 sec\n",
      "Epoch 31, Loss(train/val) 0.23924/0.33064. Took 0.13 sec\n",
      "Epoch 32, Loss(train/val) 0.23288/0.32306. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.23044/0.33920. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.22147/0.31118. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.21920/0.33416. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.21604/0.31902. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.22655/0.32707. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.22053/0.34218. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.21879/0.30148. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.21624/0.35435. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.21428/0.31425. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.20530/0.31757. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.20186/0.30931. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.20210/0.33136. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.20538/0.34623. Took 0.12 sec\n",
      "Epoch 46, Loss(train/val) 0.20267/0.31167. Took 0.12 sec\n",
      "Epoch 47, Loss(train/val) 0.20683/0.32410. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.19166/0.34142. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.18739/0.31524. Took 0.12 sec\n",
      "Epoch 50, Loss(train/val) 0.19099/0.34219. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.19506/0.31065. Took 0.12 sec\n",
      "Epoch 52, Loss(train/val) 0.19539/0.33950. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.18791/0.31192. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.19292/0.34683. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.18485/0.34036. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.18411/0.31154. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.17888/0.33580. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.18274/0.34807. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.17653/0.32618. Took 0.12 sec\n",
      "Epoch 60, Loss(train/val) 0.18133/0.35889. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.17222/0.31523. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.18727/0.30922. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.17091/0.33017. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.16722/0.29823. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.16751/0.30093. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.16289/0.28235. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.16941/0.27819. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.16542/0.28944. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.16184/0.31264. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.15528/0.33844. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.16934/0.31760. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.16015/0.34842. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.15856/0.33811. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.16197/0.32658. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.16072/0.32787. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.15513/0.34310. Took 0.12 sec\n",
      "Epoch 77, Loss(train/val) 0.15348/0.30298. Took 0.12 sec\n",
      "Epoch 78, Loss(train/val) 0.15421/0.33401. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.15120/0.34442. Took 0.12 sec\n",
      "Epoch 80, Loss(train/val) 0.15654/0.32078. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.14626/0.34189. Took 0.12 sec\n",
      "Epoch 82, Loss(train/val) 0.15384/0.33008. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.15182/0.32274. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.14759/0.36480. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.14829/0.35063. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.15306/0.33824. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.15394/0.34464. Took 0.12 sec\n",
      "Epoch 88, Loss(train/val) 0.14412/0.31941. Took 0.12 sec\n",
      "Epoch 89, Loss(train/val) 0.14797/0.32523. Took 0.12 sec\n",
      "Epoch 90, Loss(train/val) 0.14811/0.35769. Took 0.12 sec\n",
      "Epoch 91, Loss(train/val) 0.13520/0.33928. Took 0.12 sec\n",
      "Epoch 92, Loss(train/val) 0.13846/0.33672. Took 0.12 sec\n",
      "Epoch 93, Loss(train/val) 0.13794/0.34696. Took 0.12 sec\n",
      "Epoch 94, Loss(train/val) 0.14824/0.35753. Took 0.12 sec\n",
      "Epoch 95, Loss(train/val) 0.14334/0.29322. Took 0.12 sec\n",
      "Epoch 96, Loss(train/val) 0.15565/0.36763. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.15403/0.33209. Took 0.12 sec\n",
      "Epoch 98, Loss(train/val) 0.14721/0.33284. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.14332/0.35129. Took 0.13 sec\n",
      "ACC: 0.6875, MCC: 0.37081517019273486\n",
      "Epoch 0, Loss(train/val) 0.49307/0.49212. Took 0.13 sec\n",
      "Epoch 1, Loss(train/val) 0.46973/0.48135. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.43380/0.45350. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.39784/0.43855. Took 0.12 sec\n",
      "Epoch 4, Loss(train/val) 0.36998/0.40839. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.35554/0.37208. Took 0.12 sec\n",
      "Epoch 6, Loss(train/val) 0.34521/0.38125. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.33314/0.47895. Took 0.12 sec\n",
      "Epoch 8, Loss(train/val) 0.32146/0.48997. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.31484/0.48063. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.31173/0.49933. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.30633/0.49377. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.30441/0.46445. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.30223/0.46449. Took 0.12 sec\n",
      "Epoch 14, Loss(train/val) 0.29873/0.47070. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.28568/0.44100. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.27520/0.45589. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.27881/0.40820. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.27368/0.43280. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.26931/0.39992. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.26383/0.40778. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.26134/0.39212. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.25617/0.41581. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.25743/0.41945. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.24845/0.41908. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.24795/0.43269. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.24540/0.40564. Took 0.13 sec\n",
      "Epoch 27, Loss(train/val) 0.24134/0.40582. Took 0.13 sec\n",
      "Epoch 28, Loss(train/val) 0.24203/0.43426. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.24584/0.40288. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.23071/0.38907. Took 0.13 sec\n",
      "Epoch 31, Loss(train/val) 0.23537/0.38556. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.22378/0.38690. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.23473/0.40608. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.22041/0.39342. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.23184/0.39781. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.22002/0.38614. Took 0.13 sec\n",
      "Epoch 37, Loss(train/val) 0.22263/0.40269. Took 0.12 sec\n",
      "Epoch 38, Loss(train/val) 0.21716/0.39292. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.22235/0.38913. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.22671/0.37224. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.22057/0.38171. Took 0.12 sec\n",
      "Epoch 42, Loss(train/val) 0.21960/0.39579. Took 0.12 sec\n",
      "Epoch 43, Loss(train/val) 0.22838/0.39871. Took 0.12 sec\n",
      "Epoch 44, Loss(train/val) 0.21612/0.40782. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.21640/0.40743. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.20542/0.42861. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.20052/0.41690. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.20638/0.37633. Took 0.12 sec\n",
      "Epoch 49, Loss(train/val) 0.20548/0.38186. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.20078/0.39393. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.20069/0.37978. Took 0.12 sec\n",
      "Epoch 52, Loss(train/val) 0.20640/0.37169. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.20437/0.39204. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.20746/0.38937. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.20615/0.37362. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.19653/0.35645. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.19599/0.37916. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.18592/0.38200. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.18196/0.37868. Took 0.12 sec\n",
      "Epoch 60, Loss(train/val) 0.18459/0.38309. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.19305/0.35722. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.18613/0.37285. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.18244/0.36350. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.18545/0.37442. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.18662/0.37842. Took 0.12 sec\n",
      "Epoch 66, Loss(train/val) 0.17590/0.37987. Took 0.12 sec\n",
      "Epoch 67, Loss(train/val) 0.18544/0.39179. Took 0.12 sec\n",
      "Epoch 68, Loss(train/val) 0.18145/0.39113. Took 0.12 sec\n",
      "Epoch 69, Loss(train/val) 0.17853/0.37714. Took 0.12 sec\n",
      "Epoch 70, Loss(train/val) 0.17578/0.37406. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.17071/0.36959. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.18069/0.36958. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.18171/0.35668. Took 0.12 sec\n",
      "Epoch 74, Loss(train/val) 0.18448/0.36803. Took 0.12 sec\n",
      "Epoch 75, Loss(train/val) 0.16897/0.37241. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.16756/0.33980. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.16313/0.36339. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.17029/0.34278. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.16224/0.36462. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.16540/0.36583. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.16779/0.36526. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.16657/0.36529. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.16885/0.36509. Took 0.12 sec\n",
      "Epoch 84, Loss(train/val) 0.16697/0.34707. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.15483/0.36540. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.16570/0.30656. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.16334/0.36182. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.16291/0.37106. Took 0.12 sec\n",
      "Epoch 89, Loss(train/val) 0.16578/0.35788. Took 0.12 sec\n",
      "Epoch 90, Loss(train/val) 0.16807/0.38243. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.17139/0.36330. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.15121/0.36533. Took 0.12 sec\n",
      "Epoch 93, Loss(train/val) 0.15713/0.36653. Took 0.12 sec\n",
      "Epoch 94, Loss(train/val) 0.14974/0.37392. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.14712/0.36185. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.16119/0.33848. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.14757/0.34447. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.14965/0.36178. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.15177/0.35985. Took 0.13 sec\n",
      "ACC: 0.671875, MCC: 0.2893284564486454\n",
      "Epoch 0, Loss(train/val) 0.49619/0.47953. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.47613/0.43685. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.44716/0.39765. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.41255/0.37272. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.38486/0.34548. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.35960/0.31837. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.34215/0.31256. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.32994/0.30953. Took 0.12 sec\n",
      "Epoch 8, Loss(train/val) 0.31494/0.30925. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.31505/0.31445. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.30512/0.30976. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.31471/0.33132. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.29804/0.29603. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.29455/0.30984. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.30002/0.32685. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.28658/0.33213. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.28425/0.31983. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.28011/0.32826. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.27442/0.33968. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.29183/0.33058. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.27645/0.33746. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.27131/0.32773. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.26280/0.31519. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.25383/0.31652. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.25345/0.31756. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.25459/0.33792. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.24732/0.31861. Took 0.13 sec\n",
      "Epoch 27, Loss(train/val) 0.24176/0.32500. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.23694/0.30869. Took 0.13 sec\n",
      "Epoch 29, Loss(train/val) 0.24432/0.31186. Took 0.13 sec\n",
      "Epoch 30, Loss(train/val) 0.23426/0.30261. Took 0.13 sec\n",
      "Epoch 31, Loss(train/val) 0.23059/0.30782. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.22974/0.31601. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.23596/0.30724. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.23739/0.30450. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.22691/0.29336. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.22678/0.29927. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.22310/0.30517. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.22412/0.30273. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.21180/0.30629. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.21575/0.30578. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.21528/0.29950. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.21780/0.29723. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.21227/0.32018. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.20288/0.31154. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.20540/0.31192. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.20530/0.31734. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.20275/0.31949. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.20134/0.30770. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.20149/0.31426. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.19727/0.31821. Took 0.12 sec\n",
      "Epoch 51, Loss(train/val) 0.19555/0.31287. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.19243/0.31135. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.20010/0.32852. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.19286/0.31822. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.20014/0.30864. Took 0.12 sec\n",
      "Epoch 56, Loss(train/val) 0.19578/0.32918. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.19172/0.34153. Took 0.12 sec\n",
      "Epoch 58, Loss(train/val) 0.19057/0.31504. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.19659/0.32701. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.18743/0.30182. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.18177/0.30091. Took 0.12 sec\n",
      "Epoch 62, Loss(train/val) 0.17892/0.33090. Took 0.12 sec\n",
      "Epoch 63, Loss(train/val) 0.17847/0.32602. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.17905/0.30953. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.17797/0.31234. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.17273/0.30133. Took 0.12 sec\n",
      "Epoch 67, Loss(train/val) 0.17639/0.31059. Took 0.12 sec\n",
      "Epoch 68, Loss(train/val) 0.17761/0.30689. Took 0.12 sec\n",
      "Epoch 69, Loss(train/val) 0.17476/0.31557. Took 0.12 sec\n",
      "Epoch 70, Loss(train/val) 0.17910/0.31608. Took 0.12 sec\n",
      "Epoch 71, Loss(train/val) 0.18066/0.31518. Took 0.12 sec\n",
      "Epoch 72, Loss(train/val) 0.17347/0.31888. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.17233/0.31295. Took 0.12 sec\n",
      "Epoch 74, Loss(train/val) 0.16655/0.29759. Took 0.12 sec\n",
      "Epoch 75, Loss(train/val) 0.16916/0.31127. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.17168/0.30501. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.17029/0.31602. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.16132/0.30942. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.15879/0.30447. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.16166/0.31206. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.15896/0.31110. Took 0.12 sec\n",
      "Epoch 82, Loss(train/val) 0.17404/0.30304. Took 0.12 sec\n",
      "Epoch 83, Loss(train/val) 0.15985/0.32125. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.15667/0.30614. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.15913/0.32032. Took 0.12 sec\n",
      "Epoch 86, Loss(train/val) 0.15764/0.31510. Took 0.12 sec\n",
      "Epoch 87, Loss(train/val) 0.15487/0.30748. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.15943/0.31022. Took 0.12 sec\n",
      "Epoch 89, Loss(train/val) 0.15424/0.30217. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.15265/0.29928. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.15738/0.30399. Took 0.12 sec\n",
      "Epoch 92, Loss(train/val) 0.15612/0.31420. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.14917/0.32176. Took 0.12 sec\n",
      "Epoch 94, Loss(train/val) 0.15939/0.31376. Took 0.12 sec\n",
      "Epoch 95, Loss(train/val) 0.15590/0.32191. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.15196/0.33716. Took 0.12 sec\n",
      "Epoch 97, Loss(train/val) 0.15455/0.31324. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.15682/0.30821. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.15417/0.31394. Took 0.13 sec\n",
      "ACC: 0.609375, MCC: 0.24165949998852546\n",
      "Epoch 0, Loss(train/val) 0.48893/0.48991. Took 0.13 sec\n",
      "Epoch 1, Loss(train/val) 0.46448/0.46302. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.42281/0.41079. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.38764/0.38375. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.36493/0.37575. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.34711/0.36300. Took 0.12 sec\n",
      "Epoch 6, Loss(train/val) 0.33905/0.36422. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.33233/0.36966. Took 0.12 sec\n",
      "Epoch 8, Loss(train/val) 0.32231/0.35947. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.32523/0.35762. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.31796/0.35443. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.31500/0.32568. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.32313/0.34476. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.31036/0.34702. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.30958/0.33903. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.30873/0.35052. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.29903/0.32263. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.29678/0.30948. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.29733/0.33483. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.29788/0.31381. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.28310/0.30888. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.28850/0.30258. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.28429/0.32431. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.28525/0.31377. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.27416/0.35447. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.26829/0.36036. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.27666/0.34317. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.27189/0.33691. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.25930/0.36814. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.27207/0.39952. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.26257/0.39855. Took 0.13 sec\n",
      "Epoch 31, Loss(train/val) 0.26515/0.38374. Took 0.13 sec\n",
      "Epoch 32, Loss(train/val) 0.25929/0.35778. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.24959/0.36888. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.24744/0.40876. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.25330/0.38073. Took 0.13 sec\n",
      "Epoch 36, Loss(train/val) 0.25273/0.37678. Took 0.13 sec\n",
      "Epoch 37, Loss(train/val) 0.24842/0.39681. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.25132/0.39861. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.24526/0.35660. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.24227/0.39188. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.24256/0.40081. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.23619/0.37294. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.24058/0.40254. Took 0.12 sec\n",
      "Epoch 44, Loss(train/val) 0.23197/0.39852. Took 0.12 sec\n",
      "Epoch 45, Loss(train/val) 0.22978/0.38879. Took 0.12 sec\n",
      "Epoch 46, Loss(train/val) 0.22781/0.40899. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.22086/0.39301. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.23397/0.38797. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.22720/0.39987. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.22739/0.39345. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.23114/0.36335. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.22590/0.39703. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.22602/0.40258. Took 0.12 sec\n",
      "Epoch 54, Loss(train/val) 0.21344/0.39650. Took 0.12 sec\n",
      "Epoch 55, Loss(train/val) 0.21645/0.38912. Took 0.12 sec\n",
      "Epoch 56, Loss(train/val) 0.21097/0.38966. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.21293/0.39719. Took 0.12 sec\n",
      "Epoch 58, Loss(train/val) 0.21797/0.39773. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.21108/0.38605. Took 0.12 sec\n",
      "Epoch 60, Loss(train/val) 0.21164/0.38467. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.20996/0.39511. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.20654/0.39254. Took 0.12 sec\n",
      "Epoch 63, Loss(train/val) 0.20485/0.38598. Took 0.12 sec\n",
      "Epoch 64, Loss(train/val) 0.20805/0.38678. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.19973/0.39394. Took 0.12 sec\n",
      "Epoch 66, Loss(train/val) 0.20142/0.38658. Took 0.12 sec\n",
      "Epoch 67, Loss(train/val) 0.19697/0.38505. Took 0.12 sec\n",
      "Epoch 68, Loss(train/val) 0.19816/0.39830. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.19822/0.40261. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.20071/0.38151. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.20430/0.40355. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.19871/0.38814. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.19014/0.38586. Took 0.12 sec\n",
      "Epoch 74, Loss(train/val) 0.19350/0.38178. Took 0.12 sec\n",
      "Epoch 75, Loss(train/val) 0.18991/0.39043. Took 0.12 sec\n",
      "Epoch 76, Loss(train/val) 0.18798/0.40000. Took 0.12 sec\n",
      "Epoch 77, Loss(train/val) 0.19376/0.38667. Took 0.12 sec\n",
      "Epoch 78, Loss(train/val) 0.19209/0.37210. Took 0.12 sec\n",
      "Epoch 79, Loss(train/val) 0.18816/0.38272. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.18855/0.38728. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.19743/0.37889. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.19648/0.39788. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.19963/0.37162. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.18444/0.37833. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.18789/0.38167. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.18870/0.37970. Took 0.12 sec\n",
      "Epoch 87, Loss(train/val) 0.17754/0.38898. Took 0.12 sec\n",
      "Epoch 88, Loss(train/val) 0.18519/0.38538. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.18515/0.38336. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.17938/0.38551. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.17934/0.39713. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.17835/0.38304. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.16991/0.37316. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.17857/0.37342. Took 0.12 sec\n",
      "Epoch 95, Loss(train/val) 0.18398/0.36878. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.17697/0.39140. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.16910/0.37109. Took 0.12 sec\n",
      "Epoch 98, Loss(train/val) 0.17287/0.36443. Took 0.12 sec\n",
      "Epoch 99, Loss(train/val) 0.16363/0.36091. Took 0.12 sec\n",
      "ACC: 0.6875, MCC: 0.41184152944810126\n",
      "Epoch 0, Loss(train/val) 0.49167/0.47893. Took 0.13 sec\n",
      "Epoch 1, Loss(train/val) 0.46974/0.45100. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.43855/0.41440. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.40098/0.36197. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.37657/0.33374. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.36209/0.31022. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.35368/0.31746. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.33235/0.29599. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.32955/0.30914. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.32303/0.29401. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.32103/0.33623. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.31950/0.32064. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.31062/0.31622. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.30228/0.31710. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.29567/0.32633. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.30403/0.35337. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.28654/0.33569. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.28039/0.34940. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.26906/0.34422. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.26950/0.35416. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.26852/0.34901. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.26411/0.35964. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.26829/0.35432. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.26239/0.34896. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.24964/0.34206. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.24155/0.34334. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.23489/0.35578. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.24204/0.33115. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.23970/0.33801. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.22867/0.35495. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.22492/0.35967. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.22587/0.34331. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.21638/0.36311. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.22380/0.35699. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.21521/0.34907. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.21000/0.35215. Took 0.13 sec\n",
      "Epoch 36, Loss(train/val) 0.20382/0.33782. Took 0.13 sec\n",
      "Epoch 37, Loss(train/val) 0.20818/0.33131. Took 0.12 sec\n",
      "Epoch 38, Loss(train/val) 0.20753/0.36015. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.20380/0.33734. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.20421/0.35025. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.19423/0.34461. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.19719/0.33841. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.19934/0.35998. Took 0.12 sec\n",
      "Epoch 44, Loss(train/val) 0.19348/0.38412. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.19261/0.34994. Took 0.12 sec\n",
      "Epoch 46, Loss(train/val) 0.19605/0.32874. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.18614/0.34694. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.18105/0.34301. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.18925/0.36462. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.17829/0.34752. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.18145/0.35673. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.17479/0.34390. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.16912/0.33915. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.17413/0.35333. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.16751/0.35913. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.16867/0.36364. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.17442/0.34913. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.17102/0.35066. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.16700/0.36211. Took 0.12 sec\n",
      "Epoch 60, Loss(train/val) 0.17374/0.35181. Took 0.12 sec\n",
      "Epoch 61, Loss(train/val) 0.16512/0.38520. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.15864/0.36425. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.15651/0.35706. Took 0.12 sec\n",
      "Epoch 64, Loss(train/val) 0.15738/0.36207. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.15104/0.36832. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.16817/0.35377. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.15888/0.35990. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.15714/0.36140. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.16403/0.34163. Took 0.12 sec\n",
      "Epoch 70, Loss(train/val) 0.15394/0.36625. Took 0.12 sec\n",
      "Epoch 71, Loss(train/val) 0.15202/0.36574. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.15573/0.39959. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.14636/0.39025. Took 0.12 sec\n",
      "Epoch 74, Loss(train/val) 0.15155/0.36025. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.14532/0.36047. Took 0.12 sec\n",
      "Epoch 76, Loss(train/val) 0.14485/0.35784. Took 0.12 sec\n",
      "Epoch 77, Loss(train/val) 0.14268/0.36694. Took 0.12 sec\n",
      "Epoch 78, Loss(train/val) 0.14175/0.37540. Took 0.12 sec\n",
      "Epoch 79, Loss(train/val) 0.14314/0.34503. Took 0.12 sec\n",
      "Epoch 80, Loss(train/val) 0.14242/0.34519. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.14631/0.35158. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.14314/0.34711. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.14234/0.36221. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.13649/0.35364. Took 0.12 sec\n",
      "Epoch 85, Loss(train/val) 0.13938/0.35373. Took 0.12 sec\n",
      "Epoch 86, Loss(train/val) 0.14049/0.35059. Took 0.12 sec\n",
      "Epoch 87, Loss(train/val) 0.13588/0.35203. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.13185/0.35416. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.13101/0.35645. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.13031/0.36274. Took 0.14 sec\n",
      "Epoch 91, Loss(train/val) 0.13190/0.36270. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.13578/0.35618. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.12368/0.35810. Took 0.12 sec\n",
      "Epoch 94, Loss(train/val) 0.12914/0.34886. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.12615/0.35114. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.13105/0.34293. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.12560/0.34503. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.12423/0.34939. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.12893/0.35331. Took 0.13 sec\n",
      "ACC: 0.546875, MCC: 0.24913643956121992\n",
      "Epoch 0, Loss(train/val) 0.49323/0.49622. Took 0.13 sec\n",
      "Epoch 1, Loss(train/val) 0.47339/0.47658. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.44818/0.44301. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.42368/0.41333. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.40485/0.39837. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.38530/0.39931. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.37279/0.37261. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.35822/0.36673. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.34847/0.37938. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.33869/0.34865. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.33023/0.36151. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.32778/0.33096. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.32473/0.33042. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.30647/0.33625. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.30630/0.38237. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.29981/0.38193. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.29226/0.34623. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.28756/0.43148. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.28690/0.36250. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.27903/0.38274. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.27362/0.44624. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.27281/0.35630. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.26489/0.34163. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.25982/0.35022. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.25402/0.33727. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.26059/0.34579. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.25120/0.34903. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.25606/0.32869. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.25128/0.36174. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.24423/0.32971. Took 0.13 sec\n",
      "Epoch 30, Loss(train/val) 0.24238/0.33608. Took 0.13 sec\n",
      "Epoch 31, Loss(train/val) 0.24377/0.32453. Took 0.13 sec\n",
      "Epoch 32, Loss(train/val) 0.23731/0.33896. Took 0.13 sec\n",
      "Epoch 33, Loss(train/val) 0.24042/0.31090. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.23418/0.33300. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.22848/0.31670. Took 0.13 sec\n",
      "Epoch 36, Loss(train/val) 0.22388/0.32697. Took 0.13 sec\n",
      "Epoch 37, Loss(train/val) 0.21689/0.36381. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.22377/0.33306. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.20958/0.35057. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.21351/0.33662. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.21773/0.32957. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.21115/0.33071. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.20493/0.32479. Took 0.12 sec\n",
      "Epoch 44, Loss(train/val) 0.21595/0.35484. Took 0.12 sec\n",
      "Epoch 45, Loss(train/val) 0.21031/0.32486. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.19395/0.32740. Took 0.12 sec\n",
      "Epoch 47, Loss(train/val) 0.19682/0.35700. Took 0.12 sec\n",
      "Epoch 48, Loss(train/val) 0.19711/0.34552. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.19908/0.33946. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.20463/0.31366. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.19703/0.33385. Took 0.12 sec\n",
      "Epoch 52, Loss(train/val) 0.19294/0.34418. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.19088/0.31969. Took 0.12 sec\n",
      "Epoch 54, Loss(train/val) 0.17779/0.36827. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.18420/0.33172. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.18201/0.34303. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.18405/0.35872. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.17642/0.39055. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.18431/0.35602. Took 0.12 sec\n",
      "Epoch 60, Loss(train/val) 0.17141/0.35539. Took 0.12 sec\n",
      "Epoch 61, Loss(train/val) 0.18135/0.34389. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.17042/0.35023. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.16138/0.34575. Took 0.12 sec\n",
      "Epoch 64, Loss(train/val) 0.16817/0.36872. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.17695/0.36414. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.16636/0.33813. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.16370/0.33555. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.16856/0.34572. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.16858/0.33622. Took 0.12 sec\n",
      "Epoch 70, Loss(train/val) 0.16162/0.34876. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.16086/0.38811. Took 0.12 sec\n",
      "Epoch 72, Loss(train/val) 0.15286/0.35216. Took 0.12 sec\n",
      "Epoch 73, Loss(train/val) 0.15656/0.34617. Took 0.12 sec\n",
      "Epoch 74, Loss(train/val) 0.16010/0.37070. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.15576/0.37497. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.14893/0.38661. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.14353/0.37948. Took 0.12 sec\n",
      "Epoch 78, Loss(train/val) 0.15434/0.36672. Took 0.12 sec\n",
      "Epoch 79, Loss(train/val) 0.14669/0.38124. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.14342/0.37435. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.15155/0.34219. Took 0.12 sec\n",
      "Epoch 82, Loss(train/val) 0.14456/0.36181. Took 0.12 sec\n",
      "Epoch 83, Loss(train/val) 0.15458/0.35321. Took 0.12 sec\n",
      "Epoch 84, Loss(train/val) 0.15112/0.37889. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.14509/0.37629. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.14060/0.37878. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.14415/0.40931. Took 0.12 sec\n",
      "Epoch 88, Loss(train/val) 0.15673/0.36437. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.14280/0.37921. Took 0.12 sec\n",
      "Epoch 90, Loss(train/val) 0.14068/0.34760. Took 0.12 sec\n",
      "Epoch 91, Loss(train/val) 0.14367/0.38980. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.13555/0.34366. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.13949/0.39844. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.13448/0.37158. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.13961/0.34938. Took 0.12 sec\n",
      "Epoch 96, Loss(train/val) 0.13402/0.35199. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.14015/0.34909. Took 0.12 sec\n",
      "Epoch 98, Loss(train/val) 0.13367/0.40582. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.13798/0.37215. Took 0.13 sec\n",
      "ACC: 0.625, MCC: 0.24334975369458128\n",
      "Epoch 0, Loss(train/val) 0.49474/0.49764. Took 0.13 sec\n",
      "Epoch 1, Loss(train/val) 0.47481/0.48148. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.44661/0.44220. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.41341/0.40849. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.38963/0.39177. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.37134/0.35158. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.35624/0.33784. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.33429/0.33976. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.31621/0.32408. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.31416/0.30646. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.30678/0.27820. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.31083/0.30335. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.29411/0.28912. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.28811/0.30897. Took 0.12 sec\n",
      "Epoch 14, Loss(train/val) 0.28226/0.28348. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.28664/0.28587. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.27334/0.29920. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.27224/0.27864. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.27054/0.30338. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.27164/0.29058. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.26531/0.26333. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.26262/0.29537. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.26021/0.27063. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.25021/0.27534. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.24141/0.26615. Took 0.15 sec\n",
      "Epoch 25, Loss(train/val) 0.24800/0.26444. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.24280/0.27409. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.24207/0.27271. Took 0.13 sec\n",
      "Epoch 28, Loss(train/val) 0.23784/0.27797. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.22834/0.28195. Took 0.13 sec\n",
      "Epoch 30, Loss(train/val) 0.23027/0.26717. Took 0.13 sec\n",
      "Epoch 31, Loss(train/val) 0.22330/0.24468. Took 0.13 sec\n",
      "Epoch 32, Loss(train/val) 0.21684/0.28088. Took 0.13 sec\n",
      "Epoch 33, Loss(train/val) 0.23385/0.27071. Took 0.12 sec\n",
      "Epoch 34, Loss(train/val) 0.23140/0.26505. Took 0.13 sec\n",
      "Epoch 35, Loss(train/val) 0.21827/0.26260. Took 0.12 sec\n",
      "Epoch 36, Loss(train/val) 0.21709/0.30324. Took 0.13 sec\n",
      "Epoch 37, Loss(train/val) 0.21675/0.26253. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.20573/0.27516. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.20864/0.30127. Took 0.12 sec\n",
      "Epoch 40, Loss(train/val) 0.20902/0.28290. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.21445/0.25945. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.20767/0.28996. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.20811/0.29280. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.20033/0.26980. Took 0.12 sec\n",
      "Epoch 45, Loss(train/val) 0.20327/0.32580. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.19867/0.29884. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.19742/0.26681. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.19817/0.30902. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.18803/0.30756. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.18531/0.29675. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.20158/0.30218. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.20101/0.31270. Took 0.12 sec\n",
      "Epoch 53, Loss(train/val) 0.19251/0.30022. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.18508/0.29254. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.18289/0.28590. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.17492/0.28700. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.18099/0.30782. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.17563/0.33870. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.17664/0.30462. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.18266/0.31168. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.17518/0.32978. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.17352/0.32629. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.17785/0.30868. Took 0.12 sec\n",
      "Epoch 64, Loss(train/val) 0.16839/0.34601. Took 0.12 sec\n",
      "Epoch 65, Loss(train/val) 0.17687/0.33192. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.16938/0.37107. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.16780/0.31341. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.17539/0.35072. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.16286/0.29293. Took 0.12 sec\n",
      "Epoch 70, Loss(train/val) 0.16749/0.32834. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.16768/0.34019. Took 0.12 sec\n",
      "Epoch 72, Loss(train/val) 0.16586/0.29889. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.16392/0.34922. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.16305/0.33577. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.15790/0.34588. Took 0.12 sec\n",
      "Epoch 76, Loss(train/val) 0.16237/0.33478. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.15323/0.31811. Took 0.12 sec\n",
      "Epoch 78, Loss(train/val) 0.15363/0.36218. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.16274/0.34786. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.16118/0.31624. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.15305/0.33796. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.15627/0.31831. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.15550/0.39970. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.14756/0.31529. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.15365/0.35553. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.13704/0.36295. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.14929/0.35597. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.15289/0.31649. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.14718/0.31035. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.14257/0.34934. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.14665/0.40453. Took 0.12 sec\n",
      "Epoch 92, Loss(train/val) 0.15292/0.35534. Took 0.12 sec\n",
      "Epoch 93, Loss(train/val) 0.14526/0.36061. Took 0.12 sec\n",
      "Epoch 94, Loss(train/val) 0.14277/0.34216. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.13864/0.34692. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.14309/0.38710. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.14294/0.31874. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.14163/0.35319. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.14176/0.34950. Took 0.12 sec\n",
      "ACC: 0.625, MCC: 0.21162620215089678\n",
      "Epoch 0, Loss(train/val) 0.49593/0.48527. Took 0.13 sec\n",
      "Epoch 1, Loss(train/val) 0.47769/0.45389. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.44433/0.41246. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.40936/0.39093. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.39177/0.37667. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.37862/0.36502. Took 0.12 sec\n",
      "Epoch 6, Loss(train/val) 0.36742/0.35762. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.35428/0.34663. Took 0.12 sec\n",
      "Epoch 8, Loss(train/val) 0.33970/0.36108. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.31561/0.40673. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.32149/0.46442. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.29744/0.40281. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.30182/0.44354. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.30333/0.46565. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.28607/0.43239. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.30462/0.40782. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.28017/0.38147. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.29943/0.42561. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.28753/0.48187. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.28073/0.48299. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.28365/0.48516. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.28186/0.44838. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.28312/0.45781. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.28883/0.45963. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.26384/0.46666. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.27417/0.47054. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.27142/0.44427. Took 0.13 sec\n",
      "Epoch 27, Loss(train/val) 0.26370/0.42842. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.26130/0.44020. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.25059/0.44572. Took 0.13 sec\n",
      "Epoch 30, Loss(train/val) 0.26052/0.43534. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.25659/0.42011. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.24622/0.43658. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.23765/0.43545. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.25352/0.45282. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.23812/0.45383. Took 0.13 sec\n",
      "Epoch 36, Loss(train/val) 0.23614/0.45021. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.24222/0.44850. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.23623/0.46211. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.23149/0.45502. Took 0.12 sec\n",
      "Epoch 40, Loss(train/val) 0.23980/0.44592. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.23615/0.47916. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.23590/0.47603. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.24642/0.45256. Took 0.12 sec\n",
      "Epoch 44, Loss(train/val) 0.21962/0.42559. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.24497/0.44021. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.24319/0.41295. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.23915/0.43349. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.23047/0.39582. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.22885/0.43958. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.21564/0.42974. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.22098/0.43100. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.21505/0.42452. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.21218/0.44372. Took 0.12 sec\n",
      "Epoch 54, Loss(train/val) 0.21752/0.40969. Took 0.12 sec\n",
      "Epoch 55, Loss(train/val) 0.21723/0.44550. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.21301/0.42260. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.21138/0.42492. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.20294/0.44120. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.20658/0.42592. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.22855/0.42322. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.22984/0.41557. Took 0.12 sec\n",
      "Epoch 62, Loss(train/val) 0.22375/0.43453. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.21180/0.42597. Took 0.12 sec\n",
      "Epoch 64, Loss(train/val) 0.20290/0.37645. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.20612/0.43154. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.19374/0.38137. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.19494/0.43026. Took 0.12 sec\n",
      "Epoch 68, Loss(train/val) 0.19633/0.36447. Took 0.12 sec\n",
      "Epoch 69, Loss(train/val) 0.19392/0.42017. Took 0.12 sec\n",
      "Epoch 70, Loss(train/val) 0.18270/0.44301. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.20022/0.41967. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.19623/0.39195. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.19270/0.41862. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.18944/0.44042. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.18960/0.43375. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.18764/0.40412. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.19171/0.42124. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.17642/0.39518. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.18834/0.41553. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.19084/0.44379. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.18063/0.40415. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.17395/0.41493. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.17334/0.44187. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.16986/0.43755. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.18375/0.39072. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.18020/0.44253. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.17162/0.43040. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.17238/0.44238. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.16748/0.43339. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.17051/0.40647. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.17419/0.40295. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.16333/0.44986. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.16530/0.42984. Took 0.12 sec\n",
      "Epoch 94, Loss(train/val) 0.16153/0.46276. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.15317/0.42226. Took 0.12 sec\n",
      "Epoch 96, Loss(train/val) 0.15723/0.42927. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.14414/0.41889. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.15968/0.43760. Took 0.14 sec\n",
      "Epoch 99, Loss(train/val) 0.16348/0.46286. Took 0.13 sec\n",
      "ACC: 0.671875, MCC: 0.32411166008994946\n",
      "Epoch 0, Loss(train/val) 0.49653/0.48540. Took 0.13 sec\n",
      "Epoch 1, Loss(train/val) 0.47882/0.45777. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.44532/0.40241. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.40853/0.35727. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.38404/0.34175. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.36989/0.33536. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.35017/0.33428. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.33922/0.29805. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.34127/0.30402. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.32511/0.25687. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.32979/0.26431. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.31254/0.29276. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.31187/0.25778. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.30548/0.26315. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.31212/0.26548. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.29872/0.27499. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.29444/0.27165. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.28920/0.26980. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.29159/0.26012. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.31609/0.28977. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.30185/0.27579. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.27153/0.27825. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.28163/0.26955. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.26117/0.29246. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.27181/0.27429. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.26741/0.27134. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.25841/0.27576. Took 0.13 sec\n",
      "Epoch 27, Loss(train/val) 0.25031/0.28566. Took 0.13 sec\n",
      "Epoch 28, Loss(train/val) 0.25971/0.28487. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.26261/0.28750. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.25136/0.27327. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.25914/0.29012. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.25500/0.29201. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.25402/0.26664. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.26015/0.25943. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.25602/0.26711. Took 0.13 sec\n",
      "Epoch 36, Loss(train/val) 0.24612/0.27693. Took 0.13 sec\n",
      "Epoch 37, Loss(train/val) 0.23867/0.28544. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.23385/0.29319. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.24026/0.27974. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.23583/0.28667. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.23164/0.28944. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.22145/0.28692. Took 0.12 sec\n",
      "Epoch 43, Loss(train/val) 0.23871/0.27671. Took 0.12 sec\n",
      "Epoch 44, Loss(train/val) 0.23057/0.29216. Took 0.12 sec\n",
      "Epoch 45, Loss(train/val) 0.22363/0.28071. Took 0.12 sec\n",
      "Epoch 46, Loss(train/val) 0.21639/0.29300. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.21626/0.28467. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.21726/0.28801. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.21570/0.28651. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.20722/0.27943. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.21079/0.27600. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.21775/0.28564. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.21752/0.28434. Took 0.12 sec\n",
      "Epoch 54, Loss(train/val) 0.20707/0.29345. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.20829/0.28269. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.21416/0.27771. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.22188/0.27464. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.20528/0.28390. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.20930/0.28002. Took 0.12 sec\n",
      "Epoch 60, Loss(train/val) 0.19721/0.28027. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.20252/0.27109. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.19331/0.28136. Took 0.12 sec\n",
      "Epoch 63, Loss(train/val) 0.18500/0.27548. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.18931/0.28871. Took 0.12 sec\n",
      "Epoch 65, Loss(train/val) 0.19196/0.29394. Took 0.12 sec\n",
      "Epoch 66, Loss(train/val) 0.19421/0.28168. Took 0.12 sec\n",
      "Epoch 67, Loss(train/val) 0.18820/0.28409. Took 0.12 sec\n",
      "Epoch 68, Loss(train/val) 0.19026/0.29749. Took 0.12 sec\n",
      "Epoch 69, Loss(train/val) 0.18515/0.30538. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.18134/0.32104. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.18643/0.33192. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.18190/0.32916. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.17732/0.32689. Took 0.12 sec\n",
      "Epoch 74, Loss(train/val) 0.17819/0.32682. Took 0.12 sec\n",
      "Epoch 75, Loss(train/val) 0.18038/0.31184. Took 0.12 sec\n",
      "Epoch 76, Loss(train/val) 0.18537/0.32501. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.18110/0.31299. Took 0.12 sec\n",
      "Epoch 78, Loss(train/val) 0.17544/0.33298. Took 0.12 sec\n",
      "Epoch 79, Loss(train/val) 0.17627/0.29123. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.17477/0.33507. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.18047/0.34336. Took 0.12 sec\n",
      "Epoch 82, Loss(train/val) 0.16910/0.30716. Took 0.12 sec\n",
      "Epoch 83, Loss(train/val) 0.17148/0.32840. Took 0.12 sec\n",
      "Epoch 84, Loss(train/val) 0.16404/0.32607. Took 0.12 sec\n",
      "Epoch 85, Loss(train/val) 0.16869/0.34356. Took 0.12 sec\n",
      "Epoch 86, Loss(train/val) 0.16259/0.31991. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.16566/0.30912. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.16818/0.34101. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.17125/0.32846. Took 0.12 sec\n",
      "Epoch 90, Loss(train/val) 0.15593/0.33036. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.16706/0.32893. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.15910/0.33564. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.15669/0.31708. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.17854/0.31959. Took 0.14 sec\n",
      "Epoch 95, Loss(train/val) 0.15798/0.32937. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.15931/0.31530. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.16222/0.33962. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.16552/0.31374. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.16534/0.31946. Took 0.13 sec\n",
      "ACC: 0.71875, MCC: 0.44810278287677535\n",
      "Epoch 0, Loss(train/val) 0.49335/0.47725. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.47093/0.44054. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.44514/0.40143. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.41744/0.36327. Took 0.15 sec\n",
      "Epoch 4, Loss(train/val) 0.39497/0.35119. Took 0.17 sec\n",
      "Epoch 5, Loss(train/val) 0.36999/0.34312. Took 0.16 sec\n",
      "Epoch 6, Loss(train/val) 0.35366/0.31690. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.34511/0.31284. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.32924/0.29281. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.31981/0.30169. Took 0.15 sec\n",
      "Epoch 10, Loss(train/val) 0.31332/0.32062. Took 0.15 sec\n",
      "Epoch 11, Loss(train/val) 0.31452/0.31157. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.30525/0.28852. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.29874/0.30986. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.29607/0.31071. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.28453/0.30277. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.28892/0.31336. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.28517/0.31984. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.29320/0.34945. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.28894/0.30748. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.28660/0.30933. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.28127/0.32453. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.28622/0.34508. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.27092/0.32759. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.26635/0.37519. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.26348/0.34638. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.26491/0.32998. Took 0.13 sec\n",
      "Epoch 27, Loss(train/val) 0.25836/0.37463. Took 0.13 sec\n",
      "Epoch 28, Loss(train/val) 0.27303/0.33300. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.26649/0.36901. Took 0.13 sec\n",
      "Epoch 30, Loss(train/val) 0.25871/0.33814. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.26320/0.38090. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.27794/0.34137. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.25434/0.31675. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.26315/0.43191. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.25047/0.36676. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.24511/0.37036. Took 0.13 sec\n",
      "Epoch 37, Loss(train/val) 0.23520/0.37713. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.24291/0.30964. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.24129/0.31688. Took 0.12 sec\n",
      "Epoch 40, Loss(train/val) 0.25084/0.39309. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.23472/0.38450. Took 0.12 sec\n",
      "Epoch 42, Loss(train/val) 0.23544/0.35455. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.23167/0.37168. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.22407/0.36551. Took 0.12 sec\n",
      "Epoch 45, Loss(train/val) 0.22325/0.36473. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.23752/0.34928. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.22854/0.36050. Took 0.12 sec\n",
      "Epoch 48, Loss(train/val) 0.22305/0.40255. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.22096/0.33176. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.21945/0.38040. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.22360/0.41237. Took 0.12 sec\n",
      "Epoch 52, Loss(train/val) 0.21393/0.37826. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.21187/0.41705. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.22069/0.32890. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.21305/0.40226. Took 0.12 sec\n",
      "Epoch 56, Loss(train/val) 0.20092/0.35455. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.21483/0.36196. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.20677/0.33835. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.19877/0.43501. Took 0.12 sec\n",
      "Epoch 60, Loss(train/val) 0.21219/0.38802. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.19789/0.41309. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.20819/0.41140. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.20644/0.41765. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.19365/0.38842. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.20174/0.43015. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.19186/0.41361. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.20115/0.43399. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.19445/0.41522. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.18913/0.36589. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.18883/0.42941. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.18226/0.35989. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.19470/0.36179. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.18231/0.39614. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.18646/0.35898. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.18610/0.36249. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.18083/0.42123. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.17412/0.38919. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.18104/0.38692. Took 0.12 sec\n",
      "Epoch 79, Loss(train/val) 0.17222/0.35894. Took 0.12 sec\n",
      "Epoch 80, Loss(train/val) 0.18288/0.41527. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.17371/0.40309. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.17901/0.33186. Took 0.12 sec\n",
      "Epoch 83, Loss(train/val) 0.17432/0.38608. Took 0.12 sec\n",
      "Epoch 84, Loss(train/val) 0.16752/0.36617. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.17588/0.42587. Took 0.12 sec\n",
      "Epoch 86, Loss(train/val) 0.17193/0.38008. Took 0.12 sec\n",
      "Epoch 87, Loss(train/val) 0.16869/0.38181. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.17026/0.38958. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.16509/0.39204. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.16971/0.36682. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.16177/0.37627. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.16747/0.39735. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.16603/0.36630. Took 0.12 sec\n",
      "Epoch 94, Loss(train/val) 0.16214/0.42186. Took 0.12 sec\n",
      "Epoch 95, Loss(train/val) 0.16884/0.37940. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.16409/0.38073. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.15700/0.42485. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.15210/0.38863. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.15062/0.41284. Took 0.13 sec\n",
      "ACC: 0.625, MCC: 0.31214723679042466\n",
      "Epoch 0, Loss(train/val) 0.49032/0.47666. Took 0.13 sec\n",
      "Epoch 1, Loss(train/val) 0.46302/0.43055. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.42889/0.41002. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.40620/0.39819. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.39018/0.40177. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.37055/0.38929. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.36438/0.38634. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.34533/0.36424. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.34425/0.36440. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.33479/0.35589. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.32494/0.35138. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.32716/0.32184. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.32716/0.32322. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.32307/0.34644. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.31416/0.33186. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.30681/0.37866. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.31648/0.42657. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.29545/0.40175. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.29364/0.34204. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.28942/0.34983. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.28419/0.40156. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.27761/0.34213. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.29682/0.33993. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.27615/0.32421. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.27183/0.25659. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.27003/0.37391. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.26054/0.30246. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.26548/0.29944. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.27858/0.32940. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.26222/0.34989. Took 0.13 sec\n",
      "Epoch 30, Loss(train/val) 0.25450/0.32282. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.25463/0.29615. Took 0.13 sec\n",
      "Epoch 32, Loss(train/val) 0.26262/0.36261. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.24614/0.31371. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.25258/0.34896. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.24240/0.30977. Took 0.13 sec\n",
      "Epoch 36, Loss(train/val) 0.24521/0.32711. Took 0.13 sec\n",
      "Epoch 37, Loss(train/val) 0.23195/0.43384. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.24172/0.31027. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.23566/0.33267. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.22827/0.37063. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.22401/0.37516. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.22170/0.38749. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.22031/0.35574. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.22065/0.37113. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.21785/0.38360. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.22094/0.36606. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.21194/0.36913. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.20966/0.37209. Took 0.16 sec\n",
      "Epoch 49, Loss(train/val) 0.20817/0.39589. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.20435/0.38478. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.21378/0.39768. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.19921/0.39459. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.19798/0.37715. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.19939/0.40908. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.20130/0.41279. Took 0.12 sec\n",
      "Epoch 56, Loss(train/val) 0.20392/0.39321. Took 0.12 sec\n",
      "Epoch 57, Loss(train/val) 0.20753/0.38466. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.19600/0.42601. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.20320/0.37650. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.18959/0.38549. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.18534/0.38241. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.19330/0.38604. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.18998/0.38150. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.18641/0.39173. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.18101/0.37206. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.18167/0.38298. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.18004/0.37821. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.17311/0.38622. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.18306/0.38828. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.17675/0.40689. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.17447/0.39130. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.16915/0.38178. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.17564/0.39124. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.17180/0.39156. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.17371/0.38388. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.17053/0.36448. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.16775/0.37152. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.17063/0.38899. Took 0.14 sec\n",
      "Epoch 79, Loss(train/val) 0.17164/0.37689. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.15907/0.35249. Took 0.14 sec\n",
      "Epoch 81, Loss(train/val) 0.16384/0.39763. Took 0.15 sec\n",
      "Epoch 82, Loss(train/val) 0.16278/0.35204. Took 0.15 sec\n",
      "Epoch 83, Loss(train/val) 0.16389/0.38646. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.16812/0.37057. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.16297/0.42711. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.16068/0.34506. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.15566/0.36237. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.15625/0.36594. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.15594/0.39165. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.15030/0.36845. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.16145/0.37323. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.16109/0.35267. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.15143/0.36843. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.14825/0.39819. Took 0.14 sec\n",
      "Epoch 95, Loss(train/val) 0.15634/0.38848. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.14298/0.37989. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.14680/0.38164. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.14415/0.35725. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.14416/0.38139. Took 0.13 sec\n",
      "ACC: 0.6875, MCC: 0.39477101697586137\n",
      "Epoch 0, Loss(train/val) 0.49339/0.50108. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.46926/0.48027. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.43093/0.39953. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.40155/0.37498. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.38259/0.37580. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.37047/0.34575. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.35407/0.41029. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.35149/0.39181. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.34559/0.32218. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.33066/0.34667. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.32727/0.29826. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.32712/0.33978. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.31792/0.32265. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.31202/0.31570. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.30392/0.30564. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.30156/0.30663. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.29522/0.29009. Took 0.16 sec\n",
      "Epoch 17, Loss(train/val) 0.29095/0.33313. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.29134/0.30321. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.27853/0.33314. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.27822/0.33517. Took 0.17 sec\n",
      "Epoch 21, Loss(train/val) 0.27084/0.30933. Took 0.16 sec\n",
      "Epoch 22, Loss(train/val) 0.27680/0.31725. Took 0.16 sec\n",
      "Epoch 23, Loss(train/val) 0.26678/0.32862. Took 0.17 sec\n",
      "Epoch 24, Loss(train/val) 0.25862/0.31426. Took 0.16 sec\n",
      "Epoch 25, Loss(train/val) 0.25366/0.34096. Took 0.16 sec\n",
      "Epoch 26, Loss(train/val) 0.25801/0.31634. Took 0.17 sec\n",
      "Epoch 27, Loss(train/val) 0.25907/0.32543. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.25037/0.31606. Took 0.18 sec\n",
      "Epoch 29, Loss(train/val) 0.24875/0.31684. Took 0.16 sec\n",
      "Epoch 30, Loss(train/val) 0.23811/0.32809. Took 0.18 sec\n",
      "Epoch 31, Loss(train/val) 0.24185/0.31908. Took 0.16 sec\n",
      "Epoch 32, Loss(train/val) 0.24116/0.30408. Took 0.16 sec\n",
      "Epoch 33, Loss(train/val) 0.23441/0.29325. Took 0.13 sec\n",
      "Epoch 34, Loss(train/val) 0.23863/0.29620. Took 0.13 sec\n",
      "Epoch 35, Loss(train/val) 0.23812/0.30214. Took 0.13 sec\n",
      "Epoch 36, Loss(train/val) 0.22626/0.29628. Took 0.13 sec\n",
      "Epoch 37, Loss(train/val) 0.23925/0.29669. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.23205/0.30351. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.22033/0.29526. Took 0.15 sec\n",
      "Epoch 40, Loss(train/val) 0.22111/0.30156. Took 0.15 sec\n",
      "Epoch 41, Loss(train/val) 0.21292/0.31170. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.21480/0.31442. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.21688/0.31361. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.20479/0.30205. Took 0.16 sec\n",
      "Epoch 45, Loss(train/val) 0.21402/0.30025. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.21612/0.28880. Took 0.15 sec\n",
      "Epoch 47, Loss(train/val) 0.20913/0.27999. Took 0.15 sec\n",
      "Epoch 48, Loss(train/val) 0.20537/0.28736. Took 0.15 sec\n",
      "Epoch 49, Loss(train/val) 0.19890/0.29883. Took 0.15 sec\n",
      "Epoch 50, Loss(train/val) 0.20161/0.29950. Took 0.15 sec\n",
      "Epoch 51, Loss(train/val) 0.19516/0.29934. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.19584/0.31193. Took 0.15 sec\n",
      "Epoch 53, Loss(train/val) 0.19801/0.31305. Took 0.15 sec\n",
      "Epoch 54, Loss(train/val) 0.20070/0.32028. Took 0.15 sec\n",
      "Epoch 55, Loss(train/val) 0.18328/0.30505. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.18921/0.30803. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.17807/0.31812. Took 0.15 sec\n",
      "Epoch 58, Loss(train/val) 0.18721/0.31132. Took 0.16 sec\n",
      "Epoch 59, Loss(train/val) 0.17786/0.30512. Took 0.15 sec\n",
      "Epoch 60, Loss(train/val) 0.17975/0.31667. Took 0.16 sec\n",
      "Epoch 61, Loss(train/val) 0.17662/0.34608. Took 0.16 sec\n",
      "Epoch 62, Loss(train/val) 0.18820/0.34196. Took 0.15 sec\n",
      "Epoch 63, Loss(train/val) 0.17833/0.32130. Took 0.15 sec\n",
      "Epoch 64, Loss(train/val) 0.17678/0.36246. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.17407/0.32612. Took 0.15 sec\n",
      "Epoch 66, Loss(train/val) 0.16971/0.31690. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) 0.17236/0.33732. Took 0.15 sec\n",
      "Epoch 68, Loss(train/val) 0.17079/0.32627. Took 0.16 sec\n",
      "Epoch 69, Loss(train/val) 0.17399/0.32641. Took 0.15 sec\n",
      "Epoch 70, Loss(train/val) 0.16288/0.31874. Took 0.15 sec\n",
      "Epoch 71, Loss(train/val) 0.16837/0.34286. Took 0.16 sec\n",
      "Epoch 72, Loss(train/val) 0.17100/0.33464. Took 0.15 sec\n",
      "Epoch 73, Loss(train/val) 0.16735/0.32866. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.15834/0.32700. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.17172/0.32704. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.15209/0.34587. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.15483/0.32517. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.15780/0.32188. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.15475/0.31769. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.16397/0.33212. Took 0.15 sec\n",
      "Epoch 81, Loss(train/val) 0.16063/0.31596. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.15575/0.31758. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) 0.15126/0.33195. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.14860/0.33100. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.14470/0.31467. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.14538/0.32988. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.14940/0.34951. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.15131/0.33593. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.14637/0.33751. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.14437/0.33278. Took 0.14 sec\n",
      "Epoch 91, Loss(train/val) 0.13850/0.34130. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.13860/0.33833. Took 0.16 sec\n",
      "Epoch 93, Loss(train/val) 0.13826/0.33777. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.14552/0.33972. Took 0.15 sec\n",
      "Epoch 95, Loss(train/val) 0.14015/0.33426. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.15317/0.34299. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.14215/0.35502. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.14440/0.32961. Took 0.14 sec\n",
      "Epoch 99, Loss(train/val) 0.14192/0.35381. Took 0.13 sec\n",
      "ACC: 0.671875, MCC: 0.3598637460328732\n",
      "Epoch 0, Loss(train/val) 0.49135/0.49591. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.46927/0.47329. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.43646/0.41999. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.40727/0.38915. Took 0.15 sec\n",
      "Epoch 4, Loss(train/val) 0.39475/0.38675. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.38252/0.38714. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.36409/0.37532. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.34337/0.36480. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.33413/0.34963. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.32038/0.30043. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.31363/0.30689. Took 0.16 sec\n",
      "Epoch 11, Loss(train/val) 0.30125/0.29647. Took 0.15 sec\n",
      "Epoch 12, Loss(train/val) 0.29526/0.27425. Took 0.16 sec\n",
      "Epoch 13, Loss(train/val) 0.28577/0.27420. Took 0.16 sec\n",
      "Epoch 14, Loss(train/val) 0.28553/0.33852. Took 0.16 sec\n",
      "Epoch 15, Loss(train/val) 0.28298/0.34691. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.27828/0.29665. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.27404/0.28057. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.27223/0.32188. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.26464/0.29650. Took 0.15 sec\n",
      "Epoch 20, Loss(train/val) 0.25984/0.30616. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.26072/0.31378. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.26461/0.33237. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.25595/0.31467. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.25995/0.29617. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.24723/0.35914. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.24137/0.30809. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.24273/0.31153. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.23897/0.31355. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.22981/0.32555. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.23240/0.32183. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.24042/0.36576. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.23208/0.32130. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.22261/0.31144. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.22655/0.32677. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.22136/0.31986. Took 0.13 sec\n",
      "Epoch 36, Loss(train/val) 0.22630/0.33666. Took 0.13 sec\n",
      "Epoch 37, Loss(train/val) 0.21784/0.32333. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.22590/0.32228. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.21284/0.32867. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.20944/0.33199. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.21702/0.33672. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.19909/0.32145. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.20963/0.33656. Took 0.12 sec\n",
      "Epoch 44, Loss(train/val) 0.20090/0.33613. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.20634/0.34066. Took 0.12 sec\n",
      "Epoch 46, Loss(train/val) 0.19760/0.35846. Took 0.12 sec\n",
      "Epoch 47, Loss(train/val) 0.20695/0.38431. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.19818/0.33431. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.19998/0.32335. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.19773/0.37459. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.19649/0.33211. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.19084/0.33670. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.19756/0.36727. Took 0.12 sec\n",
      "Epoch 54, Loss(train/val) 0.19466/0.34086. Took 0.12 sec\n",
      "Epoch 55, Loss(train/val) 0.18230/0.35498. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.19523/0.36102. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.19120/0.34228. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.19240/0.33849. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.19096/0.35827. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.16973/0.30537. Took 0.15 sec\n",
      "Epoch 61, Loss(train/val) 0.18761/0.32244. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.18569/0.33290. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.17313/0.33402. Took 0.15 sec\n",
      "Epoch 64, Loss(train/val) 0.18619/0.32200. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.17891/0.33931. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.18015/0.32520. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.18090/0.31435. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.18091/0.34197. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.17163/0.31807. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.17187/0.30506. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.17370/0.32425. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.17166/0.31700. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.17107/0.35039. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.18485/0.38003. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.17301/0.34390. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.17538/0.35713. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.16844/0.31072. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.17626/0.32829. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.16343/0.33401. Took 0.12 sec\n",
      "Epoch 80, Loss(train/val) 0.15813/0.33340. Took 0.12 sec\n",
      "Epoch 81, Loss(train/val) 0.16430/0.33438. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.16740/0.30871. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.16883/0.30490. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.15768/0.32250. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.15637/0.31711. Took 0.12 sec\n",
      "Epoch 86, Loss(train/val) 0.16278/0.37008. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.16138/0.34916. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.16873/0.34971. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.15078/0.33932. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.16718/0.34098. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.15637/0.32620. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.15986/0.32747. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.15880/0.35739. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.15458/0.30946. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.15352/0.32332. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.16036/0.32744. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.16366/0.33808. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.15257/0.33951. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.14993/0.34408. Took 0.13 sec\n",
      "ACC: 0.703125, MCC: 0.40804713337332393\n",
      "Epoch 0, Loss(train/val) 0.49427/0.48131. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.47383/0.43636. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.43839/0.37140. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.40417/0.33150. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.38746/0.28882. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.36869/0.27148. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.35061/0.26535. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.33765/0.26568. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.33347/0.25654. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.31792/0.26685. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.31480/0.27059. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.30333/0.25877. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.29971/0.26796. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.28769/0.26486. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.28866/0.26876. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.28241/0.26911. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.28784/0.27140. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.28626/0.26917. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.28076/0.27426. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.27215/0.26285. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.27461/0.26835. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.26911/0.26249. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.26363/0.27432. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.26407/0.27147. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.26068/0.27669. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.25284/0.27080. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.24743/0.28019. Took 0.15 sec\n",
      "Epoch 27, Loss(train/val) 0.25198/0.27489. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.25110/0.25026. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.24972/0.26903. Took 0.16 sec\n",
      "Epoch 30, Loss(train/val) 0.24350/0.27265. Took 0.17 sec\n",
      "Epoch 31, Loss(train/val) 0.24006/0.28158. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.23860/0.26033. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.23616/0.28580. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.24057/0.28181. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.22621/0.28366. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.23091/0.28495. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.23262/0.28546. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.22944/0.30180. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.22139/0.28613. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.22096/0.29444. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.23093/0.27920. Took 0.12 sec\n",
      "Epoch 42, Loss(train/val) 0.21874/0.27575. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.21393/0.29064. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.21389/0.28602. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.22176/0.32323. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.20946/0.29680. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.21427/0.30857. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.20985/0.30529. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.20460/0.32070. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.20212/0.31025. Took 0.15 sec\n",
      "Epoch 51, Loss(train/val) 0.19989/0.32609. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.20549/0.33177. Took 0.15 sec\n",
      "Epoch 53, Loss(train/val) 0.20627/0.32138. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.20755/0.33323. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.19733/0.32031. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.20291/0.33114. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.20022/0.30720. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.19806/0.32263. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.19206/0.31631. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.19157/0.31933. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.18588/0.32328. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.18329/0.32439. Took 0.12 sec\n",
      "Epoch 63, Loss(train/val) 0.19333/0.32107. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.18302/0.31782. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.19292/0.32313. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.18698/0.32742. Took 0.12 sec\n",
      "Epoch 67, Loss(train/val) 0.18071/0.30805. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.18801/0.32479. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.18642/0.31485. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.18630/0.30859. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.17245/0.32017. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.17906/0.31435. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.17717/0.32678. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.17302/0.33089. Took 0.12 sec\n",
      "Epoch 75, Loss(train/val) 0.17523/0.33188. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.17147/0.32688. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.16822/0.32938. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.16600/0.32315. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.16203/0.32844. Took 0.12 sec\n",
      "Epoch 80, Loss(train/val) 0.17527/0.33295. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.16526/0.33310. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.16026/0.32350. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.15428/0.32306. Took 0.12 sec\n",
      "Epoch 84, Loss(train/val) 0.15727/0.32937. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.15644/0.33066. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.16077/0.33195. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.15767/0.34174. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.15725/0.33601. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.15607/0.34227. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.16268/0.32613. Took 0.14 sec\n",
      "Epoch 91, Loss(train/val) 0.15827/0.35135. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.14962/0.35141. Took 0.15 sec\n",
      "Epoch 93, Loss(train/val) 0.14790/0.34385. Took 0.15 sec\n",
      "Epoch 94, Loss(train/val) 0.15385/0.35047. Took 0.15 sec\n",
      "Epoch 95, Loss(train/val) 0.14779/0.33619. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.14923/0.34319. Took 0.14 sec\n",
      "Epoch 97, Loss(train/val) 0.14963/0.34476. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.14508/0.34043. Took 0.14 sec\n",
      "Epoch 99, Loss(train/val) 0.14493/0.33952. Took 0.14 sec\n",
      "ACC: 0.625, MCC: 0.1868706368604627\n",
      "Epoch 0, Loss(train/val) 0.49328/0.48250. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.47376/0.46224. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.43844/0.43950. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.40553/0.42427. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.38686/0.42275. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.37084/0.42464. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.35903/0.42887. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.34556/0.42395. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.33772/0.42208. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.31895/0.41477. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.31883/0.40135. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.30068/0.41609. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.29863/0.37834. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.29057/0.43506. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.28735/0.38879. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.27463/0.39217. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.29069/0.35540. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.26416/0.37394. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.26104/0.34345. Took 0.15 sec\n",
      "Epoch 19, Loss(train/val) 0.26447/0.35399. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.26695/0.35016. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.26128/0.36152. Took 0.17 sec\n",
      "Epoch 22, Loss(train/val) 0.27476/0.32200. Took 0.17 sec\n",
      "Epoch 23, Loss(train/val) 0.25787/0.35746. Took 0.17 sec\n",
      "Epoch 24, Loss(train/val) 0.25544/0.34653. Took 0.16 sec\n",
      "Epoch 25, Loss(train/val) 0.25011/0.33681. Took 0.16 sec\n",
      "Epoch 26, Loss(train/val) 0.24246/0.33639. Took 0.18 sec\n",
      "Epoch 27, Loss(train/val) 0.23944/0.32899. Took 0.19 sec\n",
      "Epoch 28, Loss(train/val) 0.24397/0.33364. Took 0.17 sec\n",
      "Epoch 29, Loss(train/val) 0.24292/0.33936. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.23386/0.32908. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.23626/0.33416. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.24270/0.31471. Took 0.17 sec\n",
      "Epoch 33, Loss(train/val) 0.23000/0.33797. Took 0.18 sec\n",
      "Epoch 34, Loss(train/val) 0.23773/0.34334. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.22292/0.34633. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.22552/0.34228. Took 0.13 sec\n",
      "Epoch 37, Loss(train/val) 0.21920/0.33212. Took 0.12 sec\n",
      "Epoch 38, Loss(train/val) 0.21342/0.31805. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.21814/0.32893. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.21296/0.35538. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.20693/0.34693. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.21331/0.32068. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.21308/0.33458. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.21323/0.34909. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.20306/0.36320. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.20090/0.36675. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.20548/0.35908. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.19978/0.34860. Took 0.15 sec\n",
      "Epoch 49, Loss(train/val) 0.19718/0.34580. Took 0.15 sec\n",
      "Epoch 50, Loss(train/val) 0.19273/0.36641. Took 0.15 sec\n",
      "Epoch 51, Loss(train/val) 0.19188/0.36082. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.18998/0.37392. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.18246/0.37933. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.18139/0.37277. Took 0.16 sec\n",
      "Epoch 55, Loss(train/val) 0.18679/0.38158. Took 0.15 sec\n",
      "Epoch 56, Loss(train/val) 0.18104/0.37411. Took 0.15 sec\n",
      "Epoch 57, Loss(train/val) 0.18252/0.36716. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.18298/0.38115. Took 0.14 sec\n",
      "Epoch 59, Loss(train/val) 0.17437/0.37601. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.18906/0.37700. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.18071/0.36701. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.18093/0.37851. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.17344/0.35784. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.17219/0.38562. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.17427/0.37995. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.16940/0.37648. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.16686/0.36700. Took 0.16 sec\n",
      "Epoch 68, Loss(train/val) 0.16789/0.38207. Took 0.15 sec\n",
      "Epoch 69, Loss(train/val) 0.16716/0.36120. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.17039/0.33462. Took 0.15 sec\n",
      "Epoch 71, Loss(train/val) 0.16132/0.35590. Took 0.15 sec\n",
      "Epoch 72, Loss(train/val) 0.16757/0.36160. Took 0.15 sec\n",
      "Epoch 73, Loss(train/val) 0.16487/0.36959. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.15320/0.35100. Took 0.15 sec\n",
      "Epoch 75, Loss(train/val) 0.15677/0.37061. Took 0.15 sec\n",
      "Epoch 76, Loss(train/val) 0.15370/0.36281. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.15904/0.37346. Took 0.12 sec\n",
      "Epoch 78, Loss(train/val) 0.15016/0.36385. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.15563/0.35504. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.16395/0.33755. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.15784/0.34238. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.15536/0.35531. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.15226/0.34169. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.16393/0.37790. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.13993/0.36783. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.14839/0.35706. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.14524/0.34592. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.15234/0.34162. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.14449/0.33242. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.15731/0.36955. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.14789/0.35572. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.13728/0.34383. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.14071/0.35590. Took 0.12 sec\n",
      "Epoch 94, Loss(train/val) 0.13721/0.36619. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.14005/0.35018. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.15066/0.34611. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.13899/0.33102. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.13754/0.32285. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.13719/0.35041. Took 0.13 sec\n",
      "ACC: 0.59375, MCC: 0.2866857437632499\n",
      "Epoch 0, Loss(train/val) 0.48850/0.47114. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.46325/0.43750. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.42361/0.41491. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.39415/0.39447. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.37925/0.37002. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.36773/0.35683. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.35656/0.35984. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.34528/0.35895. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.33426/0.36785. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.31856/0.35391. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.31562/0.35347. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.30551/0.38688. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.30450/0.35413. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.29053/0.42101. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.27748/0.37487. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.27095/0.44452. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.26829/0.37439. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.26007/0.33500. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.26184/0.37904. Took 0.15 sec\n",
      "Epoch 19, Loss(train/val) 0.26368/0.39089. Took 0.15 sec\n",
      "Epoch 20, Loss(train/val) 0.25141/0.44813. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.25353/0.38399. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.24194/0.37939. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.24135/0.35757. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.24333/0.42563. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.22995/0.40138. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.22877/0.37021. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.22963/0.34634. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.23095/0.37097. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.22795/0.39364. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.22625/0.40097. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.21001/0.38493. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.23327/0.34044. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.20843/0.33091. Took 0.13 sec\n",
      "Epoch 34, Loss(train/val) 0.21489/0.38162. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.20569/0.36851. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.20710/0.43681. Took 0.13 sec\n",
      "Epoch 37, Loss(train/val) 0.20824/0.43247. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.20495/0.39380. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.21474/0.39727. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.20293/0.42786. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.19967/0.39631. Took 0.12 sec\n",
      "Epoch 42, Loss(train/val) 0.20171/0.37410. Took 0.12 sec\n",
      "Epoch 43, Loss(train/val) 0.21809/0.46050. Took 0.12 sec\n",
      "Epoch 44, Loss(train/val) 0.20161/0.38423. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.19455/0.40105. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.18533/0.39233. Took 0.12 sec\n",
      "Epoch 47, Loss(train/val) 0.19823/0.43113. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.18912/0.40546. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.19366/0.39545. Took 0.12 sec\n",
      "Epoch 50, Loss(train/val) 0.19311/0.43351. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.19370/0.40286. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.18787/0.38393. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.19011/0.40776. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.17775/0.40645. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.17749/0.40135. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.17216/0.39027. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.17200/0.39555. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.17346/0.43220. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.17340/0.42435. Took 0.12 sec\n",
      "Epoch 60, Loss(train/val) 0.16887/0.39784. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.16904/0.38855. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.17308/0.39539. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.16587/0.37690. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.16365/0.38539. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.15011/0.36695. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.16185/0.38145. Took 0.16 sec\n",
      "Epoch 67, Loss(train/val) 0.15918/0.38389. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.16376/0.40262. Took 0.15 sec\n",
      "Epoch 69, Loss(train/val) 0.15817/0.40002. Took 0.15 sec\n",
      "Epoch 70, Loss(train/val) 0.15024/0.36936. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.15938/0.38133. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.15886/0.36579. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.15866/0.37768. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.14625/0.35967. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.14643/0.39359. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.14176/0.36362. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.15656/0.35028. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.15620/0.36955. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.15373/0.36883. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.14312/0.35802. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.15103/0.36569. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.15369/0.37006. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.13954/0.38024. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.14329/0.36872. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.14134/0.36419. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.13779/0.37046. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.14111/0.39008. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.14195/0.38847. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.14740/0.36899. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.13268/0.34921. Took 0.12 sec\n",
      "Epoch 91, Loss(train/val) 0.14032/0.36396. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.13858/0.38560. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.13030/0.38795. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.13274/0.41649. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.13117/0.39574. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.13348/0.37498. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.12623/0.37203. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.13445/0.35740. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.12300/0.39673. Took 0.13 sec\n",
      "ACC: 0.59375, MCC: 0.20321305705762227\n",
      "Epoch 0, Loss(train/val) 0.49276/0.49195. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.47584/0.46317. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.44632/0.40224. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.40767/0.35883. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.38727/0.33958. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.37233/0.33180. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.36034/0.32852. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.35275/0.32990. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.34675/0.30345. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.33636/0.32402. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.33935/0.31920. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.32241/0.40086. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.32381/0.29976. Took 0.15 sec\n",
      "Epoch 13, Loss(train/val) 0.32173/0.33980. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.31455/0.35246. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.30895/0.30506. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.30067/0.32891. Took 0.15 sec\n",
      "Epoch 17, Loss(train/val) 0.29220/0.31465. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.29293/0.37263. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.29687/0.34781. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.28766/0.37469. Took 0.15 sec\n",
      "Epoch 21, Loss(train/val) 0.28166/0.34298. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.27404/0.38698. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.26936/0.36513. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.27339/0.34457. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.26455/0.36496. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.25737/0.40232. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.26023/0.36244. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.25886/0.35885. Took 0.13 sec\n",
      "Epoch 29, Loss(train/val) 0.24488/0.34531. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.24485/0.34885. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.24022/0.33054. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.24668/0.35830. Took 0.13 sec\n",
      "Epoch 33, Loss(train/val) 0.23912/0.34687. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.23036/0.33659. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.23584/0.35958. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.22044/0.34086. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.23246/0.33549. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.21907/0.34869. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.22284/0.31741. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.20924/0.35116. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.21347/0.35184. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.21088/0.36007. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.20273/0.35637. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.20779/0.37092. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) 0.20800/0.36047. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.21614/0.35247. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.21095/0.36518. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.18618/0.36695. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.19723/0.36882. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.19041/0.35912. Took 0.15 sec\n",
      "Epoch 51, Loss(train/val) 0.18253/0.35846. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.18717/0.37550. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.18137/0.37961. Took 0.15 sec\n",
      "Epoch 54, Loss(train/val) 0.18475/0.39082. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.17676/0.37501. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.17940/0.35649. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.17591/0.35935. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.17274/0.36619. Took 0.15 sec\n",
      "Epoch 59, Loss(train/val) 0.17283/0.37041. Took 0.15 sec\n",
      "Epoch 60, Loss(train/val) 0.17213/0.37075. Took 0.15 sec\n",
      "Epoch 61, Loss(train/val) 0.16150/0.37474. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.16078/0.36241. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.16455/0.35783. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.17535/0.35721. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.16710/0.38292. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.16410/0.36760. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.16012/0.37937. Took 0.15 sec\n",
      "Epoch 68, Loss(train/val) 0.15307/0.37634. Took 0.14 sec\n",
      "Epoch 69, Loss(train/val) 0.16005/0.38659. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.15173/0.37019. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.15278/0.37791. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.14818/0.37112. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.14058/0.37244. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.15312/0.38646. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.14912/0.37763. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.15276/0.37746. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.14784/0.37306. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.15709/0.44222. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.15331/0.39689. Took 0.16 sec\n",
      "Epoch 80, Loss(train/val) 0.13879/0.38275. Took 0.16 sec\n",
      "Epoch 81, Loss(train/val) 0.13759/0.37856. Took 0.15 sec\n",
      "Epoch 82, Loss(train/val) 0.14092/0.38451. Took 0.15 sec\n",
      "Epoch 83, Loss(train/val) 0.13671/0.37208. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.15067/0.43990. Took 0.16 sec\n",
      "Epoch 85, Loss(train/val) 0.14512/0.39164. Took 0.17 sec\n",
      "Epoch 86, Loss(train/val) 0.13891/0.37863. Took 0.18 sec\n",
      "Epoch 87, Loss(train/val) 0.13452/0.41284. Took 0.15 sec\n",
      "Epoch 88, Loss(train/val) 0.12939/0.39870. Took 0.14 sec\n",
      "Epoch 89, Loss(train/val) 0.12542/0.43664. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.13159/0.42223. Took 0.14 sec\n",
      "Epoch 91, Loss(train/val) 0.12837/0.41652. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.12487/0.39540. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.12641/0.39850. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.12538/0.40194. Took 0.14 sec\n",
      "Epoch 95, Loss(train/val) 0.12815/0.42367. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.13261/0.42699. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.12396/0.41414. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.12895/0.41551. Took 0.14 sec\n",
      "Epoch 99, Loss(train/val) 0.12101/0.42971. Took 0.13 sec\n",
      "ACC: 0.515625, MCC: 0.1572471042478079\n",
      "Epoch 0, Loss(train/val) 0.49422/0.48629. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.47561/0.46127. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.44069/0.41630. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.40227/0.39073. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.37644/0.38212. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.36306/0.37088. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.34923/0.35916. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.34488/0.34880. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.34299/0.38051. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.33860/0.34776. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.32930/0.35018. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.32927/0.37774. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.32286/0.34786. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.32257/0.35006. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.31293/0.35198. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.32328/0.35826. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.31091/0.35836. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.30613/0.35981. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.30256/0.35540. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.30335/0.35577. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.30057/0.33941. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.29913/0.35751. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.28999/0.35111. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.29209/0.35965. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.28499/0.33214. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.28669/0.34877. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.29331/0.33907. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.28170/0.33962. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.27772/0.33880. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.28650/0.35464. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.27231/0.37808. Took 0.16 sec\n",
      "Epoch 31, Loss(train/val) 0.27012/0.32710. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.26375/0.33285. Took 0.16 sec\n",
      "Epoch 33, Loss(train/val) 0.25699/0.34965. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.26017/0.34469. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.25625/0.33674. Took 0.16 sec\n",
      "Epoch 36, Loss(train/val) 0.25206/0.34940. Took 0.16 sec\n",
      "Epoch 37, Loss(train/val) 0.25440/0.33611. Took 0.15 sec\n",
      "Epoch 38, Loss(train/val) 0.24954/0.37238. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.25064/0.36812. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.24279/0.37312. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.24863/0.35401. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.24726/0.35231. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.23460/0.39258. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.23765/0.35611. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.24207/0.35538. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.24565/0.40120. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.24434/0.40021. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.24102/0.36275. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.23217/0.37959. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.22651/0.38141. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.22317/0.38799. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.22402/0.37129. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.21712/0.36983. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.21485/0.35658. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.22027/0.38226. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.22808/0.41649. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.22532/0.40746. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.21705/0.40452. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.22190/0.38218. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.22013/0.37062. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.21520/0.40370. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.21790/0.35761. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.21263/0.34028. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.21418/0.35587. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.21284/0.34180. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.22188/0.38271. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.20305/0.36335. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.20954/0.34544. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.20407/0.34930. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.20492/0.37841. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.20505/0.37497. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.19901/0.38127. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.19808/0.38769. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.20066/0.37354. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.20641/0.36732. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.20083/0.36344. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.19548/0.36443. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.18759/0.35698. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.18856/0.36005. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.19991/0.37873. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.19143/0.35221. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.18884/0.36704. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.19820/0.37297. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.20042/0.35386. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.19128/0.37917. Took 0.12 sec\n",
      "Epoch 86, Loss(train/val) 0.20128/0.39517. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.19848/0.35554. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.19308/0.35969. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.19207/0.34282. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.18798/0.34684. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.18746/0.35736. Took 0.15 sec\n",
      "Epoch 92, Loss(train/val) 0.18699/0.36000. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.18337/0.34413. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.18874/0.37424. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.18617/0.33259. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.18235/0.34325. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.18255/0.35202. Took 0.15 sec\n",
      "Epoch 98, Loss(train/val) 0.18682/0.33809. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.18031/0.36125. Took 0.13 sec\n",
      "ACC: 0.640625, MCC: 0.2771507137113173\n",
      "Epoch 0, Loss(train/val) 0.49691/0.49548. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.48181/0.48533. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.45228/0.46435. Took 0.15 sec\n",
      "Epoch 3, Loss(train/val) 0.41276/0.44770. Took 0.15 sec\n",
      "Epoch 4, Loss(train/val) 0.38449/0.44064. Took 0.15 sec\n",
      "Epoch 5, Loss(train/val) 0.36927/0.43642. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.36025/0.43188. Took 0.15 sec\n",
      "Epoch 7, Loss(train/val) 0.34985/0.43042. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.34073/0.42573. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.33906/0.42781. Took 0.15 sec\n",
      "Epoch 10, Loss(train/val) 0.33537/0.42526. Took 0.15 sec\n",
      "Epoch 11, Loss(train/val) 0.33485/0.42022. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.33038/0.41183. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.32268/0.41755. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.32230/0.43895. Took 0.15 sec\n",
      "Epoch 15, Loss(train/val) 0.32451/0.42697. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.31304/0.45045. Took 0.16 sec\n",
      "Epoch 17, Loss(train/val) 0.30158/0.43819. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.30163/0.41911. Took 0.16 sec\n",
      "Epoch 19, Loss(train/val) 0.29617/0.43039. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.29540/0.43696. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.29160/0.42047. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.29604/0.42565. Took 0.15 sec\n",
      "Epoch 23, Loss(train/val) 0.28126/0.41716. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.27894/0.42026. Took 0.15 sec\n",
      "Epoch 25, Loss(train/val) 0.27214/0.41454. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.28055/0.40969. Took 0.15 sec\n",
      "Epoch 27, Loss(train/val) 0.28558/0.39266. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.27228/0.38898. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.26812/0.37859. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.26331/0.39264. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.26492/0.34205. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.25688/0.36640. Took 0.16 sec\n",
      "Epoch 33, Loss(train/val) 0.25614/0.35057. Took 0.16 sec\n",
      "Epoch 34, Loss(train/val) 0.24153/0.34348. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.25442/0.36603. Took 0.16 sec\n",
      "Epoch 36, Loss(train/val) 0.25258/0.37201. Took 0.16 sec\n",
      "Epoch 37, Loss(train/val) 0.23512/0.36939. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.23517/0.37305. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.23402/0.37772. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.23763/0.37279. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.24459/0.36139. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.23604/0.37364. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.22091/0.37187. Took 0.15 sec\n",
      "Epoch 44, Loss(train/val) 0.22782/0.35709. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) 0.22991/0.36062. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.22536/0.39244. Took 0.15 sec\n",
      "Epoch 47, Loss(train/val) 0.22739/0.37713. Took 0.16 sec\n",
      "Epoch 48, Loss(train/val) 0.23394/0.37654. Took 0.15 sec\n",
      "Epoch 49, Loss(train/val) 0.21981/0.36204. Took 0.15 sec\n",
      "Epoch 50, Loss(train/val) 0.20593/0.38337. Took 0.15 sec\n",
      "Epoch 51, Loss(train/val) 0.22554/0.37653. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.21682/0.36017. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.21743/0.36067. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.21459/0.35497. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.21132/0.36903. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.20885/0.35889. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.20781/0.36783. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.20301/0.35690. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.20103/0.36847. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.20219/0.36480. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.20306/0.37359. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.19146/0.36276. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.19511/0.36883. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.19863/0.35153. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.19011/0.35116. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.18934/0.35393. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.18823/0.36432. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.19485/0.35837. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.17896/0.35470. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.18713/0.35642. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.19071/0.36515. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.18216/0.34919. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.18111/0.34391. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.18047/0.34414. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.19439/0.33811. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.17585/0.33985. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.17199/0.34468. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.17181/0.34758. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.18033/0.34715. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.16741/0.35564. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.17453/0.35781. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.17032/0.38500. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.17441/0.37254. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.16483/0.36921. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.17465/0.36637. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.16263/0.33605. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.16116/0.34683. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.16356/0.36318. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.16817/0.36485. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.15914/0.36760. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.15892/0.33298. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.16834/0.32766. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.16363/0.32870. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.16181/0.35997. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.15684/0.37077. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.15982/0.36844. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.15508/0.37721. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.15856/0.35912. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.15869/0.37895. Took 0.13 sec\n",
      "ACC: 0.546875, MCC: 0.04052204492365539\n",
      "Epoch 0, Loss(train/val) 0.49387/0.48390. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.46786/0.44616. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.42663/0.40441. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.39094/0.38882. Took 0.15 sec\n",
      "Epoch 4, Loss(train/val) 0.37605/0.38105. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.36184/0.37304. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.35777/0.37396. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.34873/0.37467. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.34038/0.36799. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.33152/0.36993. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.33844/0.37301. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.32233/0.36123. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.32481/0.38903. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.32727/0.38241. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.31105/0.36277. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.30769/0.38294. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.30279/0.37153. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.30274/0.38173. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.30632/0.33467. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.29821/0.37079. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.29325/0.36052. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.28917/0.37150. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.28876/0.35275. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.28736/0.34424. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.27894/0.37186. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.27672/0.36297. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.27129/0.36057. Took 0.13 sec\n",
      "Epoch 27, Loss(train/val) 0.26972/0.37033. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.27074/0.37556. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.26405/0.35446. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.26038/0.34625. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.25337/0.35477. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.25321/0.37116. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.25470/0.35774. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.23861/0.36395. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.24076/0.35750. Took 0.13 sec\n",
      "Epoch 36, Loss(train/val) 0.23222/0.35660. Took 0.13 sec\n",
      "Epoch 37, Loss(train/val) 0.23438/0.35902. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.23207/0.34947. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.23086/0.37180. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.23248/0.37851. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.22114/0.35062. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.22941/0.35256. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.22347/0.34604. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.22306/0.33901. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.20900/0.35812. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.21245/0.36215. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.20726/0.37099. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.20603/0.37627. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.20724/0.38013. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.20300/0.36311. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.20530/0.38033. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.19776/0.37564. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.19716/0.40573. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.18915/0.39074. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.19189/0.40258. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.20055/0.40240. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.19750/0.41789. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.18374/0.41172. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.18490/0.40942. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.18248/0.40142. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.18460/0.41624. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.18628/0.40330. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.18429/0.39883. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.17553/0.39604. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.18637/0.42306. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.17671/0.40982. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.17004/0.39432. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.17626/0.41975. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.17165/0.39525. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.17296/0.43107. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.16535/0.41187. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.16564/0.41234. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.16728/0.40483. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.16367/0.42460. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.16127/0.39231. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.15932/0.42815. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.16858/0.41872. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.16315/0.42848. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.15198/0.42441. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.15699/0.43723. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.15210/0.43388. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.16504/0.41263. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.15951/0.43221. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.15322/0.42789. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.15084/0.43954. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.14703/0.41733. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.15248/0.40890. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.14805/0.44057. Took 0.14 sec\n",
      "Epoch 89, Loss(train/val) 0.14824/0.43494. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.15489/0.46117. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.15434/0.44878. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.15602/0.45421. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.16150/0.43539. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.15237/0.41806. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.14846/0.42643. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.15307/0.43796. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.14285/0.44141. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.14471/0.43367. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.14594/0.43934. Took 0.13 sec\n",
      "ACC: 0.59375, MCC: 0.20556755962059384\n",
      "Epoch 0, Loss(train/val) 0.48968/0.48854. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.45918/0.47076. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.41402/0.45334. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.38017/0.43663. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.35734/0.41077. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.34638/0.41898. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.33482/0.38172. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.32888/0.40798. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.32414/0.37804. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.32296/0.41043. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.32033/0.40435. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.31517/0.37014. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.31531/0.42281. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.31275/0.41673. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.31004/0.36239. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.30386/0.35418. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.31388/0.37648. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.30495/0.38589. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.29860/0.41609. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.30114/0.38893. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.29959/0.40792. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.29140/0.36481. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.29154/0.38093. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.28745/0.38742. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.29297/0.32257. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.28606/0.30959. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.28615/0.38727. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.27569/0.40449. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.27257/0.36242. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.27114/0.41553. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.27061/0.37284. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.26853/0.34210. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.27232/0.39277. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.26319/0.33925. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.25547/0.38052. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.25094/0.32953. Took 0.13 sec\n",
      "Epoch 36, Loss(train/val) 0.25861/0.33180. Took 0.13 sec\n",
      "Epoch 37, Loss(train/val) 0.24731/0.39167. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.24024/0.33336. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.24854/0.33388. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.23826/0.37241. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.23132/0.30420. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.23535/0.42167. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.23217/0.32006. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.21812/0.29415. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.22366/0.28802. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.21064/0.28930. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.21199/0.34435. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.21568/0.32667. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.22156/0.33523. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.20695/0.32890. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.20447/0.33774. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.20952/0.35628. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.19792/0.35275. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.20514/0.33988. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.20177/0.35469. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.19024/0.30457. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.19967/0.31929. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.19430/0.34180. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.18660/0.36479. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.18369/0.32639. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.19005/0.32358. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.18608/0.34509. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.17303/0.30214. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.18568/0.30725. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.17095/0.32555. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.18262/0.35912. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.18077/0.33008. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.18641/0.34247. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.16248/0.37559. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.16805/0.32731. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.17245/0.32821. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.17019/0.35998. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.17338/0.31068. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.16737/0.32643. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.16144/0.33940. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.15808/0.36099. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.16471/0.32501. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.16576/0.33333. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.16590/0.31869. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.16206/0.31169. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.15004/0.34481. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.15711/0.32273. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.15810/0.31880. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.15536/0.32157. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.15232/0.34464. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.15341/0.38073. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.14852/0.34719. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.14545/0.30605. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.14041/0.32941. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.13616/0.32562. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.14840/0.32023. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.14434/0.32848. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.14232/0.36873. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.14231/0.34419. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.14219/0.34903. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.13609/0.34990. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.13891/0.35291. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.15035/0.32008. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.14011/0.34207. Took 0.13 sec\n",
      "ACC: 0.609375, MCC: 0.28801192988277585\n",
      "Epoch 0, Loss(train/val) 0.49061/0.47128. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.46415/0.43661. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.42444/0.40529. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.38897/0.40409. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.36754/0.38625. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.35220/0.40391. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.34216/0.39018. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.33552/0.38564. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.32913/0.41053. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.33348/0.41730. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.32886/0.34341. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.32112/0.36255. Took 0.15 sec\n",
      "Epoch 12, Loss(train/val) 0.32171/0.34723. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.31974/0.37597. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.31699/0.33465. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.31822/0.41092. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.31996/0.37692. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.30893/0.38237. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.31200/0.38012. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.30207/0.36113. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.29937/0.31406. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.29865/0.33368. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.29583/0.35898. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.28991/0.32712. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.28774/0.30860. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.28882/0.31508. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.28050/0.32250. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.27863/0.32515. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.27019/0.32618. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.27145/0.35866. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.26645/0.37479. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.26532/0.32917. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.26248/0.28729. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.26357/0.31620. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.24872/0.32647. Took 0.13 sec\n",
      "Epoch 35, Loss(train/val) 0.25353/0.39394. Took 0.13 sec\n",
      "Epoch 36, Loss(train/val) 0.25393/0.30909. Took 0.13 sec\n",
      "Epoch 37, Loss(train/val) 0.24256/0.34065. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.23757/0.30655. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.23652/0.29564. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.24057/0.26945. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.23511/0.31569. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.23063/0.30934. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.22677/0.33327. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.23579/0.32751. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.23844/0.30880. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.22635/0.31951. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.22450/0.35866. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.21107/0.35899. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.21254/0.30549. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.22300/0.31653. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.21990/0.31528. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.21163/0.31511. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.20304/0.32383. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.20836/0.34058. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.20605/0.37878. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.23179/0.39466. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.22131/0.36799. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.20032/0.33416. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.20663/0.33186. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.20495/0.32667. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.19845/0.40175. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.21071/0.39777. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.19598/0.34574. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.19190/0.35970. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.19906/0.31405. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.19360/0.34236. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.19585/0.38246. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.19763/0.33634. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.19524/0.42077. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.19252/0.37366. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.18534/0.36555. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.18673/0.32464. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.18406/0.39823. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.19334/0.36374. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.17589/0.36327. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.18131/0.32931. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.17686/0.37191. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.17932/0.43360. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.17814/0.40591. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.18154/0.30221. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.17934/0.29427. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.17005/0.33218. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.17638/0.34371. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.17644/0.35379. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.17174/0.36566. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.16768/0.43816. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.16674/0.33135. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.17708/0.43835. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.16095/0.41639. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.17496/0.37436. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.16310/0.46580. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.16861/0.36705. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.16442/0.37106. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.16663/0.44458. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.15649/0.43846. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.16511/0.35082. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.16565/0.43510. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.16367/0.36787. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.15953/0.35211. Took 0.13 sec\n",
      "ACC: 0.71875, MCC: 0.4555869462835626\n",
      "Epoch 0, Loss(train/val) 0.49401/0.48820. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.47025/0.46205. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.42856/0.42830. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.39296/0.41709. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.37245/0.39316. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.35822/0.35085. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.34714/0.38713. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.35828/0.40727. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.34278/0.33207. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.33761/0.31004. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.32539/0.32100. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.32011/0.33059. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.30357/0.31693. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.30077/0.31709. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.28036/0.29924. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.29758/0.27803. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.28776/0.30245. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.27485/0.31750. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.28287/0.33866. Took 0.15 sec\n",
      "Epoch 19, Loss(train/val) 0.27698/0.36415. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.27133/0.33177. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.26180/0.32768. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.25752/0.32906. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.25457/0.34761. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.25105/0.34390. Took 0.15 sec\n",
      "Epoch 25, Loss(train/val) 0.25175/0.35229. Took 0.16 sec\n",
      "Epoch 26, Loss(train/val) 0.24464/0.34077. Took 0.16 sec\n",
      "Epoch 27, Loss(train/val) 0.24365/0.35120. Took 0.17 sec\n",
      "Epoch 28, Loss(train/val) 0.24831/0.34039. Took 0.19 sec\n",
      "Epoch 29, Loss(train/val) 0.24788/0.36777. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.24001/0.34154. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.22631/0.34120. Took 0.16 sec\n",
      "Epoch 32, Loss(train/val) 0.22846/0.36301. Took 0.17 sec\n",
      "Epoch 33, Loss(train/val) 0.22890/0.34855. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.21819/0.33502. Took 0.17 sec\n",
      "Epoch 35, Loss(train/val) 0.22212/0.33550. Took 0.17 sec\n",
      "Epoch 36, Loss(train/val) 0.21483/0.35938. Took 0.16 sec\n",
      "Epoch 37, Loss(train/val) 0.20796/0.37634. Took 0.15 sec\n",
      "Epoch 38, Loss(train/val) 0.22000/0.36439. Took 0.15 sec\n",
      "Epoch 39, Loss(train/val) 0.22015/0.33177. Took 0.15 sec\n",
      "Epoch 40, Loss(train/val) 0.22089/0.35228. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.20493/0.36961. Took 0.15 sec\n",
      "Epoch 42, Loss(train/val) 0.19546/0.35711. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.21613/0.37030. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.19898/0.38438. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.20524/0.35617. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.20934/0.38870. Took 0.15 sec\n",
      "Epoch 47, Loss(train/val) 0.20983/0.36580. Took 0.16 sec\n",
      "Epoch 48, Loss(train/val) 0.20401/0.36779. Took 0.15 sec\n",
      "Epoch 49, Loss(train/val) 0.20609/0.38934. Took 0.15 sec\n",
      "Epoch 50, Loss(train/val) 0.19590/0.35402. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.20147/0.36678. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.18906/0.37994. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.20210/0.40441. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.19203/0.37443. Took 0.15 sec\n",
      "Epoch 55, Loss(train/val) 0.18756/0.38635. Took 0.15 sec\n",
      "Epoch 56, Loss(train/val) 0.18532/0.36204. Took 0.16 sec\n",
      "Epoch 57, Loss(train/val) 0.18264/0.36859. Took 0.15 sec\n",
      "Epoch 58, Loss(train/val) 0.18277/0.37128. Took 0.16 sec\n",
      "Epoch 59, Loss(train/val) 0.18262/0.37154. Took 0.15 sec\n",
      "Epoch 60, Loss(train/val) 0.18094/0.34625. Took 0.15 sec\n",
      "Epoch 61, Loss(train/val) 0.17769/0.37807. Took 0.16 sec\n",
      "Epoch 62, Loss(train/val) 0.18304/0.36832. Took 0.16 sec\n",
      "Epoch 63, Loss(train/val) 0.17733/0.35511. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.17446/0.36452. Took 0.16 sec\n",
      "Epoch 65, Loss(train/val) 0.17089/0.34007. Took 0.15 sec\n",
      "Epoch 66, Loss(train/val) 0.17490/0.36009. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) 0.17721/0.35962. Took 0.15 sec\n",
      "Epoch 68, Loss(train/val) 0.17708/0.33973. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.16957/0.35356. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.16939/0.37219. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.16747/0.39552. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.16246/0.36086. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.16896/0.39326. Took 0.15 sec\n",
      "Epoch 74, Loss(train/val) 0.16308/0.36115. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) 0.15948/0.36490. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.15293/0.36961. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.16149/0.37414. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.15734/0.38032. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.16142/0.37332. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.14780/0.37969. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.15067/0.37775. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.15261/0.38294. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.14536/0.36981. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.14604/0.39101. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.13541/0.37876. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.14547/0.38582. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.13875/0.38796. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.14565/0.39898. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.14972/0.38581. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.15201/0.37363. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.13936/0.39201. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.14850/0.38433. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.13935/0.41053. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.13804/0.39045. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.13842/0.40681. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.13222/0.41263. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.13739/0.40168. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.12936/0.41451. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.12888/0.41268. Took 0.13 sec\n",
      "ACC: 0.640625, MCC: 0.4038390887440659\n",
      "Epoch 0, Loss(train/val) 0.48920/0.46364. Took 0.38 sec\n",
      "Epoch 1, Loss(train/val) 0.46128/0.41059. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.41874/0.36975. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.38500/0.36055. Took 0.17 sec\n",
      "Epoch 4, Loss(train/val) 0.36848/0.36379. Took 0.16 sec\n",
      "Epoch 5, Loss(train/val) 0.35404/0.37614. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.34602/0.37385. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.33700/0.38506. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.33324/0.38536. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.32783/0.38947. Took 0.17 sec\n",
      "Epoch 10, Loss(train/val) 0.32416/0.37287. Took 0.16 sec\n",
      "Epoch 11, Loss(train/val) 0.31316/0.39161. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.30844/0.41786. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.30586/0.38928. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.29774/0.40628. Took 0.15 sec\n",
      "Epoch 15, Loss(train/val) 0.29367/0.41285. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.29402/0.43867. Took 0.17 sec\n",
      "Epoch 17, Loss(train/val) 0.29217/0.40116. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.29678/0.39471. Took 0.15 sec\n",
      "Epoch 19, Loss(train/val) 0.28703/0.41112. Took 0.15 sec\n",
      "Epoch 20, Loss(train/val) 0.27558/0.44349. Took 0.16 sec\n",
      "Epoch 21, Loss(train/val) 0.27617/0.41429. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.26977/0.44998. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.25633/0.45160. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.26551/0.45318. Took 0.18 sec\n",
      "Epoch 25, Loss(train/val) 0.25811/0.44296. Took 0.19 sec\n",
      "Epoch 26, Loss(train/val) 0.26348/0.46444. Took 0.20 sec\n",
      "Epoch 27, Loss(train/val) 0.26073/0.47722. Took 0.16 sec\n",
      "Epoch 28, Loss(train/val) 0.25075/0.43447. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.25199/0.45294. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.23979/0.44738. Took 0.13 sec\n",
      "Epoch 31, Loss(train/val) 0.23542/0.44086. Took 0.13 sec\n",
      "Epoch 32, Loss(train/val) 0.22983/0.43083. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.23913/0.42718. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.22237/0.41786. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.22225/0.42134. Took 0.13 sec\n",
      "Epoch 36, Loss(train/val) 0.23025/0.41549. Took 0.13 sec\n",
      "Epoch 37, Loss(train/val) 0.22571/0.41032. Took 0.16 sec\n",
      "Epoch 38, Loss(train/val) 0.22172/0.41240. Took 0.15 sec\n",
      "Epoch 39, Loss(train/val) 0.21926/0.42071. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.20803/0.39693. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.22163/0.39606. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.21307/0.40892. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.20431/0.40659. Took 0.15 sec\n",
      "Epoch 44, Loss(train/val) 0.19836/0.38825. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) 0.19983/0.40971. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.19282/0.38393. Took 0.15 sec\n",
      "Epoch 47, Loss(train/val) 0.19405/0.40245. Took 0.15 sec\n",
      "Epoch 48, Loss(train/val) 0.18840/0.39316. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.19804/0.39918. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.18554/0.39435. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.18340/0.38511. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.18627/0.36231. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.17954/0.38084. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.17496/0.37970. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.17795/0.37275. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.19358/0.36031. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.18620/0.36288. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.17294/0.37070. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.16960/0.36815. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.17085/0.35893. Took 0.14 sec\n",
      "Epoch 61, Loss(train/val) 0.16738/0.34528. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.16231/0.36540. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.15904/0.35591. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.15888/0.35169. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.15729/0.35103. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.16494/0.36228. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) 0.16686/0.35716. Took 0.15 sec\n",
      "Epoch 68, Loss(train/val) 0.15565/0.36651. Took 0.15 sec\n",
      "Epoch 69, Loss(train/val) 0.15703/0.34063. Took 0.16 sec\n",
      "Epoch 70, Loss(train/val) 0.15765/0.34952. Took 0.16 sec\n",
      "Epoch 71, Loss(train/val) 0.15471/0.32483. Took 0.15 sec\n",
      "Epoch 72, Loss(train/val) 0.15145/0.34066. Took 0.16 sec\n",
      "Epoch 73, Loss(train/val) 0.15720/0.33965. Took 0.16 sec\n",
      "Epoch 74, Loss(train/val) 0.14848/0.37839. Took 0.15 sec\n",
      "Epoch 75, Loss(train/val) 0.14915/0.34468. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.14766/0.34840. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.15130/0.33753. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.14150/0.36936. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.14227/0.34048. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.14757/0.33596. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.15065/0.34934. Took 0.15 sec\n",
      "Epoch 82, Loss(train/val) 0.15109/0.35393. Took 0.16 sec\n",
      "Epoch 83, Loss(train/val) 0.14615/0.33388. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.14191/0.34753. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.13902/0.35126. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.13397/0.36064. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.13832/0.34785. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.14703/0.33794. Took 0.14 sec\n",
      "Epoch 89, Loss(train/val) 0.13879/0.34592. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.13785/0.31493. Took 0.15 sec\n",
      "Epoch 91, Loss(train/val) 0.13801/0.31024. Took 0.15 sec\n",
      "Epoch 92, Loss(train/val) 0.12589/0.33190. Took 0.17 sec\n",
      "Epoch 93, Loss(train/val) 0.13260/0.32234. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.13217/0.34288. Took 0.15 sec\n",
      "Epoch 95, Loss(train/val) 0.12893/0.33163. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.12447/0.31985. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.13557/0.32054. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.13375/0.32483. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.13549/0.33201. Took 0.13 sec\n",
      "ACC: 0.640625, MCC: 0.27475662250225863\n",
      "Epoch 0, Loss(train/val) 0.48910/0.47602. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.46475/0.44366. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.42768/0.42141. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.39650/0.41693. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.38219/0.41051. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.37204/0.40998. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.35885/0.40296. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.34475/0.40741. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.33231/0.39773. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.32733/0.41435. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.31624/0.39322. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.30609/0.39360. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.30092/0.39380. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.28446/0.39123. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.29011/0.35997. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.28590/0.36295. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.28102/0.37234. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.27862/0.36571. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.27034/0.35138. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.26649/0.36801. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.25852/0.36389. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.25380/0.34900. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.26698/0.34559. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.25158/0.35618. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.26653/0.34417. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.25895/0.35515. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.25505/0.36400. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.24969/0.34433. Took 0.16 sec\n",
      "Epoch 28, Loss(train/val) 0.23733/0.34172. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.24529/0.36184. Took 0.16 sec\n",
      "Epoch 30, Loss(train/val) 0.23003/0.34802. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.23953/0.34821. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.24488/0.35260. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.24157/0.36275. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.23288/0.35848. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.22715/0.35409. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.23425/0.35123. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.23426/0.35609. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.23513/0.32837. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.23446/0.35176. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.22785/0.34603. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.22337/0.35824. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.22559/0.35166. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.21685/0.34061. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.21696/0.35297. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.22109/0.34572. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.21953/0.34438. Took 0.15 sec\n",
      "Epoch 47, Loss(train/val) 0.21383/0.35316. Took 0.16 sec\n",
      "Epoch 48, Loss(train/val) 0.22076/0.34017. Took 0.15 sec\n",
      "Epoch 49, Loss(train/val) 0.21195/0.35411. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.21632/0.34031. Took 0.14 sec\n",
      "Epoch 51, Loss(train/val) 0.20610/0.33149. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.21185/0.36352. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) 0.20625/0.34036. Took 0.16 sec\n",
      "Epoch 54, Loss(train/val) 0.20209/0.33284. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.20761/0.33717. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.19959/0.34556. Took 0.15 sec\n",
      "Epoch 57, Loss(train/val) 0.20614/0.35162. Took 0.15 sec\n",
      "Epoch 58, Loss(train/val) 0.20205/0.34086. Took 0.15 sec\n",
      "Epoch 59, Loss(train/val) 0.19987/0.35326. Took 0.15 sec\n",
      "Epoch 60, Loss(train/val) 0.20654/0.33267. Took 0.15 sec\n",
      "Epoch 61, Loss(train/val) 0.19162/0.36721. Took 0.16 sec\n",
      "Epoch 62, Loss(train/val) 0.19088/0.32604. Took 0.15 sec\n",
      "Epoch 63, Loss(train/val) 0.18919/0.34440. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.19422/0.31992. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.19261/0.34167. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.19227/0.32749. Took 0.15 sec\n",
      "Epoch 67, Loss(train/val) 0.19278/0.33485. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.18742/0.34474. Took 0.14 sec\n",
      "Epoch 69, Loss(train/val) 0.19043/0.36572. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.18900/0.33339. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.18215/0.36259. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.19044/0.36601. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.18504/0.35458. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.18211/0.34418. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.18099/0.33848. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.18678/0.35750. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.18713/0.33515. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.17319/0.36461. Took 0.14 sec\n",
      "Epoch 79, Loss(train/val) 0.17463/0.37076. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.17623/0.35579. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.17540/0.35997. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.17023/0.35569. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.16947/0.36891. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.17324/0.34491. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.15971/0.36585. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.17125/0.34535. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.16422/0.34220. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.16432/0.34137. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.16636/0.36722. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.16214/0.35834. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.16487/0.37940. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.16632/0.33636. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.15432/0.32408. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.16524/0.34292. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.16099/0.37304. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.15766/0.33054. Took 0.14 sec\n",
      "Epoch 97, Loss(train/val) 0.15804/0.35448. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.16066/0.32191. Took 0.14 sec\n",
      "Epoch 99, Loss(train/val) 0.15528/0.31632. Took 0.13 sec\n",
      "ACC: 0.640625, MCC: 0.27539875076496495\n",
      "Epoch 0, Loss(train/val) 0.49198/0.48149. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.46721/0.45018. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.43003/0.42597. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.40134/0.42251. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.38667/0.41583. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.37210/0.39416. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.35863/0.37084. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.35125/0.36712. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.33839/0.33501. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.34317/0.39149. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.32136/0.33250. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.31155/0.33619. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.30038/0.35019. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.29654/0.33867. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.28710/0.41886. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.28522/0.33860. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.28367/0.33668. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.27773/0.33654. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.26047/0.40885. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.26604/0.36118. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.26153/0.39572. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.25934/0.42747. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.26255/0.35152. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.25760/0.38617. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.25585/0.41647. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.26105/0.33985. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.26127/0.37765. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.24920/0.39186. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.25197/0.41557. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.24216/0.33715. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.25423/0.36435. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.23915/0.42416. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.22789/0.41931. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.22341/0.43218. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.22010/0.41182. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.22474/0.41942. Took 0.17 sec\n",
      "Epoch 36, Loss(train/val) 0.22695/0.43470. Took 0.18 sec\n",
      "Epoch 37, Loss(train/val) 0.21540/0.39803. Took 0.18 sec\n",
      "Epoch 38, Loss(train/val) 0.22386/0.41681. Took 0.18 sec\n",
      "Epoch 39, Loss(train/val) 0.22082/0.41888. Took 0.17 sec\n",
      "Epoch 40, Loss(train/val) 0.21666/0.43798. Took 0.15 sec\n",
      "Epoch 41, Loss(train/val) 0.20399/0.43077. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.20961/0.42607. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.21188/0.39870. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.21416/0.38922. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) 0.20426/0.44174. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.20823/0.44249. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.21357/0.39026. Took 0.12 sec\n",
      "Epoch 48, Loss(train/val) 0.20766/0.42084. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.21203/0.44848. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.19662/0.42437. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.20046/0.40281. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.19439/0.40392. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.19583/0.39533. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.19910/0.37152. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.19145/0.36905. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.19831/0.37861. Took 0.15 sec\n",
      "Epoch 57, Loss(train/val) 0.19311/0.39978. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.18343/0.40978. Took 0.14 sec\n",
      "Epoch 59, Loss(train/val) 0.19170/0.40844. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.19360/0.36459. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.18316/0.37876. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.18375/0.38279. Took 0.16 sec\n",
      "Epoch 63, Loss(train/val) 0.17910/0.41632. Took 0.15 sec\n",
      "Epoch 64, Loss(train/val) 0.18548/0.44131. Took 0.16 sec\n",
      "Epoch 65, Loss(train/val) 0.18941/0.39553. Took 0.15 sec\n",
      "Epoch 66, Loss(train/val) 0.17635/0.40446. Took 0.17 sec\n",
      "Epoch 67, Loss(train/val) 0.18286/0.41896. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.18349/0.38852. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.18283/0.38736. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.17896/0.40611. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.18578/0.39078. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.17543/0.38679. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.18600/0.40769. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.18571/0.38307. Took 0.15 sec\n",
      "Epoch 75, Loss(train/val) 0.18936/0.38692. Took 0.15 sec\n",
      "Epoch 76, Loss(train/val) 0.18055/0.37682. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.17062/0.40487. Took 0.15 sec\n",
      "Epoch 78, Loss(train/val) 0.16894/0.35310. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.16685/0.40077. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.17312/0.36158. Took 0.14 sec\n",
      "Epoch 81, Loss(train/val) 0.17153/0.39667. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.17001/0.37458. Took 0.15 sec\n",
      "Epoch 83, Loss(train/val) 0.17643/0.39414. Took 0.15 sec\n",
      "Epoch 84, Loss(train/val) 0.16657/0.36602. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.16703/0.36038. Took 0.15 sec\n",
      "Epoch 86, Loss(train/val) 0.15693/0.37339. Took 0.15 sec\n",
      "Epoch 87, Loss(train/val) 0.16479/0.35805. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.16997/0.35984. Took 0.14 sec\n",
      "Epoch 89, Loss(train/val) 0.16331/0.35932. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.15854/0.36204. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.16783/0.33284. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.16439/0.35562. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.15939/0.34449. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.15703/0.35941. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.15424/0.35217. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.16485/0.35189. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.16048/0.36223. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.15481/0.34595. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.14992/0.35267. Took 0.13 sec\n",
      "ACC: 0.6875, MCC: 0.29277002188455997\n",
      "Epoch 0, Loss(train/val) 0.49355/0.48186. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.47202/0.44086. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.43836/0.40013. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.40373/0.38792. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.38577/0.38142. Took 0.15 sec\n",
      "Epoch 5, Loss(train/val) 0.37369/0.36744. Took 0.15 sec\n",
      "Epoch 6, Loss(train/val) 0.36971/0.36791. Took 0.15 sec\n",
      "Epoch 7, Loss(train/val) 0.35389/0.36415. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.34549/0.36128. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.33613/0.35264. Took 0.16 sec\n",
      "Epoch 10, Loss(train/val) 0.32431/0.34350. Took 0.16 sec\n",
      "Epoch 11, Loss(train/val) 0.30903/0.33065. Took 0.16 sec\n",
      "Epoch 12, Loss(train/val) 0.30847/0.37584. Took 0.15 sec\n",
      "Epoch 13, Loss(train/val) 0.33017/0.36162. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.31046/0.37402. Took 0.16 sec\n",
      "Epoch 15, Loss(train/val) 0.30888/0.39538. Took 0.16 sec\n",
      "Epoch 16, Loss(train/val) 0.30595/0.42307. Took 0.18 sec\n",
      "Epoch 17, Loss(train/val) 0.28854/0.40201. Took 0.17 sec\n",
      "Epoch 18, Loss(train/val) 0.28186/0.41068. Took 0.16 sec\n",
      "Epoch 19, Loss(train/val) 0.28217/0.42328. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.27401/0.41607. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.27610/0.40286. Took 0.16 sec\n",
      "Epoch 22, Loss(train/val) 0.27483/0.40333. Took 0.18 sec\n",
      "Epoch 23, Loss(train/val) 0.27028/0.40196. Took 0.17 sec\n",
      "Epoch 24, Loss(train/val) 0.26020/0.41968. Took 0.15 sec\n",
      "Epoch 25, Loss(train/val) 0.25595/0.39564. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.25574/0.42298. Took 0.15 sec\n",
      "Epoch 27, Loss(train/val) 0.25697/0.38880. Took 0.16 sec\n",
      "Epoch 28, Loss(train/val) 0.25473/0.43759. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.25050/0.42481. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.23968/0.41636. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.23715/0.42663. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.24125/0.42124. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.22559/0.41382. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.23208/0.42097. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.23130/0.41637. Took 0.13 sec\n",
      "Epoch 36, Loss(train/val) 0.21915/0.40807. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.23009/0.40211. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.22753/0.40816. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.21991/0.41129. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.22315/0.39626. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.22645/0.40612. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.23041/0.41361. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.22513/0.39861. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.21862/0.37774. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.21075/0.38346. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.21127/0.38731. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.22301/0.39642. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.21017/0.38641. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.21024/0.41169. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.20995/0.40396. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.20037/0.38416. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.19827/0.38922. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) 0.19451/0.35577. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.19812/0.36127. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.19693/0.36055. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.18457/0.37450. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.19681/0.40428. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.19248/0.39689. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.18248/0.36321. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.18675/0.36895. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.19254/0.36713. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.18679/0.37287. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.18845/0.36886. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.18390/0.39066. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.18145/0.38931. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.18266/0.37620. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.17410/0.38969. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.17536/0.40982. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.17477/0.37266. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.17400/0.38179. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.18444/0.40311. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.17688/0.37980. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.17369/0.40197. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.17447/0.38917. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) 0.16719/0.39415. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.16594/0.41534. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.16372/0.38586. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.16654/0.40441. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.16614/0.39024. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.16332/0.38639. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.17161/0.39654. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.16340/0.41372. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) 0.15251/0.44663. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.15951/0.41362. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.15530/0.42312. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.14800/0.42908. Took 0.15 sec\n",
      "Epoch 87, Loss(train/val) 0.14755/0.42593. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.15154/0.41593. Took 0.15 sec\n",
      "Epoch 89, Loss(train/val) 0.14776/0.46961. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.14346/0.40576. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.15128/0.41639. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.15280/0.41951. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.14787/0.40683. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.14797/0.44071. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.14278/0.42880. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.14486/0.42906. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.14788/0.42335. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.14827/0.42775. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.13697/0.42989. Took 0.13 sec\n",
      "ACC: 0.765625, MCC: 0.518680746847247\n",
      "Epoch 0, Loss(train/val) 0.49065/0.49696. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.46615/0.48391. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.43603/0.43847. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.40779/0.40069. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.39318/0.38265. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.38171/0.36555. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.36768/0.34425. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.35914/0.32774. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.34753/0.32419. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.33618/0.31507. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.33019/0.29450. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.31981/0.29275. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.31489/0.27147. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.30577/0.26187. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.29473/0.26652. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.28857/0.25546. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.29150/0.26092. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.27788/0.24681. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.27252/0.23502. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.27175/0.26829. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.27254/0.23088. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.26859/0.19742. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.26670/0.20177. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.25579/0.20228. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.25946/0.24032. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.25626/0.21858. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.24794/0.25392. Took 0.13 sec\n",
      "Epoch 27, Loss(train/val) 0.24412/0.22298. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.24223/0.24492. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.24132/0.23518. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.23907/0.24233. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.23242/0.23891. Took 0.13 sec\n",
      "Epoch 32, Loss(train/val) 0.24717/0.22745. Took 0.13 sec\n",
      "Epoch 33, Loss(train/val) 0.23513/0.24868. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.24102/0.23893. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.23161/0.24142. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.22122/0.24749. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.23090/0.23125. Took 0.19 sec\n",
      "Epoch 38, Loss(train/val) 0.21381/0.21907. Took 0.18 sec\n",
      "Epoch 39, Loss(train/val) 0.21825/0.23039. Took 0.18 sec\n",
      "Epoch 40, Loss(train/val) 0.21426/0.20967. Took 0.18 sec\n",
      "Epoch 41, Loss(train/val) 0.21299/0.21920. Took 0.17 sec\n",
      "Epoch 42, Loss(train/val) 0.20817/0.22851. Took 0.16 sec\n",
      "Epoch 43, Loss(train/val) 0.21951/0.23590. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.20893/0.22826. Took 0.16 sec\n",
      "Epoch 45, Loss(train/val) 0.21336/0.22306. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.20603/0.23524. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.21153/0.24345. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.21280/0.24335. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.21260/0.25930. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.21046/0.27102. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.19744/0.23349. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.19968/0.22272. Took 0.15 sec\n",
      "Epoch 53, Loss(train/val) 0.19024/0.22656. Took 0.16 sec\n",
      "Epoch 54, Loss(train/val) 0.19490/0.26022. Took 0.15 sec\n",
      "Epoch 55, Loss(train/val) 0.19499/0.22709. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.19064/0.24925. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.19366/0.24256. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.18577/0.28857. Took 0.14 sec\n",
      "Epoch 59, Loss(train/val) 0.20313/0.27727. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.18852/0.25855. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.18248/0.24937. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.18115/0.24614. Took 0.15 sec\n",
      "Epoch 63, Loss(train/val) 0.17874/0.25743. Took 0.15 sec\n",
      "Epoch 64, Loss(train/val) 0.18532/0.26039. Took 0.16 sec\n",
      "Epoch 65, Loss(train/val) 0.17086/0.25351. Took 0.16 sec\n",
      "Epoch 66, Loss(train/val) 0.17679/0.25377. Took 0.15 sec\n",
      "Epoch 67, Loss(train/val) 0.17283/0.23740. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.16563/0.25901. Took 0.15 sec\n",
      "Epoch 69, Loss(train/val) 0.16521/0.24698. Took 0.15 sec\n",
      "Epoch 70, Loss(train/val) 0.17178/0.26199. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.16462/0.24727. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.16325/0.26373. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.15995/0.27189. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.15811/0.27389. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.16113/0.26814. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.15368/0.26623. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.15508/0.27534. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.15693/0.28871. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.14624/0.28624. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.15992/0.25653. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.14474/0.26518. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.15651/0.27307. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.14610/0.26265. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.15303/0.26555. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.14696/0.26240. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.13948/0.27943. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.13526/0.28749. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.13656/0.28848. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.14264/0.27982. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.13186/0.26578. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.13332/0.26263. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.14224/0.27545. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.12927/0.26340. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.13146/0.26761. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.12109/0.27423. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.13122/0.26741. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.12555/0.25616. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.11688/0.26988. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.11540/0.28161. Took 0.13 sec\n",
      "ACC: 0.65625, MCC: 0.3333333333333333\n",
      "Epoch 0, Loss(train/val) 0.49303/0.48052. Took 0.13 sec\n",
      "Epoch 1, Loss(train/val) 0.47235/0.44654. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.43933/0.40765. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.40768/0.38951. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.38646/0.37782. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.37158/0.36841. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.35432/0.36677. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.33844/0.39407. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.32926/0.36868. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.32370/0.32072. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.30451/0.36186. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.29810/0.38134. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.30713/0.35650. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.29801/0.37836. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.30461/0.32801. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.28460/0.34337. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.28080/0.33062. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.28416/0.33617. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.28411/0.33523. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.28149/0.33573. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.28148/0.32968. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.28483/0.34664. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.27973/0.34222. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.26155/0.33571. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.27311/0.34345. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.27491/0.34381. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.26630/0.31826. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.26712/0.32287. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.28400/0.35405. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.27495/0.31572. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.26432/0.35275. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.25505/0.35263. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.25115/0.35314. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.24838/0.33835. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.24156/0.33459. Took 0.13 sec\n",
      "Epoch 35, Loss(train/val) 0.25476/0.35278. Took 0.13 sec\n",
      "Epoch 36, Loss(train/val) 0.24561/0.34742. Took 0.13 sec\n",
      "Epoch 37, Loss(train/val) 0.24095/0.37359. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.23786/0.36371. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.22690/0.36076. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.21739/0.35082. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.23154/0.34998. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.22802/0.34463. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.22188/0.36357. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.21160/0.35918. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.22364/0.35850. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.21698/0.36566. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.20549/0.36813. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.21708/0.34373. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.20779/0.34884. Took 0.15 sec\n",
      "Epoch 50, Loss(train/val) 0.20334/0.36359. Took 0.14 sec\n",
      "Epoch 51, Loss(train/val) 0.19632/0.34471. Took 0.15 sec\n",
      "Epoch 52, Loss(train/val) 0.20256/0.34182. Took 0.15 sec\n",
      "Epoch 53, Loss(train/val) 0.18872/0.34860. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.19439/0.35129. Took 0.15 sec\n",
      "Epoch 55, Loss(train/val) 0.18498/0.34984. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.19029/0.36077. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.19461/0.35421. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.19657/0.34871. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.19491/0.34139. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.18337/0.34932. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.18978/0.34416. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.18275/0.34842. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.17976/0.33753. Took 0.15 sec\n",
      "Epoch 64, Loss(train/val) 0.17771/0.33860. Took 0.16 sec\n",
      "Epoch 65, Loss(train/val) 0.18269/0.35058. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.18445/0.34842. Took 0.16 sec\n",
      "Epoch 67, Loss(train/val) 0.17907/0.33556. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.17616/0.33077. Took 0.16 sec\n",
      "Epoch 69, Loss(train/val) 0.17172/0.35517. Took 0.16 sec\n",
      "Epoch 70, Loss(train/val) 0.17173/0.33723. Took 0.15 sec\n",
      "Epoch 71, Loss(train/val) 0.17080/0.33489. Took 0.16 sec\n",
      "Epoch 72, Loss(train/val) 0.17222/0.32427. Took 0.16 sec\n",
      "Epoch 73, Loss(train/val) 0.16888/0.33294. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.16307/0.31014. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.18663/0.31897. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.17405/0.31523. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.17052/0.31596. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.16852/0.33268. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.15918/0.32479. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.16623/0.35528. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.16012/0.32924. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.16314/0.32728. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.16154/0.33674. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.16881/0.32612. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.16122/0.32923. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.15758/0.34034. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.15763/0.34404. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.15531/0.34527. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.15453/0.33316. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.15287/0.35692. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.15164/0.34908. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.14878/0.34600. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.14656/0.33603. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.15006/0.32000. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.16095/0.33498. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.14934/0.32470. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.15717/0.37304. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.15318/0.33091. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.14945/0.34405. Took 0.13 sec\n",
      "ACC: 0.8125, MCC: 0.6061538461538462\n",
      "Epoch 0, Loss(train/val) 0.49653/0.49510. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.48206/0.48504. Took 0.15 sec\n",
      "Epoch 2, Loss(train/val) 0.45932/0.46941. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.43052/0.45450. Took 0.17 sec\n",
      "Epoch 4, Loss(train/val) 0.41007/0.45881. Took 0.17 sec\n",
      "Epoch 5, Loss(train/val) 0.39395/0.45948. Took 0.15 sec\n",
      "Epoch 6, Loss(train/val) 0.38091/0.45594. Took 0.15 sec\n",
      "Epoch 7, Loss(train/val) 0.37561/0.43830. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.36450/0.44960. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.35131/0.48606. Took 0.18 sec\n",
      "Epoch 10, Loss(train/val) 0.35836/0.48293. Took 0.17 sec\n",
      "Epoch 11, Loss(train/val) 0.34876/0.46896. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.34543/0.43274. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.32698/0.45117. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.32287/0.43864. Took 0.15 sec\n",
      "Epoch 15, Loss(train/val) 0.34034/0.44616. Took 0.19 sec\n",
      "Epoch 16, Loss(train/val) 0.32497/0.45564. Took 0.17 sec\n",
      "Epoch 17, Loss(train/val) 0.32594/0.47326. Took 0.16 sec\n",
      "Epoch 18, Loss(train/val) 0.33203/0.43307. Took 0.15 sec\n",
      "Epoch 19, Loss(train/val) 0.31814/0.41156. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.30810/0.40779. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.30378/0.40821. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.30409/0.39026. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.29639/0.38338. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.29465/0.39141. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.29280/0.39804. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.30282/0.41347. Took 0.15 sec\n",
      "Epoch 27, Loss(train/val) 0.30737/0.39367. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.29984/0.38438. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.29941/0.39597. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.28052/0.39938. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.27048/0.39362. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.28645/0.39593. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.28383/0.38943. Took 0.13 sec\n",
      "Epoch 34, Loss(train/val) 0.28370/0.40270. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.28542/0.39807. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.27976/0.40519. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.27160/0.40388. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.26609/0.41373. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.26877/0.42226. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.26858/0.42130. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.26110/0.42257. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.25721/0.39814. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.25576/0.41483. Took 0.16 sec\n",
      "Epoch 44, Loss(train/val) 0.25198/0.41241. Took 0.15 sec\n",
      "Epoch 45, Loss(train/val) 0.25567/0.41587. Took 0.15 sec\n",
      "Epoch 46, Loss(train/val) 0.24573/0.41654. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.23917/0.41556. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.24031/0.41895. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.23763/0.42885. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.23790/0.41246. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.23846/0.42791. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.22855/0.42219. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.23271/0.41463. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.21979/0.41529. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.21632/0.41923. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.21509/0.42732. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.21567/0.42110. Took 0.12 sec\n",
      "Epoch 58, Loss(train/val) 0.21719/0.41297. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.22169/0.42515. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.21726/0.41061. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.21072/0.41864. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.21596/0.41740. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.21420/0.43506. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.20241/0.41033. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.19719/0.40741. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.20134/0.41614. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.19983/0.41355. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.20024/0.41025. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.19917/0.41140. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.18960/0.40595. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.19291/0.39682. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.18391/0.40031. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.18941/0.39096. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.18447/0.39575. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.18581/0.37933. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.18502/0.38991. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.17784/0.39438. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.18176/0.40259. Took 0.14 sec\n",
      "Epoch 79, Loss(train/val) 0.18242/0.39880. Took 0.15 sec\n",
      "Epoch 80, Loss(train/val) 0.17541/0.39787. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.18024/0.38193. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.18027/0.37587. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.18530/0.39300. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.17898/0.38797. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.17978/0.40812. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.17150/0.39570. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.16897/0.39447. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.16676/0.37901. Took 0.14 sec\n",
      "Epoch 89, Loss(train/val) 0.16531/0.38913. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.17040/0.38640. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.16720/0.39473. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.17238/0.41278. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.16899/0.39146. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.17424/0.38344. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.16979/0.37544. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.16620/0.39700. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.16593/0.39010. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.16766/0.39816. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.16339/0.39229. Took 0.12 sec\n",
      "ACC: 0.546875, MCC: 0.09956278193761034\n",
      "Epoch 0, Loss(train/val) 0.49466/0.48980. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.47933/0.47196. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.45766/0.44312. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.43465/0.41884. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.41222/0.40020. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.40018/0.38423. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.38122/0.37302. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.37333/0.35195. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.36429/0.36459. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.35532/0.37673. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.34588/0.34981. Took 0.17 sec\n",
      "Epoch 11, Loss(train/val) 0.33667/0.38153. Took 0.17 sec\n",
      "Epoch 12, Loss(train/val) 0.32816/0.33712. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.31501/0.36947. Took 0.17 sec\n",
      "Epoch 14, Loss(train/val) 0.31212/0.36371. Took 0.16 sec\n",
      "Epoch 15, Loss(train/val) 0.31141/0.35661. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.30062/0.36776. Took 0.16 sec\n",
      "Epoch 17, Loss(train/val) 0.30758/0.36935. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.29512/0.43111. Took 0.15 sec\n",
      "Epoch 19, Loss(train/val) 0.28816/0.43051. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.28508/0.44677. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.28417/0.42211. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.28139/0.41321. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.28257/0.42232. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.27449/0.42288. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.27319/0.39293. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.26921/0.44761. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.26258/0.44145. Took 0.13 sec\n",
      "Epoch 28, Loss(train/val) 0.26422/0.43965. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.25256/0.44682. Took 0.16 sec\n",
      "Epoch 30, Loss(train/val) 0.24897/0.43076. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.25062/0.42884. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.24158/0.41899. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.24068/0.40184. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.24544/0.42390. Took 0.17 sec\n",
      "Epoch 35, Loss(train/val) 0.24302/0.43352. Took 0.18 sec\n",
      "Epoch 36, Loss(train/val) 0.23809/0.40220. Took 0.17 sec\n",
      "Epoch 37, Loss(train/val) 0.23618/0.37037. Took 0.17 sec\n",
      "Epoch 38, Loss(train/val) 0.24044/0.37596. Took 0.16 sec\n",
      "Epoch 39, Loss(train/val) 0.22497/0.39319. Took 0.15 sec\n",
      "Epoch 40, Loss(train/val) 0.22176/0.39109. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.21441/0.38069. Took 0.15 sec\n",
      "Epoch 42, Loss(train/val) 0.22382/0.38063. Took 0.16 sec\n",
      "Epoch 43, Loss(train/val) 0.21758/0.38069. Took 0.15 sec\n",
      "Epoch 44, Loss(train/val) 0.21549/0.36697. Took 0.15 sec\n",
      "Epoch 45, Loss(train/val) 0.21026/0.37792. Took 0.15 sec\n",
      "Epoch 46, Loss(train/val) 0.21192/0.39168. Took 0.15 sec\n",
      "Epoch 47, Loss(train/val) 0.20718/0.38049. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.20534/0.37381. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.21638/0.38935. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.20307/0.38418. Took 0.15 sec\n",
      "Epoch 51, Loss(train/val) 0.21251/0.37913. Took 0.15 sec\n",
      "Epoch 52, Loss(train/val) 0.20548/0.38615. Took 0.15 sec\n",
      "Epoch 53, Loss(train/val) 0.19646/0.38060. Took 0.15 sec\n",
      "Epoch 54, Loss(train/val) 0.20490/0.37885. Took 0.15 sec\n",
      "Epoch 55, Loss(train/val) 0.19952/0.37116. Took 0.15 sec\n",
      "Epoch 56, Loss(train/val) 0.20119/0.37885. Took 0.15 sec\n",
      "Epoch 57, Loss(train/val) 0.18509/0.37224. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.18917/0.37790. Took 0.16 sec\n",
      "Epoch 59, Loss(train/val) 0.18639/0.36659. Took 0.16 sec\n",
      "Epoch 60, Loss(train/val) 0.18825/0.35867. Took 0.15 sec\n",
      "Epoch 61, Loss(train/val) 0.17573/0.36114. Took 0.15 sec\n",
      "Epoch 62, Loss(train/val) 0.18375/0.36855. Took 0.15 sec\n",
      "Epoch 63, Loss(train/val) 0.18230/0.36279. Took 0.15 sec\n",
      "Epoch 64, Loss(train/val) 0.18249/0.36004. Took 0.15 sec\n",
      "Epoch 65, Loss(train/val) 0.18270/0.35176. Took 0.15 sec\n",
      "Epoch 66, Loss(train/val) 0.18026/0.36492. Took 0.17 sec\n",
      "Epoch 67, Loss(train/val) 0.17454/0.36277. Took 0.15 sec\n",
      "Epoch 68, Loss(train/val) 0.18166/0.36772. Took 0.15 sec\n",
      "Epoch 69, Loss(train/val) 0.17344/0.35938. Took 0.17 sec\n",
      "Epoch 70, Loss(train/val) 0.18817/0.37203. Took 0.16 sec\n",
      "Epoch 71, Loss(train/val) 0.17672/0.36404. Took 0.16 sec\n",
      "Epoch 72, Loss(train/val) 0.16771/0.36059. Took 0.19 sec\n",
      "Epoch 73, Loss(train/val) 0.16650/0.35807. Took 0.16 sec\n",
      "Epoch 74, Loss(train/val) 0.16473/0.37146. Took 0.15 sec\n",
      "Epoch 75, Loss(train/val) 0.16632/0.37238. Took 0.15 sec\n",
      "Epoch 76, Loss(train/val) 0.15942/0.36267. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.16002/0.35668. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.15718/0.37576. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.16073/0.37786. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.15830/0.36164. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.15565/0.36658. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.15667/0.35527. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.15791/0.36243. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.15960/0.36419. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.14842/0.35583. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.15710/0.35683. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.15145/0.36410. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.15149/0.35580. Took 0.14 sec\n",
      "Epoch 89, Loss(train/val) 0.15143/0.35556. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.14756/0.38032. Took 0.14 sec\n",
      "Epoch 91, Loss(train/val) 0.14533/0.37125. Took 0.15 sec\n",
      "Epoch 92, Loss(train/val) 0.13783/0.37112. Took 0.15 sec\n",
      "Epoch 93, Loss(train/val) 0.14118/0.38297. Took 0.16 sec\n",
      "Epoch 94, Loss(train/val) 0.13902/0.36535. Took 0.15 sec\n",
      "Epoch 95, Loss(train/val) 0.14174/0.36214. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.13807/0.37288. Took 0.14 sec\n",
      "Epoch 97, Loss(train/val) 0.13907/0.37915. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.13782/0.37022. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.14143/0.35452. Took 0.13 sec\n",
      "ACC: 0.609375, MCC: 0.2032905342780163\n",
      "Epoch 0, Loss(train/val) 0.50044/0.49590. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.48479/0.49251. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.46418/0.48340. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.43088/0.45871. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.40089/0.44103. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.38109/0.42274. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.35959/0.40923. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.35064/0.39909. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.33620/0.46077. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.34089/0.49022. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.33298/0.41499. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.31577/0.40132. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.30645/0.48045. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.32777/0.52366. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.33598/0.49366. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.30686/0.44879. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.29811/0.39676. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.30950/0.51435. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.30695/0.45351. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.29825/0.37551. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.29044/0.38268. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.29140/0.37420. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.28947/0.44762. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.29410/0.39578. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.26973/0.41758. Took 0.16 sec\n",
      "Epoch 25, Loss(train/val) 0.26971/0.40363. Took 0.16 sec\n",
      "Epoch 26, Loss(train/val) 0.26507/0.42759. Took 0.17 sec\n",
      "Epoch 27, Loss(train/val) 0.26221/0.41770. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.26702/0.40325. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.26980/0.42298. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.25547/0.42297. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.26042/0.42256. Took 0.17 sec\n",
      "Epoch 32, Loss(train/val) 0.25930/0.41550. Took 0.16 sec\n",
      "Epoch 33, Loss(train/val) 0.26031/0.41145. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.25644/0.43371. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.24527/0.41730. Took 0.15 sec\n",
      "Epoch 36, Loss(train/val) 0.24961/0.42850. Took 0.16 sec\n",
      "Epoch 37, Loss(train/val) 0.25078/0.42068. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.26112/0.40164. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.24254/0.39912. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.23978/0.41205. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.23417/0.41275. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.23236/0.41860. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.23864/0.40757. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.23594/0.41640. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) 0.21849/0.41459. Took 0.16 sec\n",
      "Epoch 46, Loss(train/val) 0.23061/0.41828. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.22354/0.39008. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.23156/0.40248. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.22849/0.42734. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.22893/0.43115. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.22377/0.41842. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.23121/0.42726. Took 0.15 sec\n",
      "Epoch 53, Loss(train/val) 0.22242/0.41494. Took 0.15 sec\n",
      "Epoch 54, Loss(train/val) 0.22295/0.41711. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.21558/0.38854. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.21253/0.39841. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.22013/0.42162. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.21694/0.42396. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.19777/0.42458. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.21026/0.40496. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.20804/0.42067. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.21500/0.41100. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.21053/0.40740. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.20808/0.40537. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.20220/0.40515. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.20758/0.39775. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.20057/0.42328. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.21058/0.38221. Took 0.14 sec\n",
      "Epoch 69, Loss(train/val) 0.20267/0.42537. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.19596/0.40763. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.19512/0.39201. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.19146/0.41808. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.20079/0.43741. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.19562/0.40380. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.19333/0.39497. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.18733/0.39214. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.18156/0.38110. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.19092/0.38022. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.21053/0.38192. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.21503/0.41519. Took 0.14 sec\n",
      "Epoch 81, Loss(train/val) 0.18680/0.42093. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.18890/0.42382. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.18155/0.40038. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.18754/0.40368. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.18412/0.40857. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.17840/0.42707. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.17684/0.40534. Took 0.15 sec\n",
      "Epoch 88, Loss(train/val) 0.17890/0.40865. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.18263/0.38480. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.17725/0.39175. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.18360/0.39169. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.16869/0.40156. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.17785/0.37916. Took 0.17 sec\n",
      "Epoch 94, Loss(train/val) 0.17022/0.38152. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.18523/0.38017. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.17904/0.38431. Took 0.16 sec\n",
      "Epoch 97, Loss(train/val) 0.17202/0.37917. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.16960/0.41071. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.18109/0.42539. Took 0.13 sec\n",
      "ACC: 0.609375, MCC: 0.33097897779259655\n",
      "Epoch 0, Loss(train/val) 0.49659/0.49064. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.47957/0.47493. Took 0.15 sec\n",
      "Epoch 2, Loss(train/val) 0.45249/0.45533. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.42344/0.43898. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.40147/0.41830. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.38061/0.41646. Took 0.16 sec\n",
      "Epoch 6, Loss(train/val) 0.36690/0.39620. Took 0.15 sec\n",
      "Epoch 7, Loss(train/val) 0.35285/0.43223. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.34360/0.42699. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.33407/0.42839. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.32282/0.43248. Took 0.15 sec\n",
      "Epoch 11, Loss(train/val) 0.32096/0.33908. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.32400/0.44151. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.30724/0.37097. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.30926/0.36182. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.30448/0.35348. Took 0.16 sec\n",
      "Epoch 16, Loss(train/val) 0.30496/0.33408. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.28829/0.42584. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.29158/0.42642. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.29030/0.44003. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.28656/0.42447. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.27083/0.43388. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.26838/0.43371. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.27123/0.45690. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.27163/0.44268. Took 0.18 sec\n",
      "Epoch 25, Loss(train/val) 0.26676/0.44919. Took 0.18 sec\n",
      "Epoch 26, Loss(train/val) 0.25034/0.45294. Took 0.19 sec\n",
      "Epoch 27, Loss(train/val) 0.26138/0.46034. Took 0.19 sec\n",
      "Epoch 28, Loss(train/val) 0.25569/0.44462. Took 0.18 sec\n",
      "Epoch 29, Loss(train/val) 0.24853/0.46120. Took 0.19 sec\n",
      "Epoch 30, Loss(train/val) 0.24603/0.46391. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.24063/0.44626. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.23806/0.44398. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.22714/0.45398. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.22978/0.44792. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.22000/0.45309. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.22518/0.46040. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.22280/0.45835. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.22148/0.47636. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.21836/0.47045. Took 0.15 sec\n",
      "Epoch 40, Loss(train/val) 0.20848/0.46194. Took 0.17 sec\n",
      "Epoch 41, Loss(train/val) 0.21459/0.46932. Took 0.17 sec\n",
      "Epoch 42, Loss(train/val) 0.20629/0.45533. Took 0.16 sec\n",
      "Epoch 43, Loss(train/val) 0.21369/0.46742. Took 0.16 sec\n",
      "Epoch 44, Loss(train/val) 0.20468/0.46253. Took 0.18 sec\n",
      "Epoch 45, Loss(train/val) 0.20875/0.45979. Took 0.17 sec\n",
      "Epoch 46, Loss(train/val) 0.20750/0.43419. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.18610/0.44738. Took 0.16 sec\n",
      "Epoch 48, Loss(train/val) 0.19804/0.44428. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.19077/0.45264. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.18389/0.44994. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.18471/0.44624. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.17959/0.44164. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.18162/0.44586. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.17212/0.43447. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.18194/0.41311. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.18262/0.43816. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.17997/0.44570. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.17759/0.42468. Took 0.14 sec\n",
      "Epoch 59, Loss(train/val) 0.17877/0.43853. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.17110/0.43186. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.16426/0.44476. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.17557/0.44685. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.16435/0.43108. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.16769/0.44094. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.16251/0.44066. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.16548/0.42867. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.16284/0.42630. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.15578/0.43465. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.15120/0.42289. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.16000/0.41631. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.14574/0.44358. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.15199/0.42069. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.15336/0.42617. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.15129/0.45334. Took 0.15 sec\n",
      "Epoch 75, Loss(train/val) 0.15580/0.43224. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.14330/0.42872. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.14683/0.41997. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.14512/0.40386. Took 0.14 sec\n",
      "Epoch 79, Loss(train/val) 0.14603/0.40560. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.13920/0.44780. Took 0.14 sec\n",
      "Epoch 81, Loss(train/val) 0.14327/0.43380. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.14508/0.44507. Took 0.15 sec\n",
      "Epoch 83, Loss(train/val) 0.14031/0.42904. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.14576/0.44055. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.13295/0.42383. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.12523/0.44997. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.12804/0.42091. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.12964/0.42543. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.13874/0.42049. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.13268/0.44684. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.13558/0.41576. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.12912/0.41239. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.12810/0.45988. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.14270/0.43526. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.13884/0.40474. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.11895/0.40786. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.13329/0.42189. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.13374/0.41109. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.12325/0.41882. Took 0.14 sec\n",
      "ACC: 0.671875, MCC: 0.34055756704227924\n",
      "Epoch 0, Loss(train/val) 0.49433/0.48651. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.47244/0.46439. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.43987/0.44528. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.40721/0.43375. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.37857/0.42004. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.36311/0.41299. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.34936/0.41155. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.33773/0.40281. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.32551/0.36913. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.32317/0.36593. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.31280/0.36705. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.31298/0.32915. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.33615/0.33844. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.31003/0.34274. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.29965/0.34168. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.30619/0.34855. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.29444/0.34589. Took 0.16 sec\n",
      "Epoch 17, Loss(train/val) 0.28991/0.35245. Took 0.16 sec\n",
      "Epoch 18, Loss(train/val) 0.29192/0.33948. Took 0.17 sec\n",
      "Epoch 19, Loss(train/val) 0.28125/0.32436. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.28917/0.29921. Took 0.16 sec\n",
      "Epoch 21, Loss(train/val) 0.28999/0.32868. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.28032/0.31995. Took 0.15 sec\n",
      "Epoch 23, Loss(train/val) 0.28472/0.32316. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.28851/0.32381. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.26670/0.32841. Took 0.16 sec\n",
      "Epoch 26, Loss(train/val) 0.26966/0.32198. Took 0.17 sec\n",
      "Epoch 27, Loss(train/val) 0.25863/0.27727. Took 0.17 sec\n",
      "Epoch 28, Loss(train/val) 0.26318/0.30779. Took 0.18 sec\n",
      "Epoch 29, Loss(train/val) 0.25236/0.30568. Took 0.16 sec\n",
      "Epoch 30, Loss(train/val) 0.26500/0.32077. Took 0.18 sec\n",
      "Epoch 31, Loss(train/val) 0.24240/0.30320. Took 0.16 sec\n",
      "Epoch 32, Loss(train/val) 0.25371/0.30230. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.24942/0.31230. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.24298/0.33390. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.24909/0.30894. Took 0.15 sec\n",
      "Epoch 36, Loss(train/val) 0.23560/0.28886. Took 0.17 sec\n",
      "Epoch 37, Loss(train/val) 0.22435/0.32417. Took 0.20 sec\n",
      "Epoch 38, Loss(train/val) 0.21986/0.30154. Took 0.15 sec\n",
      "Epoch 39, Loss(train/val) 0.22673/0.27334. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.23851/0.32619. Took 0.15 sec\n",
      "Epoch 41, Loss(train/val) 0.22297/0.38112. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.23150/0.34317. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.22293/0.30684. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.22251/0.34505. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.21727/0.31954. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.22502/0.31878. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.21414/0.32178. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.22446/0.30668. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.22326/0.31916. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.21248/0.33307. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.21584/0.34344. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.20580/0.32879. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) 0.20087/0.30964. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.20159/0.34138. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.20738/0.37780. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.20893/0.33761. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.21348/0.30264. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.19825/0.30971. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.20160/0.35971. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.19531/0.34644. Took 0.14 sec\n",
      "Epoch 61, Loss(train/val) 0.19930/0.34772. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.19573/0.30292. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.19072/0.31000. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.18932/0.32705. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.18740/0.32407. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.17673/0.32934. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.17692/0.32062. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.17706/0.33566. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.17784/0.33350. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.17767/0.35959. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.17793/0.33444. Took 0.15 sec\n",
      "Epoch 72, Loss(train/val) 0.17061/0.30390. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.16667/0.35289. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.16837/0.31310. Took 0.15 sec\n",
      "Epoch 75, Loss(train/val) 0.16996/0.34368. Took 0.15 sec\n",
      "Epoch 76, Loss(train/val) 0.16147/0.34013. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.16515/0.34604. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.16803/0.33015. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.16040/0.32081. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.16319/0.31034. Took 0.14 sec\n",
      "Epoch 81, Loss(train/val) 0.15727/0.31624. Took 0.15 sec\n",
      "Epoch 82, Loss(train/val) 0.15437/0.32561. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.16040/0.29254. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.16059/0.31767. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.16187/0.30210. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.16682/0.32440. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.16187/0.30872. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.15277/0.31297. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.14403/0.31749. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.14559/0.32416. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.14719/0.31841. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.15391/0.31725. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.13955/0.31485. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.14052/0.34646. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.14563/0.34572. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.13604/0.31647. Took 0.14 sec\n",
      "Epoch 97, Loss(train/val) 0.14462/0.28549. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.14040/0.33934. Took 0.14 sec\n",
      "Epoch 99, Loss(train/val) 0.15251/0.31194. Took 0.15 sec\n",
      "ACC: 0.609375, MCC: 0.22452606449532778\n",
      "Epoch 0, Loss(train/val) 0.49225/0.48745. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.47201/0.47340. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.44851/0.45970. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.42103/0.44747. Took 0.17 sec\n",
      "Epoch 4, Loss(train/val) 0.40338/0.44315. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.38532/0.43528. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.36769/0.43715. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.35970/0.42777. Took 0.15 sec\n",
      "Epoch 8, Loss(train/val) 0.34870/0.42002. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.33262/0.42310. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.32128/0.43336. Took 0.15 sec\n",
      "Epoch 11, Loss(train/val) 0.30828/0.41567. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.29540/0.40328. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.30161/0.41176. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.28757/0.41985. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.28842/0.38117. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.28581/0.39527. Took 0.15 sec\n",
      "Epoch 17, Loss(train/val) 0.26678/0.40676. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.27793/0.42220. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.26448/0.39855. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.25422/0.39772. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.24281/0.39222. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.24252/0.40069. Took 0.17 sec\n",
      "Epoch 23, Loss(train/val) 0.23778/0.39159. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.24402/0.39738. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.23932/0.40018. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.23335/0.38941. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.23345/0.38626. Took 0.18 sec\n",
      "Epoch 28, Loss(train/val) 0.23197/0.40290. Took 0.19 sec\n",
      "Epoch 29, Loss(train/val) 0.22173/0.37878. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.21733/0.40316. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.21713/0.39108. Took 0.16 sec\n",
      "Epoch 32, Loss(train/val) 0.21513/0.38108. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.20786/0.39587. Took 0.16 sec\n",
      "Epoch 34, Loss(train/val) 0.20967/0.38240. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.20638/0.38703. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.19914/0.39484. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.19627/0.38715. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.20206/0.40091. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.19850/0.40634. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.19739/0.40526. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.19177/0.39720. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.18788/0.38561. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.19908/0.40225. Took 0.15 sec\n",
      "Epoch 44, Loss(train/val) 0.18242/0.38214. Took 0.16 sec\n",
      "Epoch 45, Loss(train/val) 0.18245/0.37788. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.18250/0.40538. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.18061/0.37958. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.17391/0.39753. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.17774/0.39888. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.18018/0.38455. Took 0.14 sec\n",
      "Epoch 51, Loss(train/val) 0.18349/0.38258. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.17621/0.40057. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.17988/0.40196. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.17467/0.37512. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.16909/0.38318. Took 0.16 sec\n",
      "Epoch 56, Loss(train/val) 0.17208/0.39008. Took 0.15 sec\n",
      "Epoch 57, Loss(train/val) 0.16766/0.38849. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.17490/0.41396. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.16691/0.39003. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.17018/0.38754. Took 0.15 sec\n",
      "Epoch 61, Loss(train/val) 0.15988/0.39087. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.16479/0.38222. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.15514/0.38982. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.16367/0.40183. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.16409/0.39529. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.15155/0.40235. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) 0.15494/0.39769. Took 0.16 sec\n",
      "Epoch 68, Loss(train/val) 0.15299/0.38124. Took 0.19 sec\n",
      "Epoch 69, Loss(train/val) 0.15206/0.38985. Took 0.17 sec\n",
      "Epoch 70, Loss(train/val) 0.15428/0.38170. Took 0.17 sec\n",
      "Epoch 71, Loss(train/val) 0.15293/0.37447. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.14734/0.38294. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.14534/0.38887. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.14598/0.37916. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) 0.14295/0.37847. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.14567/0.38515. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.14613/0.38163. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.14603/0.37322. Took 0.14 sec\n",
      "Epoch 79, Loss(train/val) 0.15465/0.38262. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.14231/0.37708. Took 0.14 sec\n",
      "Epoch 81, Loss(train/val) 0.14237/0.37930. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.14115/0.38385. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.14098/0.38404. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.13958/0.38719. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.14934/0.38789. Took 0.15 sec\n",
      "Epoch 86, Loss(train/val) 0.14433/0.39642. Took 0.15 sec\n",
      "Epoch 87, Loss(train/val) 0.14255/0.37106. Took 0.15 sec\n",
      "Epoch 88, Loss(train/val) 0.14872/0.37969. Took 0.17 sec\n",
      "Epoch 89, Loss(train/val) 0.13968/0.37660. Took 0.15 sec\n",
      "Epoch 90, Loss(train/val) 0.13132/0.38327. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.13570/0.38309. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.13075/0.38415. Took 0.16 sec\n",
      "Epoch 93, Loss(train/val) 0.13784/0.38141. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.13383/0.37840. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.12942/0.37769. Took 0.16 sec\n",
      "Epoch 96, Loss(train/val) 0.13503/0.38880. Took 0.15 sec\n",
      "Epoch 97, Loss(train/val) 0.13132/0.36449. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.13387/0.37990. Took 0.18 sec\n",
      "Epoch 99, Loss(train/val) 0.12747/0.36605. Took 0.14 sec\n",
      "ACC: 0.609375, MCC: 0.2512366785266634\n",
      "Epoch 0, Loss(train/val) 0.49680/0.47839. Took 0.16 sec\n",
      "Epoch 1, Loss(train/val) 0.48039/0.44568. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.45816/0.40298. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.42758/0.37212. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.40431/0.33607. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.38752/0.33001. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.37284/0.30613. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.36610/0.40085. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.35859/0.42805. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.34295/0.38045. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.33294/0.39750. Took 0.15 sec\n",
      "Epoch 11, Loss(train/val) 0.32968/0.45103. Took 0.15 sec\n",
      "Epoch 12, Loss(train/val) 0.32409/0.37541. Took 0.15 sec\n",
      "Epoch 13, Loss(train/val) 0.31072/0.41917. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.30973/0.47035. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.30538/0.42730. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.29857/0.47145. Took 0.15 sec\n",
      "Epoch 17, Loss(train/val) 0.29755/0.41649. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.29674/0.42346. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.28976/0.47412. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.29367/0.43943. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.29206/0.41973. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.27840/0.44204. Took 0.15 sec\n",
      "Epoch 23, Loss(train/val) 0.28294/0.45149. Took 0.18 sec\n",
      "Epoch 24, Loss(train/val) 0.26518/0.43059. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.26575/0.44635. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.27641/0.44731. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.26224/0.44272. Took 0.19 sec\n",
      "Epoch 28, Loss(train/val) 0.25526/0.45626. Took 0.16 sec\n",
      "Epoch 29, Loss(train/val) 0.26569/0.45370. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.25484/0.44444. Took 0.20 sec\n",
      "Epoch 31, Loss(train/val) 0.24777/0.46926. Took 0.21 sec\n",
      "Epoch 32, Loss(train/val) 0.26015/0.46793. Took 0.17 sec\n",
      "Epoch 33, Loss(train/val) 0.24696/0.43909. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.24188/0.44118. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.23580/0.43294. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.24437/0.43772. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.24135/0.45535. Took 0.17 sec\n",
      "Epoch 38, Loss(train/val) 0.24448/0.44413. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.23620/0.43814. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.22867/0.41738. Took 0.15 sec\n",
      "Epoch 41, Loss(train/val) 0.22245/0.42013. Took 0.15 sec\n",
      "Epoch 42, Loss(train/val) 0.23260/0.41990. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.22350/0.43973. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.21962/0.46513. Took 0.16 sec\n",
      "Epoch 45, Loss(train/val) 0.21376/0.40549. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.21145/0.45924. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.22048/0.41328. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.20857/0.46972. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.20759/0.41812. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.20314/0.43824. Took 0.15 sec\n",
      "Epoch 51, Loss(train/val) 0.20160/0.41079. Took 0.15 sec\n",
      "Epoch 52, Loss(train/val) 0.19118/0.41979. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) 0.20117/0.42754. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.19853/0.45101. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.20129/0.41894. Took 0.15 sec\n",
      "Epoch 56, Loss(train/val) 0.20455/0.42876. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.18344/0.45624. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.21236/0.43549. Took 0.14 sec\n",
      "Epoch 59, Loss(train/val) 0.20291/0.49088. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.19327/0.47556. Took 0.14 sec\n",
      "Epoch 61, Loss(train/val) 0.19103/0.48312. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.20873/0.39895. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.20423/0.47595. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.19935/0.51646. Took 0.16 sec\n",
      "Epoch 65, Loss(train/val) 0.18196/0.51306. Took 0.15 sec\n",
      "Epoch 66, Loss(train/val) 0.17914/0.49842. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) 0.18374/0.41961. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.17365/0.46744. Took 0.16 sec\n",
      "Epoch 69, Loss(train/val) 0.18295/0.42045. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.18357/0.48976. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.16920/0.46219. Took 0.16 sec\n",
      "Epoch 72, Loss(train/val) 0.17663/0.50629. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.16853/0.49715. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.17824/0.50850. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.16692/0.47501. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.17096/0.49329. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.17096/0.47767. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.17458/0.47336. Took 0.14 sec\n",
      "Epoch 79, Loss(train/val) 0.16434/0.48057. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.16452/0.48968. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.17907/0.46577. Took 0.15 sec\n",
      "Epoch 82, Loss(train/val) 0.16117/0.50065. Took 0.15 sec\n",
      "Epoch 83, Loss(train/val) 0.16285/0.47114. Took 0.16 sec\n",
      "Epoch 84, Loss(train/val) 0.16132/0.48795. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.17318/0.46771. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.18319/0.46070. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.16772/0.49075. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.17207/0.44613. Took 0.14 sec\n",
      "Epoch 89, Loss(train/val) 0.16745/0.47279. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.15582/0.50778. Took 0.14 sec\n",
      "Epoch 91, Loss(train/val) 0.16326/0.52380. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.15923/0.48645. Took 0.15 sec\n",
      "Epoch 93, Loss(train/val) 0.15854/0.46728. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.16406/0.49621. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.15890/0.46781. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.15675/0.43237. Took 0.16 sec\n",
      "Epoch 97, Loss(train/val) 0.16025/0.51485. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.16336/0.49501. Took 0.17 sec\n",
      "Epoch 99, Loss(train/val) 0.15389/0.47607. Took 0.16 sec\n",
      "ACC: 0.71875, MCC: 0.42276002160669474\n",
      "Epoch 0, Loss(train/val) 0.49426/0.48302. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.47677/0.45138. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.44861/0.40656. Took 0.15 sec\n",
      "Epoch 3, Loss(train/val) 0.41902/0.37195. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.39740/0.34213. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.38567/0.33173. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.37130/0.32436. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.36055/0.34442. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.36364/0.28112. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.36430/0.27571. Took 0.15 sec\n",
      "Epoch 10, Loss(train/val) 0.35174/0.31612. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.34621/0.28091. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.34723/0.28163. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.34066/0.28307. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.33448/0.30448. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.33801/0.31404. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.33731/0.26594. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.32499/0.29516. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.31220/0.28437. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.30384/0.28185. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.30484/0.28208. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.29346/0.28265. Took 0.16 sec\n",
      "Epoch 22, Loss(train/val) 0.30101/0.27807. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.29159/0.27138. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.28381/0.27940. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.30221/0.37738. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.29912/0.41048. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.29794/0.38477. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.28394/0.39071. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.27397/0.37849. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.27289/0.38378. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.26150/0.40224. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.26165/0.35891. Took 0.16 sec\n",
      "Epoch 33, Loss(train/val) 0.25179/0.35240. Took 0.16 sec\n",
      "Epoch 34, Loss(train/val) 0.26560/0.39348. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.25385/0.38333. Took 0.15 sec\n",
      "Epoch 36, Loss(train/val) 0.24972/0.34224. Took 0.16 sec\n",
      "Epoch 37, Loss(train/val) 0.24288/0.39204. Took 0.15 sec\n",
      "Epoch 38, Loss(train/val) 0.24983/0.34092. Took 0.18 sec\n",
      "Epoch 39, Loss(train/val) 0.23476/0.31548. Took 0.20 sec\n",
      "Epoch 40, Loss(train/val) 0.23778/0.28150. Took 0.15 sec\n",
      "Epoch 41, Loss(train/val) 0.23211/0.29078. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.23813/0.27570. Took 0.15 sec\n",
      "Epoch 43, Loss(train/val) 0.22793/0.28009. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.22172/0.28743. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) 0.23281/0.28363. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.21691/0.29419. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.21308/0.31959. Took 0.15 sec\n",
      "Epoch 48, Loss(train/val) 0.22116/0.37054. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.22299/0.34054. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.21678/0.34225. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.21757/0.31461. Took 0.15 sec\n",
      "Epoch 52, Loss(train/val) 0.21681/0.30623. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) 0.21697/0.31987. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.20872/0.36967. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.20706/0.35204. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.20496/0.33861. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.20207/0.37732. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.18859/0.33908. Took 0.14 sec\n",
      "Epoch 59, Loss(train/val) 0.20007/0.33171. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.19648/0.37368. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.19365/0.35414. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.19587/0.34555. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.17993/0.36096. Took 0.15 sec\n",
      "Epoch 64, Loss(train/val) 0.18320/0.36839. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.18368/0.36791. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.17624/0.32198. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) 0.18561/0.35221. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.17975/0.34828. Took 0.14 sec\n",
      "Epoch 69, Loss(train/val) 0.17979/0.36110. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.16862/0.32499. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.18605/0.35732. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.19341/0.29133. Took 0.15 sec\n",
      "Epoch 73, Loss(train/val) 0.16803/0.32286. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.17116/0.32573. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) 0.16388/0.29356. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.16953/0.31823. Took 0.17 sec\n",
      "Epoch 77, Loss(train/val) 0.15577/0.37508. Took 0.19 sec\n",
      "Epoch 78, Loss(train/val) 0.16651/0.33463. Took 0.15 sec\n",
      "Epoch 79, Loss(train/val) 0.16383/0.30657. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.16886/0.31375. Took 0.16 sec\n",
      "Epoch 81, Loss(train/val) 0.16460/0.33394. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.15702/0.30900. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) 0.16944/0.34482. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.15833/0.33310. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.15250/0.33554. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.14709/0.34640. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.15060/0.33052. Took 0.15 sec\n",
      "Epoch 88, Loss(train/val) 0.14294/0.34598. Took 0.14 sec\n",
      "Epoch 89, Loss(train/val) 0.13785/0.31083. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.14555/0.34396. Took 0.14 sec\n",
      "Epoch 91, Loss(train/val) 0.14620/0.32840. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.14320/0.35597. Took 0.15 sec\n",
      "Epoch 93, Loss(train/val) 0.14460/0.35910. Took 0.15 sec\n",
      "Epoch 94, Loss(train/val) 0.14707/0.32773. Took 0.14 sec\n",
      "Epoch 95, Loss(train/val) 0.13896/0.37948. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.13921/0.36006. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.13427/0.36425. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.13170/0.36392. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.13760/0.36400. Took 0.13 sec\n",
      "ACC: 0.734375, MCC: 0.44134202205058454\n",
      "Epoch 0, Loss(train/val) 0.49318/0.47650. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.47418/0.43221. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.44557/0.37578. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.41302/0.33971. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.38987/0.31798. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.37487/0.30195. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.36324/0.29658. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.35276/0.28697. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.34397/0.28131. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.33283/0.26093. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.33344/0.27063. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.31866/0.25643. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.31319/0.27027. Took 0.15 sec\n",
      "Epoch 13, Loss(train/val) 0.31198/0.25971. Took 0.19 sec\n",
      "Epoch 14, Loss(train/val) 0.31055/0.21334. Took 0.15 sec\n",
      "Epoch 15, Loss(train/val) 0.30611/0.23483. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.30660/0.21904. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.29773/0.21886. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.28736/0.22039. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.28777/0.22129. Took 0.15 sec\n",
      "Epoch 20, Loss(train/val) 0.29136/0.20918. Took 0.15 sec\n",
      "Epoch 21, Loss(train/val) 0.28933/0.19799. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.27890/0.19607. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.27538/0.22188. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.27202/0.20703. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.26792/0.22375. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.26687/0.22484. Took 0.15 sec\n",
      "Epoch 27, Loss(train/val) 0.26667/0.20690. Took 0.13 sec\n",
      "Epoch 28, Loss(train/val) 0.26924/0.23461. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.25931/0.21820. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.25656/0.22253. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.24994/0.21741. Took 0.16 sec\n",
      "Epoch 32, Loss(train/val) 0.25156/0.23238. Took 0.16 sec\n",
      "Epoch 33, Loss(train/val) 0.23882/0.23089. Took 0.16 sec\n",
      "Epoch 34, Loss(train/val) 0.24574/0.23172. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.23913/0.23063. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.23151/0.25560. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.23816/0.23873. Took 0.15 sec\n",
      "Epoch 38, Loss(train/val) 0.24605/0.27153. Took 0.15 sec\n",
      "Epoch 39, Loss(train/val) 0.22925/0.25031. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.23399/0.26269. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.23645/0.27302. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.23459/0.23583. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.22527/0.25419. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.22085/0.26603. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.21495/0.26420. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.22472/0.28392. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.22039/0.24555. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.22428/0.23244. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.22273/0.29062. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.20842/0.25166. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.20409/0.24805. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.20293/0.27076. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) 0.21681/0.27612. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.21307/0.28829. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.21024/0.24322. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.21317/0.26335. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.20174/0.26531. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.20159/0.25801. Took 0.14 sec\n",
      "Epoch 59, Loss(train/val) 0.21147/0.25067. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.20731/0.27129. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.20323/0.26878. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.19911/0.26641. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.19543/0.27821. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.20060/0.27772. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.19189/0.27652. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.18935/0.26132. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.18995/0.27347. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.19377/0.27169. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.21205/0.24678. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.18971/0.24998. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.18698/0.25995. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.18379/0.24962. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.18426/0.27283. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.17923/0.29362. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.18405/0.27992. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.17125/0.28166. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.17748/0.32534. Took 0.15 sec\n",
      "Epoch 78, Loss(train/val) 0.17491/0.29762. Took 0.14 sec\n",
      "Epoch 79, Loss(train/val) 0.17377/0.28267. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.17715/0.30664. Took 0.14 sec\n",
      "Epoch 81, Loss(train/val) 0.17580/0.29353. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.17110/0.29745. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) 0.17180/0.27334. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.18123/0.28681. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.17340/0.29200. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.17360/0.26349. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.17161/0.26771. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.16751/0.29889. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.15856/0.30920. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.17077/0.28608. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.16593/0.29519. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.15749/0.26420. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.16061/0.27865. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.15241/0.31623. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.14587/0.26980. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.14946/0.31110. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.15444/0.25936. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.15987/0.28739. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.15162/0.25597. Took 0.13 sec\n",
      "ACC: 0.578125, MCC: 0.31829167735840913\n",
      "Epoch 0, Loss(train/val) 0.48998/0.48337. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.46691/0.45589. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.43785/0.39950. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.41090/0.33475. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.39180/0.30126. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.37650/0.28206. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.36257/0.28104. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.35308/0.27957. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.34372/0.36565. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.32893/0.32427. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.32798/0.35497. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.31584/0.37189. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.31619/0.36766. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.30206/0.40921. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.29703/0.44018. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.30139/0.37795. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.30183/0.31338. Took 0.15 sec\n",
      "Epoch 17, Loss(train/val) 0.29021/0.40419. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.28636/0.41377. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.28246/0.38862. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.28078/0.44683. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.27437/0.45824. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.27894/0.44397. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.27388/0.44584. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.26966/0.42980. Took 0.15 sec\n",
      "Epoch 25, Loss(train/val) 0.27106/0.44802. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.27084/0.46182. Took 0.15 sec\n",
      "Epoch 27, Loss(train/val) 0.28269/0.44022. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.27234/0.48137. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.26892/0.42388. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.25876/0.46359. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.25811/0.46937. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.25533/0.44848. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.25548/0.45300. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.25423/0.42527. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.25446/0.44157. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.24888/0.40152. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.26335/0.44760. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.24877/0.46999. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.25397/0.46882. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.24348/0.45119. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.24939/0.44722. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.23889/0.48019. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.23916/0.46325. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.23821/0.44920. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.23655/0.45995. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.23573/0.47943. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.23926/0.46961. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.23334/0.45884. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.22491/0.45710. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.22765/0.46194. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.21933/0.46849. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.22545/0.48818. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.24637/0.45513. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.23231/0.47178. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.22540/0.48542. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.21697/0.48654. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.22424/0.50544. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.21528/0.48329. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.22370/0.48598. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.20540/0.47678. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.20507/0.47421. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.21340/0.46536. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.20691/0.47863. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.20790/0.47164. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.20654/0.45953. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.20004/0.45990. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.20328/0.46413. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.21619/0.42861. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.19663/0.44005. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.19276/0.44416. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.20209/0.43827. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.19734/0.44959. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.20983/0.45872. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.20088/0.48457. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.19875/0.46157. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.18855/0.47410. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.19547/0.45749. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.18707/0.43764. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.18266/0.44927. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.20300/0.45475. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.19640/0.46142. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.19364/0.40010. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.18392/0.39995. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.18649/0.42367. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.18603/0.47064. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.18733/0.43832. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.18939/0.42415. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.19395/0.44193. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.18952/0.41898. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.18050/0.40306. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.18494/0.41946. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.18064/0.43319. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.17397/0.42680. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.18306/0.44481. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.17635/0.41488. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.16666/0.39327. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.18294/0.37655. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.16816/0.38564. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.17713/0.40923. Took 0.13 sec\n",
      "ACC: 0.6875, MCC: 0.37998029782867415\n",
      "Epoch 0, Loss(train/val) 0.49654/0.49441. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.47974/0.48020. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.45330/0.45355. Took 0.15 sec\n",
      "Epoch 3, Loss(train/val) 0.41877/0.43955. Took 0.15 sec\n",
      "Epoch 4, Loss(train/val) 0.40157/0.43505. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.39169/0.42720. Took 0.15 sec\n",
      "Epoch 6, Loss(train/val) 0.38014/0.42044. Took 0.16 sec\n",
      "Epoch 7, Loss(train/val) 0.36524/0.41549. Took 0.17 sec\n",
      "Epoch 8, Loss(train/val) 0.35719/0.40299. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.35539/0.39203. Took 0.16 sec\n",
      "Epoch 10, Loss(train/val) 0.34897/0.39919. Took 0.15 sec\n",
      "Epoch 11, Loss(train/val) 0.34053/0.40140. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.32752/0.38929. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.31774/0.37747. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.31531/0.39546. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.30348/0.39853. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.30634/0.38925. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.30459/0.37808. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.29267/0.39764. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.28815/0.37086. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.29304/0.37629. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.29214/0.38394. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.28022/0.39571. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.27251/0.38533. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.26264/0.38139. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.25924/0.37754. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.27582/0.38702. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.25845/0.37639. Took 0.13 sec\n",
      "Epoch 28, Loss(train/val) 0.25395/0.41195. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.25663/0.35334. Took 0.13 sec\n",
      "Epoch 30, Loss(train/val) 0.25911/0.41799. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.25389/0.39275. Took 0.13 sec\n",
      "Epoch 32, Loss(train/val) 0.24692/0.37566. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.24052/0.39707. Took 0.13 sec\n",
      "Epoch 34, Loss(train/val) 0.25187/0.38842. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.25167/0.38044. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.23342/0.37122. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.24748/0.39631. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.23624/0.36493. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.24208/0.37600. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.24545/0.37731. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.22784/0.37570. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.23863/0.39426. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.23634/0.38472. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.23246/0.38700. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.22438/0.37878. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.21968/0.37267. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.22016/0.37287. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.22171/0.39810. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.23288/0.33006. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.23956/0.35722. Took 0.15 sec\n",
      "Epoch 51, Loss(train/val) 0.22634/0.34536. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.23117/0.37403. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.21467/0.36450. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.21096/0.37418. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.20956/0.35426. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.20538/0.35525. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.21394/0.34296. Took 0.12 sec\n",
      "Epoch 58, Loss(train/val) 0.20930/0.34661. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.21480/0.36055. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.20796/0.37898. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.20273/0.35804. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.20937/0.38982. Took 0.15 sec\n",
      "Epoch 63, Loss(train/val) 0.21914/0.37713. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.19997/0.36432. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.19812/0.36699. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.19204/0.35285. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) 0.20360/0.36964. Took 0.17 sec\n",
      "Epoch 68, Loss(train/val) 0.19306/0.36305. Took 0.15 sec\n",
      "Epoch 69, Loss(train/val) 0.19632/0.35279. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.19217/0.36868. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.19754/0.37370. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.19518/0.36435. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.19088/0.35891. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.17633/0.36017. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.18649/0.36737. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.18137/0.34301. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.18670/0.33317. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.17793/0.34100. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.18631/0.39603. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.18603/0.36463. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.18495/0.36060. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.18228/0.35760. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) 0.18297/0.36566. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.18341/0.35192. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.17477/0.35703. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.17251/0.35778. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.17429/0.36608. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.17108/0.37827. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.16295/0.38028. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.16895/0.36813. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.16613/0.37741. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.15734/0.38817. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.16407/0.37503. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.17053/0.38687. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.16130/0.37740. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.16171/0.37846. Took 0.14 sec\n",
      "Epoch 97, Loss(train/val) 0.15534/0.37922. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.16774/0.37983. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.16473/0.36983. Took 0.13 sec\n",
      "ACC: 0.671875, MCC: 0.34263375168884014\n",
      "Epoch 0, Loss(train/val) 0.49383/0.49289. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.47712/0.48466. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.44916/0.47462. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.41826/0.47022. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.40575/0.46086. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.39578/0.43943. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.38727/0.43288. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.38019/0.40760. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.36944/0.38548. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.36241/0.42150. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.35508/0.32869. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.33146/0.32539. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.32188/0.31976. Took 0.15 sec\n",
      "Epoch 13, Loss(train/val) 0.31813/0.32841. Took 0.17 sec\n",
      "Epoch 14, Loss(train/val) 0.30921/0.28943. Took 0.18 sec\n",
      "Epoch 15, Loss(train/val) 0.30775/0.30574. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.30067/0.31322. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.29746/0.33282. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.29055/0.30004. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.28393/0.29013. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.28837/0.27495. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.27719/0.30600. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.27667/0.31229. Took 0.18 sec\n",
      "Epoch 23, Loss(train/val) 0.27666/0.31294. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.27173/0.30039. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.26995/0.33843. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.27414/0.32858. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.26492/0.31436. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.26191/0.32176. Took 0.16 sec\n",
      "Epoch 29, Loss(train/val) 0.25657/0.33862. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.26836/0.26920. Took 0.17 sec\n",
      "Epoch 31, Loss(train/val) 0.25584/0.30807. Took 0.17 sec\n",
      "Epoch 32, Loss(train/val) 0.24626/0.33443. Took 0.19 sec\n",
      "Epoch 33, Loss(train/val) 0.24391/0.32323. Took 0.19 sec\n",
      "Epoch 34, Loss(train/val) 0.24848/0.31596. Took 0.17 sec\n",
      "Epoch 35, Loss(train/val) 0.24480/0.29520. Took 0.17 sec\n",
      "Epoch 36, Loss(train/val) 0.25075/0.31667. Took 0.20 sec\n",
      "Epoch 37, Loss(train/val) 0.24423/0.32514. Took 0.17 sec\n",
      "Epoch 38, Loss(train/val) 0.23246/0.30466. Took 0.15 sec\n",
      "Epoch 39, Loss(train/val) 0.23141/0.27251. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.23095/0.30076. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.23468/0.32869. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.22909/0.28411. Took 0.16 sec\n",
      "Epoch 43, Loss(train/val) 0.22842/0.33644. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.22129/0.32462. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.21980/0.31915. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.21688/0.33654. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.21428/0.34617. Took 0.16 sec\n",
      "Epoch 48, Loss(train/val) 0.21837/0.32777. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.22518/0.32513. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.20888/0.32813. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.22454/0.32846. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.21282/0.31942. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) 0.21066/0.30979. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.20683/0.34079. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.20317/0.31581. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.19473/0.31249. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.20394/0.31719. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.20964/0.31846. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.19214/0.32641. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.20472/0.31756. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.19910/0.32084. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.18886/0.32563. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.19297/0.32394. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.18262/0.33377. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.18055/0.30515. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.18218/0.32571. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.18174/0.30271. Took 0.15 sec\n",
      "Epoch 68, Loss(train/val) 0.17995/0.32187. Took 0.16 sec\n",
      "Epoch 69, Loss(train/val) 0.18098/0.32332. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.17984/0.32134. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.16573/0.32665. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.17244/0.33423. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.18365/0.34252. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.17644/0.30281. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) 0.17693/0.32755. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.16650/0.32430. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.16777/0.29461. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.17527/0.30795. Took 0.14 sec\n",
      "Epoch 79, Loss(train/val) 0.16799/0.33559. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.16323/0.32415. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.16804/0.32657. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.17078/0.34186. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.16593/0.31791. Took 0.12 sec\n",
      "Epoch 84, Loss(train/val) 0.15720/0.32999. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.16068/0.32382. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.15721/0.31272. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.16043/0.32403. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.16065/0.32092. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.16119/0.32404. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.15263/0.31888. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.15059/0.32290. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.15231/0.31648. Took 0.15 sec\n",
      "Epoch 93, Loss(train/val) 0.15815/0.31832. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.14377/0.32341. Took 0.14 sec\n",
      "Epoch 95, Loss(train/val) 0.15234/0.32639. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.15052/0.31732. Took 0.14 sec\n",
      "Epoch 97, Loss(train/val) 0.14913/0.31630. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.15058/0.31869. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.14602/0.31521. Took 0.13 sec\n",
      "ACC: 0.578125, MCC: 0.28137670960041816\n",
      "Epoch 0, Loss(train/val) 0.49603/0.48716. Took 0.13 sec\n",
      "Epoch 1, Loss(train/val) 0.48147/0.45796. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.45619/0.41992. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.42833/0.40225. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.41075/0.39030. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.39895/0.37295. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.38672/0.36461. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.37491/0.34987. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.36743/0.35722. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.35699/0.31721. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.34165/0.32834. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.33103/0.32959. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.32579/0.38652. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.33351/0.30750. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.32372/0.35614. Took 0.15 sec\n",
      "Epoch 15, Loss(train/val) 0.31609/0.32729. Took 0.18 sec\n",
      "Epoch 16, Loss(train/val) 0.30176/0.32682. Took 0.19 sec\n",
      "Epoch 17, Loss(train/val) 0.32181/0.32678. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.30333/0.31749. Took 0.17 sec\n",
      "Epoch 19, Loss(train/val) 0.32117/0.31447. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.31639/0.32173. Took 0.15 sec\n",
      "Epoch 21, Loss(train/val) 0.29907/0.39296. Took 0.16 sec\n",
      "Epoch 22, Loss(train/val) 0.32266/0.36408. Took 0.17 sec\n",
      "Epoch 23, Loss(train/val) 0.30923/0.34029. Took 0.16 sec\n",
      "Epoch 24, Loss(train/val) 0.30521/0.34973. Took 0.18 sec\n",
      "Epoch 25, Loss(train/val) 0.28900/0.34968. Took 0.17 sec\n",
      "Epoch 26, Loss(train/val) 0.28828/0.35086. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.29523/0.33773. Took 0.16 sec\n",
      "Epoch 28, Loss(train/val) 0.28581/0.33301. Took 0.26 sec\n",
      "Epoch 29, Loss(train/val) 0.28309/0.32308. Took 0.19 sec\n",
      "Epoch 30, Loss(train/val) 0.28149/0.33521. Took 0.21 sec\n",
      "Epoch 31, Loss(train/val) 0.28632/0.32686. Took 0.17 sec\n",
      "Epoch 32, Loss(train/val) 0.26971/0.33230. Took 0.18 sec\n",
      "Epoch 33, Loss(train/val) 0.28454/0.33139. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.27640/0.33556. Took 0.16 sec\n",
      "Epoch 35, Loss(train/val) 0.27724/0.35850. Took 0.15 sec\n",
      "Epoch 36, Loss(train/val) 0.28166/0.30767. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.28050/0.31408. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.26485/0.33291. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.27276/0.29612. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.25919/0.29930. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.26227/0.30178. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.25397/0.27875. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.26014/0.26065. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.24952/0.27830. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.25542/0.26497. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.25216/0.31071. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.24160/0.30888. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.25526/0.30095. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.23469/0.29782. Took 0.16 sec\n",
      "Epoch 50, Loss(train/val) 0.23399/0.29782. Took 0.16 sec\n",
      "Epoch 51, Loss(train/val) 0.24908/0.29491. Took 0.15 sec\n",
      "Epoch 52, Loss(train/val) 0.24351/0.27996. Took 0.18 sec\n",
      "Epoch 53, Loss(train/val) 0.24007/0.29032. Took 0.18 sec\n",
      "Epoch 54, Loss(train/val) 0.23601/0.29401. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.23238/0.29989. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.24168/0.28806. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.25036/0.31687. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.24191/0.29107. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.22368/0.28615. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.22723/0.28496. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.22889/0.30420. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.22176/0.29375. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.22370/0.29896. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.22580/0.29839. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.23175/0.29780. Took 0.12 sec\n",
      "Epoch 66, Loss(train/val) 0.21740/0.28870. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.21944/0.28984. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.21839/0.28168. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.21178/0.28743. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.21248/0.27200. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.20184/0.29795. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.20018/0.31561. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.19906/0.28928. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.20431/0.28779. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.19490/0.27478. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.19258/0.29293. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.19494/0.28305. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.19880/0.27284. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.19378/0.27023. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.20143/0.28089. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.19368/0.27130. Took 0.15 sec\n",
      "Epoch 82, Loss(train/val) 0.19351/0.28057. Took 0.17 sec\n",
      "Epoch 83, Loss(train/val) 0.19133/0.27294. Took 0.15 sec\n",
      "Epoch 84, Loss(train/val) 0.19176/0.26551. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.18927/0.28374. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.18612/0.27083. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.19330/0.27309. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.19147/0.29048. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.18288/0.27573. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.17639/0.28456. Took 0.14 sec\n",
      "Epoch 91, Loss(train/val) 0.17972/0.28360. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.16846/0.27285. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.17317/0.26083. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.17200/0.25297. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.17459/0.26230. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.16710/0.27370. Took 0.14 sec\n",
      "Epoch 97, Loss(train/val) 0.17893/0.25121. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.18221/0.26116. Took 0.17 sec\n",
      "Epoch 99, Loss(train/val) 0.17212/0.26961. Took 0.15 sec\n",
      "ACC: 0.625, MCC: 0.26980637731157286\n",
      "Epoch 0, Loss(train/val) 0.49407/0.48861. Took 0.13 sec\n",
      "Epoch 1, Loss(train/val) 0.47580/0.46374. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.44711/0.42311. Took 0.12 sec\n",
      "Epoch 3, Loss(train/val) 0.41787/0.39001. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.40362/0.38273. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.38870/0.38291. Took 0.12 sec\n",
      "Epoch 6, Loss(train/val) 0.37885/0.38693. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.36906/0.37416. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.35155/0.38896. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.33946/0.37623. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.33437/0.34758. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.33402/0.34641. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.32550/0.35172. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.32030/0.33211. Took 0.16 sec\n",
      "Epoch 14, Loss(train/val) 0.31689/0.36925. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.31422/0.30830. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.30374/0.33493. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.29938/0.31401. Took 0.16 sec\n",
      "Epoch 18, Loss(train/val) 0.30059/0.31518. Took 0.15 sec\n",
      "Epoch 19, Loss(train/val) 0.29152/0.33378. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.28837/0.33153. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.28299/0.36233. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.28638/0.34623. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.27883/0.32619. Took 0.16 sec\n",
      "Epoch 24, Loss(train/val) 0.27700/0.32309. Took 0.15 sec\n",
      "Epoch 25, Loss(train/val) 0.27519/0.33780. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.26323/0.34307. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.26003/0.35077. Took 0.18 sec\n",
      "Epoch 28, Loss(train/val) 0.26184/0.35079. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.25180/0.34673. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.26053/0.36007. Took 0.16 sec\n",
      "Epoch 31, Loss(train/val) 0.25210/0.37100. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.24964/0.34189. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.26602/0.33675. Took 0.16 sec\n",
      "Epoch 34, Loss(train/val) 0.24657/0.37762. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.25205/0.33059. Took 0.13 sec\n",
      "Epoch 36, Loss(train/val) 0.25129/0.31648. Took 0.13 sec\n",
      "Epoch 37, Loss(train/val) 0.23157/0.33577. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.23271/0.36456. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.23060/0.37077. Took 0.15 sec\n",
      "Epoch 40, Loss(train/val) 0.22939/0.35929. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.22902/0.37941. Took 0.16 sec\n",
      "Epoch 42, Loss(train/val) 0.22566/0.34671. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.23203/0.34576. Took 0.15 sec\n",
      "Epoch 44, Loss(train/val) 0.22185/0.33361. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.22063/0.37698. Took 0.12 sec\n",
      "Epoch 46, Loss(train/val) 0.22238/0.31979. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.21634/0.37613. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.21628/0.35123. Took 0.15 sec\n",
      "Epoch 49, Loss(train/val) 0.22072/0.32285. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.21032/0.33998. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.21323/0.33541. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.21435/0.34325. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) 0.20539/0.37700. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.19760/0.36180. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.19837/0.39040. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.21058/0.37239. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.20128/0.29061. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.19723/0.36776. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.18652/0.37194. Took 0.12 sec\n",
      "Epoch 60, Loss(train/val) 0.19611/0.35153. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.18578/0.35300. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.18920/0.30722. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.19273/0.37580. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.19666/0.34949. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.18434/0.36362. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.19218/0.36535. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) 0.18095/0.34034. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.18329/0.36049. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.18438/0.32628. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.17899/0.32677. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.18287/0.33141. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.17933/0.34033. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.17640/0.33290. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.17519/0.30555. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.16723/0.33300. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.18076/0.30941. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.16617/0.33728. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.16720/0.34486. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.16761/0.32847. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.16732/0.35518. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.17097/0.34215. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.17638/0.35046. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.17226/0.34425. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.16366/0.32929. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.17047/0.34159. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.16439/0.32291. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.15536/0.31727. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.16089/0.32972. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.16383/0.34970. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.16083/0.33605. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.16594/0.33820. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.15800/0.34414. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.15429/0.34859. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.15573/0.35410. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.15475/0.37199. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.15227/0.33131. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.14650/0.31775. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.15046/0.37110. Took 0.14 sec\n",
      "Epoch 99, Loss(train/val) 0.14464/0.33049. Took 0.14 sec\n",
      "ACC: 0.671875, MCC: 0.3241163729049171\n",
      "Epoch 0, Loss(train/val) 0.49740/0.48886. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.48332/0.46591. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.45824/0.43153. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.43022/0.40718. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.40981/0.39463. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.39927/0.40025. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.39228/0.39520. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.38618/0.39253. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.37748/0.39500. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.37431/0.40415. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.36701/0.40068. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.35753/0.39530. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.34738/0.39187. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.33886/0.33658. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.33784/0.35752. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.32895/0.30938. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.30961/0.31923. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.31419/0.33159. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.29743/0.30675. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.29290/0.32907. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.28853/0.30102. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.28102/0.31007. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.27231/0.31168. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.27075/0.32121. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.26504/0.31098. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.26409/0.31203. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.25401/0.31335. Took 0.13 sec\n",
      "Epoch 27, Loss(train/val) 0.26684/0.32023. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.25654/0.31943. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.24942/0.30690. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.26284/0.31841. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.23582/0.31329. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.25089/0.30864. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.22752/0.33053. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.23969/0.30761. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.24352/0.31627. Took 0.13 sec\n",
      "Epoch 36, Loss(train/val) 0.22728/0.34513. Took 0.13 sec\n",
      "Epoch 37, Loss(train/val) 0.23754/0.30357. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.22312/0.33126. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.22746/0.28493. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.22781/0.31142. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.22783/0.31250. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.22134/0.29076. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.23079/0.32435. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.23196/0.26488. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) 0.22282/0.28303. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.22503/0.30650. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.21020/0.30515. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.21691/0.28079. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.20857/0.29786. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.20560/0.29312. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.19941/0.29929. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.19068/0.29855. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) 0.19020/0.30833. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.19508/0.30694. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.19447/0.32508. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.21720/0.30268. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.19667/0.33003. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.19891/0.28944. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.19776/0.32871. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.19275/0.29094. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.17413/0.32174. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.17677/0.28977. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.19538/0.30088. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.17926/0.29032. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.16688/0.29082. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.17763/0.31994. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.17884/0.31483. Took 0.12 sec\n",
      "Epoch 68, Loss(train/val) 0.18176/0.29088. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.17643/0.30002. Took 0.12 sec\n",
      "Epoch 70, Loss(train/val) 0.17451/0.30565. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.15753/0.27240. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.16861/0.27776. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.17116/0.31457. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.17607/0.30125. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.15691/0.31134. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.17069/0.30957. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.16458/0.30762. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.15830/0.31507. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.15056/0.31852. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.15983/0.29135. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.16692/0.31831. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.15732/0.30901. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.15590/0.28704. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.15569/0.31500. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.15352/0.31936. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.15647/0.32939. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.14956/0.31486. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.15135/0.35346. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.14780/0.34507. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.15527/0.32666. Took 0.14 sec\n",
      "Epoch 91, Loss(train/val) 0.14543/0.30958. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.15056/0.32595. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.15678/0.32086. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.14036/0.29860. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.14959/0.30370. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.13562/0.31883. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.14179/0.31436. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.14061/0.28829. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.13831/0.31664. Took 0.13 sec\n",
      "ACC: 0.671875, MCC: 0.39445217598501997\n",
      "Epoch 0, Loss(train/val) 0.49375/0.48127. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.47568/0.44288. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.44740/0.38650. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.41815/0.35689. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.40301/0.34498. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.39122/0.34066. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.38270/0.33366. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.38382/0.32739. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.37059/0.32141. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.36507/0.31431. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.35338/0.36146. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.34523/0.36437. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.33523/0.32996. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.32125/0.34220. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.31832/0.31123. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.33031/0.30462. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.32780/0.32635. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.30657/0.28714. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.29608/0.37430. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.30876/0.30355. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.30143/0.39178. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.29336/0.34356. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.30456/0.30376. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.29032/0.28404. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.30538/0.30630. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.28889/0.31564. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.26913/0.36613. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.27343/0.32098. Took 0.13 sec\n",
      "Epoch 28, Loss(train/val) 0.29000/0.38213. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.27936/0.37704. Took 0.13 sec\n",
      "Epoch 30, Loss(train/val) 0.28256/0.39705. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.27305/0.35955. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.26251/0.36400. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.27633/0.36905. Took 0.18 sec\n",
      "Epoch 34, Loss(train/val) 0.27828/0.39381. Took 0.16 sec\n",
      "Epoch 35, Loss(train/val) 0.27111/0.38409. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.26899/0.35017. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.24396/0.30482. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.26994/0.33292. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.25417/0.34868. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.25152/0.41032. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.25627/0.40155. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.26022/0.39712. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.23684/0.36740. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.22735/0.36969. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.23069/0.36645. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.24488/0.30789. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.24537/0.31196. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.23584/0.35023. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.23390/0.36788. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.22922/0.35956. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.22672/0.35242. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.22707/0.35375. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.22136/0.36467. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.21324/0.36241. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.22475/0.39897. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.21723/0.38217. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.20965/0.37329. Took 0.15 sec\n",
      "Epoch 58, Loss(train/val) 0.20530/0.37346. Took 0.15 sec\n",
      "Epoch 59, Loss(train/val) 0.20968/0.38970. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.20540/0.39214. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.22081/0.34450. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.22626/0.36814. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.20587/0.45818. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.19580/0.43590. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.20095/0.38034. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.20461/0.36689. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.19973/0.43112. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.19143/0.41712. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.18751/0.35399. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.18942/0.42082. Took 0.12 sec\n",
      "Epoch 71, Loss(train/val) 0.19203/0.38282. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.18731/0.38442. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.20079/0.36508. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.18854/0.36549. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.19202/0.39967. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.19579/0.40240. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.19916/0.40085. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.18649/0.36244. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.20139/0.31139. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.19790/0.37248. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.18415/0.36107. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.18108/0.35743. Took 0.12 sec\n",
      "Epoch 83, Loss(train/val) 0.18892/0.33102. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.18139/0.39235. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.18638/0.39307. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.17534/0.36387. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.17468/0.30163. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.16966/0.34668. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.17638/0.37903. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.16958/0.38116. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.16892/0.42686. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.16959/0.37520. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.15814/0.40118. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.16930/0.40748. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.16972/0.38931. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.16043/0.42209. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.15862/0.34352. Took 0.15 sec\n",
      "Epoch 98, Loss(train/val) 0.16635/0.35798. Took 0.15 sec\n",
      "Epoch 99, Loss(train/val) 0.15803/0.40214. Took 0.13 sec\n",
      "ACC: 0.75, MCC: 0.5128294906920802\n",
      "Epoch 0, Loss(train/val) 0.49199/0.47402. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.47434/0.42864. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.44384/0.36574. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.41342/0.32776. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.39495/0.29167. Took 0.15 sec\n",
      "Epoch 5, Loss(train/val) 0.38641/0.28604. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.37340/0.28566. Took 0.15 sec\n",
      "Epoch 7, Loss(train/val) 0.35914/0.30091. Took 0.16 sec\n",
      "Epoch 8, Loss(train/val) 0.34579/0.32452. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.33164/0.27615. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.31603/0.29912. Took 0.15 sec\n",
      "Epoch 11, Loss(train/val) 0.30762/0.30700. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.32144/0.29586. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.31292/0.30246. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.31343/0.28280. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.30186/0.30546. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.29753/0.32069. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.29819/0.30514. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.30979/0.32918. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.30305/0.34055. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.31637/0.30599. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.32022/0.29869. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.29695/0.28588. Took 0.15 sec\n",
      "Epoch 23, Loss(train/val) 0.29647/0.29192. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.27886/0.29885. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.27295/0.30267. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.28061/0.29062. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.26651/0.31080. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.27268/0.29659. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.26130/0.30579. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.25546/0.30368. Took 0.16 sec\n",
      "Epoch 31, Loss(train/val) 0.27383/0.31862. Took 0.13 sec\n",
      "Epoch 32, Loss(train/val) 0.27231/0.32376. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.25532/0.31074. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.25957/0.31090. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.25249/0.30787. Took 0.15 sec\n",
      "Epoch 36, Loss(train/val) 0.24924/0.31666. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.25957/0.31850. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.23401/0.31961. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.23277/0.31764. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.22543/0.32570. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.23550/0.32219. Took 0.12 sec\n",
      "Epoch 42, Loss(train/val) 0.22519/0.32057. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.22641/0.31279. Took 0.12 sec\n",
      "Epoch 44, Loss(train/val) 0.21280/0.32172. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.22559/0.31367. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.21770/0.31067. Took 0.12 sec\n",
      "Epoch 47, Loss(train/val) 0.21056/0.32145. Took 0.12 sec\n",
      "Epoch 48, Loss(train/val) 0.21479/0.32055. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.20554/0.31283. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.20720/0.32067. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.19631/0.31232. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.19656/0.32190. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.20210/0.34000. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.20306/0.32890. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.20238/0.31371. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.19239/0.31514. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.19143/0.32064. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.19206/0.33043. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.19237/0.33533. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.18113/0.30617. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.18463/0.31890. Took 0.12 sec\n",
      "Epoch 62, Loss(train/val) 0.17801/0.32509. Took 0.12 sec\n",
      "Epoch 63, Loss(train/val) 0.18034/0.32872. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.17953/0.31642. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.18007/0.32055. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.17513/0.32047. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.17800/0.32295. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.17401/0.33821. Took 0.14 sec\n",
      "Epoch 69, Loss(train/val) 0.16872/0.31574. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.17381/0.32678. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.16941/0.32010. Took 0.12 sec\n",
      "Epoch 72, Loss(train/val) 0.16532/0.32057. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.16752/0.33319. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.16654/0.33446. Took 0.12 sec\n",
      "Epoch 75, Loss(train/val) 0.17047/0.32515. Took 0.12 sec\n",
      "Epoch 76, Loss(train/val) 0.16534/0.32023. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.15706/0.31972. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.15700/0.31599. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.15598/0.30795. Took 0.12 sec\n",
      "Epoch 80, Loss(train/val) 0.15437/0.31419. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.15290/0.33055. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.15855/0.30817. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.15515/0.32016. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.15997/0.30546. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.15247/0.32400. Took 0.12 sec\n",
      "Epoch 86, Loss(train/val) 0.15089/0.31986. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.14361/0.31320. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.15363/0.32611. Took 0.12 sec\n",
      "Epoch 89, Loss(train/val) 0.14422/0.31477. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.14164/0.32267. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.14397/0.31840. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.14216/0.31711. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.14640/0.32697. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.13281/0.33069. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.14425/0.31924. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.13755/0.32181. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.14423/0.31335. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.14982/0.35082. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.14394/0.29687. Took 0.12 sec\n",
      "ACC: 0.609375, MCC: 0.23865721224648745\n",
      "Epoch 0, Loss(train/val) 0.49149/0.48338. Took 0.13 sec\n",
      "Epoch 1, Loss(train/val) 0.47168/0.44874. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.44178/0.39536. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.41265/0.36037. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.39715/0.34609. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.38741/0.34235. Took 0.12 sec\n",
      "Epoch 6, Loss(train/val) 0.38132/0.35524. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.36893/0.30536. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.36754/0.32828. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.35738/0.32391. Took 0.12 sec\n",
      "Epoch 10, Loss(train/val) 0.35056/0.31099. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.33188/0.29100. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.33217/0.29702. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.33310/0.29150. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.31571/0.37323. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.30857/0.38864. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.31809/0.33489. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.29970/0.37109. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.29792/0.40422. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.29726/0.43546. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.30144/0.39088. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.28637/0.44084. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.29050/0.44045. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.28525/0.41566. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.27655/0.45310. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.28067/0.43550. Took 0.16 sec\n",
      "Epoch 26, Loss(train/val) 0.27524/0.43357. Took 0.15 sec\n",
      "Epoch 27, Loss(train/val) 0.26793/0.44606. Took 0.13 sec\n",
      "Epoch 28, Loss(train/val) 0.26143/0.40378. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.26674/0.41829. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.25588/0.39592. Took 0.18 sec\n",
      "Epoch 31, Loss(train/val) 0.27209/0.42113. Took 0.16 sec\n",
      "Epoch 32, Loss(train/val) 0.25219/0.39370. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.25133/0.43295. Took 0.16 sec\n",
      "Epoch 34, Loss(train/val) 0.25118/0.40449. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.25217/0.43494. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.24249/0.43606. Took 0.16 sec\n",
      "Epoch 37, Loss(train/val) 0.24644/0.41125. Took 0.15 sec\n",
      "Epoch 38, Loss(train/val) 0.24965/0.42030. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.24333/0.42943. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.24317/0.40487. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.22832/0.42941. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.24128/0.42921. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.23875/0.42398. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.22261/0.40434. Took 0.15 sec\n",
      "Epoch 45, Loss(train/val) 0.22480/0.36215. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.21611/0.40821. Took 0.16 sec\n",
      "Epoch 47, Loss(train/val) 0.22718/0.40074. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.22949/0.39112. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.21819/0.35824. Took 0.16 sec\n",
      "Epoch 50, Loss(train/val) 0.21794/0.40442. Took 0.14 sec\n",
      "Epoch 51, Loss(train/val) 0.21499/0.40089. Took 0.16 sec\n",
      "Epoch 52, Loss(train/val) 0.21007/0.38588. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.20810/0.39408. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.21912/0.37792. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.20651/0.40852. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.20377/0.39683. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.20067/0.38241. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.21466/0.41619. Took 0.14 sec\n",
      "Epoch 59, Loss(train/val) 0.21096/0.38562. Took 0.15 sec\n",
      "Epoch 60, Loss(train/val) 0.20321/0.41037. Took 0.17 sec\n",
      "Epoch 61, Loss(train/val) 0.20337/0.37310. Took 0.17 sec\n",
      "Epoch 62, Loss(train/val) 0.20290/0.39389. Took 0.18 sec\n",
      "Epoch 63, Loss(train/val) 0.19702/0.38658. Took 0.16 sec\n",
      "Epoch 64, Loss(train/val) 0.19657/0.37076. Took 0.15 sec\n",
      "Epoch 65, Loss(train/val) 0.19445/0.39020. Took 0.16 sec\n",
      "Epoch 66, Loss(train/val) 0.18391/0.40212. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.18886/0.39621. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.18443/0.41579. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.19463/0.39186. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.17668/0.39131. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.18111/0.39702. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.18546/0.38337. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.19018/0.40719. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.18857/0.40573. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.18402/0.39587. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.17895/0.40781. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.18077/0.38861. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.17073/0.38984. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.18559/0.37940. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.17306/0.38771. Took 0.16 sec\n",
      "Epoch 81, Loss(train/val) 0.17491/0.38745. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.16547/0.38932. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) 0.17297/0.40021. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.17755/0.39713. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.17785/0.37158. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.17739/0.41614. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.16441/0.39670. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.17196/0.42734. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.16034/0.42922. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.16696/0.43383. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.16076/0.43280. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.16556/0.40901. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.15855/0.42834. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.16178/0.43104. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.15925/0.40071. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.16579/0.42702. Took 0.14 sec\n",
      "Epoch 97, Loss(train/val) 0.15619/0.41951. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.15165/0.40230. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.14954/0.38982. Took 0.13 sec\n",
      "ACC: 0.578125, MCC: 0.15338050190388622\n",
      "Epoch 0, Loss(train/val) 0.49292/0.49348. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.47426/0.48659. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.44498/0.47926. Took 0.15 sec\n",
      "Epoch 3, Loss(train/val) 0.41268/0.47737. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.39273/0.46900. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.38475/0.44067. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.37283/0.40907. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.36837/0.39418. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.35943/0.40002. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.35841/0.43173. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.35413/0.44037. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.35369/0.38599. Took 0.15 sec\n",
      "Epoch 12, Loss(train/val) 0.35306/0.42660. Took 0.15 sec\n",
      "Epoch 13, Loss(train/val) 0.34337/0.41831. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.34210/0.41752. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.33120/0.41905. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.33655/0.45489. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.32784/0.43773. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.33199/0.47756. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.32683/0.47533. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.31948/0.47843. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.31254/0.48012. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.31259/0.48135. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.31088/0.46707. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.30666/0.48143. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.30900/0.45455. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.31846/0.41452. Took 0.15 sec\n",
      "Epoch 27, Loss(train/val) 0.31112/0.44309. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.29932/0.40618. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.29354/0.42348. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.29368/0.44634. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.29185/0.44483. Took 0.16 sec\n",
      "Epoch 32, Loss(train/val) 0.28227/0.46732. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.29022/0.47459. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.29096/0.48093. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.27689/0.48397. Took 0.15 sec\n",
      "Epoch 36, Loss(train/val) 0.27311/0.48258. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.27656/0.44216. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.29556/0.47617. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.27722/0.45014. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.26794/0.45898. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.27500/0.46510. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.26686/0.48137. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.25809/0.46315. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.26954/0.47557. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.26415/0.46456. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.26001/0.44145. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.25867/0.40671. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.26427/0.46720. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.25966/0.43716. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.24752/0.43482. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.24824/0.44843. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.24826/0.43770. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.25130/0.43360. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.24530/0.45328. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.25146/0.43153. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.24167/0.44949. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.24639/0.43032. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.24597/0.41730. Took 0.15 sec\n",
      "Epoch 59, Loss(train/val) 0.23479/0.43426. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.23999/0.46611. Took 0.14 sec\n",
      "Epoch 61, Loss(train/val) 0.22246/0.44670. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.22477/0.40757. Took 0.15 sec\n",
      "Epoch 63, Loss(train/val) 0.22953/0.42602. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.21899/0.43515. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.21817/0.44952. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.23204/0.44030. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.22207/0.45063. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.23447/0.45185. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.21950/0.42434. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.21666/0.38666. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.21922/0.37057. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.22863/0.39081. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.21416/0.43345. Took 0.15 sec\n",
      "Epoch 74, Loss(train/val) 0.22037/0.40264. Took 0.16 sec\n",
      "Epoch 75, Loss(train/val) 0.22726/0.39009. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.20901/0.44793. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.20409/0.40363. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.20753/0.41063. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.21945/0.40406. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.20938/0.37606. Took 0.14 sec\n",
      "Epoch 81, Loss(train/val) 0.21922/0.40921. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.21257/0.40244. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.20937/0.39438. Took 0.12 sec\n",
      "Epoch 84, Loss(train/val) 0.20477/0.43144. Took 0.12 sec\n",
      "Epoch 85, Loss(train/val) 0.21153/0.39340. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.22348/0.39922. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.20554/0.40179. Took 0.12 sec\n",
      "Epoch 88, Loss(train/val) 0.20054/0.39085. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.19318/0.40542. Took 0.12 sec\n",
      "Epoch 90, Loss(train/val) 0.19095/0.34847. Took 0.12 sec\n",
      "Epoch 91, Loss(train/val) 0.19609/0.37164. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.18841/0.37872. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.20217/0.39133. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.18832/0.36082. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.19878/0.41568. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.20053/0.39469. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.19114/0.44766. Took 0.12 sec\n",
      "Epoch 98, Loss(train/val) 0.19459/0.40913. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.18821/0.43901. Took 0.12 sec\n",
      "ACC: 0.640625, MCC: 0.30779350562554625\n",
      "Epoch 0, Loss(train/val) 0.49573/0.49544. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.48220/0.48648. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.45655/0.46858. Took 0.15 sec\n",
      "Epoch 3, Loss(train/val) 0.41815/0.45400. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.39365/0.45562. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.37939/0.46276. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.37081/0.46217. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.36345/0.47890. Took 0.16 sec\n",
      "Epoch 8, Loss(train/val) 0.35604/0.44409. Took 0.15 sec\n",
      "Epoch 9, Loss(train/val) 0.35832/0.42478. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.34893/0.44436. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.35116/0.40669. Took 0.15 sec\n",
      "Epoch 12, Loss(train/val) 0.34306/0.32742. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.33797/0.34014. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.31856/0.33392. Took 0.15 sec\n",
      "Epoch 15, Loss(train/val) 0.33649/0.34779. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.32728/0.31802. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.33470/0.42222. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.31645/0.32553. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.32046/0.33496. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.31221/0.27865. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.30218/0.28678. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.30278/0.39803. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.30121/0.33976. Took 0.16 sec\n",
      "Epoch 24, Loss(train/val) 0.30338/0.38280. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.29160/0.44868. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.29574/0.38911. Took 0.15 sec\n",
      "Epoch 27, Loss(train/val) 0.29464/0.35634. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.28107/0.35288. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.28403/0.30875. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.28929/0.35617. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.27598/0.37904. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.26848/0.37466. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.27424/0.35261. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.27982/0.42162. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.26732/0.40224. Took 0.13 sec\n",
      "Epoch 36, Loss(train/val) 0.26567/0.46246. Took 0.18 sec\n",
      "Epoch 37, Loss(train/val) 0.26270/0.43321. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.26539/0.42583. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.26664/0.46664. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.26176/0.43295. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.25798/0.42718. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.25569/0.47006. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.25267/0.45920. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.25136/0.45537. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.24970/0.46789. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.24097/0.47451. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.23220/0.41128. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.24680/0.43158. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.23467/0.46562. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.23274/0.47343. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.21991/0.44349. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.22261/0.47008. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) 0.21525/0.46197. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.22824/0.47199. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.22871/0.47469. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.22263/0.43551. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.21825/0.47351. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.20681/0.47860. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.21197/0.47231. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.21539/0.48248. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.19377/0.47626. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.19816/0.47621. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.19487/0.47708. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.20253/0.48319. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.21539/0.47323. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.20360/0.46370. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.19665/0.45972. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.19688/0.49226. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.20607/0.49251. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.19236/0.48837. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.19383/0.48417. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.18791/0.48444. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.18923/0.49736. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.19341/0.49880. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.18668/0.46686. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.17613/0.49878. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.18692/0.48180. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.18603/0.45999. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.18360/0.49145. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.17816/0.48044. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.17635/0.49797. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.17189/0.49622. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.18177/0.41117. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.17551/0.47982. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.18693/0.49472. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.18141/0.47663. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.18705/0.49414. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.16839/0.49113. Took 0.14 sec\n",
      "Epoch 89, Loss(train/val) 0.17249/0.47954. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.16387/0.49156. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.15847/0.45641. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.16919/0.44373. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.17258/0.45399. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.16717/0.47695. Took 0.14 sec\n",
      "Epoch 95, Loss(train/val) 0.17481/0.48384. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.16574/0.43076. Took 0.14 sec\n",
      "Epoch 97, Loss(train/val) 0.16841/0.44426. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.16349/0.44296. Took 0.16 sec\n",
      "Epoch 99, Loss(train/val) 0.16755/0.47340. Took 0.16 sec\n",
      "ACC: 0.625, MCC: 0.24334975369458128\n",
      "Epoch 0, Loss(train/val) 0.49171/0.48402. Took 0.17 sec\n",
      "Epoch 1, Loss(train/val) 0.46442/0.45421. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.43108/0.41751. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.39830/0.38413. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.37497/0.38041. Took 0.16 sec\n",
      "Epoch 5, Loss(train/val) 0.36181/0.32624. Took 0.16 sec\n",
      "Epoch 6, Loss(train/val) 0.35303/0.31920. Took 0.15 sec\n",
      "Epoch 7, Loss(train/val) 0.34542/0.35982. Took 0.15 sec\n",
      "Epoch 8, Loss(train/val) 0.33610/0.31019. Took 0.16 sec\n",
      "Epoch 9, Loss(train/val) 0.33168/0.32025. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.31774/0.30336. Took 0.15 sec\n",
      "Epoch 11, Loss(train/val) 0.30662/0.34567. Took 0.15 sec\n",
      "Epoch 12, Loss(train/val) 0.30546/0.31552. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.29628/0.30771. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.29630/0.28108. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.28553/0.30831. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.28532/0.26553. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.27042/0.28586. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.27241/0.28268. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.27101/0.26458. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.26524/0.30722. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.25868/0.29492. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.25943/0.27015. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.25729/0.30912. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.25346/0.29843. Took 0.16 sec\n",
      "Epoch 25, Loss(train/val) 0.25386/0.29013. Took 0.17 sec\n",
      "Epoch 26, Loss(train/val) 0.24676/0.30396. Took 0.15 sec\n",
      "Epoch 27, Loss(train/val) 0.24504/0.29529. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.23570/0.30525. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.23259/0.31129. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.22685/0.33385. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.23196/0.35607. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.22723/0.29106. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.21935/0.34627. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.22943/0.31282. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.22634/0.33056. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.22142/0.34382. Took 0.13 sec\n",
      "Epoch 37, Loss(train/val) 0.21482/0.37594. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.20720/0.34076. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.21196/0.33450. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.20697/0.34235. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.20159/0.34735. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.21025/0.28144. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.20795/0.38580. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.20125/0.29540. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.19614/0.31980. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.19131/0.31932. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.18677/0.33856. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.18576/0.31543. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.18146/0.34881. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.18010/0.30733. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.18429/0.31620. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.17548/0.32745. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.17656/0.33176. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.17282/0.33874. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.17882/0.30957. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.17287/0.29111. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.17099/0.33187. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.17245/0.28415. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.17227/0.31251. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.16974/0.26813. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.17145/0.34206. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.16543/0.26901. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.16963/0.28310. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.16116/0.30161. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.16081/0.31459. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.16899/0.30204. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) 0.16690/0.31495. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.16323/0.34977. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.15486/0.32829. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.15023/0.30570. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.16445/0.32135. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.16625/0.32045. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.16848/0.29083. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.16045/0.32419. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.16028/0.31308. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.16460/0.25202. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.15244/0.28400. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.15629/0.28245. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.15170/0.31067. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.14938/0.30706. Took 0.14 sec\n",
      "Epoch 81, Loss(train/val) 0.14741/0.31981. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.15109/0.35954. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) 0.15410/0.32761. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.15089/0.31796. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.14676/0.31561. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.14578/0.40239. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.15167/0.33471. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.15022/0.36300. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.14840/0.37574. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.14853/0.32957. Took 0.14 sec\n",
      "Epoch 91, Loss(train/val) 0.14579/0.31807. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.14649/0.35010. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.14633/0.34982. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.14380/0.34531. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.13977/0.30808. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.14273/0.31194. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.14126/0.33638. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.13210/0.31385. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.14272/0.35025. Took 0.13 sec\n",
      "ACC: 0.65625, MCC: 0.19518001458970666\n",
      "Epoch 0, Loss(train/val) 0.48972/0.45682. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.46133/0.40323. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.42630/0.36995. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.38973/0.35329. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.36305/0.34910. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.34724/0.33670. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.33653/0.32445. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.33501/0.32698. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.32169/0.31697. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.31056/0.29599. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.30541/0.37794. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.30565/0.36452. Took 0.16 sec\n",
      "Epoch 12, Loss(train/val) 0.30077/0.35692. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.29572/0.38044. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.29717/0.32873. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.28699/0.39774. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.26892/0.34040. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.27478/0.39234. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.26271/0.36338. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.26691/0.42640. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.26308/0.34565. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.25145/0.37650. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.25196/0.34242. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.24955/0.35143. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.24589/0.35171. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.24424/0.35994. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.23489/0.34574. Took 0.15 sec\n",
      "Epoch 27, Loss(train/val) 0.24275/0.32345. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.24377/0.37218. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.24865/0.34385. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.23864/0.34832. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.24169/0.33257. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.24284/0.31771. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.22825/0.33496. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.22295/0.33481. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.23598/0.34997. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.23208/0.34574. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.22095/0.33601. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.22253/0.33670. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.21634/0.34567. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.20931/0.37577. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.22296/0.32676. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.21820/0.31454. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.21392/0.32279. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.20781/0.31767. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.21723/0.30118. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.21455/0.30703. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.21415/0.31339. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.20369/0.32109. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.20349/0.31891. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.20543/0.31956. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.19924/0.32458. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.19918/0.33238. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.20510/0.32715. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.20213/0.32820. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.19099/0.32819. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.19800/0.32597. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.19171/0.33306. Took 0.15 sec\n",
      "Epoch 58, Loss(train/val) 0.19440/0.32790. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.18480/0.33320. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.18208/0.31836. Took 0.14 sec\n",
      "Epoch 61, Loss(train/val) 0.19146/0.32239. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.17720/0.32039. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.18677/0.31394. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.18578/0.32422. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.18212/0.32569. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.16880/0.32221. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.17667/0.31542. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.17637/0.31286. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.18100/0.31951. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.17421/0.32383. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.16905/0.32296. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.18124/0.31010. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.17781/0.30940. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.17065/0.31108. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.18178/0.33689. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.16516/0.29156. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.16833/0.29652. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.16944/0.30548. Took 0.15 sec\n",
      "Epoch 79, Loss(train/val) 0.16665/0.30191. Took 0.15 sec\n",
      "Epoch 80, Loss(train/val) 0.15774/0.30237. Took 0.17 sec\n",
      "Epoch 81, Loss(train/val) 0.16292/0.30937. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.16439/0.32992. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) 0.15725/0.32101. Took 0.16 sec\n",
      "Epoch 84, Loss(train/val) 0.15698/0.31014. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.15856/0.31900. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.15463/0.32314. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.15914/0.32998. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.16079/0.33517. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.15272/0.31610. Took 0.15 sec\n",
      "Epoch 90, Loss(train/val) 0.15616/0.32035. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.15109/0.34316. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.16836/0.30353. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.15848/0.31294. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.14824/0.31745. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.15406/0.33039. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.14665/0.34591. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.14941/0.35245. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.13957/0.33157. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.15109/0.35371. Took 0.13 sec\n",
      "ACC: 0.6875, MCC: 0.42449211985624113\n",
      "Epoch 0, Loss(train/val) 0.48571/0.48683. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.45402/0.46061. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.42154/0.42819. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.39298/0.41773. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.37071/0.40672. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.36348/0.38849. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.34642/0.38498. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.33769/0.38941. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.33308/0.37807. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.32115/0.37608. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.31331/0.36460. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.30596/0.36724. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.29877/0.36484. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.29566/0.35906. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.28918/0.41281. Took 0.17 sec\n",
      "Epoch 15, Loss(train/val) 0.27680/0.37072. Took 0.16 sec\n",
      "Epoch 16, Loss(train/val) 0.28123/0.31774. Took 0.15 sec\n",
      "Epoch 17, Loss(train/val) 0.27500/0.37075. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.26982/0.34545. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.26318/0.37109. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.25376/0.35864. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.25564/0.38472. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.26207/0.34676. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.24834/0.35561. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.25546/0.35998. Took 0.15 sec\n",
      "Epoch 25, Loss(train/val) 0.23603/0.36859. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.23946/0.36841. Took 0.16 sec\n",
      "Epoch 27, Loss(train/val) 0.22876/0.36010. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.23407/0.36942. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.23051/0.38426. Took 0.16 sec\n",
      "Epoch 30, Loss(train/val) 0.23775/0.38082. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.22706/0.39151. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.22587/0.37826. Took 0.16 sec\n",
      "Epoch 33, Loss(train/val) 0.21900/0.39119. Took 0.17 sec\n",
      "Epoch 34, Loss(train/val) 0.21228/0.39592. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.20856/0.38876. Took 0.15 sec\n",
      "Epoch 36, Loss(train/val) 0.22116/0.38444. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.20822/0.40587. Took 0.15 sec\n",
      "Epoch 38, Loss(train/val) 0.19987/0.39914. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.20048/0.38845. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.19498/0.38331. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.19889/0.39994. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.19579/0.36153. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.19517/0.40975. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.19374/0.39248. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.18847/0.38502. Took 0.15 sec\n",
      "Epoch 46, Loss(train/val) 0.18802/0.39701. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.18519/0.37890. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.18468/0.39695. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.17700/0.40421. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.17949/0.48138. Took 0.14 sec\n",
      "Epoch 51, Loss(train/val) 0.17272/0.47851. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.16697/0.45048. Took 0.15 sec\n",
      "Epoch 53, Loss(train/val) 0.17470/0.47840. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.17529/0.49390. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.18196/0.43342. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.17875/0.45036. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.16337/0.40963. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.17029/0.44268. Took 0.14 sec\n",
      "Epoch 59, Loss(train/val) 0.16343/0.44846. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.15208/0.47166. Took 0.14 sec\n",
      "Epoch 61, Loss(train/val) 0.16098/0.44243. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.15928/0.45877. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.15903/0.41291. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.15963/0.43903. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.15411/0.46463. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.15274/0.40854. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) 0.14802/0.41383. Took 0.15 sec\n",
      "Epoch 68, Loss(train/val) 0.14713/0.44396. Took 0.14 sec\n",
      "Epoch 69, Loss(train/val) 0.14817/0.44676. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.14507/0.46607. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.14632/0.41799. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.13889/0.44550. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.13837/0.44481. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.13938/0.44951. Took 0.15 sec\n",
      "Epoch 75, Loss(train/val) 0.13865/0.47617. Took 0.17 sec\n",
      "Epoch 76, Loss(train/val) 0.14360/0.44483. Took 0.15 sec\n",
      "Epoch 77, Loss(train/val) 0.14656/0.41081. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.13705/0.40676. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.14191/0.42118. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.13257/0.43964. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.14023/0.40039. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.13644/0.39848. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) 0.13957/0.39895. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.13161/0.40495. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.12839/0.39977. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.13439/0.41949. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.13440/0.39021. Took 0.15 sec\n",
      "Epoch 88, Loss(train/val) 0.12273/0.42636. Took 0.14 sec\n",
      "Epoch 89, Loss(train/val) 0.11517/0.41077. Took 0.15 sec\n",
      "Epoch 90, Loss(train/val) 0.12440/0.40347. Took 0.15 sec\n",
      "Epoch 91, Loss(train/val) 0.12605/0.41801. Took 0.15 sec\n",
      "Epoch 92, Loss(train/val) 0.12267/0.42730. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.11626/0.41879. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.11957/0.39345. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.11908/0.44032. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.11974/0.44559. Took 0.14 sec\n",
      "Epoch 97, Loss(train/val) 0.11199/0.43900. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.11678/0.44596. Took 0.14 sec\n",
      "Epoch 99, Loss(train/val) 0.11396/0.43398. Took 0.13 sec\n",
      "ACC: 0.65625, MCC: 0.30164090937813576\n",
      "Epoch 0, Loss(train/val) 0.48909/0.47803. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.46545/0.44659. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.43517/0.40786. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.39417/0.35169. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.36254/0.31563. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.33900/0.29386. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.32494/0.30174. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.32495/0.27305. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.31401/0.25006. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.28655/0.23564. Took 0.15 sec\n",
      "Epoch 10, Loss(train/val) 0.28950/0.22147. Took 0.17 sec\n",
      "Epoch 11, Loss(train/val) 0.28174/0.21764. Took 0.17 sec\n",
      "Epoch 12, Loss(train/val) 0.27015/0.21723. Took 0.16 sec\n",
      "Epoch 13, Loss(train/val) 0.27038/0.21633. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.27045/0.26724. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.27811/0.29462. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.27296/0.25090. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.26763/0.19457. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.27015/0.27383. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.26102/0.26579. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.25934/0.27121. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.25905/0.23479. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.24566/0.20248. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.25926/0.25359. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.25310/0.28820. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.24362/0.26763. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.24073/0.26084. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.23567/0.22784. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.24325/0.27147. Took 0.17 sec\n",
      "Epoch 29, Loss(train/val) 0.23586/0.24840. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.24767/0.23396. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.24013/0.25242. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.22430/0.25106. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.21810/0.24188. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.22622/0.26720. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.21157/0.28862. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.21216/0.27524. Took 0.13 sec\n",
      "Epoch 37, Loss(train/val) 0.21621/0.30192. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.20651/0.27917. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.20883/0.30062. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.20754/0.27012. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.20380/0.27733. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.19481/0.29003. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.19330/0.28105. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.19310/0.30469. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.18815/0.29047. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.19213/0.30487. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.18817/0.27901. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.18896/0.30169. Took 0.15 sec\n",
      "Epoch 49, Loss(train/val) 0.18807/0.27448. Took 0.16 sec\n",
      "Epoch 50, Loss(train/val) 0.19711/0.30132. Took 0.14 sec\n",
      "Epoch 51, Loss(train/val) 0.18110/0.32342. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.18063/0.33125. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) 0.18653/0.29905. Took 0.15 sec\n",
      "Epoch 54, Loss(train/val) 0.17803/0.33366. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.17803/0.30480. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.17907/0.28060. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.16623/0.31669. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.17179/0.30704. Took 0.14 sec\n",
      "Epoch 59, Loss(train/val) 0.17631/0.29660. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.17159/0.28277. Took 0.15 sec\n",
      "Epoch 61, Loss(train/val) 0.16590/0.31790. Took 0.15 sec\n",
      "Epoch 62, Loss(train/val) 0.16932/0.28724. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.16140/0.30596. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.16078/0.32542. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.16131/0.30003. Took 0.15 sec\n",
      "Epoch 66, Loss(train/val) 0.15748/0.28281. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) 0.16093/0.31084. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.15302/0.31670. Took 0.17 sec\n",
      "Epoch 69, Loss(train/val) 0.15704/0.29037. Took 0.16 sec\n",
      "Epoch 70, Loss(train/val) 0.14857/0.28102. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.15540/0.27491. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.14993/0.29326. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.14714/0.31452. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.14823/0.27453. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) 0.14897/0.28746. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.14738/0.30184. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.14225/0.30382. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.14231/0.30282. Took 0.14 sec\n",
      "Epoch 79, Loss(train/val) 0.14158/0.31777. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.14424/0.31838. Took 0.14 sec\n",
      "Epoch 81, Loss(train/val) 0.13436/0.30346. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.14004/0.31627. Took 0.15 sec\n",
      "Epoch 83, Loss(train/val) 0.13278/0.29685. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.13545/0.33458. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.13414/0.31831. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.12809/0.30933. Took 0.15 sec\n",
      "Epoch 87, Loss(train/val) 0.13854/0.31714. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.14820/0.34889. Took 0.14 sec\n",
      "Epoch 89, Loss(train/val) 0.13708/0.32794. Took 0.15 sec\n",
      "Epoch 90, Loss(train/val) 0.12356/0.33463. Took 0.15 sec\n",
      "Epoch 91, Loss(train/val) 0.12734/0.31405. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.13315/0.33404. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.12134/0.35017. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.12271/0.32859. Took 0.17 sec\n",
      "Epoch 95, Loss(train/val) 0.13004/0.30078. Took 0.16 sec\n",
      "Epoch 96, Loss(train/val) 0.13047/0.34440. Took 0.15 sec\n",
      "Epoch 97, Loss(train/val) 0.12262/0.29057. Took 0.16 sec\n",
      "Epoch 98, Loss(train/val) 0.12374/0.32969. Took 0.14 sec\n",
      "Epoch 99, Loss(train/val) 0.12312/0.34619. Took 0.14 sec\n",
      "ACC: 0.703125, MCC: 0.4425209104681113\n",
      "Epoch 0, Loss(train/val) 0.48695/0.47793. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.45961/0.43620. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.42311/0.41305. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.39120/0.41673. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.36096/0.42961. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.34985/0.37786. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.32387/0.41093. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.32676/0.39425. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.30874/0.39324. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.31012/0.41112. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.29567/0.37503. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.28846/0.37932. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.27828/0.41712. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.28390/0.39055. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.27036/0.41842. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.28937/0.38059. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.26747/0.41618. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.28088/0.38983. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.26099/0.37367. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.25930/0.39372. Took 0.16 sec\n",
      "Epoch 20, Loss(train/val) 0.25211/0.38451. Took 0.15 sec\n",
      "Epoch 21, Loss(train/val) 0.25265/0.39836. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.26138/0.38058. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.26799/0.38192. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.25846/0.36884. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.25127/0.37152. Took 0.19 sec\n",
      "Epoch 26, Loss(train/val) 0.25214/0.36245. Took 0.16 sec\n",
      "Epoch 27, Loss(train/val) 0.24272/0.36593. Took 0.16 sec\n",
      "Epoch 28, Loss(train/val) 0.24766/0.38162. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.24645/0.36755. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.23567/0.38398. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.23211/0.38814. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.22964/0.38587. Took 0.17 sec\n",
      "Epoch 33, Loss(train/val) 0.22554/0.37842. Took 0.13 sec\n",
      "Epoch 34, Loss(train/val) 0.22887/0.38117. Took 0.13 sec\n",
      "Epoch 35, Loss(train/val) 0.22657/0.37489. Took 0.13 sec\n",
      "Epoch 36, Loss(train/val) 0.22486/0.38170. Took 0.13 sec\n",
      "Epoch 37, Loss(train/val) 0.22174/0.38495. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.21098/0.37491. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.21669/0.37598. Took 0.15 sec\n",
      "Epoch 40, Loss(train/val) 0.21485/0.37518. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.19824/0.37798. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.21072/0.37367. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.21706/0.38033. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.20735/0.38911. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.20381/0.38336. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.19504/0.39157. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.20400/0.38693. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.19470/0.38587. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.19477/0.38164. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.20695/0.36679. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.20626/0.37367. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.21515/0.38064. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.19667/0.37707. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.20066/0.38546. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.19222/0.36200. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.18551/0.38672. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.19135/0.37936. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.18648/0.38050. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.18811/0.36749. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.19323/0.35079. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.18449/0.37540. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.19055/0.37883. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.17943/0.37756. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.17512/0.38386. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.17529/0.37201. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.18173/0.37308. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.17076/0.37816. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.17945/0.36569. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.17550/0.36004. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.16351/0.35896. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.17126/0.36256. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.17109/0.36156. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.17325/0.35023. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.17034/0.35417. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) 0.16672/0.35624. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.16744/0.38196. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.16559/0.37215. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.16819/0.37588. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.16538/0.33904. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.16080/0.38955. Took 0.14 sec\n",
      "Epoch 81, Loss(train/val) 0.16838/0.36466. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.15521/0.36253. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) 0.15953/0.36704. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.15821/0.36086. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.15526/0.35177. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.15379/0.27247. Took 0.17 sec\n",
      "Epoch 87, Loss(train/val) 0.16911/0.31564. Took 0.15 sec\n",
      "Epoch 88, Loss(train/val) 0.15391/0.33509. Took 0.14 sec\n",
      "Epoch 89, Loss(train/val) 0.15004/0.34899. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.15921/0.29667. Took 0.14 sec\n",
      "Epoch 91, Loss(train/val) 0.15833/0.35934. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.15359/0.26010. Took 0.15 sec\n",
      "Epoch 93, Loss(train/val) 0.15489/0.33492. Took 0.15 sec\n",
      "Epoch 94, Loss(train/val) 0.14649/0.29823. Took 0.15 sec\n",
      "Epoch 95, Loss(train/val) 0.14034/0.28775. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.14494/0.27509. Took 0.16 sec\n",
      "Epoch 97, Loss(train/val) 0.14698/0.31053. Took 0.18 sec\n",
      "Epoch 98, Loss(train/val) 0.14441/0.28453. Took 0.17 sec\n",
      "Epoch 99, Loss(train/val) 0.14332/0.28170. Took 0.15 sec\n",
      "ACC: 0.65625, MCC: 0.3274218273290659\n",
      "Epoch 0, Loss(train/val) 0.48812/0.47162. Took 0.18 sec\n",
      "Epoch 1, Loss(train/val) 0.45716/0.42147. Took 0.16 sec\n",
      "Epoch 2, Loss(train/val) 0.41684/0.38095. Took 0.15 sec\n",
      "Epoch 3, Loss(train/val) 0.38712/0.37683. Took 0.16 sec\n",
      "Epoch 4, Loss(train/val) 0.37135/0.37255. Took 0.16 sec\n",
      "Epoch 5, Loss(train/val) 0.35207/0.37163. Took 0.19 sec\n",
      "Epoch 6, Loss(train/val) 0.34731/0.36586. Took 0.18 sec\n",
      "Epoch 7, Loss(train/val) 0.33604/0.36294. Took 0.16 sec\n",
      "Epoch 8, Loss(train/val) 0.33320/0.35882. Took 0.15 sec\n",
      "Epoch 9, Loss(train/val) 0.32673/0.35526. Took 0.15 sec\n",
      "Epoch 10, Loss(train/val) 0.32917/0.35584. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.31909/0.35292. Took 0.16 sec\n",
      "Epoch 12, Loss(train/val) 0.31809/0.35390. Took 0.18 sec\n",
      "Epoch 13, Loss(train/val) 0.31256/0.35712. Took 0.24 sec\n",
      "Epoch 14, Loss(train/val) 0.30812/0.35982. Took 0.21 sec\n",
      "Epoch 15, Loss(train/val) 0.30941/0.35859. Took 0.19 sec\n",
      "Epoch 16, Loss(train/val) 0.30463/0.34661. Took 0.22 sec\n",
      "Epoch 17, Loss(train/val) 0.30237/0.38008. Took 0.19 sec\n",
      "Epoch 18, Loss(train/val) 0.29558/0.34973. Took 0.18 sec\n",
      "Epoch 19, Loss(train/val) 0.29864/0.36882. Took 0.16 sec\n",
      "Epoch 20, Loss(train/val) 0.29507/0.36639. Took 0.17 sec\n",
      "Epoch 21, Loss(train/val) 0.28845/0.35149. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.29117/0.36971. Took 0.16 sec\n",
      "Epoch 23, Loss(train/val) 0.27779/0.35666. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.28504/0.37903. Took 0.16 sec\n",
      "Epoch 25, Loss(train/val) 0.27922/0.37014. Took 0.16 sec\n",
      "Epoch 26, Loss(train/val) 0.28188/0.37160. Took 0.15 sec\n",
      "Epoch 27, Loss(train/val) 0.28029/0.37652. Took 0.17 sec\n",
      "Epoch 28, Loss(train/val) 0.27021/0.36924. Took 0.17 sec\n",
      "Epoch 29, Loss(train/val) 0.26616/0.37261. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.26406/0.37597. Took 0.16 sec\n",
      "Epoch 31, Loss(train/val) 0.25668/0.36348. Took 0.17 sec\n",
      "Epoch 32, Loss(train/val) 0.26635/0.34040. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.25433/0.33376. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.25506/0.32298. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.24308/0.31369. Took 0.16 sec\n",
      "Epoch 36, Loss(train/val) 0.23596/0.34690. Took 0.18 sec\n",
      "Epoch 37, Loss(train/val) 0.24022/0.34134. Took 0.18 sec\n",
      "Epoch 38, Loss(train/val) 0.25335/0.36504. Took 0.17 sec\n",
      "Epoch 39, Loss(train/val) 0.26587/0.34422. Took 0.16 sec\n",
      "Epoch 40, Loss(train/val) 0.24466/0.34427. Took 0.15 sec\n",
      "Epoch 41, Loss(train/val) 0.23860/0.36553. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.23413/0.35053. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.23812/0.34618. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.23867/0.34075. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.23363/0.33754. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.22728/0.33277. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.22811/0.33740. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.22685/0.36168. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.22198/0.37171. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.22918/0.33816. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.21241/0.35768. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.21500/0.34545. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.21420/0.33958. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.21702/0.33209. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.20413/0.35183. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.20795/0.33843. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.21891/0.30874. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.22876/0.34584. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.20919/0.31803. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.20524/0.33532. Took 0.14 sec\n",
      "Epoch 61, Loss(train/val) 0.19551/0.31787. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.20711/0.37164. Took 0.15 sec\n",
      "Epoch 63, Loss(train/val) 0.20369/0.32388. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.19430/0.33594. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.19834/0.34314. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.20208/0.36157. Took 0.15 sec\n",
      "Epoch 67, Loss(train/val) 0.19982/0.37160. Took 0.16 sec\n",
      "Epoch 68, Loss(train/val) 0.19398/0.35970. Took 0.15 sec\n",
      "Epoch 69, Loss(train/val) 0.19777/0.38247. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.20625/0.33188. Took 0.15 sec\n",
      "Epoch 71, Loss(train/val) 0.18580/0.31871. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.18722/0.32468. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.18624/0.35816. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.20152/0.33599. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) 0.18700/0.34511. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.18363/0.30500. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.18402/0.34058. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.18529/0.34734. Took 0.15 sec\n",
      "Epoch 79, Loss(train/val) 0.18311/0.35987. Took 0.16 sec\n",
      "Epoch 80, Loss(train/val) 0.18404/0.32372. Took 0.15 sec\n",
      "Epoch 81, Loss(train/val) 0.19063/0.31977. Took 0.15 sec\n",
      "Epoch 82, Loss(train/val) 0.18249/0.29068. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) 0.18633/0.32317. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.17364/0.32319. Took 0.16 sec\n",
      "Epoch 85, Loss(train/val) 0.18067/0.30436. Took 0.17 sec\n",
      "Epoch 86, Loss(train/val) 0.17579/0.33628. Took 0.15 sec\n",
      "Epoch 87, Loss(train/val) 0.17576/0.32145. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.17468/0.35696. Took 0.14 sec\n",
      "Epoch 89, Loss(train/val) 0.17637/0.35259. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.18214/0.37606. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.17545/0.35503. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.17375/0.38183. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.17183/0.33032. Took 0.15 sec\n",
      "Epoch 94, Loss(train/val) 0.17031/0.34597. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.16134/0.38355. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.16332/0.38801. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.17152/0.34827. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.16791/0.36714. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.17733/0.35407. Took 0.14 sec\n",
      "ACC: 0.6875, MCC: 0.3962389192686809\n",
      "Epoch 0, Loss(train/val) 0.48961/0.48338. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.45824/0.45030. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.41474/0.43333. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.38244/0.43582. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.36149/0.42528. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.34639/0.41634. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.33997/0.42260. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.32602/0.39021. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.32393/0.42181. Took 0.15 sec\n",
      "Epoch 9, Loss(train/val) 0.32237/0.40182. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.31489/0.36208. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.29182/0.37152. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.29052/0.37128. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.28628/0.39540. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.28133/0.37081. Took 0.15 sec\n",
      "Epoch 15, Loss(train/val) 0.27133/0.35730. Took 0.16 sec\n",
      "Epoch 16, Loss(train/val) 0.28512/0.37374. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.28919/0.38952. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.28717/0.35492. Took 0.16 sec\n",
      "Epoch 19, Loss(train/val) 0.27179/0.36579. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.27484/0.35710. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.26556/0.35901. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.26819/0.36083. Took 0.15 sec\n",
      "Epoch 23, Loss(train/val) 0.26364/0.36359. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.25913/0.35334. Took 0.15 sec\n",
      "Epoch 25, Loss(train/val) 0.25939/0.38399. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.25485/0.34076. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.25171/0.34558. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.24390/0.34435. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.24365/0.33855. Took 0.16 sec\n",
      "Epoch 30, Loss(train/val) 0.23811/0.34098. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.24413/0.35453. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.23145/0.34431. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.23177/0.34275. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.22401/0.33795. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.22672/0.34114. Took 0.13 sec\n",
      "Epoch 36, Loss(train/val) 0.21288/0.35529. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.22482/0.36401. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.21986/0.31896. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.21671/0.34133. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.21336/0.33647. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.20586/0.34270. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.20159/0.35958. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.20932/0.35813. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.19948/0.34683. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.19828/0.32460. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.19056/0.31880. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.19155/0.35741. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.18721/0.35288. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.19096/0.34340. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.19424/0.36041. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.19277/0.35120. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.18951/0.33622. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) 0.18978/0.35858. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.19768/0.32139. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.18639/0.32659. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.17589/0.32513. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.18543/0.33266. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.17230/0.29344. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.17720/0.32028. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.17801/0.31223. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.17650/0.31026. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.16780/0.31856. Took 0.12 sec\n",
      "Epoch 63, Loss(train/val) 0.17014/0.30767. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.16772/0.30960. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.16632/0.31846. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.16742/0.31415. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.16414/0.30632. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.16138/0.29645. Took 0.14 sec\n",
      "Epoch 69, Loss(train/val) 0.15845/0.31334. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.16833/0.31511. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.15912/0.29143. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.15863/0.30575. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.15349/0.30400. Took 0.12 sec\n",
      "Epoch 74, Loss(train/val) 0.15323/0.32104. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.14015/0.29952. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.15187/0.33640. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.15142/0.30029. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.14694/0.31041. Took 0.14 sec\n",
      "Epoch 79, Loss(train/val) 0.14157/0.28988. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.14564/0.32844. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.14250/0.28178. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.14490/0.30710. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.14776/0.29411. Took 0.12 sec\n",
      "Epoch 84, Loss(train/val) 0.14274/0.30496. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.14072/0.32949. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.14149/0.32928. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.13669/0.28605. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.14878/0.33438. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.13407/0.28860. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.13744/0.31054. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.13849/0.33215. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.13354/0.30355. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.14084/0.30785. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.12909/0.30304. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.12156/0.31235. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.13018/0.30114. Took 0.14 sec\n",
      "Epoch 97, Loss(train/val) 0.12992/0.32869. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.13065/0.33932. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.12820/0.33770. Took 0.13 sec\n",
      "ACC: 0.6875, MCC: 0.3694581280788177\n",
      "Epoch 0, Loss(train/val) 0.48550/0.48782. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.45241/0.45652. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.41003/0.40051. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.37879/0.37029. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.36118/0.35327. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.35149/0.35270. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.34484/0.33295. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.33537/0.32115. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.32890/0.29317. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.32330/0.28784. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.31619/0.29098. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.31730/0.29805. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.30910/0.29890. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.29913/0.32417. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.29260/0.33049. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.27687/0.33349. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.26929/0.35616. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.27684/0.34838. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.26523/0.33409. Took 0.15 sec\n",
      "Epoch 19, Loss(train/val) 0.26561/0.34202. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.25028/0.34862. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.24911/0.33206. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.25331/0.30231. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.24225/0.34133. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.24103/0.33341. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.22480/0.33117. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.23094/0.30738. Took 0.15 sec\n",
      "Epoch 27, Loss(train/val) 0.23423/0.33653. Took 0.17 sec\n",
      "Epoch 28, Loss(train/val) 0.22868/0.34916. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.22872/0.31482. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.22439/0.30859. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.23389/0.34142. Took 0.19 sec\n",
      "Epoch 32, Loss(train/val) 0.21300/0.32911. Took 0.22 sec\n",
      "Epoch 33, Loss(train/val) 0.20720/0.33706. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.22337/0.31905. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.21118/0.33155. Took 0.15 sec\n",
      "Epoch 36, Loss(train/val) 0.20757/0.32640. Took 0.16 sec\n",
      "Epoch 37, Loss(train/val) 0.20551/0.31109. Took 0.20 sec\n",
      "Epoch 38, Loss(train/val) 0.20493/0.31441. Took 0.20 sec\n",
      "Epoch 39, Loss(train/val) 0.20498/0.30905. Took 0.20 sec\n",
      "Epoch 40, Loss(train/val) 0.21055/0.33496. Took 0.17 sec\n",
      "Epoch 41, Loss(train/val) 0.20799/0.31659. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.19463/0.33852. Took 0.15 sec\n",
      "Epoch 43, Loss(train/val) 0.19832/0.30935. Took 0.15 sec\n",
      "Epoch 44, Loss(train/val) 0.20541/0.31580. Took 0.15 sec\n",
      "Epoch 45, Loss(train/val) 0.19841/0.32785. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.18499/0.32197. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.19696/0.29825. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.19249/0.30629. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.18973/0.31701. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.19191/0.30781. Took 0.15 sec\n",
      "Epoch 51, Loss(train/val) 0.19389/0.30808. Took 0.15 sec\n",
      "Epoch 52, Loss(train/val) 0.18992/0.31450. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.19189/0.31925. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.18079/0.31137. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.18374/0.31802. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.18595/0.30110. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.18771/0.30791. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.17767/0.31024. Took 0.14 sec\n",
      "Epoch 59, Loss(train/val) 0.19052/0.33418. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.18700/0.31177. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.18376/0.29981. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.17639/0.29255. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.17416/0.29641. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.17227/0.28051. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.16869/0.28614. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.17148/0.27829. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.17464/0.28172. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.16487/0.30168. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.16184/0.29802. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.16874/0.29068. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.16871/0.29575. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.18284/0.28677. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.16913/0.35415. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.15713/0.32679. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) 0.16420/0.35091. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.17170/0.31947. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.17001/0.30754. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.16110/0.29537. Took 0.14 sec\n",
      "Epoch 79, Loss(train/val) 0.17043/0.29917. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.16114/0.32646. Took 0.14 sec\n",
      "Epoch 81, Loss(train/val) 0.16787/0.30302. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.16875/0.31163. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) 0.15182/0.30519. Took 0.16 sec\n",
      "Epoch 84, Loss(train/val) 0.16103/0.31549. Took 0.17 sec\n",
      "Epoch 85, Loss(train/val) 0.16487/0.33029. Took 0.17 sec\n",
      "Epoch 86, Loss(train/val) 0.15658/0.31948. Took 0.15 sec\n",
      "Epoch 87, Loss(train/val) 0.16126/0.31540. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.15022/0.32244. Took 0.14 sec\n",
      "Epoch 89, Loss(train/val) 0.15149/0.30646. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.15634/0.30681. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.15432/0.30389. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.16591/0.36523. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.15090/0.35607. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.14887/0.35156. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.14756/0.33736. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.15293/0.33767. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.14714/0.31882. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.14915/0.30952. Took 0.14 sec\n",
      "Epoch 99, Loss(train/val) 0.15158/0.33803. Took 0.13 sec\n",
      "ACC: 0.71875, MCC: 0.46512360739915587\n",
      "Epoch 0, Loss(train/val) 0.49217/0.47388. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.46256/0.42894. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.41926/0.39644. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.38856/0.37277. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.36673/0.35588. Took 0.16 sec\n",
      "Epoch 5, Loss(train/val) 0.35063/0.34615. Took 0.15 sec\n",
      "Epoch 6, Loss(train/val) 0.34270/0.35183. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.33407/0.34605. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.33026/0.33529. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.32653/0.32915. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.32461/0.32669. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.31563/0.32855. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.32207/0.31409. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.32428/0.31804. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.31155/0.32628. Took 0.15 sec\n",
      "Epoch 15, Loss(train/val) 0.30078/0.33601. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.29787/0.32130. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.29966/0.32695. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.28810/0.32627. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.28011/0.32530. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.27979/0.31626. Took 0.15 sec\n",
      "Epoch 21, Loss(train/val) 0.27269/0.32717. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.27231/0.31517. Took 0.15 sec\n",
      "Epoch 23, Loss(train/val) 0.27090/0.31773. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.26168/0.31480. Took 0.15 sec\n",
      "Epoch 25, Loss(train/val) 0.25770/0.32613. Took 0.17 sec\n",
      "Epoch 26, Loss(train/val) 0.26145/0.26805. Took 0.20 sec\n",
      "Epoch 27, Loss(train/val) 0.24972/0.32797. Took 0.20 sec\n",
      "Epoch 28, Loss(train/val) 0.25371/0.32872. Took 0.20 sec\n",
      "Epoch 29, Loss(train/val) 0.25616/0.31544. Took 0.21 sec\n",
      "Epoch 30, Loss(train/val) 0.24912/0.29845. Took 0.17 sec\n",
      "Epoch 31, Loss(train/val) 0.23517/0.29503. Took 0.17 sec\n",
      "Epoch 32, Loss(train/val) 0.24036/0.32017. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.23280/0.33521. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.23246/0.33159. Took 0.16 sec\n",
      "Epoch 35, Loss(train/val) 0.22740/0.33669. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.23161/0.31188. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.22924/0.30973. Took 0.15 sec\n",
      "Epoch 38, Loss(train/val) 0.21941/0.28882. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.21829/0.30691. Took 0.15 sec\n",
      "Epoch 40, Loss(train/val) 0.21797/0.30827. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.20627/0.31315. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.20342/0.30814. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.20362/0.30281. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.21097/0.30502. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) 0.20378/0.29589. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.20109/0.31834. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.19403/0.32584. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.19862/0.31230. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.18887/0.31281. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.18651/0.32761. Took 0.14 sec\n",
      "Epoch 51, Loss(train/val) 0.18934/0.32854. Took 0.15 sec\n",
      "Epoch 52, Loss(train/val) 0.18469/0.31187. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.19271/0.31722. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.18837/0.31381. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.18056/0.31316. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.18781/0.31091. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.18364/0.31643. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.18210/0.30641. Took 0.14 sec\n",
      "Epoch 59, Loss(train/val) 0.18012/0.34396. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.17702/0.32836. Took 0.15 sec\n",
      "Epoch 61, Loss(train/val) 0.17812/0.32865. Took 0.16 sec\n",
      "Epoch 62, Loss(train/val) 0.17368/0.31491. Took 0.18 sec\n",
      "Epoch 63, Loss(train/val) 0.17067/0.32632. Took 0.15 sec\n",
      "Epoch 64, Loss(train/val) 0.18195/0.31268. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.17155/0.33083. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.16445/0.33283. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.16740/0.32540. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.16135/0.31810. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.16337/0.34177. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.16135/0.34318. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.15884/0.32923. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.16436/0.32231. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.16461/0.31801. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.16567/0.33749. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.15899/0.34264. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.14903/0.33588. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.15369/0.32275. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.15273/0.34217. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.15206/0.34140. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.14964/0.35687. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.15143/0.34805. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.14898/0.35160. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.15439/0.34581. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.15068/0.34832. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.15012/0.34531. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.14532/0.35703. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.15048/0.34526. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.14596/0.33716. Took 0.15 sec\n",
      "Epoch 89, Loss(train/val) 0.14749/0.33827. Took 0.15 sec\n",
      "Epoch 90, Loss(train/val) 0.13955/0.34177. Took 0.15 sec\n",
      "Epoch 91, Loss(train/val) 0.13675/0.33819. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.14171/0.35586. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.14141/0.33667. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.13891/0.33879. Took 0.14 sec\n",
      "Epoch 95, Loss(train/val) 0.13947/0.34958. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.13378/0.34315. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.12991/0.33583. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.13879/0.33649. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.13189/0.35484. Took 0.14 sec\n",
      "ACC: 0.71875, MCC: 0.4383570037596047\n",
      "Epoch 0, Loss(train/val) 0.49699/0.49052. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.47684/0.47109. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.44091/0.45250. Took 0.15 sec\n",
      "Epoch 3, Loss(train/val) 0.39634/0.43559. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.37406/0.40047. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.36139/0.37722. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.35197/0.35411. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.34036/0.32070. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.33822/0.30021. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.32700/0.29649. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.32280/0.26880. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.30858/0.27058. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.29743/0.30642. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.28889/0.29343. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.28318/0.27798. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.28105/0.30336. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.27318/0.30904. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.27584/0.28830. Took 0.16 sec\n",
      "Epoch 18, Loss(train/val) 0.26421/0.29767. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.25392/0.28731. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.25807/0.28757. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.25620/0.30170. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.25535/0.29183. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.23520/0.29928. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.24217/0.29805. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.23741/0.29642. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.22508/0.30497. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.21183/0.31126. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.21589/0.29998. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.22392/0.31148. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.22157/0.31722. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.22028/0.29700. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.20929/0.30301. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.22262/0.31423. Took 0.16 sec\n",
      "Epoch 34, Loss(train/val) 0.21327/0.31616. Took 0.16 sec\n",
      "Epoch 35, Loss(train/val) 0.21047/0.31512. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.20717/0.29652. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.20338/0.30717. Took 0.16 sec\n",
      "Epoch 38, Loss(train/val) 0.20951/0.30068. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.20832/0.31592. Took 0.15 sec\n",
      "Epoch 40, Loss(train/val) 0.19646/0.30871. Took 0.15 sec\n",
      "Epoch 41, Loss(train/val) 0.19162/0.30532. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.18492/0.31573. Took 0.15 sec\n",
      "Epoch 43, Loss(train/val) 0.19349/0.30908. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.18995/0.31173. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.18497/0.31910. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.19263/0.29866. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.18886/0.33567. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.18717/0.31756. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.18388/0.32756. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.17815/0.31495. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.17680/0.31400. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.17773/0.31352. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.18639/0.30910. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.17794/0.31823. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.18400/0.33029. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.18448/0.30536. Took 0.15 sec\n",
      "Epoch 57, Loss(train/val) 0.17471/0.34288. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.17665/0.33719. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.16413/0.32998. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.16336/0.32683. Took 0.15 sec\n",
      "Epoch 61, Loss(train/val) 0.16766/0.30830. Took 0.15 sec\n",
      "Epoch 62, Loss(train/val) 0.15937/0.30930. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.16232/0.31310. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.14966/0.33365. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.16197/0.30054. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.14160/0.31447. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.15299/0.32002. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.14464/0.32068. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.15428/0.33212. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.15655/0.32550. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.15356/0.32393. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.15694/0.30578. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.15282/0.32335. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.15039/0.32238. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.15113/0.32876. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.15157/0.31906. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.14641/0.32204. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.15373/0.31705. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.14134/0.31966. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.13901/0.33304. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.15040/0.31403. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.14130/0.32150. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) 0.13364/0.31787. Took 0.16 sec\n",
      "Epoch 84, Loss(train/val) 0.13696/0.32276. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.13344/0.33634. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.13221/0.33194. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.13749/0.34171. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.14082/0.33013. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.14181/0.32741. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.13381/0.33389. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.12769/0.34207. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.12458/0.32454. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.12245/0.34297. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.11748/0.32522. Took 0.14 sec\n",
      "Epoch 95, Loss(train/val) 0.12158/0.34173. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.12674/0.31953. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.12473/0.33509. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.11952/0.32607. Took 0.14 sec\n",
      "Epoch 99, Loss(train/val) 0.12867/0.32097. Took 0.13 sec\n",
      "ACC: 0.640625, MCC: 0.29308032406162626\n",
      "Epoch 0, Loss(train/val) 0.49343/0.48285. Took 0.16 sec\n",
      "Epoch 1, Loss(train/val) 0.47127/0.46339. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.43565/0.45071. Took 0.15 sec\n",
      "Epoch 3, Loss(train/val) 0.39926/0.43799. Took 0.15 sec\n",
      "Epoch 4, Loss(train/val) 0.38204/0.43921. Took 0.15 sec\n",
      "Epoch 5, Loss(train/val) 0.37174/0.41446. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.35870/0.42180. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.35706/0.41384. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.34431/0.41650. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.33579/0.40922. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.33156/0.40067. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.33826/0.39246. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.32805/0.38631. Took 0.16 sec\n",
      "Epoch 13, Loss(train/val) 0.31390/0.36950. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.31788/0.36304. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.29777/0.34929. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.29317/0.34919. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.29444/0.33855. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.27916/0.31413. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.28240/0.32404. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.28186/0.34303. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.27946/0.31703. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.27071/0.32757. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.26680/0.31696. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.26129/0.31660. Took 0.16 sec\n",
      "Epoch 25, Loss(train/val) 0.26096/0.29325. Took 0.18 sec\n",
      "Epoch 26, Loss(train/val) 0.25714/0.30092. Took 0.17 sec\n",
      "Epoch 27, Loss(train/val) 0.25675/0.31528. Took 0.16 sec\n",
      "Epoch 28, Loss(train/val) 0.24320/0.28926. Took 0.17 sec\n",
      "Epoch 29, Loss(train/val) 0.24301/0.28247. Took 0.16 sec\n",
      "Epoch 30, Loss(train/val) 0.24124/0.31703. Took 0.16 sec\n",
      "Epoch 31, Loss(train/val) 0.24035/0.28982. Took 0.17 sec\n",
      "Epoch 32, Loss(train/val) 0.23882/0.28968. Took 0.18 sec\n",
      "Epoch 33, Loss(train/val) 0.22351/0.28250. Took 0.16 sec\n",
      "Epoch 34, Loss(train/val) 0.22234/0.29132. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.22749/0.31912. Took 0.15 sec\n",
      "Epoch 36, Loss(train/val) 0.21606/0.28946. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.21263/0.28767. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.22231/0.27015. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.21744/0.29618. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.21426/0.30211. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.20577/0.29909. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.19817/0.27986. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.20741/0.29112. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.20530/0.29145. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.20838/0.28148. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.19693/0.29431. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.19339/0.27387. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.19796/0.31985. Took 0.15 sec\n",
      "Epoch 49, Loss(train/val) 0.19582/0.27714. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.19097/0.28666. Took 0.14 sec\n",
      "Epoch 51, Loss(train/val) 0.18561/0.31322. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.18925/0.29219. Took 0.15 sec\n",
      "Epoch 53, Loss(train/val) 0.17795/0.30292. Took 0.15 sec\n",
      "Epoch 54, Loss(train/val) 0.18138/0.30108. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.17943/0.28666. Took 0.15 sec\n",
      "Epoch 56, Loss(train/val) 0.18801/0.30446. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.18233/0.32358. Took 0.15 sec\n",
      "Epoch 58, Loss(train/val) 0.16959/0.27415. Took 0.15 sec\n",
      "Epoch 59, Loss(train/val) 0.16320/0.28163. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.17129/0.31026. Took 0.14 sec\n",
      "Epoch 61, Loss(train/val) 0.17640/0.30804. Took 0.17 sec\n",
      "Epoch 62, Loss(train/val) 0.16629/0.32694. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.16888/0.28990. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.16967/0.29757. Took 0.15 sec\n",
      "Epoch 65, Loss(train/val) 0.16966/0.33320. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.16822/0.30099. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.16611/0.27417. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.17300/0.33418. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.15947/0.33471. Took 0.15 sec\n",
      "Epoch 70, Loss(train/val) 0.16082/0.29156. Took 0.15 sec\n",
      "Epoch 71, Loss(train/val) 0.16237/0.27522. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.15676/0.28989. Took 0.15 sec\n",
      "Epoch 73, Loss(train/val) 0.15551/0.33381. Took 0.15 sec\n",
      "Epoch 74, Loss(train/val) 0.15454/0.30269. Took 0.15 sec\n",
      "Epoch 75, Loss(train/val) 0.15597/0.29273. Took 0.15 sec\n",
      "Epoch 76, Loss(train/val) 0.14997/0.29346. Took 0.16 sec\n",
      "Epoch 77, Loss(train/val) 0.14867/0.30629. Took 0.15 sec\n",
      "Epoch 78, Loss(train/val) 0.15001/0.29278. Took 0.15 sec\n",
      "Epoch 79, Loss(train/val) 0.15559/0.30336. Took 0.15 sec\n",
      "Epoch 80, Loss(train/val) 0.15548/0.30494. Took 0.16 sec\n",
      "Epoch 81, Loss(train/val) 0.15179/0.31573. Took 0.16 sec\n",
      "Epoch 82, Loss(train/val) 0.14666/0.33304. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) 0.14655/0.28789. Took 0.15 sec\n",
      "Epoch 84, Loss(train/val) 0.13817/0.30643. Took 0.15 sec\n",
      "Epoch 85, Loss(train/val) 0.13963/0.30639. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.14276/0.31555. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.13777/0.26421. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.13955/0.31845. Took 0.14 sec\n",
      "Epoch 89, Loss(train/val) 0.13711/0.26933. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.13672/0.31172. Took 0.14 sec\n",
      "Epoch 91, Loss(train/val) 0.14130/0.34813. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.14162/0.29062. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.13958/0.34434. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.14183/0.33048. Took 0.14 sec\n",
      "Epoch 95, Loss(train/val) 0.13036/0.33335. Took 0.12 sec\n",
      "Epoch 96, Loss(train/val) 0.12889/0.32104. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.12618/0.30763. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.13675/0.33946. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.13037/0.26605. Took 0.13 sec\n",
      "ACC: 0.609375, MCC: 0.2677052359180148\n",
      "Epoch 0, Loss(train/val) 0.49610/0.48730. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.47625/0.46675. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.44532/0.43274. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.40975/0.40980. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.38406/0.40231. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.36309/0.40914. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.35495/0.40564. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.34770/0.40228. Took 0.16 sec\n",
      "Epoch 8, Loss(train/val) 0.33788/0.39273. Took 0.16 sec\n",
      "Epoch 9, Loss(train/val) 0.33373/0.39607. Took 0.15 sec\n",
      "Epoch 10, Loss(train/val) 0.32570/0.40620. Took 0.16 sec\n",
      "Epoch 11, Loss(train/val) 0.33528/0.39089. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.32678/0.38792. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.31541/0.39070. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.31634/0.37486. Took 0.15 sec\n",
      "Epoch 15, Loss(train/val) 0.31238/0.33288. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.31160/0.31545. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.30043/0.32109. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.29589/0.31257. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.29310/0.30090. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.28415/0.28775. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.27749/0.29321. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.28699/0.28329. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.26452/0.28733. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.27318/0.30228. Took 0.15 sec\n",
      "Epoch 25, Loss(train/val) 0.27365/0.28046. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.26199/0.26766. Took 0.17 sec\n",
      "Epoch 27, Loss(train/val) 0.25769/0.25763. Took 0.17 sec\n",
      "Epoch 28, Loss(train/val) 0.24700/0.27140. Took 0.16 sec\n",
      "Epoch 29, Loss(train/val) 0.25331/0.27117. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.24494/0.26142. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.23368/0.25822. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.24104/0.25593. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.24560/0.26431. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.23849/0.24458. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.22843/0.22867. Took 0.13 sec\n",
      "Epoch 36, Loss(train/val) 0.22120/0.23509. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.21374/0.24420. Took 0.15 sec\n",
      "Epoch 38, Loss(train/val) 0.22354/0.24405. Took 0.15 sec\n",
      "Epoch 39, Loss(train/val) 0.22329/0.23849. Took 0.15 sec\n",
      "Epoch 40, Loss(train/val) 0.21622/0.24066. Took 0.15 sec\n",
      "Epoch 41, Loss(train/val) 0.21565/0.24942. Took 0.18 sec\n",
      "Epoch 42, Loss(train/val) 0.20691/0.25600. Took 0.15 sec\n",
      "Epoch 43, Loss(train/val) 0.20995/0.24370. Took 0.16 sec\n",
      "Epoch 44, Loss(train/val) 0.20466/0.23799. Took 0.17 sec\n",
      "Epoch 45, Loss(train/val) 0.20087/0.23677. Took 0.16 sec\n",
      "Epoch 46, Loss(train/val) 0.19640/0.25384. Took 0.16 sec\n",
      "Epoch 47, Loss(train/val) 0.19823/0.22296. Took 0.16 sec\n",
      "Epoch 48, Loss(train/val) 0.19685/0.25555. Took 0.15 sec\n",
      "Epoch 49, Loss(train/val) 0.19873/0.22866. Took 0.16 sec\n",
      "Epoch 50, Loss(train/val) 0.18819/0.21402. Took 0.15 sec\n",
      "Epoch 51, Loss(train/val) 0.19304/0.27001. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.18667/0.25307. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) 0.18843/0.23799. Took 0.17 sec\n",
      "Epoch 54, Loss(train/val) 0.18170/0.24452. Took 0.17 sec\n",
      "Epoch 55, Loss(train/val) 0.18028/0.24150. Took 0.17 sec\n",
      "Epoch 56, Loss(train/val) 0.18124/0.25503. Took 0.16 sec\n",
      "Epoch 57, Loss(train/val) 0.18687/0.27098. Took 0.16 sec\n",
      "Epoch 58, Loss(train/val) 0.19204/0.25864. Took 0.15 sec\n",
      "Epoch 59, Loss(train/val) 0.16972/0.24823. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.17344/0.26647. Took 0.14 sec\n",
      "Epoch 61, Loss(train/val) 0.17273/0.24592. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.17803/0.28183. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.17583/0.26775. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.15974/0.23043. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.16352/0.28605. Took 0.15 sec\n",
      "Epoch 66, Loss(train/val) 0.16798/0.24909. Took 0.15 sec\n",
      "Epoch 67, Loss(train/val) 0.16251/0.25336. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.16830/0.26311. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.15557/0.26798. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.14813/0.28995. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.16060/0.25145. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.15181/0.25876. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.15583/0.29230. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.15345/0.25182. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) 0.15954/0.26422. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.15264/0.26194. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.14556/0.28760. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.13787/0.26046. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.14753/0.24318. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.14310/0.30862. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.15752/0.28327. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.14264/0.24953. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.14924/0.28629. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.13871/0.25809. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.13713/0.29782. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.15118/0.25867. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.14786/0.28427. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.14921/0.25901. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.14975/0.29743. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.14006/0.26708. Took 0.14 sec\n",
      "Epoch 91, Loss(train/val) 0.13292/0.30360. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.13271/0.26224. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.13318/0.28227. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.13626/0.30308. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.13785/0.27900. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.13418/0.31068. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.12877/0.29015. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.13287/0.27333. Took 0.14 sec\n",
      "Epoch 99, Loss(train/val) 0.12871/0.27747. Took 0.13 sec\n",
      "ACC: 0.5625, MCC: 0.11318329168362205\n",
      "Epoch 0, Loss(train/val) 0.49525/0.48943. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.47692/0.47136. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.44647/0.44021. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.41108/0.41587. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.38917/0.39414. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.37266/0.37299. Took 0.15 sec\n",
      "Epoch 6, Loss(train/val) 0.35793/0.36568. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.34616/0.35324. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.33273/0.39233. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.33865/0.35327. Took 0.15 sec\n",
      "Epoch 10, Loss(train/val) 0.31917/0.38365. Took 0.15 sec\n",
      "Epoch 11, Loss(train/val) 0.33055/0.33500. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.30993/0.35845. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.30402/0.33750. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.29265/0.32289. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.29407/0.32327. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.28788/0.31518. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.28410/0.30455. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.28062/0.30766. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.27858/0.29218. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.28190/0.29508. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.26420/0.32601. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.26884/0.28993. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.25962/0.30430. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.26039/0.29320. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.24873/0.27574. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.25077/0.29600. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.23992/0.29876. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.24546/0.28791. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.24751/0.32712. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.24290/0.30619. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.22954/0.28472. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.23694/0.29763. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.23695/0.30928. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.22635/0.32228. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.22680/0.31099. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.22727/0.29997. Took 0.13 sec\n",
      "Epoch 37, Loss(train/val) 0.22595/0.34017. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.22304/0.32180. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.21455/0.31332. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.21093/0.34258. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.22017/0.29849. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.22055/0.32571. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.21571/0.32558. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.21308/0.32058. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) 0.21355/0.33587. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.20396/0.32990. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.20220/0.35073. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.20009/0.33018. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.20206/0.33790. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.19968/0.34870. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.19680/0.34452. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.19537/0.32704. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) 0.19548/0.34699. Took 0.15 sec\n",
      "Epoch 54, Loss(train/val) 0.18350/0.35257. Took 0.19 sec\n",
      "Epoch 55, Loss(train/val) 0.18433/0.34549. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.18255/0.35090. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.18698/0.36367. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.18844/0.36726. Took 0.14 sec\n",
      "Epoch 59, Loss(train/val) 0.18533/0.36009. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.17490/0.34746. Took 0.15 sec\n",
      "Epoch 61, Loss(train/val) 0.17979/0.33461. Took 0.15 sec\n",
      "Epoch 62, Loss(train/val) 0.19289/0.39212. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.17344/0.38803. Took 0.16 sec\n",
      "Epoch 64, Loss(train/val) 0.17892/0.36057. Took 0.17 sec\n",
      "Epoch 65, Loss(train/val) 0.17755/0.34249. Took 0.15 sec\n",
      "Epoch 66, Loss(train/val) 0.17392/0.37079. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) 0.17757/0.36343. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.17355/0.35077. Took 0.14 sec\n",
      "Epoch 69, Loss(train/val) 0.17075/0.35080. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.16331/0.34498. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.16511/0.35439. Took 0.15 sec\n",
      "Epoch 72, Loss(train/val) 0.16752/0.35936. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.17129/0.34211. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.17438/0.36945. Took 0.15 sec\n",
      "Epoch 75, Loss(train/val) 0.16886/0.37073. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.17401/0.34821. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.17107/0.36333. Took 0.16 sec\n",
      "Epoch 78, Loss(train/val) 0.16778/0.36164. Took 0.17 sec\n",
      "Epoch 79, Loss(train/val) 0.16143/0.35744. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.16646/0.34223. Took 0.16 sec\n",
      "Epoch 81, Loss(train/val) 0.16480/0.34762. Took 0.15 sec\n",
      "Epoch 82, Loss(train/val) 0.16648/0.36577. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) 0.16438/0.36059. Took 0.15 sec\n",
      "Epoch 84, Loss(train/val) 0.15821/0.36918. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.15782/0.35835. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.15159/0.36022. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.15643/0.35986. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.15106/0.38651. Took 0.14 sec\n",
      "Epoch 89, Loss(train/val) 0.18010/0.40421. Took 0.16 sec\n",
      "Epoch 90, Loss(train/val) 0.16446/0.38912. Took 0.15 sec\n",
      "Epoch 91, Loss(train/val) 0.16195/0.37149. Took 0.15 sec\n",
      "Epoch 92, Loss(train/val) 0.15984/0.37977. Took 0.16 sec\n",
      "Epoch 93, Loss(train/val) 0.14876/0.36082. Took 0.15 sec\n",
      "Epoch 94, Loss(train/val) 0.15383/0.37230. Took 0.15 sec\n",
      "Epoch 95, Loss(train/val) 0.14854/0.37570. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.14992/0.36254. Took 0.15 sec\n",
      "Epoch 97, Loss(train/val) 0.14507/0.36268. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.14617/0.36899. Took 0.14 sec\n",
      "Epoch 99, Loss(train/val) 0.14606/0.36628. Took 0.13 sec\n",
      "ACC: 0.671875, MCC: 0.26489818259524006\n",
      "Epoch 0, Loss(train/val) 0.49507/0.47403. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.47118/0.41901. Took 0.15 sec\n",
      "Epoch 2, Loss(train/val) 0.43355/0.38141. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.40379/0.36890. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.38480/0.36632. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.37929/0.37113. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.37282/0.36400. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.36610/0.36563. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.36102/0.37181. Took 0.15 sec\n",
      "Epoch 9, Loss(train/val) 0.35917/0.36849. Took 0.15 sec\n",
      "Epoch 10, Loss(train/val) 0.36209/0.37155. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.35050/0.33845. Took 0.15 sec\n",
      "Epoch 12, Loss(train/val) 0.33218/0.34433. Took 0.15 sec\n",
      "Epoch 13, Loss(train/val) 0.31977/0.32269. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.31492/0.33752. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.32495/0.33243. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.31969/0.34814. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.31248/0.31875. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.31380/0.35707. Took 0.15 sec\n",
      "Epoch 19, Loss(train/val) 0.31099/0.40552. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.29703/0.37013. Took 0.15 sec\n",
      "Epoch 21, Loss(train/val) 0.29979/0.43491. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.29296/0.36963. Took 0.17 sec\n",
      "Epoch 23, Loss(train/val) 0.28601/0.35669. Took 0.16 sec\n",
      "Epoch 24, Loss(train/val) 0.27904/0.44153. Took 0.20 sec\n",
      "Epoch 25, Loss(train/val) 0.28029/0.37234. Took 0.19 sec\n",
      "Epoch 26, Loss(train/val) 0.26987/0.37870. Took 0.18 sec\n",
      "Epoch 27, Loss(train/val) 0.27439/0.36955. Took 0.19 sec\n",
      "Epoch 28, Loss(train/val) 0.27326/0.37004. Took 0.17 sec\n",
      "Epoch 29, Loss(train/val) 0.26603/0.37349. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.26387/0.37307. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.26639/0.41647. Took 0.16 sec\n",
      "Epoch 32, Loss(train/val) 0.25555/0.37772. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.25233/0.35260. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.25318/0.33918. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.25040/0.32843. Took 0.15 sec\n",
      "Epoch 36, Loss(train/val) 0.24912/0.37107. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.25133/0.35918. Took 0.15 sec\n",
      "Epoch 38, Loss(train/val) 0.25950/0.38573. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.26580/0.35879. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.24640/0.35439. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.24317/0.37040. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.24555/0.39240. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.24584/0.36153. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.23736/0.36402. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.23383/0.45387. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.24842/0.44528. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.23632/0.37256. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.23469/0.44787. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.23340/0.41994. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.22774/0.43587. Took 0.14 sec\n",
      "Epoch 51, Loss(train/val) 0.21490/0.44532. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.21549/0.44683. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) 0.22301/0.45100. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.21084/0.43861. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.20860/0.41219. Took 0.16 sec\n",
      "Epoch 56, Loss(train/val) 0.20904/0.42068. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.21173/0.44462. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.20704/0.46051. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.20765/0.45585. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.20072/0.44429. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.20650/0.42793. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.20191/0.41977. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.20281/0.41798. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.19176/0.42668. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.19832/0.42550. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.19106/0.42427. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.19063/0.42768. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.18759/0.40657. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.19248/0.43805. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.18459/0.43262. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.18092/0.42627. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.17802/0.44577. Took 0.15 sec\n",
      "Epoch 73, Loss(train/val) 0.18233/0.43101. Took 0.15 sec\n",
      "Epoch 74, Loss(train/val) 0.18529/0.42790. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) 0.17782/0.40933. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.18432/0.41490. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.17633/0.42877. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.17447/0.43739. Took 0.14 sec\n",
      "Epoch 79, Loss(train/val) 0.17467/0.41937. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.17994/0.35307. Took 0.14 sec\n",
      "Epoch 81, Loss(train/val) 0.18400/0.33964. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.18778/0.44093. Took 0.15 sec\n",
      "Epoch 83, Loss(train/val) 0.17991/0.42220. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.16532/0.44971. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.15766/0.44919. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.16494/0.43166. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.16810/0.40681. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.16996/0.39566. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.16617/0.39636. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.16417/0.41838. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.16006/0.44565. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.15775/0.45057. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.16021/0.40764. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.16034/0.36025. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.16017/0.43117. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.15493/0.36380. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.15262/0.37164. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.15237/0.42619. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.14634/0.36016. Took 0.13 sec\n",
      "ACC: 0.75, MCC: 0.4836617263207963\n",
      "Epoch 0, Loss(train/val) 0.49144/0.46221. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.45906/0.39325. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.41942/0.32749. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.39403/0.29518. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.37806/0.28330. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.36867/0.27894. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.35633/0.27246. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.34889/0.28678. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.33618/0.29323. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.31883/0.32077. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.30326/0.34610. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.29952/0.36240. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.28680/0.39608. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.28683/0.35463. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.29451/0.39084. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.27919/0.38926. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.28411/0.40098. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.27882/0.35478. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.27301/0.39248. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.26731/0.38912. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.26605/0.40985. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.26084/0.38852. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.26268/0.39688. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.25542/0.39694. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.24971/0.38673. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.25167/0.39348. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.24716/0.39139. Took 0.13 sec\n",
      "Epoch 27, Loss(train/val) 0.24827/0.40115. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.24185/0.40262. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.24117/0.39238. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.24223/0.39313. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.25580/0.38211. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.23500/0.40631. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.23472/0.41186. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.23100/0.36678. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.23013/0.39507. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.22382/0.40819. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.22922/0.41511. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.22760/0.41655. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.22274/0.41715. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.23007/0.41493. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.22422/0.41276. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.21447/0.40711. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.22877/0.42687. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.21898/0.38813. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.21762/0.37063. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.21747/0.40489. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.22136/0.40779. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.21802/0.38577. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.22005/0.41727. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.21311/0.41723. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.20868/0.41743. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.21548/0.39100. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.20619/0.40255. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.20406/0.39463. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.20729/0.42843. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.20331/0.42048. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.20988/0.39637. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.20274/0.41860. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.19742/0.39948. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.20153/0.42204. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.19868/0.41774. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.20577/0.42144. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.19843/0.43672. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.19390/0.43687. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.19340/0.43369. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.18802/0.44037. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.19123/0.43300. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.18584/0.42797. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.19101/0.44140. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.18376/0.44032. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.18544/0.42803. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.18510/0.42305. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.18389/0.43851. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.18825/0.42795. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.18501/0.44678. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.18478/0.43790. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.18678/0.44159. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.18157/0.43550. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.18043/0.44096. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.17726/0.44497. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.17255/0.43767. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.18556/0.42980. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.17210/0.44143. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.17913/0.42392. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.17495/0.44850. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.17109/0.43660. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.16693/0.44652. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.17101/0.42696. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.16701/0.43311. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.15991/0.44348. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.16759/0.43545. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.16658/0.43668. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.16769/0.44432. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.17014/0.43064. Took 0.14 sec\n",
      "Epoch 95, Loss(train/val) 0.15239/0.43547. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.15810/0.41736. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.16333/0.39644. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.16224/0.42745. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.15923/0.42885. Took 0.13 sec\n",
      "ACC: 0.609375, MCC: 0.21971768720102058\n",
      "Epoch 0, Loss(train/val) 0.49184/0.49897. Took 0.13 sec\n",
      "Epoch 1, Loss(train/val) 0.46620/0.48747. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.43586/0.45746. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.40856/0.43091. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.38927/0.42443. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.37835/0.42757. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.36616/0.42582. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.36001/0.42602. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.35252/0.42161. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.34237/0.42531. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.34401/0.42108. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.33029/0.42881. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.32068/0.41869. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.31121/0.42720. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.30217/0.41807. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.30217/0.41650. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.29700/0.41950. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.28542/0.40894. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.27442/0.40289. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.26936/0.40602. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.27247/0.41037. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.27044/0.41775. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.26783/0.36094. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.26463/0.39209. Took 0.16 sec\n",
      "Epoch 24, Loss(train/val) 0.26304/0.41301. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.26376/0.41725. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.25278/0.37551. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.25475/0.41523. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.24051/0.37389. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.25036/0.45440. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.24565/0.40057. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.26887/0.46504. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.24248/0.40348. Took 0.13 sec\n",
      "Epoch 33, Loss(train/val) 0.24554/0.41811. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.23533/0.38746. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.22969/0.34648. Took 0.13 sec\n",
      "Epoch 36, Loss(train/val) 0.23162/0.38900. Took 0.13 sec\n",
      "Epoch 37, Loss(train/val) 0.23197/0.37016. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.23124/0.38499. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.22113/0.37583. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.22366/0.39485. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.21696/0.38786. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.22160/0.38541. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.21738/0.38866. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.21553/0.44201. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.23925/0.41477. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.22117/0.36403. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.20792/0.35005. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.20814/0.38461. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.20404/0.34966. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.21265/0.36828. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.20969/0.35864. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.20175/0.37666. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.21081/0.37744. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.20226/0.37860. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.20568/0.38701. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.19276/0.36893. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.19871/0.37182. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.18902/0.35871. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.18662/0.38219. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.19540/0.36032. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.18950/0.34429. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.18795/0.36579. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.18270/0.35933. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.18823/0.35826. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.18042/0.37048. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.17830/0.35356. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.18469/0.37485. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.18256/0.39124. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.17763/0.33638. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.17966/0.35335. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.18392/0.33938. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.17693/0.31546. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.17777/0.32072. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.16740/0.31395. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.17534/0.33169. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.16936/0.32274. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.16836/0.35855. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.16581/0.34216. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.17053/0.33074. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.16955/0.37654. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.16832/0.37071. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.16965/0.34066. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.15666/0.34421. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.16561/0.31759. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.16626/0.33226. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.15727/0.39122. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.16216/0.32240. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.15025/0.31664. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.15800/0.31170. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.15931/0.31269. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.15057/0.31287. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.14933/0.31265. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.14710/0.30173. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.15017/0.31602. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.14861/0.30780. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.14964/0.30812. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.14513/0.29573. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.14439/0.31125. Took 0.14 sec\n",
      "Epoch 99, Loss(train/val) 0.14965/0.32503. Took 0.13 sec\n",
      "ACC: 0.734375, MCC: 0.46979524081643825\n",
      "Epoch 0, Loss(train/val) 0.48988/0.48095. Took 0.13 sec\n",
      "Epoch 1, Loss(train/val) 0.46501/0.44404. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.43009/0.39505. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.40314/0.36613. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.38661/0.34771. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.37342/0.35034. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.36486/0.35658. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.35457/0.35913. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.34438/0.38020. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.33388/0.36472. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.32796/0.39713. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.30961/0.39578. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.30764/0.41835. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.30150/0.40638. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.28857/0.34573. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.28835/0.39660. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.28306/0.37560. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.28082/0.39133. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.26224/0.41126. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.26484/0.42317. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.26306/0.42536. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.25919/0.39453. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.25690/0.40742. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.25025/0.39129. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.26196/0.41167. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.25111/0.43242. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.25368/0.39296. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.24546/0.43084. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.24352/0.44339. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.24482/0.41242. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.24553/0.42607. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.24502/0.44022. Took 0.16 sec\n",
      "Epoch 32, Loss(train/val) 0.24176/0.40839. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.22506/0.43317. Took 0.17 sec\n",
      "Epoch 34, Loss(train/val) 0.23088/0.42161. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.22867/0.43469. Took 0.16 sec\n",
      "Epoch 36, Loss(train/val) 0.23194/0.44447. Took 0.18 sec\n",
      "Epoch 37, Loss(train/val) 0.21996/0.42064. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.22455/0.43801. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.22280/0.44355. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.21806/0.43872. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.22529/0.41135. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.20355/0.43858. Took 0.15 sec\n",
      "Epoch 43, Loss(train/val) 0.21569/0.43216. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.21212/0.40302. Took 0.15 sec\n",
      "Epoch 45, Loss(train/val) 0.20688/0.39802. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.20461/0.40628. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.19880/0.41914. Took 0.15 sec\n",
      "Epoch 48, Loss(train/val) 0.19820/0.41906. Took 0.15 sec\n",
      "Epoch 49, Loss(train/val) 0.19642/0.43447. Took 0.15 sec\n",
      "Epoch 50, Loss(train/val) 0.21422/0.40957. Took 0.15 sec\n",
      "Epoch 51, Loss(train/val) 0.20471/0.43944. Took 0.15 sec\n",
      "Epoch 52, Loss(train/val) 0.19893/0.43847. Took 0.15 sec\n",
      "Epoch 53, Loss(train/val) 0.20392/0.33989. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.20391/0.41781. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.18059/0.41763. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.20141/0.33975. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.20379/0.38245. Took 0.15 sec\n",
      "Epoch 58, Loss(train/val) 0.19342/0.36787. Took 0.15 sec\n",
      "Epoch 59, Loss(train/val) 0.18693/0.36235. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.18058/0.34726. Took 0.14 sec\n",
      "Epoch 61, Loss(train/val) 0.18653/0.38848. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.19338/0.40682. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.19110/0.37984. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.19105/0.41668. Took 0.15 sec\n",
      "Epoch 65, Loss(train/val) 0.18570/0.37754. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.18450/0.35557. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.18003/0.34795. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.17520/0.32617. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.17051/0.33527. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.17972/0.33315. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.17157/0.37475. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.17308/0.37874. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.16715/0.36734. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.16770/0.37017. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.16043/0.36404. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.16641/0.36817. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.17386/0.34991. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.16987/0.34547. Took 0.17 sec\n",
      "Epoch 79, Loss(train/val) 0.16413/0.39818. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.16381/0.35740. Took 0.15 sec\n",
      "Epoch 81, Loss(train/val) 0.15465/0.36378. Took 0.15 sec\n",
      "Epoch 82, Loss(train/val) 0.17693/0.37422. Took 0.17 sec\n",
      "Epoch 83, Loss(train/val) 0.16109/0.38748. Took 0.20 sec\n",
      "Epoch 84, Loss(train/val) 0.16348/0.34116. Took 0.15 sec\n",
      "Epoch 85, Loss(train/val) 0.15517/0.37474. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.16381/0.36207. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.15436/0.34724. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.15974/0.38824. Took 0.14 sec\n",
      "Epoch 89, Loss(train/val) 0.14655/0.34077. Took 0.16 sec\n",
      "Epoch 90, Loss(train/val) 0.15119/0.37513. Took 0.18 sec\n",
      "Epoch 91, Loss(train/val) 0.14824/0.35825. Took 0.16 sec\n",
      "Epoch 92, Loss(train/val) 0.14382/0.34019. Took 0.15 sec\n",
      "Epoch 93, Loss(train/val) 0.15128/0.35736. Took 0.15 sec\n",
      "Epoch 94, Loss(train/val) 0.15040/0.35912. Took 0.16 sec\n",
      "Epoch 95, Loss(train/val) 0.14041/0.40039. Took 0.18 sec\n",
      "Epoch 96, Loss(train/val) 0.15634/0.30447. Took 0.16 sec\n",
      "Epoch 97, Loss(train/val) 0.15319/0.36225. Took 0.15 sec\n",
      "Epoch 98, Loss(train/val) 0.14912/0.37000. Took 0.15 sec\n",
      "Epoch 99, Loss(train/val) 0.14316/0.36603. Took 0.15 sec\n",
      "ACC: 0.625, MCC: 0.31483366180271377\n",
      "Epoch 0, Loss(train/val) 0.48991/0.49255. Took 0.16 sec\n",
      "Epoch 1, Loss(train/val) 0.46483/0.47410. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.43754/0.43693. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.40884/0.40021. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.38728/0.36615. Took 0.15 sec\n",
      "Epoch 5, Loss(train/val) 0.37315/0.35148. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.36508/0.35300. Took 0.15 sec\n",
      "Epoch 7, Loss(train/val) 0.35561/0.36942. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.34894/0.38848. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.33953/0.42489. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.33216/0.41898. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.32869/0.45339. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.32407/0.42959. Took 0.15 sec\n",
      "Epoch 13, Loss(train/val) 0.31235/0.43773. Took 0.18 sec\n",
      "Epoch 14, Loss(train/val) 0.30679/0.45131. Took 0.18 sec\n",
      "Epoch 15, Loss(train/val) 0.29985/0.44725. Took 0.16 sec\n",
      "Epoch 16, Loss(train/val) 0.29724/0.45014. Took 0.18 sec\n",
      "Epoch 17, Loss(train/val) 0.28866/0.44669. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.28623/0.45594. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.28209/0.44545. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.28036/0.46419. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.27597/0.44483. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.26642/0.45359. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.26515/0.46388. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.25841/0.45778. Took 0.15 sec\n",
      "Epoch 25, Loss(train/val) 0.26612/0.46064. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.25666/0.45440. Took 0.15 sec\n",
      "Epoch 27, Loss(train/val) 0.25334/0.45060. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.25294/0.44220. Took 0.16 sec\n",
      "Epoch 29, Loss(train/val) 0.25703/0.44645. Took 0.17 sec\n",
      "Epoch 30, Loss(train/val) 0.25586/0.44136. Took 0.16 sec\n",
      "Epoch 31, Loss(train/val) 0.24846/0.44986. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.23856/0.45404. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.24164/0.45369. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.23634/0.46128. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.24232/0.42765. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.23837/0.42581. Took 0.16 sec\n",
      "Epoch 37, Loss(train/val) 0.23177/0.42917. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.23085/0.41588. Took 0.16 sec\n",
      "Epoch 39, Loss(train/val) 0.23822/0.43901. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.23025/0.44247. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.22047/0.42265. Took 0.15 sec\n",
      "Epoch 42, Loss(train/val) 0.22441/0.40682. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.22261/0.38573. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.21590/0.42338. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) 0.22125/0.36129. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.21944/0.37027. Took 0.15 sec\n",
      "Epoch 47, Loss(train/val) 0.22117/0.44179. Took 0.16 sec\n",
      "Epoch 48, Loss(train/val) 0.21394/0.38502. Took 0.15 sec\n",
      "Epoch 49, Loss(train/val) 0.21184/0.39724. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.20593/0.39047. Took 0.14 sec\n",
      "Epoch 51, Loss(train/val) 0.20397/0.36781. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.21456/0.42554. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) 0.21480/0.44416. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.21077/0.38083. Took 0.17 sec\n",
      "Epoch 55, Loss(train/val) 0.20621/0.43417. Took 0.16 sec\n",
      "Epoch 56, Loss(train/val) 0.19817/0.42676. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.20693/0.41412. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.20112/0.42015. Took 0.15 sec\n",
      "Epoch 59, Loss(train/val) 0.19993/0.40748. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.19557/0.44211. Took 0.14 sec\n",
      "Epoch 61, Loss(train/val) 0.20378/0.42206. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.19440/0.40057. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.20040/0.33694. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.19891/0.37082. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.18753/0.40736. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.19102/0.40828. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.19371/0.37681. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.18533/0.38980. Took 0.16 sec\n",
      "Epoch 69, Loss(train/val) 0.18145/0.40040. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.18744/0.35339. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.18632/0.38615. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.18168/0.40088. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.18175/0.35505. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.19312/0.38705. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) 0.17930/0.36914. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.17898/0.37188. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.17973/0.39427. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.17954/0.39770. Took 0.14 sec\n",
      "Epoch 79, Loss(train/val) 0.17546/0.39008. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.17568/0.39763. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.16849/0.36125. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.18464/0.38460. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) 0.17221/0.37693. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.16853/0.36829. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.16667/0.32533. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.17504/0.38356. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.16831/0.33567. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.16963/0.37248. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.16843/0.31783. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.17099/0.32280. Took 0.14 sec\n",
      "Epoch 91, Loss(train/val) 0.17307/0.35849. Took 0.15 sec\n",
      "Epoch 92, Loss(train/val) 0.16955/0.31090. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.16799/0.29869. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.16397/0.31662. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.16171/0.34947. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.16538/0.31760. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.16100/0.36398. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.15931/0.35465. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.16382/0.32481. Took 0.13 sec\n",
      "ACC: 0.609375, MCC: 0.2032905342780163\n",
      "Epoch 0, Loss(train/val) 0.48689/0.49594. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.45706/0.48679. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.41505/0.45947. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.38580/0.43678. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.36848/0.42825. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.36296/0.42557. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.34962/0.41872. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.34968/0.40984. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.34133/0.40454. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.33681/0.40662. Took 0.12 sec\n",
      "Epoch 10, Loss(train/val) 0.33194/0.38831. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.32821/0.40356. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.30992/0.40190. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.32313/0.39087. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.30759/0.39977. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.30179/0.40024. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.28677/0.38859. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.28928/0.38965. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.28534/0.38429. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.28254/0.36987. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.27211/0.37413. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.27364/0.38293. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.27442/0.40570. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.26530/0.38289. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.26048/0.37072. Took 0.16 sec\n",
      "Epoch 25, Loss(train/val) 0.24949/0.38870. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.25639/0.36574. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.25366/0.37113. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.24612/0.38396. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.23965/0.34984. Took 0.13 sec\n",
      "Epoch 30, Loss(train/val) 0.24193/0.33909. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.24441/0.38315. Took 0.16 sec\n",
      "Epoch 32, Loss(train/val) 0.23422/0.36762. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.23842/0.34714. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.23246/0.37310. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.22500/0.36580. Took 0.16 sec\n",
      "Epoch 36, Loss(train/val) 0.22621/0.34389. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.22336/0.35327. Took 0.17 sec\n",
      "Epoch 38, Loss(train/val) 0.21991/0.39311. Took 0.16 sec\n",
      "Epoch 39, Loss(train/val) 0.21618/0.35886. Took 0.15 sec\n",
      "Epoch 40, Loss(train/val) 0.21886/0.34724. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.21380/0.37112. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.20581/0.36839. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.20645/0.34052. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.21008/0.35654. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.19891/0.33210. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.19620/0.37564. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.20975/0.38248. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.19375/0.38294. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.19338/0.39501. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.19996/0.35452. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.19643/0.34675. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.19499/0.37934. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) 0.20548/0.37734. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.19951/0.35756. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.19148/0.34402. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.17455/0.35579. Took 0.16 sec\n",
      "Epoch 57, Loss(train/val) 0.19436/0.34837. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.18446/0.35846. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.17752/0.37462. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.18098/0.36717. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.18131/0.34862. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.18544/0.35113. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.17633/0.36912. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.17541/0.33870. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.17604/0.39672. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.18022/0.36777. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.17280/0.38134. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.16878/0.40050. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.16128/0.38651. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.17124/0.36475. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.16765/0.37149. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.18074/0.33847. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.17120/0.39007. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.17232/0.39150. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.16191/0.37995. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.16568/0.33791. Took 0.15 sec\n",
      "Epoch 77, Loss(train/val) 0.16706/0.35780. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.16954/0.35175. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.15384/0.35895. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.16010/0.33408. Took 0.14 sec\n",
      "Epoch 81, Loss(train/val) 0.16785/0.37024. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.15935/0.38066. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.16461/0.35017. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.14978/0.36013. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.14643/0.36159. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.15766/0.36096. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.16166/0.37316. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.16243/0.39444. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.15440/0.36362. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.15323/0.35180. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.15617/0.35986. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.15105/0.38527. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.15623/0.34163. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.14343/0.38872. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.14509/0.38311. Took 0.12 sec\n",
      "Epoch 96, Loss(train/val) 0.14484/0.37750. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.15518/0.38270. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.14993/0.39051. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.14449/0.37822. Took 0.13 sec\n",
      "ACC: 0.71875, MCC: 0.4714520339716288\n",
      "Epoch 0, Loss(train/val) 0.49081/0.47273. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.46752/0.43087. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.43276/0.38597. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.39976/0.36455. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.38026/0.36153. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.36946/0.35984. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.35977/0.35855. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.35673/0.35328. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.35377/0.36078. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.34458/0.35791. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.33917/0.35418. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.33717/0.35408. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.33509/0.34629. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.32963/0.34288. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.32323/0.34556. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.31385/0.33983. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.31270/0.33873. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.29924/0.33495. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.30716/0.34248. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.29659/0.30877. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.29568/0.34313. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.29105/0.31283. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.29486/0.30792. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.28124/0.32530. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.27275/0.29506. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.27327/0.31574. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.26640/0.29169. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.25215/0.28365. Took 0.13 sec\n",
      "Epoch 28, Loss(train/val) 0.25406/0.32690. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.27892/0.27274. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.26951/0.29429. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.26339/0.28422. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.24754/0.28528. Took 0.16 sec\n",
      "Epoch 33, Loss(train/val) 0.24123/0.32674. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.24834/0.28258. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.24128/0.27801. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.22934/0.29169. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.22628/0.28129. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.22676/0.27767. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.22483/0.28973. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.21820/0.29134. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.22462/0.27157. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.21986/0.30420. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.21232/0.28335. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.20777/0.28947. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.21180/0.29044. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.21179/0.29152. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.20701/0.27373. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.19899/0.28630. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.20931/0.30167. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.20707/0.30052. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.19779/0.31308. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.20063/0.29081. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.19133/0.27610. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.18811/0.31073. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.19672/0.31559. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.19151/0.30054. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.19169/0.29463. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.18536/0.29863. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.19090/0.30581. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.18104/0.28716. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.17941/0.31110. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.17370/0.29280. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.18213/0.29980. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.16480/0.28441. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.16443/0.29013. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.16297/0.29372. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.16317/0.30672. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.16259/0.30125. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.17546/0.29626. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.16757/0.30395. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.15854/0.30528. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.16668/0.28787. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.14618/0.30870. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.15382/0.31231. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.15562/0.32649. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.14928/0.31595. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.16032/0.33341. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.15253/0.32729. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.14755/0.34216. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.15972/0.32376. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.15322/0.31607. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.15930/0.32029. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.16100/0.32924. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.15443/0.34479. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.14538/0.31454. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.14468/0.31741. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.13854/0.32733. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.13949/0.33643. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.13590/0.32762. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.13682/0.32422. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.13026/0.35063. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.12994/0.34300. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.12803/0.32188. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.13537/0.32535. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.12364/0.33853. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.13031/0.32171. Took 0.14 sec\n",
      "Epoch 97, Loss(train/val) 0.12936/0.31325. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.12935/0.31552. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.13198/0.31772. Took 0.13 sec\n",
      "ACC: 0.65625, MCC: 0.3028893994409716\n",
      "Epoch 0, Loss(train/val) 0.48659/0.51130. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.45208/0.52013. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.42177/0.47324. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.39502/0.42122. Took 0.16 sec\n",
      "Epoch 4, Loss(train/val) 0.37835/0.39815. Took 0.15 sec\n",
      "Epoch 5, Loss(train/val) 0.36130/0.38111. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.34714/0.36895. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.33815/0.37768. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.32297/0.36576. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.31259/0.36506. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.30993/0.36809. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.29884/0.37046. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.29051/0.36785. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.28847/0.35610. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.27493/0.34729. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.27631/0.37326. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.26710/0.37490. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.27161/0.36186. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.26073/0.37739. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.25619/0.36090. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.25199/0.35938. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.25710/0.37216. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.24111/0.37784. Took 0.15 sec\n",
      "Epoch 23, Loss(train/val) 0.23844/0.36830. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.24370/0.37470. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.23887/0.38615. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.22775/0.37008. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.22915/0.36478. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.22549/0.36038. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.22656/0.35565. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.22009/0.34790. Took 0.13 sec\n",
      "Epoch 31, Loss(train/val) 0.22158/0.35140. Took 0.13 sec\n",
      "Epoch 32, Loss(train/val) 0.22113/0.34141. Took 0.13 sec\n",
      "Epoch 33, Loss(train/val) 0.22002/0.34585. Took 0.13 sec\n",
      "Epoch 34, Loss(train/val) 0.21978/0.35424. Took 0.13 sec\n",
      "Epoch 35, Loss(train/val) 0.21673/0.34368. Took 0.13 sec\n",
      "Epoch 36, Loss(train/val) 0.20939/0.34201. Took 0.13 sec\n",
      "Epoch 37, Loss(train/val) 0.21147/0.34706. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.20235/0.34280. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.20408/0.35094. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.20126/0.34589. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.20670/0.36588. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.20074/0.34046. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.19792/0.33453. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.19037/0.33265. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.18823/0.32840. Took 0.16 sec\n",
      "Epoch 46, Loss(train/val) 0.18996/0.33826. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.18367/0.32462. Took 0.16 sec\n",
      "Epoch 48, Loss(train/val) 0.17608/0.36044. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.18183/0.32856. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.17815/0.33766. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.17859/0.33960. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.17637/0.35504. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.17709/0.36294. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.17701/0.35383. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.17114/0.36758. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.17019/0.38131. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.17255/0.36168. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.17288/0.34617. Took 0.14 sec\n",
      "Epoch 59, Loss(train/val) 0.16783/0.37761. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.16610/0.36736. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.16776/0.37911. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.16410/0.37829. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.15895/0.39272. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.16337/0.37674. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.15289/0.35993. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.15555/0.39501. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.16129/0.36371. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.15896/0.37602. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.15714/0.39114. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.15512/0.35841. Took 0.12 sec\n",
      "Epoch 71, Loss(train/val) 0.15704/0.37146. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.15264/0.36616. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.14926/0.38481. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.14935/0.38466. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.14019/0.39719. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.14257/0.40378. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.14424/0.38620. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.14620/0.38099. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.14175/0.38165. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.14469/0.35353. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.13839/0.38891. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.13772/0.41650. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.13971/0.39830. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.14233/0.41577. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.14113/0.41496. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.14648/0.40180. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.13413/0.40761. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.13716/0.39944. Took 0.14 sec\n",
      "Epoch 89, Loss(train/val) 0.13499/0.41820. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.14058/0.40409. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.13745/0.40171. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.12782/0.42630. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.13034/0.42615. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.13246/0.41243. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.12526/0.42550. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.12542/0.40280. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.12653/0.42584. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.13141/0.42427. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.12897/0.40877. Took 0.13 sec\n",
      "ACC: 0.65625, MCC: 0.3509664885977756\n",
      "Epoch 0, Loss(train/val) 0.49278/0.49427. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.46900/0.47191. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.43901/0.42211. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.40483/0.37636. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.38179/0.33440. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.36336/0.33554. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.35181/0.27530. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.34745/0.27231. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.33757/0.26158. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.33052/0.26925. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.31890/0.27790. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.31965/0.26785. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.32178/0.26953. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.31869/0.27188. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.32256/0.27749. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.30281/0.29105. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.30627/0.25519. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.30427/0.25036. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.29131/0.24631. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.28800/0.24904. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.28510/0.24943. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.28933/0.27094. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.28448/0.28205. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.27149/0.28482. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.27348/0.28052. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.27365/0.29104. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.27199/0.27292. Took 0.13 sec\n",
      "Epoch 27, Loss(train/val) 0.27326/0.27891. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.26043/0.25704. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.25505/0.27891. Took 0.13 sec\n",
      "Epoch 30, Loss(train/val) 0.26606/0.27351. Took 0.13 sec\n",
      "Epoch 31, Loss(train/val) 0.25413/0.27874. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.25339/0.27734. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.24814/0.28086. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.23946/0.28869. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.23868/0.27242. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.24344/0.27788. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.23726/0.27319. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.23239/0.27320. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.23381/0.27703. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.22850/0.26415. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.22637/0.27147. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.23505/0.28189. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.23876/0.27982. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.23888/0.27300. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) 0.23108/0.26256. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.22262/0.27241. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.20779/0.26538. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.21673/0.28341. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.20630/0.27595. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.20933/0.27252. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.20170/0.26777. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.20071/0.26862. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.20428/0.27061. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.20112/0.26417. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.20260/0.27464. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.19697/0.26184. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.19898/0.28716. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.19625/0.26774. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.19952/0.28013. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.19786/0.27358. Took 0.14 sec\n",
      "Epoch 61, Loss(train/val) 0.19343/0.31120. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.18982/0.27682. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.19247/0.28425. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.18913/0.30874. Took 0.16 sec\n",
      "Epoch 65, Loss(train/val) 0.19372/0.27964. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.18943/0.26757. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) 0.18564/0.25961. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.18465/0.32287. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.18503/0.28182. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.18195/0.28756. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.18001/0.32963. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.17378/0.31158. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.17244/0.27563. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.17431/0.31963. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.16902/0.29267. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.17022/0.32285. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.16863/0.28744. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.16456/0.30980. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.15981/0.29321. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.16249/0.34870. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.15705/0.31075. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.15766/0.34508. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.15732/0.27817. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.15975/0.31458. Took 0.15 sec\n",
      "Epoch 85, Loss(train/val) 0.15364/0.30089. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.14641/0.29862. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.15277/0.30236. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.14615/0.31840. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.14999/0.32945. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.14552/0.30067. Took 0.15 sec\n",
      "Epoch 91, Loss(train/val) 0.13739/0.31050. Took 0.17 sec\n",
      "Epoch 92, Loss(train/val) 0.14222/0.30012. Took 0.16 sec\n",
      "Epoch 93, Loss(train/val) 0.13363/0.33926. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.14237/0.30028. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.13990/0.33410. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.13901/0.32815. Took 0.15 sec\n",
      "Epoch 97, Loss(train/val) 0.13133/0.34839. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.13500/0.33823. Took 0.16 sec\n",
      "Epoch 99, Loss(train/val) 0.14158/0.29896. Took 0.15 sec\n",
      "ACC: 0.71875, MCC: 0.4383570037596047\n",
      "Epoch 0, Loss(train/val) 0.49255/0.49179. Took 0.17 sec\n",
      "Epoch 1, Loss(train/val) 0.46999/0.47561. Took 0.15 sec\n",
      "Epoch 2, Loss(train/val) 0.43563/0.43682. Took 0.16 sec\n",
      "Epoch 3, Loss(train/val) 0.39526/0.38655. Took 0.16 sec\n",
      "Epoch 4, Loss(train/val) 0.37091/0.35823. Took 0.17 sec\n",
      "Epoch 5, Loss(train/val) 0.34957/0.34626. Took 0.15 sec\n",
      "Epoch 6, Loss(train/val) 0.33690/0.33271. Took 0.16 sec\n",
      "Epoch 7, Loss(train/val) 0.32796/0.34294. Took 0.15 sec\n",
      "Epoch 8, Loss(train/val) 0.32116/0.32779. Took 0.16 sec\n",
      "Epoch 9, Loss(train/val) 0.31664/0.32654. Took 0.16 sec\n",
      "Epoch 10, Loss(train/val) 0.30544/0.33838. Took 0.15 sec\n",
      "Epoch 11, Loss(train/val) 0.30373/0.31205. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.29328/0.30037. Took 0.16 sec\n",
      "Epoch 13, Loss(train/val) 0.29336/0.32205. Took 0.18 sec\n",
      "Epoch 14, Loss(train/val) 0.28862/0.31082. Took 0.16 sec\n",
      "Epoch 15, Loss(train/val) 0.28590/0.30960. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.29324/0.33641. Took 0.15 sec\n",
      "Epoch 17, Loss(train/val) 0.28009/0.32675. Took 0.17 sec\n",
      "Epoch 18, Loss(train/val) 0.28565/0.31880. Took 0.15 sec\n",
      "Epoch 19, Loss(train/val) 0.28057/0.31252. Took 0.16 sec\n",
      "Epoch 20, Loss(train/val) 0.27565/0.31036. Took 0.16 sec\n",
      "Epoch 21, Loss(train/val) 0.28034/0.32888. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.27369/0.30760. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.26964/0.30276. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.26624/0.32021. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.27361/0.38995. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.28176/0.33528. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.25487/0.33540. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.25933/0.36862. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.26425/0.31443. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.25553/0.36214. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.24584/0.31943. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.24536/0.35226. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.24337/0.34437. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.24893/0.34925. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.24669/0.32864. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.23317/0.33220. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.24595/0.37801. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.23208/0.33592. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.23949/0.36048. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.23308/0.35199. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.23558/0.32826. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.23870/0.37777. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.22403/0.34097. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.22429/0.36220. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.22889/0.34784. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.22851/0.34175. Took 0.15 sec\n",
      "Epoch 47, Loss(train/val) 0.21395/0.39406. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.20998/0.35246. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.22315/0.36335. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.20720/0.39775. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.20224/0.35046. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.20807/0.36458. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) 0.21490/0.35733. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.19725/0.34288. Took 0.15 sec\n",
      "Epoch 55, Loss(train/val) 0.21916/0.40363. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.20003/0.41336. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.20203/0.39853. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.20966/0.39295. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.19334/0.37923. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.21131/0.36747. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.20063/0.36648. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.19740/0.37901. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.18960/0.37971. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.18153/0.38003. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.18607/0.39885. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.18765/0.40110. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.19247/0.37277. Took 0.15 sec\n",
      "Epoch 68, Loss(train/val) 0.19971/0.37332. Took 0.16 sec\n",
      "Epoch 69, Loss(train/val) 0.20181/0.38896. Took 0.16 sec\n",
      "Epoch 70, Loss(train/val) 0.18857/0.39372. Took 0.16 sec\n",
      "Epoch 71, Loss(train/val) 0.18211/0.39344. Took 0.16 sec\n",
      "Epoch 72, Loss(train/val) 0.18296/0.38435. Took 0.17 sec\n",
      "Epoch 73, Loss(train/val) 0.19714/0.36339. Took 0.16 sec\n",
      "Epoch 74, Loss(train/val) 0.19252/0.36625. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) 0.18093/0.38631. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.17825/0.37152. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.17258/0.37208. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.17403/0.36967. Took 0.14 sec\n",
      "Epoch 79, Loss(train/val) 0.17630/0.36414. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.17812/0.35993. Took 0.15 sec\n",
      "Epoch 81, Loss(train/val) 0.17189/0.36444. Took 0.15 sec\n",
      "Epoch 82, Loss(train/val) 0.16442/0.36244. Took 0.15 sec\n",
      "Epoch 83, Loss(train/val) 0.17947/0.36141. Took 0.15 sec\n",
      "Epoch 84, Loss(train/val) 0.16125/0.36546. Took 0.16 sec\n",
      "Epoch 85, Loss(train/val) 0.16669/0.37004. Took 0.17 sec\n",
      "Epoch 86, Loss(train/val) 0.16286/0.35741. Took 0.17 sec\n",
      "Epoch 87, Loss(train/val) 0.17281/0.35718. Took 0.18 sec\n",
      "Epoch 88, Loss(train/val) 0.16455/0.35219. Took 0.19 sec\n",
      "Epoch 89, Loss(train/val) 0.17860/0.36857. Took 0.15 sec\n",
      "Epoch 90, Loss(train/val) 0.17142/0.37463. Took 0.18 sec\n",
      "Epoch 91, Loss(train/val) 0.16862/0.37938. Took 0.16 sec\n",
      "Epoch 92, Loss(train/val) 0.15605/0.36321. Took 0.15 sec\n",
      "Epoch 93, Loss(train/val) 0.16262/0.36569. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.15870/0.36628. Took 0.14 sec\n",
      "Epoch 95, Loss(train/val) 0.16403/0.37089. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.16044/0.36697. Took 0.14 sec\n",
      "Epoch 97, Loss(train/val) 0.16021/0.35451. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.15559/0.36340. Took 0.14 sec\n",
      "Epoch 99, Loss(train/val) 0.16033/0.35265. Took 0.13 sec\n",
      "ACC: 0.65625, MCC: 0.3206018050323171\n",
      "Epoch 0, Loss(train/val) 0.49357/0.48304. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.47091/0.44980. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.44174/0.41635. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.40944/0.39780. Took 0.16 sec\n",
      "Epoch 4, Loss(train/val) 0.38819/0.37918. Took 0.17 sec\n",
      "Epoch 5, Loss(train/val) 0.37296/0.37128. Took 0.16 sec\n",
      "Epoch 6, Loss(train/val) 0.35812/0.36237. Took 0.16 sec\n",
      "Epoch 7, Loss(train/val) 0.34971/0.34541. Took 0.15 sec\n",
      "Epoch 8, Loss(train/val) 0.35010/0.36077. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.33622/0.34817. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.32434/0.34744. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.32136/0.35191. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.30690/0.35728. Took 0.15 sec\n",
      "Epoch 13, Loss(train/val) 0.30582/0.35004. Took 0.17 sec\n",
      "Epoch 14, Loss(train/val) 0.29247/0.35795. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.28849/0.35997. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.28081/0.36155. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.28355/0.36938. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.27349/0.36816. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.26510/0.38792. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.26822/0.39666. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.25333/0.39507. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.25216/0.39336. Took 0.15 sec\n",
      "Epoch 23, Loss(train/val) 0.24565/0.37861. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.23471/0.38779. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.22448/0.38978. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.23174/0.38982. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.22246/0.38099. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.22777/0.40010. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.22524/0.41096. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.22331/0.36951. Took 0.16 sec\n",
      "Epoch 31, Loss(train/val) 0.20449/0.38780. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.20648/0.40666. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.20615/0.39082. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.20053/0.36586. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.19080/0.33964. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.19396/0.35266. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.19310/0.33997. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.18927/0.34801. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.18543/0.35986. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.17616/0.33845. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.17388/0.33251. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.18166/0.34122. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.17397/0.34622. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.17584/0.35220. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.16977/0.33969. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.16524/0.33552. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.16909/0.34339. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.16348/0.33243. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.15815/0.33022. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.15182/0.33635. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.15866/0.32144. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.15480/0.33153. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.15146/0.32039. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.15126/0.34094. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.14289/0.34179. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.14283/0.31616. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.14597/0.33052. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.15041/0.37060. Took 0.14 sec\n",
      "Epoch 59, Loss(train/val) 0.15310/0.32371. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.14320/0.32061. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.14110/0.32015. Took 0.15 sec\n",
      "Epoch 62, Loss(train/val) 0.13990/0.33485. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.14184/0.32327. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.14172/0.33857. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.13972/0.30877. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.13612/0.33904. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.13503/0.30882. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.13502/0.33236. Took 0.15 sec\n",
      "Epoch 69, Loss(train/val) 0.13085/0.33889. Took 0.15 sec\n",
      "Epoch 70, Loss(train/val) 0.12936/0.32711. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.12809/0.34365. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.11951/0.35512. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.12839/0.35005. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.13031/0.35093. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.11695/0.36080. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.12213/0.34057. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.11867/0.35275. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.11959/0.35758. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.12408/0.35764. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.11590/0.34318. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.11320/0.35090. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.10872/0.35362. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.11080/0.35252. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.11693/0.35157. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.11787/0.35479. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.10765/0.34585. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.11447/0.35005. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.10899/0.35359. Took 0.14 sec\n",
      "Epoch 89, Loss(train/val) 0.11332/0.36405. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.11237/0.34955. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.10296/0.34633. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.09927/0.35265. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.09634/0.33924. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.10558/0.34133. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.10256/0.35056. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.10153/0.34963. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.09887/0.35402. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.09921/0.35939. Took 0.14 sec\n",
      "Epoch 99, Loss(train/val) 0.09766/0.35612. Took 0.13 sec\n",
      "ACC: 0.703125, MCC: 0.3752410702546575\n",
      "Epoch 0, Loss(train/val) 0.49413/0.47921. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.47324/0.43302. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.43770/0.38018. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.40232/0.35466. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.37764/0.35069. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.36049/0.35620. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.35215/0.35388. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.34392/0.35548. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.32948/0.35222. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.32425/0.34928. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.32039/0.35193. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.31695/0.35891. Took 0.15 sec\n",
      "Epoch 12, Loss(train/val) 0.31442/0.36083. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.29990/0.34603. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.30426/0.35110. Took 0.15 sec\n",
      "Epoch 15, Loss(train/val) 0.29902/0.35213. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.29276/0.34470. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.28974/0.34205. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.28904/0.34044. Took 0.15 sec\n",
      "Epoch 19, Loss(train/val) 0.28625/0.34007. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.27927/0.35118. Took 0.15 sec\n",
      "Epoch 21, Loss(train/val) 0.27752/0.34084. Took 0.16 sec\n",
      "Epoch 22, Loss(train/val) 0.27368/0.35308. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.27448/0.34448. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.29170/0.33880. Took 0.15 sec\n",
      "Epoch 25, Loss(train/val) 0.27293/0.36431. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.26439/0.34856. Took 0.15 sec\n",
      "Epoch 27, Loss(train/val) 0.26375/0.35335. Took 0.16 sec\n",
      "Epoch 28, Loss(train/val) 0.25778/0.36033. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.25892/0.35521. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.24944/0.33948. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.25258/0.35504. Took 0.16 sec\n",
      "Epoch 32, Loss(train/val) 0.25306/0.36926. Took 0.16 sec\n",
      "Epoch 33, Loss(train/val) 0.24861/0.33610. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.24474/0.37520. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.25479/0.34397. Took 0.15 sec\n",
      "Epoch 36, Loss(train/val) 0.24744/0.34988. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.23982/0.32392. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.24606/0.34426. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.24078/0.32700. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.24214/0.32919. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.23623/0.35571. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.23148/0.35239. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.24206/0.33432. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.22226/0.34905. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.22778/0.34778. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.22244/0.34165. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.22369/0.35533. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.22835/0.36753. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.22048/0.35881. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.21630/0.34326. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.21803/0.34951. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.20984/0.36225. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.21864/0.36313. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.21918/0.36644. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.21699/0.34397. Took 0.15 sec\n",
      "Epoch 56, Loss(train/val) 0.21558/0.36911. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.20775/0.33878. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.20853/0.34191. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.20419/0.37576. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.19859/0.36314. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.19929/0.36345. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.19866/0.34992. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.19318/0.35874. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.19735/0.36354. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.20437/0.35694. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.19957/0.34978. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.19970/0.35848. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.18617/0.33966. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.19110/0.34606. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.18261/0.33020. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.19060/0.32062. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.18377/0.33764. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.17794/0.33278. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.17806/0.32467. Took 0.16 sec\n",
      "Epoch 75, Loss(train/val) 0.17933/0.35636. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.17510/0.34053. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.16929/0.34229. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.17991/0.32533. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.17238/0.35258. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.17356/0.34612. Took 0.15 sec\n",
      "Epoch 81, Loss(train/val) 0.17496/0.33499. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.16671/0.34764. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.17523/0.35306. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.18166/0.34573. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.16972/0.32098. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.15995/0.32955. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.17506/0.30935. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.16756/0.32626. Took 0.14 sec\n",
      "Epoch 89, Loss(train/val) 0.15659/0.33395. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.16212/0.32072. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.16128/0.33424. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.16907/0.31758. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.15358/0.33288. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.15777/0.34726. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.15217/0.34515. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.15279/0.33337. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.14611/0.33210. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.15344/0.34010. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.15764/0.32789. Took 0.13 sec\n",
      "ACC: 0.671875, MCC: 0.29811857260915015\n",
      "Epoch 0, Loss(train/val) 0.49388/0.47911. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.47091/0.42997. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.43677/0.37832. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.39724/0.35617. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.36435/0.35426. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.34327/0.34853. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.33680/0.34635. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.32899/0.34636. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.32234/0.35144. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.32646/0.34765. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.32384/0.35042. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.31434/0.34510. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.31087/0.35513. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.31127/0.33626. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.30718/0.34429. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.28960/0.34792. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.29098/0.34833. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.28034/0.34181. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.28487/0.34160. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.27220/0.33986. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.27049/0.32827. Took 0.15 sec\n",
      "Epoch 21, Loss(train/val) 0.26460/0.33931. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.26521/0.33517. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.25514/0.34010. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.25488/0.32844. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.25362/0.30251. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.25419/0.31743. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.24756/0.31797. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.24544/0.31231. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.24758/0.31849. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.23699/0.32133. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.23743/0.31774. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.22891/0.31415. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.22954/0.32231. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.22921/0.31828. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.23067/0.31610. Took 0.15 sec\n",
      "Epoch 36, Loss(train/val) 0.22052/0.30250. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.21795/0.32319. Took 0.17 sec\n",
      "Epoch 38, Loss(train/val) 0.21475/0.32920. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.21767/0.32021. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.21102/0.33754. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.20706/0.31256. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.21180/0.34849. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.20725/0.32884. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.20313/0.33344. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.20783/0.33948. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.19372/0.33284. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.19777/0.32981. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.19434/0.32547. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.18590/0.33486. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.18387/0.33314. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.18547/0.33662. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.18225/0.31431. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.19200/0.32650. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.18562/0.32983. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.18250/0.33117. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.18635/0.31031. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.17803/0.33210. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.17878/0.33476. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.17323/0.31510. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.17196/0.31506. Took 0.14 sec\n",
      "Epoch 61, Loss(train/val) 0.17625/0.33930. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.16762/0.32065. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.18028/0.32617. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.16356/0.31613. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.16394/0.33276. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.16637/0.33047. Took 0.17 sec\n",
      "Epoch 67, Loss(train/val) 0.15931/0.31469. Took 0.15 sec\n",
      "Epoch 68, Loss(train/val) 0.16129/0.32831. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.15569/0.31677. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.16325/0.32210. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.15689/0.32565. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.15485/0.32203. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.15148/0.30255. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.14948/0.30213. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) 0.15173/0.30069. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.15410/0.29886. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.14147/0.30215. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.14424/0.31740. Took 0.14 sec\n",
      "Epoch 79, Loss(train/val) 0.14600/0.30347. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.14773/0.31061. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.14487/0.32713. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.14983/0.29529. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.14580/0.30212. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.13675/0.29092. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.14944/0.30287. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.14119/0.30040. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.13927/0.30149. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.13875/0.28133. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.13341/0.30682. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.13879/0.29072. Took 0.14 sec\n",
      "Epoch 91, Loss(train/val) 0.13943/0.29801. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.13554/0.28378. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.13673/0.29234. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.13226/0.28953. Took 0.14 sec\n",
      "Epoch 95, Loss(train/val) 0.14090/0.30649. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.13049/0.31369. Took 0.14 sec\n",
      "Epoch 97, Loss(train/val) 0.13183/0.29963. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.13055/0.29673. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.13441/0.30267. Took 0.13 sec\n",
      "ACC: 0.640625, MCC: 0.3354321472637219\n",
      "Epoch 0, Loss(train/val) 0.49136/0.48641. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.46948/0.45970. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.43769/0.41882. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.40458/0.37700. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.38019/0.35426. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.36172/0.35940. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.35742/0.34034. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.35265/0.33614. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.34034/0.34487. Took 0.15 sec\n",
      "Epoch 9, Loss(train/val) 0.33597/0.34629. Took 0.15 sec\n",
      "Epoch 10, Loss(train/val) 0.33144/0.33207. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.32476/0.33010. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.32399/0.34469. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.31811/0.34609. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.31211/0.34677. Took 0.15 sec\n",
      "Epoch 15, Loss(train/val) 0.30864/0.33042. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.30647/0.34342. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.29903/0.34701. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.29190/0.34916. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.29618/0.34612. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.28385/0.34575. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.29052/0.34819. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.28510/0.35224. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.27676/0.35687. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.27952/0.34707. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.27096/0.35693. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.26869/0.35657. Took 0.16 sec\n",
      "Epoch 27, Loss(train/val) 0.26525/0.35262. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.26697/0.37207. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.25967/0.35709. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.26573/0.34014. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.26170/0.36857. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.24857/0.35176. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.25183/0.36376. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.24736/0.33916. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.23576/0.36611. Took 0.13 sec\n",
      "Epoch 36, Loss(train/val) 0.23707/0.39408. Took 0.13 sec\n",
      "Epoch 37, Loss(train/val) 0.23684/0.36942. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.22705/0.37287. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.21905/0.36233. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.22534/0.35906. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.21932/0.34873. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.21160/0.37904. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.21507/0.33506. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.21702/0.36625. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.20325/0.36633. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.20474/0.36463. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.19936/0.37334. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.18880/0.36802. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.19855/0.35030. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.20537/0.37363. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.18757/0.37821. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.18748/0.38129. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.17651/0.36662. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.19076/0.38688. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.17159/0.37646. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.17667/0.38456. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.16986/0.38310. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.17766/0.38064. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.17461/0.38582. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.17358/0.37948. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.17054/0.38759. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.16196/0.37625. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.16429/0.37702. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.16290/0.35617. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.15961/0.37277. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.16131/0.37552. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.16114/0.37521. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.15777/0.37838. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.15673/0.38622. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.15383/0.37962. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.15436/0.38532. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.15859/0.38661. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.14590/0.39986. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.15118/0.37910. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.14706/0.37089. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.14763/0.38721. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.14521/0.35892. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.14023/0.36544. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.14025/0.38638. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.14083/0.37114. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.13821/0.38108. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.14155/0.41114. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.14087/0.40144. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.14228/0.37307. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.13563/0.38450. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.13735/0.38591. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.13121/0.38120. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.13468/0.38530. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.13411/0.37955. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.13453/0.39076. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.12904/0.37616. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.12997/0.37079. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.12609/0.36555. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.12433/0.39250. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.12448/0.40143. Took 0.15 sec\n",
      "Epoch 96, Loss(train/val) 0.12450/0.38068. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.12212/0.40501. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.12480/0.40829. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.12618/0.40032. Took 0.13 sec\n",
      "ACC: 0.671875, MCC: 0.33613646607466174\n",
      "Epoch 0, Loss(train/val) 0.49358/0.49272. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.47341/0.47085. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.44372/0.41662. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.40957/0.36856. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.38079/0.35887. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.36157/0.35148. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.34757/0.34631. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.33420/0.34623. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.32970/0.34398. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.32240/0.34294. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.32179/0.34021. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.30838/0.33993. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.30572/0.34475. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.30079/0.34435. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.29722/0.34576. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.29879/0.34375. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.29041/0.34531. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.28981/0.34059. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.28127/0.35007. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.28064/0.34326. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.27220/0.34732. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.27151/0.34009. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.27671/0.34902. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.26935/0.33740. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.25929/0.34668. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.26141/0.35361. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.25758/0.34773. Took 0.13 sec\n",
      "Epoch 27, Loss(train/val) 0.25861/0.35228. Took 0.13 sec\n",
      "Epoch 28, Loss(train/val) 0.25484/0.34234. Took 0.13 sec\n",
      "Epoch 29, Loss(train/val) 0.24345/0.33610. Took 0.13 sec\n",
      "Epoch 30, Loss(train/val) 0.23918/0.33850. Took 0.13 sec\n",
      "Epoch 31, Loss(train/val) 0.23769/0.33329. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.23528/0.34737. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.23393/0.33611. Took 0.13 sec\n",
      "Epoch 34, Loss(train/val) 0.23228/0.34703. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.22520/0.34093. Took 0.15 sec\n",
      "Epoch 36, Loss(train/val) 0.22655/0.32531. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.22113/0.35877. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.21666/0.34509. Took 0.16 sec\n",
      "Epoch 39, Loss(train/val) 0.21696/0.35049. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.20622/0.35102. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.20971/0.34669. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.21491/0.37462. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.20751/0.36134. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.20235/0.38359. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.20473/0.36539. Took 0.12 sec\n",
      "Epoch 46, Loss(train/val) 0.19841/0.36881. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.19366/0.38382. Took 0.12 sec\n",
      "Epoch 48, Loss(train/val) 0.20144/0.36443. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.18913/0.36729. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.19162/0.36259. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.20102/0.37021. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.19140/0.37120. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) 0.19185/0.35990. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.17819/0.37291. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.18134/0.36730. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.18513/0.39187. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.16914/0.37842. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.17030/0.36578. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.16319/0.37211. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.16678/0.38316. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.17549/0.38520. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.16305/0.38416. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.15729/0.40253. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.16082/0.37512. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.16058/0.38962. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.15922/0.37822. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.15026/0.37491. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.14719/0.37418. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.14631/0.37051. Took 0.12 sec\n",
      "Epoch 70, Loss(train/val) 0.14408/0.36693. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.14602/0.37096. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.13721/0.38356. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.13758/0.36371. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.13680/0.37410. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.13852/0.39139. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.13010/0.38296. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.13722/0.38469. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.13514/0.39851. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.13271/0.36801. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.12901/0.39903. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.12207/0.38085. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.12104/0.36371. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.13001/0.37265. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.13359/0.36240. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.12638/0.36958. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.12351/0.37379. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.12303/0.36092. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.12698/0.35947. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.12350/0.35409. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.12216/0.36363. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.12071/0.37696. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.11616/0.37090. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.11445/0.36441. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.12005/0.35834. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.11957/0.36899. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.11279/0.39657. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.11417/0.37861. Took 0.12 sec\n",
      "Epoch 98, Loss(train/val) 0.11245/0.36079. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.11174/0.36512. Took 0.13 sec\n",
      "ACC: 0.734375, MCC: 0.49729930162927966\n",
      "Epoch 0, Loss(train/val) 0.49453/0.48311. Took 0.13 sec\n",
      "Epoch 1, Loss(train/val) 0.47642/0.44280. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.44440/0.38071. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.40725/0.34650. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.38692/0.33589. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.37054/0.32403. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.35496/0.31135. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.34350/0.30697. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.33531/0.32211. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.33329/0.32122. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.32271/0.33158. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.31499/0.32021. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.31573/0.30284. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.31187/0.31623. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.29939/0.30554. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.29552/0.30849. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.29187/0.29521. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.29023/0.30616. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.28198/0.31358. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.27989/0.31024. Took 0.15 sec\n",
      "Epoch 20, Loss(train/val) 0.27539/0.30509. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.27106/0.31301. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.26123/0.33193. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.26502/0.32314. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.25462/0.33181. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.25344/0.32064. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.25453/0.33966. Took 0.13 sec\n",
      "Epoch 27, Loss(train/val) 0.23931/0.34107. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.24170/0.33117. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.23515/0.36256. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.23317/0.34412. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.23319/0.36204. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.22937/0.35292. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.22614/0.37077. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.21912/0.38385. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.23417/0.35232. Took 0.13 sec\n",
      "Epoch 36, Loss(train/val) 0.21748/0.37736. Took 0.13 sec\n",
      "Epoch 37, Loss(train/val) 0.21564/0.36771. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.21480/0.38117. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.21988/0.36643. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.21527/0.38059. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.20787/0.36805. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.20827/0.35408. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.20817/0.37162. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.20276/0.37099. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.19633/0.36101. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.19339/0.35853. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.19771/0.36625. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.20059/0.35226. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.18810/0.35012. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.19133/0.37446. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.20278/0.34740. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.18964/0.32726. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.19405/0.39092. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.18225/0.38416. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.18719/0.38416. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.18418/0.35110. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.18058/0.36693. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.17691/0.40895. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.17583/0.37480. Took 0.12 sec\n",
      "Epoch 60, Loss(train/val) 0.17777/0.36599. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.17181/0.36100. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.18057/0.37282. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.17039/0.40976. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.16985/0.40599. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.16215/0.39919. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.16404/0.35553. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.16560/0.40999. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.17463/0.40187. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.16558/0.37098. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.16602/0.43716. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.16112/0.41550. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.15795/0.42994. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.16035/0.39942. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.16144/0.41782. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.15644/0.41054. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.16181/0.41344. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.15628/0.37145. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.16119/0.40415. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.15291/0.39364. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.15511/0.44133. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.14973/0.42814. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.14376/0.43481. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.14980/0.43895. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.14540/0.41743. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.15040/0.40589. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.15867/0.45519. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.14507/0.44460. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.14212/0.43934. Took 0.14 sec\n",
      "Epoch 89, Loss(train/val) 0.14734/0.44675. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.14923/0.42704. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.14029/0.41209. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.14349/0.43367. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.14631/0.42183. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.14793/0.42394. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.13665/0.39659. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.14375/0.42205. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.13444/0.42783. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.13825/0.42571. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.13543/0.40971. Took 0.13 sec\n",
      "ACC: 0.65625, MCC: 0.30980392156862746\n",
      "Epoch 0, Loss(train/val) 0.49664/0.48524. Took 0.13 sec\n",
      "Epoch 1, Loss(train/val) 0.47733/0.46707. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.44808/0.44243. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.41277/0.43468. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.38866/0.42612. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.37737/0.41823. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.36649/0.42178. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.35664/0.37768. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.34933/0.38090. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.34666/0.35630. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.34084/0.35673. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.33619/0.35069. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.33242/0.34689. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.33312/0.36088. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.32299/0.35493. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.31971/0.35717. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.31059/0.34730. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.30893/0.35638. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.30578/0.34666. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.29658/0.34197. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.29375/0.33956. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.29250/0.35256. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.29133/0.35877. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.28188/0.34882. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.28126/0.35487. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.27336/0.33771. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.26718/0.32612. Took 0.13 sec\n",
      "Epoch 27, Loss(train/val) 0.27217/0.32453. Took 0.13 sec\n",
      "Epoch 28, Loss(train/val) 0.26198/0.31892. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.25357/0.33943. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.25875/0.31712. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.24827/0.32105. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.24702/0.32852. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.24263/0.32258. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.23564/0.31838. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.23152/0.31358. Took 0.15 sec\n",
      "Epoch 36, Loss(train/val) 0.24050/0.32327. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.23151/0.32170. Took 0.15 sec\n",
      "Epoch 38, Loss(train/val) 0.22887/0.31999. Took 0.15 sec\n",
      "Epoch 39, Loss(train/val) 0.22996/0.32321. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.21560/0.33547. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.21970/0.32580. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.20740/0.32294. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.20745/0.32303. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.20611/0.32198. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.21005/0.30363. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.21862/0.32497. Took 0.15 sec\n",
      "Epoch 47, Loss(train/val) 0.20349/0.31956. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.19261/0.33086. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.19694/0.29703. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.19721/0.31801. Took 0.14 sec\n",
      "Epoch 51, Loss(train/val) 0.18542/0.30942. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.19328/0.32504. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) 0.17536/0.31608. Took 0.15 sec\n",
      "Epoch 54, Loss(train/val) 0.18344/0.31981. Took 0.15 sec\n",
      "Epoch 55, Loss(train/val) 0.17175/0.33532. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.18065/0.30527. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.17049/0.30955. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.17836/0.33028. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.17669/0.32442. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.17527/0.35520. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.16455/0.36741. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.16543/0.35618. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.15765/0.32078. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.15642/0.34505. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.15698/0.30232. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.15605/0.35762. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.15589/0.35112. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.15548/0.33252. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.15152/0.31711. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.14361/0.34295. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.14823/0.31137. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.15370/0.36872. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.14661/0.34974. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.14508/0.34110. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.13559/0.34850. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.13740/0.37468. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.13465/0.36482. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.13736/0.35710. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.14274/0.33194. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.13271/0.34976. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.14173/0.36221. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.13552/0.35402. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.13094/0.33541. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.13118/0.35234. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.13144/0.35567. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.12617/0.31861. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.12111/0.31831. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.12520/0.34423. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.12722/0.32070. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.12139/0.34259. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.11530/0.35530. Took 0.15 sec\n",
      "Epoch 92, Loss(train/val) 0.11412/0.29479. Took 0.15 sec\n",
      "Epoch 93, Loss(train/val) 0.12323/0.34435. Took 0.17 sec\n",
      "Epoch 94, Loss(train/val) 0.12144/0.32929. Took 0.14 sec\n",
      "Epoch 95, Loss(train/val) 0.11922/0.34221. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.11672/0.33650. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.11370/0.31803. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.12368/0.34333. Took 0.14 sec\n",
      "Epoch 99, Loss(train/val) 0.11615/0.31728. Took 0.13 sec\n",
      "ACC: 0.59375, MCC: 0.2631733660459241\n",
      "Epoch 0, Loss(train/val) 0.49222/0.48263. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.46845/0.45019. Took 0.15 sec\n",
      "Epoch 2, Loss(train/val) 0.43640/0.39737. Took 0.16 sec\n",
      "Epoch 3, Loss(train/val) 0.39960/0.36483. Took 0.15 sec\n",
      "Epoch 4, Loss(train/val) 0.37476/0.34893. Took 0.18 sec\n",
      "Epoch 5, Loss(train/val) 0.36048/0.33901. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.35020/0.31671. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.34382/0.31642. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.33950/0.31200. Took 0.15 sec\n",
      "Epoch 9, Loss(train/val) 0.33085/0.30456. Took 0.16 sec\n",
      "Epoch 10, Loss(train/val) 0.32532/0.31154. Took 0.15 sec\n",
      "Epoch 11, Loss(train/val) 0.32064/0.31600. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.31218/0.32226. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.30410/0.31559. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.30452/0.31647. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.30405/0.32105. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.29802/0.31528. Took 0.17 sec\n",
      "Epoch 17, Loss(train/val) 0.29885/0.32480. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.29491/0.31103. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.29091/0.33300. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.28696/0.33043. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.28506/0.33261. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.28370/0.32816. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.27219/0.33038. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.26847/0.33347. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.27719/0.33131. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.27012/0.32384. Took 0.13 sec\n",
      "Epoch 27, Loss(train/val) 0.28110/0.32218. Took 0.13 sec\n",
      "Epoch 28, Loss(train/val) 0.26536/0.33173. Took 0.13 sec\n",
      "Epoch 29, Loss(train/val) 0.27210/0.33075. Took 0.13 sec\n",
      "Epoch 30, Loss(train/val) 0.26393/0.34851. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.26522/0.32617. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.25474/0.34167. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.25728/0.33375. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.24810/0.34635. Took 0.17 sec\n",
      "Epoch 35, Loss(train/val) 0.25022/0.34636. Took 0.15 sec\n",
      "Epoch 36, Loss(train/val) 0.24679/0.33876. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.23948/0.35432. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.24618/0.34644. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.24794/0.33628. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.24121/0.35627. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.23035/0.35673. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.23090/0.34412. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.24123/0.34339. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.23808/0.36542. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) 0.23096/0.34977. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.22634/0.35235. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.22098/0.36492. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.22128/0.35850. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.22604/0.35743. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.21616/0.34768. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.21699/0.36281. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.21235/0.35827. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.21489/0.36128. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.21150/0.37481. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.21425/0.36359. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.20628/0.35370. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.20125/0.37394. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.20301/0.37160. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.20601/0.37385. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.20477/0.37320. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.20720/0.38765. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.20957/0.37317. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.20298/0.36501. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.20179/0.37308. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.19171/0.38373. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.19201/0.37693. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.19319/0.38776. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.19987/0.41817. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.19744/0.36762. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.19715/0.38712. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.19344/0.41202. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.19821/0.35574. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.18298/0.36601. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.18788/0.39312. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) 0.18446/0.38184. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.18076/0.40415. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.17417/0.38885. Took 0.15 sec\n",
      "Epoch 78, Loss(train/val) 0.18222/0.41973. Took 0.14 sec\n",
      "Epoch 79, Loss(train/val) 0.17559/0.37643. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.18022/0.39615. Took 0.14 sec\n",
      "Epoch 81, Loss(train/val) 0.17903/0.40080. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.17658/0.39718. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) 0.17549/0.38340. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.16487/0.37890. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.16566/0.39136. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.16181/0.37259. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.16148/0.41817. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.16432/0.39679. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.16842/0.39487. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.16025/0.36985. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.16135/0.39649. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.15962/0.40788. Took 0.15 sec\n",
      "Epoch 93, Loss(train/val) 0.15775/0.41685. Took 0.15 sec\n",
      "Epoch 94, Loss(train/val) 0.16184/0.38126. Took 0.16 sec\n",
      "Epoch 95, Loss(train/val) 0.15844/0.41081. Took 0.15 sec\n",
      "Epoch 96, Loss(train/val) 0.15955/0.41082. Took 0.15 sec\n",
      "Epoch 97, Loss(train/val) 0.16391/0.37931. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.15846/0.41016. Took 0.15 sec\n",
      "Epoch 99, Loss(train/val) 0.15020/0.41334. Took 0.14 sec\n",
      "ACC: 0.5625, MCC: 0.12756275329753713\n",
      "Epoch 0, Loss(train/val) 0.49252/0.49218. Took 0.17 sec\n",
      "Epoch 1, Loss(train/val) 0.46886/0.46958. Took 0.15 sec\n",
      "Epoch 2, Loss(train/val) 0.43323/0.44464. Took 0.16 sec\n",
      "Epoch 3, Loss(train/val) 0.40149/0.43215. Took 0.15 sec\n",
      "Epoch 4, Loss(train/val) 0.37805/0.42259. Took 0.15 sec\n",
      "Epoch 5, Loss(train/val) 0.36812/0.41240. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.35453/0.38788. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.34688/0.39112. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.33296/0.38625. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.33222/0.38947. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.33434/0.38665. Took 0.15 sec\n",
      "Epoch 11, Loss(train/val) 0.32824/0.38406. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.31775/0.38484. Took 0.15 sec\n",
      "Epoch 13, Loss(train/val) 0.31812/0.36825. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.30897/0.36815. Took 0.17 sec\n",
      "Epoch 15, Loss(train/val) 0.30406/0.37304. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.29724/0.37604. Took 0.15 sec\n",
      "Epoch 17, Loss(train/val) 0.29601/0.36886. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.29717/0.38376. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.28908/0.37328. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.28237/0.37599. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.27558/0.37901. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.27824/0.38415. Took 0.15 sec\n",
      "Epoch 23, Loss(train/val) 0.27385/0.39974. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.26937/0.39342. Took 0.15 sec\n",
      "Epoch 25, Loss(train/val) 0.26983/0.39741. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.27537/0.39346. Took 0.15 sec\n",
      "Epoch 27, Loss(train/val) 0.25650/0.39946. Took 0.16 sec\n",
      "Epoch 28, Loss(train/val) 0.24988/0.39555. Took 0.16 sec\n",
      "Epoch 29, Loss(train/val) 0.25471/0.38341. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.24141/0.40216. Took 0.17 sec\n",
      "Epoch 31, Loss(train/val) 0.25140/0.40194. Took 0.23 sec\n",
      "Epoch 32, Loss(train/val) 0.25139/0.39069. Took 0.18 sec\n",
      "Epoch 33, Loss(train/val) 0.23974/0.37794. Took 0.16 sec\n",
      "Epoch 34, Loss(train/val) 0.24222/0.36352. Took 0.18 sec\n",
      "Epoch 35, Loss(train/val) 0.23083/0.38190. Took 0.16 sec\n",
      "Epoch 36, Loss(train/val) 0.23186/0.38205. Took 0.16 sec\n",
      "Epoch 37, Loss(train/val) 0.22367/0.38263. Took 0.18 sec\n",
      "Epoch 38, Loss(train/val) 0.22881/0.37308. Took 0.17 sec\n",
      "Epoch 39, Loss(train/val) 0.23263/0.35729. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.22720/0.37321. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.22469/0.36999. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.22598/0.36893. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.21450/0.36703. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.21323/0.37071. Took 0.15 sec\n",
      "Epoch 45, Loss(train/val) 0.21068/0.36449. Took 0.16 sec\n",
      "Epoch 46, Loss(train/val) 0.21317/0.36360. Took 0.16 sec\n",
      "Epoch 47, Loss(train/val) 0.20592/0.36121. Took 0.15 sec\n",
      "Epoch 48, Loss(train/val) 0.20739/0.35207. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.19869/0.37758. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.21033/0.36681. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.20220/0.34687. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.20005/0.36709. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.21464/0.34708. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.20307/0.34153. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.19708/0.33246. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.20096/0.36968. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.19599/0.35944. Took 0.15 sec\n",
      "Epoch 58, Loss(train/val) 0.19556/0.35848. Took 0.16 sec\n",
      "Epoch 59, Loss(train/val) 0.19967/0.33949. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.18665/0.33319. Took 0.14 sec\n",
      "Epoch 61, Loss(train/val) 0.19340/0.35295. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.19165/0.34658. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.19278/0.33535. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.18145/0.33677. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.19302/0.36372. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.18989/0.32461. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.18767/0.33672. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.18116/0.33905. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.18428/0.33683. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.18179/0.32010. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.18704/0.31219. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.18239/0.31439. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.18737/0.32581. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.17913/0.30989. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.17766/0.35490. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.16874/0.32264. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.17207/0.34369. Took 0.15 sec\n",
      "Epoch 78, Loss(train/val) 0.16715/0.35771. Took 0.15 sec\n",
      "Epoch 79, Loss(train/val) 0.17070/0.32482. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.17070/0.32670. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.17386/0.34279. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.17525/0.33374. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.16860/0.34690. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.16767/0.36908. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.16545/0.34531. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.16348/0.33286. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.16712/0.35608. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.16931/0.32986. Took 0.14 sec\n",
      "Epoch 89, Loss(train/val) 0.15661/0.34994. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.16793/0.35872. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.16496/0.35656. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.16169/0.33733. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.15749/0.32643. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.16011/0.32687. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.15738/0.33693. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.15051/0.33134. Took 0.14 sec\n",
      "Epoch 97, Loss(train/val) 0.15753/0.33662. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.15571/0.32004. Took 0.14 sec\n",
      "Epoch 99, Loss(train/val) 0.15750/0.31974. Took 0.14 sec\n",
      "ACC: 0.515625, MCC: 0.002065194638665026\n",
      "Epoch 0, Loss(train/val) 0.49556/0.49073. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.47599/0.47172. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.44124/0.45332. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.40386/0.45331. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.38458/0.45732. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.37113/0.45677. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.35328/0.44877. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.34788/0.46153. Took 0.15 sec\n",
      "Epoch 8, Loss(train/val) 0.33071/0.44022. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.33404/0.43827. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.33068/0.43785. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.31870/0.43521. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.31968/0.44152. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.31385/0.44562. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.30876/0.43646. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.30558/0.43889. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.30614/0.43904. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.29975/0.44311. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.29932/0.43969. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.29485/0.43562. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.29083/0.44190. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.29916/0.43244. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.28996/0.43407. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.27784/0.40388. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.28403/0.41992. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.27644/0.40100. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.26760/0.40710. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.26908/0.39481. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.27449/0.42457. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.26270/0.35675. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.26097/0.36908. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.25372/0.38595. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.25020/0.36014. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.24810/0.36139. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.24668/0.38670. Took 0.13 sec\n",
      "Epoch 35, Loss(train/val) 0.24623/0.40874. Took 0.13 sec\n",
      "Epoch 36, Loss(train/val) 0.24487/0.40034. Took 0.13 sec\n",
      "Epoch 37, Loss(train/val) 0.23897/0.38102. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.23147/0.37958. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.23859/0.36161. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.22749/0.35932. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.23181/0.36922. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.22011/0.36021. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.21477/0.37913. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.21962/0.36990. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.22850/0.38992. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.21943/0.38546. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.22262/0.39225. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.20609/0.38092. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.20454/0.37634. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.20191/0.38983. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.20101/0.38054. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.20201/0.37778. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.19414/0.38313. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.19651/0.39820. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.19251/0.37632. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.18447/0.37073. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.18832/0.38214. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.18495/0.37397. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.18007/0.37706. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.18623/0.37224. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.17940/0.37124. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.18571/0.35973. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.17736/0.34642. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.17987/0.35275. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.18276/0.34916. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.17777/0.35971. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.17375/0.37402. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.18203/0.35282. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.17819/0.37633. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.18273/0.36033. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.17311/0.34907. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.16731/0.36591. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.16903/0.34974. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.16484/0.35657. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.16004/0.37649. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.16604/0.36956. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.16522/0.37062. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.15151/0.36031. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.15770/0.37618. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.15902/0.34770. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.15634/0.36554. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.14663/0.36843. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.14856/0.38519. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.15398/0.37910. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.14838/0.33531. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.14317/0.33760. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.15212/0.33108. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.14622/0.39681. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.15322/0.35326. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.14763/0.35730. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.14071/0.36804. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.14411/0.36877. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.13953/0.39759. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.14483/0.36302. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.13505/0.38352. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.14003/0.35523. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.14111/0.36154. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.13992/0.36220. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.13655/0.36441. Took 0.13 sec\n",
      "ACC: 0.671875, MCC: 0.38969751925733287\n",
      "Epoch 0, Loss(train/val) 0.49450/0.49307. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.47839/0.48299. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.44886/0.47323. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.41221/0.47055. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.39589/0.46069. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.38569/0.46770. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.37023/0.44051. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.36156/0.44559. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.34784/0.43176. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.33552/0.43105. Took 0.15 sec\n",
      "Epoch 10, Loss(train/val) 0.32761/0.41143. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.32368/0.43158. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.31481/0.42550. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.31237/0.42201. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.30267/0.42131. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.29619/0.44353. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.29672/0.42525. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.28244/0.40874. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.28380/0.42976. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.27766/0.43098. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.27709/0.42483. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.26753/0.41428. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.26175/0.42020. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.25824/0.41181. Took 0.16 sec\n",
      "Epoch 24, Loss(train/val) 0.24961/0.41537. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.24222/0.40285. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.23854/0.34537. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.23972/0.40775. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.23509/0.36362. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.23793/0.41136. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.23583/0.40883. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.22677/0.39596. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.22689/0.38249. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.22058/0.38749. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.21848/0.39663. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.21925/0.38343. Took 0.13 sec\n",
      "Epoch 36, Loss(train/val) 0.22259/0.42097. Took 0.13 sec\n",
      "Epoch 37, Loss(train/val) 0.20948/0.41964. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.22243/0.42952. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.20750/0.40483. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.20438/0.39220. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.20682/0.37979. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.20122/0.43270. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.20787/0.41161. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.19802/0.39821. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.19563/0.41674. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.19339/0.41825. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.19139/0.41970. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.19217/0.41936. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.19992/0.44100. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.18798/0.42204. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.18283/0.42494. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.18122/0.42766. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.17801/0.42286. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.17393/0.42288. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.17036/0.42363. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.17780/0.42710. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.18294/0.41856. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.17567/0.41721. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.18179/0.41366. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.16666/0.39641. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.17188/0.42389. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.16523/0.40878. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.16351/0.42641. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.16073/0.43388. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.15547/0.42198. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.16218/0.41361. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) 0.15951/0.43070. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.16389/0.43844. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.15554/0.40313. Took 0.16 sec\n",
      "Epoch 70, Loss(train/val) 0.15471/0.40532. Took 0.16 sec\n",
      "Epoch 71, Loss(train/val) 0.14808/0.40632. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.15283/0.39299. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.14328/0.39139. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.16074/0.40511. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.15284/0.39504. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.15043/0.39626. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.14947/0.41117. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.15602/0.36309. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.14780/0.40043. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.15511/0.42550. Took 0.12 sec\n",
      "Epoch 81, Loss(train/val) 0.14282/0.39553. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.14297/0.40153. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.14557/0.39244. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.14484/0.37153. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.14473/0.40104. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.14059/0.40200. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.13878/0.39064. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.14464/0.40740. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.14585/0.38820. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.13961/0.41308. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.13557/0.39226. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.13900/0.40265. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.13822/0.40186. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.13046/0.37632. Took 0.15 sec\n",
      "Epoch 95, Loss(train/val) 0.13361/0.39596. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.13961/0.39128. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.13550/0.36596. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.13006/0.40089. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.13167/0.39224. Took 0.14 sec\n",
      "ACC: 0.671875, MCC: 0.3059523453200475\n",
      "Epoch 0, Loss(train/val) 0.49594/0.48398. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.47976/0.45015. Took 0.15 sec\n",
      "Epoch 2, Loss(train/val) 0.44749/0.40900. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.41352/0.39007. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.39775/0.39168. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.38920/0.38495. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.37456/0.39478. Took 0.15 sec\n",
      "Epoch 7, Loss(train/val) 0.36663/0.39192. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.35630/0.39868. Took 0.16 sec\n",
      "Epoch 9, Loss(train/val) 0.35593/0.39745. Took 0.16 sec\n",
      "Epoch 10, Loss(train/val) 0.34354/0.40210. Took 0.15 sec\n",
      "Epoch 11, Loss(train/val) 0.34410/0.40342. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.33683/0.40343. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.33055/0.40771. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.32691/0.41096. Took 0.16 sec\n",
      "Epoch 15, Loss(train/val) 0.32800/0.41116. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.31790/0.41487. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.31173/0.42134. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.31130/0.42324. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.31008/0.41500. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.29940/0.41922. Took 0.15 sec\n",
      "Epoch 21, Loss(train/val) 0.29675/0.42578. Took 0.16 sec\n",
      "Epoch 22, Loss(train/val) 0.29462/0.43546. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.29020/0.41427. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.28147/0.40533. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.27221/0.39999. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.27853/0.40562. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.26937/0.39345. Took 0.17 sec\n",
      "Epoch 28, Loss(train/val) 0.25727/0.40160. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.25463/0.40467. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.25721/0.37982. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.25883/0.39256. Took 0.13 sec\n",
      "Epoch 32, Loss(train/val) 0.24788/0.39183. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.24413/0.39627. Took 0.16 sec\n",
      "Epoch 34, Loss(train/val) 0.23661/0.37393. Took 0.18 sec\n",
      "Epoch 35, Loss(train/val) 0.22679/0.38407. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.22620/0.38768. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.22290/0.37408. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.23616/0.38514. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.21841/0.38744. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.21942/0.37427. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.22053/0.37243. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.21137/0.37896. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.21149/0.36835. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.20092/0.37474. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.21053/0.36293. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.20987/0.36719. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.19424/0.35932. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.20292/0.38029. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.19535/0.36213. Took 0.12 sec\n",
      "Epoch 50, Loss(train/val) 0.19449/0.37466. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.19673/0.37411. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.18923/0.39790. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.18774/0.38017. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.18574/0.37296. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.18378/0.36955. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.19492/0.39326. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.17617/0.40084. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.17629/0.38380. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.18199/0.38955. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.17594/0.38949. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.16945/0.38315. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.17329/0.37535. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.17142/0.37749. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.16518/0.36803. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.15916/0.35075. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.15797/0.36279. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.15933/0.37535. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.15889/0.36692. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.14946/0.36616. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.15801/0.36464. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.15469/0.36760. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.14803/0.36552. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.14712/0.36185. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.14252/0.35448. Took 0.15 sec\n",
      "Epoch 75, Loss(train/val) 0.15251/0.37194. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.14673/0.37514. Took 0.16 sec\n",
      "Epoch 77, Loss(train/val) 0.15036/0.36880. Took 0.15 sec\n",
      "Epoch 78, Loss(train/val) 0.13617/0.33869. Took 0.17 sec\n",
      "Epoch 79, Loss(train/val) 0.14348/0.36613. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.14637/0.35213. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.13834/0.33358. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.13364/0.35619. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) 0.13311/0.34745. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.14272/0.34580. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.13854/0.33428. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.13293/0.34241. Took 0.17 sec\n",
      "Epoch 87, Loss(train/val) 0.13139/0.34483. Took 0.15 sec\n",
      "Epoch 88, Loss(train/val) 0.12428/0.33989. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.12659/0.31861. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.12464/0.34256. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.12963/0.35435. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.13009/0.35292. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.12096/0.34333. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.11821/0.37040. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.12175/0.34314. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.12476/0.33903. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.12539/0.33249. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.12699/0.34629. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.11623/0.37385. Took 0.13 sec\n",
      "ACC: 0.6875, MCC: 0.37389885714349824\n",
      "Epoch 0, Loss(train/val) 0.49254/0.47664. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.47258/0.43492. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.43590/0.39099. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.40673/0.37748. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.39632/0.34697. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.38551/0.31959. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.37481/0.30285. Took 0.16 sec\n",
      "Epoch 7, Loss(train/val) 0.36418/0.28447. Took 0.16 sec\n",
      "Epoch 8, Loss(train/val) 0.36100/0.26626. Took 0.17 sec\n",
      "Epoch 9, Loss(train/val) 0.35502/0.26609. Took 0.17 sec\n",
      "Epoch 10, Loss(train/val) 0.35481/0.28467. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.35239/0.25615. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.35424/0.26141. Took 0.16 sec\n",
      "Epoch 13, Loss(train/val) 0.34187/0.25374. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.32567/0.24831. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.33194/0.25530. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.31898/0.32883. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.31529/0.30188. Took 0.17 sec\n",
      "Epoch 18, Loss(train/val) 0.30902/0.34235. Took 0.15 sec\n",
      "Epoch 19, Loss(train/val) 0.30711/0.32048. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.29973/0.30499. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.29758/0.26651. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.29495/0.27684. Took 0.15 sec\n",
      "Epoch 23, Loss(train/val) 0.29153/0.28125. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.28828/0.29893. Took 0.16 sec\n",
      "Epoch 25, Loss(train/val) 0.27783/0.26686. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.28295/0.28228. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.27552/0.31033. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.27296/0.30576. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.27550/0.28038. Took 0.16 sec\n",
      "Epoch 30, Loss(train/val) 0.26403/0.31107. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.25945/0.32249. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.26225/0.31978. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.25873/0.30412. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.25229/0.32975. Took 0.13 sec\n",
      "Epoch 35, Loss(train/val) 0.26109/0.33849. Took 0.13 sec\n",
      "Epoch 36, Loss(train/val) 0.25610/0.31035. Took 0.13 sec\n",
      "Epoch 37, Loss(train/val) 0.25435/0.30567. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.24669/0.27741. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.26104/0.38113. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.25430/0.53111. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.25188/0.27159. Took 0.15 sec\n",
      "Epoch 42, Loss(train/val) 0.24505/0.41744. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.24042/0.46267. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.23686/0.40517. Took 0.15 sec\n",
      "Epoch 45, Loss(train/val) 0.23567/0.42228. Took 0.15 sec\n",
      "Epoch 46, Loss(train/val) 0.23093/0.38448. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.23060/0.35206. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.23376/0.38162. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.22991/0.28871. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.23111/0.40226. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.22471/0.35808. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.22086/0.33195. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.21975/0.38897. Took 0.16 sec\n",
      "Epoch 54, Loss(train/val) 0.21349/0.40114. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.21422/0.32920. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.21102/0.44606. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.20926/0.37391. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.21428/0.30709. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.21198/0.39690. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.20585/0.35935. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.20313/0.29504. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.20957/0.32168. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.19277/0.37803. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.18842/0.36496. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.19569/0.43466. Took 0.15 sec\n",
      "Epoch 66, Loss(train/val) 0.19466/0.31139. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.20143/0.33095. Took 0.12 sec\n",
      "Epoch 68, Loss(train/val) 0.20006/0.45776. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.19762/0.33431. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.18813/0.33261. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.18227/0.31516. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.18496/0.33290. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.17658/0.30238. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.17644/0.28609. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.18363/0.34067. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.19248/0.45010. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.18309/0.40215. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.17822/0.30172. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.17158/0.37082. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.17610/0.34584. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.17053/0.37079. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.16155/0.31776. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.16161/0.33326. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.15923/0.40936. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.17269/0.32573. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.15953/0.33216. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.16155/0.31362. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.15712/0.37330. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.16701/0.44779. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.14700/0.34666. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.15998/0.37387. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.15284/0.35382. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.15744/0.36133. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.16473/0.43431. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.15130/0.43933. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.15003/0.31294. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.14984/0.42027. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.15115/0.37068. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.14661/0.31155. Took 0.14 sec\n",
      "ACC: 0.640625, MCC: 0.2838965371136104\n",
      "Epoch 0, Loss(train/val) 0.49270/0.48566. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.47200/0.45789. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.43837/0.43246. Took 0.15 sec\n",
      "Epoch 3, Loss(train/val) 0.41050/0.41211. Took 0.15 sec\n",
      "Epoch 4, Loss(train/val) 0.39553/0.39434. Took 0.15 sec\n",
      "Epoch 5, Loss(train/val) 0.38200/0.36368. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.37368/0.35174. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.36326/0.34402. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.36429/0.38353. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.35353/0.34428. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.34833/0.33405. Took 0.17 sec\n",
      "Epoch 11, Loss(train/val) 0.35030/0.34610. Took 0.15 sec\n",
      "Epoch 12, Loss(train/val) 0.35624/0.34287. Took 0.15 sec\n",
      "Epoch 13, Loss(train/val) 0.34225/0.34495. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.32679/0.32564. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.32996/0.32031. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.33240/0.32577. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.32525/0.31919. Took 0.16 sec\n",
      "Epoch 18, Loss(train/val) 0.32433/0.34506. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.31361/0.34571. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.30990/0.33817. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.31278/0.33926. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.31269/0.31138. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.30653/0.33558. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.29915/0.33815. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.29226/0.33278. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.29016/0.34526. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.28872/0.34050. Took 0.13 sec\n",
      "Epoch 28, Loss(train/val) 0.27515/0.33534. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.26419/0.34521. Took 0.16 sec\n",
      "Epoch 30, Loss(train/val) 0.26809/0.34097. Took 0.18 sec\n",
      "Epoch 31, Loss(train/val) 0.26181/0.33530. Took 0.18 sec\n",
      "Epoch 32, Loss(train/val) 0.26057/0.33029. Took 0.18 sec\n",
      "Epoch 33, Loss(train/val) 0.25696/0.34875. Took 0.18 sec\n",
      "Epoch 34, Loss(train/val) 0.25285/0.33962. Took 0.19 sec\n",
      "Epoch 35, Loss(train/val) 0.24424/0.33445. Took 0.15 sec\n",
      "Epoch 36, Loss(train/val) 0.25306/0.34076. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.25213/0.32737. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.24589/0.32905. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.25346/0.37617. Took 0.16 sec\n",
      "Epoch 40, Loss(train/val) 0.23991/0.36849. Took 0.15 sec\n",
      "Epoch 41, Loss(train/val) 0.23891/0.35708. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.22808/0.36216. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.23275/0.35744. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.22610/0.34766. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.22452/0.35528. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.23010/0.36431. Took 0.15 sec\n",
      "Epoch 47, Loss(train/val) 0.22752/0.37170. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.22855/0.37262. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.23322/0.39377. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.22595/0.38091. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.21958/0.37250. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.22086/0.39631. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.22801/0.40641. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.22230/0.37220. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.21940/0.38782. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.21759/0.38359. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.20884/0.38666. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.20470/0.37585. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.20088/0.36309. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.20938/0.32947. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.21566/0.36133. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.21721/0.40019. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.20574/0.36840. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.20081/0.38654. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.19277/0.39063. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.20450/0.37988. Took 0.12 sec\n",
      "Epoch 67, Loss(train/val) 0.20029/0.37485. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.19551/0.39623. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.18414/0.39011. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.18709/0.37118. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.19637/0.36575. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.18779/0.36722. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.18987/0.39599. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.18810/0.39107. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.18127/0.40234. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.18867/0.38701. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.17655/0.39825. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.18352/0.42524. Took 0.14 sec\n",
      "Epoch 79, Loss(train/val) 0.18549/0.38605. Took 0.15 sec\n",
      "Epoch 80, Loss(train/val) 0.17982/0.39552. Took 0.19 sec\n",
      "Epoch 81, Loss(train/val) 0.17908/0.40345. Took 0.16 sec\n",
      "Epoch 82, Loss(train/val) 0.17159/0.39578. Took 0.16 sec\n",
      "Epoch 83, Loss(train/val) 0.17094/0.36007. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.17597/0.36904. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.16834/0.41019. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.17108/0.41575. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.17418/0.41085. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.17270/0.41004. Took 0.14 sec\n",
      "Epoch 89, Loss(train/val) 0.16222/0.42694. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.17208/0.38342. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.17372/0.41529. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.15693/0.43997. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.15937/0.42127. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.15649/0.42434. Took 0.15 sec\n",
      "Epoch 95, Loss(train/val) 0.16559/0.40893. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.15626/0.42460. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.15319/0.44443. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.15339/0.42330. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.14654/0.42843. Took 0.13 sec\n",
      "ACC: 0.59375, MCC: 0.19364916731037085\n",
      "Epoch 0, Loss(train/val) 0.49322/0.49351. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.47373/0.48242. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.43963/0.48044. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.41256/0.47846. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.39686/0.46224. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.38296/0.45164. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.37013/0.44105. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.36563/0.44860. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.35449/0.41577. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.34806/0.42176. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.34599/0.45539. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.33672/0.41344. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.32558/0.40590. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.33463/0.45241. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.33008/0.38087. Took 0.16 sec\n",
      "Epoch 15, Loss(train/val) 0.30606/0.40225. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.31595/0.40269. Took 0.16 sec\n",
      "Epoch 17, Loss(train/val) 0.31391/0.45032. Took 0.17 sec\n",
      "Epoch 18, Loss(train/val) 0.30286/0.43185. Took 0.17 sec\n",
      "Epoch 19, Loss(train/val) 0.29698/0.39872. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.29186/0.46412. Took 0.17 sec\n",
      "Epoch 21, Loss(train/val) 0.29177/0.49588. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.28051/0.46265. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.28335/0.48465. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.27670/0.42998. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.27405/0.43827. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.28309/0.48555. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.27713/0.44544. Took 0.18 sec\n",
      "Epoch 28, Loss(train/val) 0.26740/0.42997. Took 0.16 sec\n",
      "Epoch 29, Loss(train/val) 0.26224/0.44318. Took 0.16 sec\n",
      "Epoch 30, Loss(train/val) 0.25240/0.48663. Took 0.16 sec\n",
      "Epoch 31, Loss(train/val) 0.25335/0.46696. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.25508/0.45840. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.25110/0.47154. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.25046/0.47809. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.24181/0.47049. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.23732/0.46344. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.23106/0.47252. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.23054/0.48229. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.22664/0.48667. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.23360/0.46754. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.22487/0.51629. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.20931/0.47452. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.21874/0.50169. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.21291/0.48500. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.22759/0.49752. Took 0.15 sec\n",
      "Epoch 46, Loss(train/val) 0.20260/0.52118. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.21458/0.50896. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.20227/0.48129. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.20230/0.48665. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.20923/0.47578. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.20062/0.52939. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.20623/0.45622. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.20939/0.46287. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.21041/0.49777. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.21287/0.50755. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.20122/0.50567. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.19237/0.48894. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.19277/0.47171. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.19141/0.47408. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.19226/0.48211. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.18470/0.50233. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.18614/0.50781. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.18295/0.49848. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.18915/0.48682. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.18044/0.48545. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.17746/0.48180. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.17706/0.47588. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.18345/0.47933. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.17623/0.47813. Took 0.15 sec\n",
      "Epoch 70, Loss(train/val) 0.16710/0.47580. Took 0.15 sec\n",
      "Epoch 71, Loss(train/val) 0.17349/0.48544. Took 0.15 sec\n",
      "Epoch 72, Loss(train/val) 0.16759/0.49416. Took 0.18 sec\n",
      "Epoch 73, Loss(train/val) 0.17134/0.48887. Took 0.16 sec\n",
      "Epoch 74, Loss(train/val) 0.16544/0.47629. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) 0.16126/0.45461. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.16279/0.46254. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.16949/0.46144. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.16790/0.51162. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.16717/0.47785. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.16324/0.48139. Took 0.15 sec\n",
      "Epoch 81, Loss(train/val) 0.16297/0.47419. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.15577/0.49338. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.15970/0.48160. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.15480/0.46279. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.14632/0.47001. Took 0.15 sec\n",
      "Epoch 86, Loss(train/val) 0.15138/0.47882. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.15465/0.48184. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.15197/0.48989. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.14623/0.50046. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.15119/0.49816. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.14228/0.49369. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.15260/0.50691. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.14400/0.48663. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.14041/0.50099. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.13906/0.50376. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.14288/0.48472. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.14553/0.48481. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.14289/0.49550. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.14049/0.47787. Took 0.15 sec\n",
      "ACC: 0.703125, MCC: 0.40644850966246954\n",
      "Epoch 0, Loss(train/val) 0.49593/0.48236. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.48187/0.44731. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.45812/0.39507. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.43094/0.37092. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.41480/0.36502. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.40398/0.35797. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.39736/0.35109. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.39117/0.35422. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.38096/0.33813. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.36862/0.33381. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.36226/0.32455. Took 0.15 sec\n",
      "Epoch 11, Loss(train/val) 0.35218/0.33761. Took 0.17 sec\n",
      "Epoch 12, Loss(train/val) 0.33829/0.35268. Took 0.19 sec\n",
      "Epoch 13, Loss(train/val) 0.34356/0.35328. Took 0.17 sec\n",
      "Epoch 14, Loss(train/val) 0.33523/0.37670. Took 0.16 sec\n",
      "Epoch 15, Loss(train/val) 0.33544/0.35771. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.32650/0.35541. Took 0.15 sec\n",
      "Epoch 17, Loss(train/val) 0.31386/0.36668. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.31861/0.33697. Took 0.15 sec\n",
      "Epoch 19, Loss(train/val) 0.30781/0.33390. Took 0.15 sec\n",
      "Epoch 20, Loss(train/val) 0.30146/0.34825. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.29830/0.36163. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.29230/0.35750. Took 0.17 sec\n",
      "Epoch 23, Loss(train/val) 0.28721/0.34147. Took 0.16 sec\n",
      "Epoch 24, Loss(train/val) 0.29864/0.36759. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.28593/0.35104. Took 0.16 sec\n",
      "Epoch 26, Loss(train/val) 0.27624/0.34866. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.28222/0.35127. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.26893/0.34484. Took 0.16 sec\n",
      "Epoch 29, Loss(train/val) 0.27073/0.35888. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.27621/0.37097. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.26487/0.37195. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.27456/0.34147. Took 0.17 sec\n",
      "Epoch 33, Loss(train/val) 0.26094/0.33851. Took 0.16 sec\n",
      "Epoch 34, Loss(train/val) 0.25987/0.32509. Took 0.16 sec\n",
      "Epoch 35, Loss(train/val) 0.25357/0.32720. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.25392/0.33012. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.25715/0.34088. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.25596/0.35315. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.25301/0.33259. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.25233/0.33925. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.24115/0.34052. Took 0.15 sec\n",
      "Epoch 42, Loss(train/val) 0.23343/0.34898. Took 0.15 sec\n",
      "Epoch 43, Loss(train/val) 0.24417/0.34391. Took 0.15 sec\n",
      "Epoch 44, Loss(train/val) 0.23264/0.33865. Took 0.18 sec\n",
      "Epoch 45, Loss(train/val) 0.23281/0.32841. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.23809/0.34476. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.22021/0.35008. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.22623/0.33733. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.22203/0.35097. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.22116/0.34363. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.22799/0.33052. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.22127/0.34023. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) 0.22398/0.33687. Took 0.15 sec\n",
      "Epoch 54, Loss(train/val) 0.21705/0.35520. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.21116/0.34429. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.21574/0.35715. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.20953/0.35056. Took 0.12 sec\n",
      "Epoch 58, Loss(train/val) 0.20830/0.34123. Took 0.14 sec\n",
      "Epoch 59, Loss(train/val) 0.20628/0.34891. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.19406/0.35377. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.21289/0.33694. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.20945/0.36485. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.21384/0.34049. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.20764/0.34792. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.20598/0.34531. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.20101/0.37111. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.19539/0.35024. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.19722/0.34073. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.19541/0.34959. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.19144/0.34573. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.18983/0.35755. Took 0.15 sec\n",
      "Epoch 72, Loss(train/val) 0.18200/0.35615. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.18415/0.34216. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.18266/0.34638. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.18473/0.35030. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.17243/0.35701. Took 0.15 sec\n",
      "Epoch 77, Loss(train/val) 0.16902/0.36010. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.16750/0.34906. Took 0.17 sec\n",
      "Epoch 79, Loss(train/val) 0.18569/0.35506. Took 0.15 sec\n",
      "Epoch 80, Loss(train/val) 0.18007/0.35919. Took 0.14 sec\n",
      "Epoch 81, Loss(train/val) 0.18004/0.37553. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.18353/0.35141. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) 0.17195/0.36657. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.15739/0.35788. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.16903/0.36206. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.16249/0.35859. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.16415/0.36092. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.16372/0.36864. Took 0.14 sec\n",
      "Epoch 89, Loss(train/val) 0.16475/0.37384. Took 0.15 sec\n",
      "Epoch 90, Loss(train/val) 0.15804/0.36925. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.16039/0.37354. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.16189/0.33601. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.15733/0.38751. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.15336/0.37597. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.16016/0.37974. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.16326/0.37076. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.16318/0.35045. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.15158/0.37359. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.15507/0.35538. Took 0.15 sec\n",
      "ACC: 0.671875, MCC: 0.34269767738760554\n",
      "Epoch 0, Loss(train/val) 0.49477/0.48878. Took 0.13 sec\n",
      "Epoch 1, Loss(train/val) 0.47984/0.46648. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.45322/0.43913. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.42983/0.42503. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.41292/0.40257. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.40581/0.37024. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.39408/0.38056. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.38225/0.36540. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.36987/0.36735. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.36880/0.29861. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.36269/0.31710. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.35363/0.32461. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.35159/0.28268. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.34792/0.33095. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.34428/0.33385. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.32867/0.35713. Took 0.18 sec\n",
      "Epoch 16, Loss(train/val) 0.34245/0.34690. Took 0.15 sec\n",
      "Epoch 17, Loss(train/val) 0.33881/0.33446. Took 0.16 sec\n",
      "Epoch 18, Loss(train/val) 0.33196/0.33182. Took 0.17 sec\n",
      "Epoch 19, Loss(train/val) 0.32720/0.39813. Took 0.16 sec\n",
      "Epoch 20, Loss(train/val) 0.31817/0.38240. Took 0.15 sec\n",
      "Epoch 21, Loss(train/val) 0.31816/0.33022. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.31041/0.33391. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.30433/0.38341. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.30721/0.34082. Took 0.17 sec\n",
      "Epoch 25, Loss(train/val) 0.29424/0.34883. Took 0.17 sec\n",
      "Epoch 26, Loss(train/val) 0.30105/0.35917. Took 0.15 sec\n",
      "Epoch 27, Loss(train/val) 0.29277/0.35339. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.27938/0.33919. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.27932/0.33013. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.27890/0.35004. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.28139/0.33034. Took 0.17 sec\n",
      "Epoch 32, Loss(train/val) 0.26503/0.34389. Took 0.16 sec\n",
      "Epoch 33, Loss(train/val) 0.27625/0.34254. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.26056/0.35895. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.25744/0.33366. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.25564/0.33804. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.26479/0.34472. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.25644/0.33218. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.25429/0.33323. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.24797/0.33435. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.23731/0.34110. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.24734/0.33566. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.22824/0.33272. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.22921/0.33618. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.23661/0.33439. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.23062/0.34155. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.25187/0.32299. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.22614/0.33476. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.22743/0.33434. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.21949/0.32541. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.21381/0.31798. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.20871/0.33586. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) 0.21470/0.31496. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.20791/0.31907. Took 0.16 sec\n",
      "Epoch 55, Loss(train/val) 0.21717/0.32745. Took 0.15 sec\n",
      "Epoch 56, Loss(train/val) 0.21495/0.32084. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.20943/0.32502. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.20744/0.31209. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.20352/0.33437. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.20250/0.33325. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.19370/0.33443. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.18744/0.31909. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.18979/0.32595. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.19422/0.34330. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.18994/0.33007. Took 0.12 sec\n",
      "Epoch 66, Loss(train/val) 0.19450/0.34004. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.18521/0.36240. Took 0.17 sec\n",
      "Epoch 68, Loss(train/val) 0.21308/0.38916. Took 0.15 sec\n",
      "Epoch 69, Loss(train/val) 0.20637/0.36982. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.19522/0.37065. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.19277/0.36032. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.20707/0.37176. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.19164/0.32840. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.19261/0.36897. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.18269/0.35933. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.18370/0.37246. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.17842/0.35437. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.17998/0.33750. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.17230/0.36783. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.17593/0.35045. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.18141/0.36597. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.16247/0.34477. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.16676/0.33372. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.17384/0.34154. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.16848/0.34740. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.17185/0.35959. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.16994/0.33866. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.16264/0.36776. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.16278/0.37465. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.16380/0.36074. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.15816/0.35165. Took 0.12 sec\n",
      "Epoch 92, Loss(train/val) 0.16493/0.36567. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.15341/0.34910. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.14999/0.36070. Took 0.14 sec\n",
      "Epoch 95, Loss(train/val) 0.15344/0.36253. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.15348/0.33978. Took 0.15 sec\n",
      "Epoch 97, Loss(train/val) 0.15350/0.37629. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.15216/0.34885. Took 0.14 sec\n",
      "Epoch 99, Loss(train/val) 0.14892/0.36575. Took 0.14 sec\n",
      "ACC: 0.6875, MCC: 0.4172897660939783\n",
      "Epoch 0, Loss(train/val) 0.48856/0.48360. Took 0.16 sec\n",
      "Epoch 1, Loss(train/val) 0.45903/0.45885. Took 0.15 sec\n",
      "Epoch 2, Loss(train/val) 0.43240/0.43862. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.41106/0.43128. Took 0.15 sec\n",
      "Epoch 4, Loss(train/val) 0.39271/0.43102. Took 0.15 sec\n",
      "Epoch 5, Loss(train/val) 0.37344/0.44538. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.35751/0.43461. Took 0.15 sec\n",
      "Epoch 7, Loss(train/val) 0.35591/0.38314. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.34698/0.41537. Took 0.16 sec\n",
      "Epoch 9, Loss(train/val) 0.33658/0.39684. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.32973/0.39204. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.32236/0.36141. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.32309/0.36777. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.32344/0.37799. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.30765/0.36799. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.30665/0.35595. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.30136/0.36704. Took 0.17 sec\n",
      "Epoch 17, Loss(train/val) 0.30293/0.36659. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.30006/0.38354. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.29251/0.38750. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.29714/0.37245. Took 0.15 sec\n",
      "Epoch 21, Loss(train/val) 0.28661/0.35409. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.28227/0.36707. Took 0.15 sec\n",
      "Epoch 23, Loss(train/val) 0.28425/0.37118. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.27780/0.35850. Took 0.15 sec\n",
      "Epoch 25, Loss(train/val) 0.27108/0.37629. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.26695/0.38565. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.26633/0.37784. Took 0.20 sec\n",
      "Epoch 28, Loss(train/val) 0.26764/0.35446. Took 0.16 sec\n",
      "Epoch 29, Loss(train/val) 0.27063/0.38462. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.25957/0.37815. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.26031/0.38117. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.25796/0.36051. Took 0.16 sec\n",
      "Epoch 33, Loss(train/val) 0.26165/0.36975. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.25605/0.35964. Took 0.13 sec\n",
      "Epoch 35, Loss(train/val) 0.25461/0.36349. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.24818/0.36799. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.25145/0.36831. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.24324/0.38494. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.23639/0.34909. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.24071/0.35422. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.24285/0.37756. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.23955/0.38698. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.23594/0.38085. Took 0.15 sec\n",
      "Epoch 44, Loss(train/val) 0.23577/0.38739. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) 0.23361/0.38012. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.22732/0.37319. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.24354/0.36992. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.22965/0.36970. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.23212/0.36654. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.22281/0.36661. Took 0.14 sec\n",
      "Epoch 51, Loss(train/val) 0.23376/0.36224. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.23499/0.38023. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) 0.23073/0.36027. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.22614/0.36176. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.21797/0.35872. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.22531/0.38504. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.22642/0.37887. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.21868/0.39064. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.21230/0.38295. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.21557/0.39751. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.21314/0.38609. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.21179/0.37711. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.21050/0.38957. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.20995/0.38876. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.21496/0.37806. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.21010/0.38034. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.21257/0.38911. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.21429/0.38185. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.20320/0.37977. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.21586/0.37333. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.20698/0.39165. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.20216/0.39081. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.19664/0.38035. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.20542/0.38015. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.20070/0.38205. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.19939/0.38216. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.21520/0.37878. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.19991/0.36860. Took 0.12 sec\n",
      "Epoch 79, Loss(train/val) 0.19721/0.38538. Took 0.12 sec\n",
      "Epoch 80, Loss(train/val) 0.20782/0.38470. Took 0.12 sec\n",
      "Epoch 81, Loss(train/val) 0.20346/0.38053. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.19594/0.38245. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.19221/0.37253. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.18995/0.37333. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.18781/0.38026. Took 0.12 sec\n",
      "Epoch 86, Loss(train/val) 0.19532/0.35882. Took 0.12 sec\n",
      "Epoch 87, Loss(train/val) 0.19155/0.38322. Took 0.12 sec\n",
      "Epoch 88, Loss(train/val) 0.19736/0.37517. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.19492/0.37145. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.19496/0.37433. Took 0.14 sec\n",
      "Epoch 91, Loss(train/val) 0.19745/0.36603. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.19114/0.35748. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.19337/0.37708. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.19006/0.37616. Took 0.12 sec\n",
      "Epoch 95, Loss(train/val) 0.18069/0.37904. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.18853/0.36810. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.18274/0.38366. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.18097/0.39537. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.18640/0.36552. Took 0.13 sec\n",
      "ACC: 0.609375, MCC: 0.21489596171766712\n",
      "Epoch 0, Loss(train/val) 0.49144/0.48941. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.46201/0.47263. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.43813/0.46194. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.42150/0.45008. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.40157/0.44092. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.38045/0.43488. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.35717/0.43356. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.34208/0.42496. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.32582/0.43563. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.32672/0.43648. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.31785/0.43610. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.32015/0.42667. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.31620/0.42920. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.30972/0.41726. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.31071/0.42594. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.30786/0.43317. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.30627/0.43625. Took 0.15 sec\n",
      "Epoch 17, Loss(train/val) 0.30175/0.42598. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.29145/0.43330. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.30220/0.43301. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.30470/0.43529. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.30774/0.43398. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.28401/0.41707. Took 0.15 sec\n",
      "Epoch 23, Loss(train/val) 0.29995/0.43168. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.29331/0.41308. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.27974/0.43109. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.28895/0.42037. Took 0.13 sec\n",
      "Epoch 27, Loss(train/val) 0.29047/0.42673. Took 0.13 sec\n",
      "Epoch 28, Loss(train/val) 0.30103/0.44642. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.30034/0.43166. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.32347/0.43489. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.29330/0.42869. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.30488/0.44203. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.27934/0.43452. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.27718/0.43550. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.27103/0.41488. Took 0.17 sec\n",
      "Epoch 36, Loss(train/val) 0.27824/0.43572. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.28895/0.43111. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.28369/0.43116. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.26627/0.42760. Took 0.16 sec\n",
      "Epoch 40, Loss(train/val) 0.26326/0.43322. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.27639/0.44178. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.28197/0.42936. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.26979/0.42446. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.27267/0.42087. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.26593/0.43187. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.27630/0.44443. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.26503/0.43290. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.25812/0.43311. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.25459/0.43308. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.25462/0.43229. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.25825/0.42756. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.25718/0.42779. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) 0.25186/0.42144. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.23845/0.43861. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.23634/0.43280. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.25342/0.43392. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.25038/0.43992. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.25133/0.45113. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.25077/0.43641. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.24665/0.42944. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.23718/0.41967. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.24812/0.43786. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.23599/0.43434. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.23932/0.43306. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.23353/0.43357. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.23311/0.42907. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.24816/0.41800. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.23836/0.44040. Took 0.12 sec\n",
      "Epoch 69, Loss(train/val) 0.23812/0.43967. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.24544/0.43305. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.23312/0.42806. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.22784/0.43263. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.22695/0.43357. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.23150/0.43157. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.22990/0.43146. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.21742/0.43351. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.22878/0.44992. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.22689/0.43862. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.22776/0.43080. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.24375/0.39831. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.24739/0.43766. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.22721/0.42253. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.22500/0.43645. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.22701/0.41941. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.21860/0.43081. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.22349/0.44872. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.22730/0.44856. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.22378/0.43005. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.22058/0.43586. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.22073/0.44642. Took 0.12 sec\n",
      "Epoch 91, Loss(train/val) 0.22553/0.44219. Took 0.12 sec\n",
      "Epoch 92, Loss(train/val) 0.20872/0.43121. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.21435/0.43856. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.21563/0.43005. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.21922/0.43308. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.21845/0.44367. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.21905/0.45058. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.21047/0.43552. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.26276/0.39923. Took 0.12 sec\n",
      "ACC: 0.515625, MCC: 0.25673599474580255\n",
      "Epoch 0, Loss(train/val) 0.48717/0.52009. Took 0.13 sec\n",
      "Epoch 1, Loss(train/val) 0.45794/0.54169. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.43605/0.54921. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.42455/0.51313. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.40816/0.45729. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.38668/0.43920. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.36959/0.42768. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.35331/0.48034. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.33888/0.52772. Took 0.16 sec\n",
      "Epoch 9, Loss(train/val) 0.33340/0.54109. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.32764/0.50214. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.32223/0.49753. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.32643/0.55403. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.31414/0.50307. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.35171/0.48643. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.31953/0.56108. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.30422/0.55609. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.30381/0.55810. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.29994/0.55433. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.30871/0.56334. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.29517/0.56418. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.29783/0.57188. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.29214/0.56464. Took 0.16 sec\n",
      "Epoch 23, Loss(train/val) 0.29323/0.56650. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.28387/0.56249. Took 0.15 sec\n",
      "Epoch 25, Loss(train/val) 0.28359/0.57100. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.27815/0.52706. Took 0.13 sec\n",
      "Epoch 27, Loss(train/val) 0.27924/0.57364. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.27829/0.53645. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.27945/0.57117. Took 0.16 sec\n",
      "Epoch 30, Loss(train/val) 0.28899/0.57483. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.29334/0.54862. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.27538/0.54230. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.26917/0.57319. Took 0.13 sec\n",
      "Epoch 34, Loss(train/val) 0.27077/0.54347. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.26331/0.54770. Took 0.13 sec\n",
      "Epoch 36, Loss(train/val) 0.26171/0.55418. Took 0.13 sec\n",
      "Epoch 37, Loss(train/val) 0.25525/0.57956. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.24950/0.55761. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.24380/0.54743. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.25432/0.57375. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.25100/0.57259. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.23849/0.56710. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.23969/0.56807. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.23570/0.58166. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.23357/0.58397. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.22906/0.57871. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.23109/0.58671. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.23058/0.58581. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.23181/0.56966. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.21809/0.59879. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.22072/0.57919. Took 0.12 sec\n",
      "Epoch 52, Loss(train/val) 0.21354/0.59421. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.20883/0.57947. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.20685/0.58964. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.21063/0.58421. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.20885/0.57052. Took 0.12 sec\n",
      "Epoch 57, Loss(train/val) 0.21037/0.57773. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.20014/0.58601. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.19898/0.59554. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.19302/0.59393. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.19893/0.58245. Took 0.12 sec\n",
      "Epoch 62, Loss(train/val) 0.19316/0.60454. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.19182/0.59792. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.18408/0.59352. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.19008/0.57319. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.18232/0.59231. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.18682/0.58884. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.18182/0.59243. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.17443/0.58460. Took 0.12 sec\n",
      "Epoch 70, Loss(train/val) 0.17182/0.58274. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.17160/0.59563. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.16611/0.59501. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.16865/0.58928. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.16625/0.57853. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.16644/0.53491. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.16315/0.59880. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.15506/0.57681. Took 0.12 sec\n",
      "Epoch 78, Loss(train/val) 0.15575/0.58756. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.15419/0.59168. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.15419/0.58085. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.16038/0.59894. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.14716/0.56926. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.15107/0.60504. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.14727/0.59286. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.14559/0.57780. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.13933/0.54963. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.14217/0.55034. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.14093/0.56426. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.13791/0.55738. Took 0.12 sec\n",
      "Epoch 90, Loss(train/val) 0.13972/0.54770. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.13550/0.54573. Took 0.12 sec\n",
      "Epoch 92, Loss(train/val) 0.13529/0.54237. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.13334/0.55193. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.13722/0.51564. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.13088/0.53424. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.13007/0.55853. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.12584/0.55394. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.13086/0.55312. Took 0.12 sec\n",
      "Epoch 99, Loss(train/val) 0.12871/0.54154. Took 0.13 sec\n",
      "ACC: 0.671875, MCC: 0.3133065881225898\n",
      "Epoch 0, Loss(train/val) 0.49150/0.46956. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.46820/0.43203. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.44622/0.41605. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.43217/0.39957. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.41795/0.38096. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.39879/0.36046. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.37690/0.34623. Took 0.15 sec\n",
      "Epoch 7, Loss(train/val) 0.36240/0.33545. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.36157/0.32555. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.34875/0.31902. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.33630/0.31692. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.33571/0.30680. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.32551/0.30213. Took 0.15 sec\n",
      "Epoch 13, Loss(train/val) 0.31890/0.30230. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.31455/0.30701. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.30506/0.30110. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.29399/0.29799. Took 0.15 sec\n",
      "Epoch 17, Loss(train/val) 0.29274/0.29372. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.29809/0.29609. Took 0.17 sec\n",
      "Epoch 19, Loss(train/val) 0.28802/0.28706. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.28516/0.28912. Took 0.18 sec\n",
      "Epoch 21, Loss(train/val) 0.27537/0.29031. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.27266/0.28512. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.27555/0.27423. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.26779/0.27068. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.26847/0.28437. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.25807/0.29685. Took 0.15 sec\n",
      "Epoch 27, Loss(train/val) 0.26680/0.27258. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.26184/0.29177. Took 0.13 sec\n",
      "Epoch 29, Loss(train/val) 0.25129/0.26853. Took 0.13 sec\n",
      "Epoch 30, Loss(train/val) 0.25189/0.26830. Took 0.13 sec\n",
      "Epoch 31, Loss(train/val) 0.25187/0.26290. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.24181/0.27971. Took 0.20 sec\n",
      "Epoch 33, Loss(train/val) 0.24552/0.30214. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.24259/0.26389. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.24258/0.30316. Took 0.15 sec\n",
      "Epoch 36, Loss(train/val) 0.23511/0.29853. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.22536/0.31916. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.23143/0.29658. Took 0.15 sec\n",
      "Epoch 39, Loss(train/val) 0.22675/0.29059. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.22001/0.35884. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.22794/0.31575. Took 0.15 sec\n",
      "Epoch 42, Loss(train/val) 0.22419/0.31659. Took 0.15 sec\n",
      "Epoch 43, Loss(train/val) 0.21575/0.34838. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.21021/0.33224. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.21728/0.32883. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.20691/0.35974. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.20078/0.33315. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.21520/0.30762. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.21047/0.37723. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.20571/0.37926. Took 0.14 sec\n",
      "Epoch 51, Loss(train/val) 0.20721/0.31671. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.20016/0.35326. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.18606/0.37033. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.19295/0.37354. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.19418/0.35350. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.18717/0.34572. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.18266/0.37166. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.19049/0.33337. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.18291/0.34585. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.18350/0.34919. Took 0.14 sec\n",
      "Epoch 61, Loss(train/val) 0.18371/0.33681. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.17763/0.34612. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.17802/0.38714. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.18413/0.35872. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.17173/0.37943. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.17099/0.37767. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.17893/0.33168. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.17357/0.32717. Took 0.16 sec\n",
      "Epoch 69, Loss(train/val) 0.17091/0.35977. Took 0.20 sec\n",
      "Epoch 70, Loss(train/val) 0.17410/0.38254. Took 0.17 sec\n",
      "Epoch 71, Loss(train/val) 0.16512/0.33088. Took 0.17 sec\n",
      "Epoch 72, Loss(train/val) 0.16688/0.34801. Took 0.16 sec\n",
      "Epoch 73, Loss(train/val) 0.16562/0.35661. Took 0.16 sec\n",
      "Epoch 74, Loss(train/val) 0.16916/0.33180. Took 0.15 sec\n",
      "Epoch 75, Loss(train/val) 0.16787/0.34302. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.16751/0.33503. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.16475/0.35923. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.16103/0.33500. Took 0.14 sec\n",
      "Epoch 79, Loss(train/val) 0.16433/0.36855. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.16517/0.33879. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.16331/0.34322. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.15694/0.35359. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.16343/0.39543. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.17100/0.35870. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.15811/0.36226. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.15995/0.38197. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.15697/0.34968. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.15853/0.38304. Took 0.12 sec\n",
      "Epoch 89, Loss(train/val) 0.15744/0.36754. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.15070/0.38446. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.15282/0.32866. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.15696/0.38330. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.15805/0.37644. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.14792/0.38663. Took 0.14 sec\n",
      "Epoch 95, Loss(train/val) 0.14550/0.38990. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.14216/0.34978. Took 0.14 sec\n",
      "Epoch 97, Loss(train/val) 0.14348/0.32796. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.14386/0.35057. Took 0.14 sec\n",
      "Epoch 99, Loss(train/val) 0.14430/0.37317. Took 0.13 sec\n",
      "ACC: 0.703125, MCC: 0.43816309604046616\n",
      "Epoch 0, Loss(train/val) 0.48574/0.48372. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.45696/0.46617. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.43698/0.43256. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.41755/0.39608. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.40031/0.37506. Took 0.15 sec\n",
      "Epoch 5, Loss(train/val) 0.38449/0.35179. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.37441/0.33271. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.36047/0.32431. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.35540/0.32401. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.34160/0.30708. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.33133/0.32713. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.32948/0.32251. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.32317/0.36012. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.31327/0.32702. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.31501/0.33231. Took 0.15 sec\n",
      "Epoch 15, Loss(train/val) 0.31127/0.32935. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.30315/0.33347. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.30206/0.36546. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.29779/0.35101. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.28288/0.32840. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.27774/0.34173. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.27698/0.36726. Took 0.16 sec\n",
      "Epoch 22, Loss(train/val) 0.27658/0.32676. Took 0.15 sec\n",
      "Epoch 23, Loss(train/val) 0.27733/0.31722. Took 0.17 sec\n",
      "Epoch 24, Loss(train/val) 0.28097/0.34104. Took 0.18 sec\n",
      "Epoch 25, Loss(train/val) 0.26890/0.33497. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.26604/0.38278. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.26228/0.34492. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.26042/0.32737. Took 0.20 sec\n",
      "Epoch 29, Loss(train/val) 0.25653/0.38128. Took 0.17 sec\n",
      "Epoch 30, Loss(train/val) 0.27143/0.35767. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.24383/0.33946. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.25752/0.37012. Took 0.16 sec\n",
      "Epoch 33, Loss(train/val) 0.25719/0.33980. Took 0.16 sec\n",
      "Epoch 34, Loss(train/val) 0.24538/0.33961. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.24113/0.39549. Took 0.16 sec\n",
      "Epoch 36, Loss(train/val) 0.23012/0.37046. Took 0.19 sec\n",
      "Epoch 37, Loss(train/val) 0.23261/0.34858. Took 0.15 sec\n",
      "Epoch 38, Loss(train/val) 0.22981/0.33316. Took 0.16 sec\n",
      "Epoch 39, Loss(train/val) 0.22458/0.36119. Took 0.15 sec\n",
      "Epoch 40, Loss(train/val) 0.21237/0.34443. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.21127/0.33771. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.21874/0.31944. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.21946/0.32482. Took 0.12 sec\n",
      "Epoch 44, Loss(train/val) 0.21048/0.35721. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.20913/0.33373. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.20531/0.32703. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.20391/0.32631. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.19608/0.33116. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.20064/0.33972. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.19432/0.34401. Took 0.16 sec\n",
      "Epoch 51, Loss(train/val) 0.18869/0.32031. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.18882/0.30719. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.18268/0.33387. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.19083/0.32429. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.17704/0.35090. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.18688/0.32119. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.17619/0.31894. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.16952/0.33294. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.19083/0.34453. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.17089/0.33559. Took 0.14 sec\n",
      "Epoch 61, Loss(train/val) 0.17547/0.33585. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.16460/0.33000. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.16429/0.34946. Took 0.15 sec\n",
      "Epoch 64, Loss(train/val) 0.16568/0.32958. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.16932/0.32743. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.16375/0.33046. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) 0.15689/0.33624. Took 0.15 sec\n",
      "Epoch 68, Loss(train/val) 0.14887/0.33013. Took 0.14 sec\n",
      "Epoch 69, Loss(train/val) 0.15774/0.33603. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.15582/0.34369. Took 0.16 sec\n",
      "Epoch 71, Loss(train/val) 0.14861/0.34970. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.14857/0.34141. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.15146/0.34852. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.14753/0.34308. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.14569/0.33595. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.14483/0.35658. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.14726/0.35452. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.14470/0.36366. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.13727/0.35794. Took 0.12 sec\n",
      "Epoch 80, Loss(train/val) 0.13095/0.34052. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.14200/0.34721. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.14728/0.34889. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.12867/0.35990. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.13299/0.35918. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.13020/0.34771. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.13587/0.35307. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.13887/0.35999. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.12804/0.35639. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.13182/0.32903. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.13452/0.34148. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.12813/0.34869. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.12834/0.33404. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.12290/0.34620. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.12593/0.32892. Took 0.12 sec\n",
      "Epoch 95, Loss(train/val) 0.12598/0.32834. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.12973/0.33952. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.12643/0.32522. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.12181/0.35532. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.13250/0.33875. Took 0.13 sec\n",
      "ACC: 0.65625, MCC: 0.3124282448813543\n",
      "Epoch 0, Loss(train/val) 0.49036/0.47759. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.46748/0.44820. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.44220/0.41270. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.41685/0.38205. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.39707/0.36823. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.38036/0.36484. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.37764/0.36557. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.36430/0.35395. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.35090/0.35024. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.35269/0.34034. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.34393/0.33583. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.33053/0.33278. Took 0.15 sec\n",
      "Epoch 12, Loss(train/val) 0.32497/0.35671. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.32079/0.32657. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.32561/0.32577. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.31039/0.33233. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.31257/0.32129. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.32219/0.40667. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.29934/0.33436. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.30033/0.33119. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.29554/0.34005. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.29000/0.33727. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.29126/0.34045. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.28377/0.36337. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.28812/0.31246. Took 0.18 sec\n",
      "Epoch 25, Loss(train/val) 0.28644/0.37451. Took 0.19 sec\n",
      "Epoch 26, Loss(train/val) 0.27696/0.32471. Took 0.15 sec\n",
      "Epoch 27, Loss(train/val) 0.29202/0.30456. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.28124/0.34874. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.27409/0.35548. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.26266/0.37846. Took 0.16 sec\n",
      "Epoch 31, Loss(train/val) 0.26635/0.39354. Took 0.16 sec\n",
      "Epoch 32, Loss(train/val) 0.26379/0.37457. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.26612/0.38610. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.26557/0.37222. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.27072/0.37442. Took 0.15 sec\n",
      "Epoch 36, Loss(train/val) 0.25950/0.39583. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.24982/0.38382. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.25029/0.35516. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.24472/0.34870. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.24806/0.38628. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.24770/0.35259. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.24472/0.35980. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.24946/0.31990. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.25458/0.33990. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.24048/0.33265. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.23410/0.32362. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.23959/0.35414. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.23827/0.34544. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.24191/0.36525. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.24262/0.37873. Took 0.14 sec\n",
      "Epoch 51, Loss(train/val) 0.23917/0.37974. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.23378/0.41222. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) 0.23202/0.37216. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.23838/0.39231. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.22580/0.37336. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.22513/0.36213. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.23099/0.38498. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.23200/0.39056. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.20933/0.37434. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.22018/0.40233. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.21361/0.38799. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.21010/0.34326. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.22443/0.38363. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.21439/0.41330. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.22584/0.36869. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.22680/0.37737. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) 0.21684/0.37121. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.20896/0.35603. Took 0.14 sec\n",
      "Epoch 69, Loss(train/val) 0.20558/0.34315. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.20653/0.38081. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.20398/0.35491. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.20832/0.37062. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.20798/0.33226. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.20139/0.33834. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.21101/0.33649. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.20622/0.36562. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.21411/0.33896. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.20801/0.34706. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.21308/0.35461. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.20228/0.35719. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.20375/0.36743. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.19941/0.33564. Took 0.15 sec\n",
      "Epoch 83, Loss(train/val) 0.19795/0.35386. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.19448/0.33098. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.19361/0.31190. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.20339/0.34486. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.20175/0.38332. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.19723/0.36174. Took 0.14 sec\n",
      "Epoch 89, Loss(train/val) 0.18213/0.35155. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.21328/0.34655. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.19900/0.30655. Took 0.15 sec\n",
      "Epoch 92, Loss(train/val) 0.19590/0.36200. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.20048/0.36455. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.19754/0.37188. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.19314/0.30106. Took 0.12 sec\n",
      "Epoch 96, Loss(train/val) 0.18990/0.33021. Took 0.14 sec\n",
      "Epoch 97, Loss(train/val) 0.18242/0.36050. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.19202/0.33711. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.19161/0.35240. Took 0.13 sec\n",
      "ACC: 0.703125, MCC: 0.40804713337332393\n",
      "Epoch 0, Loss(train/val) 0.49056/0.48602. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.46483/0.46393. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.43463/0.45377. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.40520/0.44328. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.38757/0.42726. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.37264/0.41809. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.36428/0.40710. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.35678/0.39451. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.34917/0.39072. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.34554/0.39885. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.34150/0.39696. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.33245/0.39126. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.32978/0.39812. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.32674/0.39893. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.31674/0.40822. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.31323/0.40016. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.30507/0.41498. Took 0.15 sec\n",
      "Epoch 17, Loss(train/val) 0.30153/0.41048. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.30108/0.40196. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.29094/0.40260. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.29124/0.40635. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.28666/0.37678. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.28516/0.42355. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.27854/0.41988. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.28118/0.41537. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.27181/0.41057. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.27167/0.41222. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.27718/0.39635. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.26804/0.40190. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.25575/0.40247. Took 0.17 sec\n",
      "Epoch 30, Loss(train/val) 0.25883/0.40035. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.25349/0.39464. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.25386/0.39146. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.24484/0.39433. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.24366/0.38438. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.25383/0.44821. Took 0.16 sec\n",
      "Epoch 36, Loss(train/val) 0.24442/0.40757. Took 0.16 sec\n",
      "Epoch 37, Loss(train/val) 0.23954/0.41208. Took 0.15 sec\n",
      "Epoch 38, Loss(train/val) 0.23236/0.39412. Took 0.16 sec\n",
      "Epoch 39, Loss(train/val) 0.24749/0.41150. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.22850/0.39789. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.22630/0.42655. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.22651/0.38431. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.21392/0.39915. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.21636/0.39486. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.21561/0.38381. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.21018/0.38946. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.20539/0.38688. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.21083/0.40483. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.20458/0.42020. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.19778/0.40414. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.19931/0.40262. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.19756/0.39774. Took 0.15 sec\n",
      "Epoch 53, Loss(train/val) 0.19666/0.38059. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.19255/0.41904. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.18319/0.38974. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.18598/0.39756. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.19024/0.39801. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.19307/0.39860. Took 0.14 sec\n",
      "Epoch 59, Loss(train/val) 0.18191/0.40549. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.17792/0.40573. Took 0.14 sec\n",
      "Epoch 61, Loss(train/val) 0.17468/0.39254. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.17499/0.40464. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.17189/0.38882. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.17869/0.43947. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.17561/0.46453. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.17928/0.40877. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.18771/0.43318. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.17513/0.42993. Took 0.14 sec\n",
      "Epoch 69, Loss(train/val) 0.16628/0.41931. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.16726/0.40791. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.15948/0.39451. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.15416/0.40200. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.15926/0.39039. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.15570/0.38815. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.16368/0.39650. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.15175/0.37704. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.15163/0.39322. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.15195/0.39599. Took 0.14 sec\n",
      "Epoch 79, Loss(train/val) 0.14993/0.40755. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.15787/0.39043. Took 0.14 sec\n",
      "Epoch 81, Loss(train/val) 0.15518/0.38865. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.14725/0.39595. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.14390/0.39717. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.14393/0.39546. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.14470/0.37575. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.14115/0.37380. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.14154/0.36805. Took 0.16 sec\n",
      "Epoch 88, Loss(train/val) 0.13157/0.39567. Took 0.14 sec\n",
      "Epoch 89, Loss(train/val) 0.13439/0.39242. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.13786/0.40641. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.13724/0.40211. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.13749/0.38866. Took 0.16 sec\n",
      "Epoch 93, Loss(train/val) 0.14098/0.36510. Took 0.15 sec\n",
      "Epoch 94, Loss(train/val) 0.13188/0.41036. Took 0.15 sec\n",
      "Epoch 95, Loss(train/val) 0.14113/0.42658. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.13312/0.38383. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.12781/0.38567. Took 0.15 sec\n",
      "Epoch 98, Loss(train/val) 0.12539/0.39667. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.12652/0.39990. Took 0.13 sec\n",
      "ACC: 0.6875, MCC: 0.3944724048765609\n",
      "Epoch 0, Loss(train/val) 0.49056/0.51188. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.46821/0.50404. Took 0.15 sec\n",
      "Epoch 2, Loss(train/val) 0.44013/0.43278. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.40720/0.37803. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.38623/0.35648. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.37408/0.34538. Took 0.12 sec\n",
      "Epoch 6, Loss(train/val) 0.36496/0.34204. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.35461/0.34427. Took 0.16 sec\n",
      "Epoch 8, Loss(train/val) 0.34653/0.34540. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.34621/0.33638. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.33677/0.31009. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.32658/0.28387. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.31091/0.27334. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.30486/0.27971. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.30241/0.33905. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.29177/0.29515. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.30503/0.35496. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.28261/0.32427. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.28091/0.32753. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.27142/0.33894. Took 0.15 sec\n",
      "Epoch 20, Loss(train/val) 0.26879/0.36273. Took 0.17 sec\n",
      "Epoch 21, Loss(train/val) 0.26225/0.38220. Took 0.18 sec\n",
      "Epoch 22, Loss(train/val) 0.25600/0.37704. Took 0.16 sec\n",
      "Epoch 23, Loss(train/val) 0.25830/0.39297. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.26349/0.32578. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.25933/0.39874. Took 0.16 sec\n",
      "Epoch 26, Loss(train/val) 0.25471/0.40666. Took 0.15 sec\n",
      "Epoch 27, Loss(train/val) 0.23687/0.41565. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.22884/0.42330. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.22886/0.41844. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.22275/0.43218. Took 0.16 sec\n",
      "Epoch 31, Loss(train/val) 0.23055/0.39379. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.22123/0.34917. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.22917/0.43836. Took 0.16 sec\n",
      "Epoch 34, Loss(train/val) 0.22159/0.40269. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.21282/0.37127. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.22187/0.44580. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.21281/0.45708. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.21989/0.40901. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.21428/0.43598. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.20974/0.43892. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.19832/0.35147. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.20758/0.36414. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.21792/0.46290. Took 0.15 sec\n",
      "Epoch 44, Loss(train/val) 0.20617/0.41402. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) 0.20071/0.37137. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.19456/0.38078. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.19533/0.37559. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.19904/0.37685. Took 0.12 sec\n",
      "Epoch 49, Loss(train/val) 0.19452/0.37482. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.18282/0.38167. Took 0.15 sec\n",
      "Epoch 51, Loss(train/val) 0.18748/0.36321. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.18299/0.36146. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.19580/0.36257. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.18967/0.33639. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.19127/0.37244. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.18656/0.41653. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.19426/0.40223. Took 0.15 sec\n",
      "Epoch 58, Loss(train/val) 0.17760/0.39872. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.17905/0.40994. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.17382/0.37098. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.17264/0.42847. Took 0.12 sec\n",
      "Epoch 62, Loss(train/val) 0.17987/0.36643. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.17045/0.36086. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.17129/0.35777. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.16958/0.36111. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.17594/0.38348. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) 0.17387/0.35828. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.17080/0.35057. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.16215/0.38002. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.17081/0.38805. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.16594/0.35063. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.16366/0.36248. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.16913/0.36863. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.15825/0.37142. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.16244/0.40167. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.15935/0.40228. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.15751/0.39851. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.15990/0.39374. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.15571/0.37534. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.15516/0.39259. Took 0.16 sec\n",
      "Epoch 81, Loss(train/val) 0.14798/0.38328. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.15146/0.38548. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.14153/0.40806. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.14577/0.47166. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.15085/0.36990. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.15512/0.36614. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.14624/0.37263. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.14609/0.38189. Took 0.15 sec\n",
      "Epoch 89, Loss(train/val) 0.14556/0.44361. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.15371/0.38974. Took 0.14 sec\n",
      "Epoch 91, Loss(train/val) 0.14414/0.42214. Took 0.16 sec\n",
      "Epoch 92, Loss(train/val) 0.14277/0.39848. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.14730/0.38013. Took 0.12 sec\n",
      "Epoch 94, Loss(train/val) 0.14495/0.38999. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.14234/0.40327. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.13568/0.37269. Took 0.14 sec\n",
      "Epoch 97, Loss(train/val) 0.14035/0.38016. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.13806/0.36744. Took 0.15 sec\n",
      "Epoch 99, Loss(train/val) 0.13754/0.38377. Took 0.15 sec\n",
      "ACC: 0.609375, MCC: 0.17491206531920717\n",
      "Epoch 0, Loss(train/val) 0.49237/0.50975. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.47361/0.49652. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.44423/0.45609. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.40827/0.41979. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.38104/0.40116. Took 0.16 sec\n",
      "Epoch 5, Loss(train/val) 0.36094/0.39391. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.34762/0.40053. Took 0.16 sec\n",
      "Epoch 7, Loss(train/val) 0.33791/0.39225. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.33657/0.41979. Took 0.17 sec\n",
      "Epoch 9, Loss(train/val) 0.32154/0.42529. Took 0.15 sec\n",
      "Epoch 10, Loss(train/val) 0.31583/0.42394. Took 0.15 sec\n",
      "Epoch 11, Loss(train/val) 0.31203/0.43515. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.30580/0.43117. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.30128/0.41560. Took 0.16 sec\n",
      "Epoch 14, Loss(train/val) 0.29424/0.43099. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.28368/0.43942. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.28649/0.42784. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.28425/0.42923. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.28450/0.42926. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.27751/0.43085. Took 0.15 sec\n",
      "Epoch 20, Loss(train/val) 0.27068/0.42322. Took 0.16 sec\n",
      "Epoch 21, Loss(train/val) 0.27535/0.43428. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.26618/0.44052. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.25428/0.43784. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.26463/0.44674. Took 0.16 sec\n",
      "Epoch 25, Loss(train/val) 0.25920/0.42129. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.26303/0.41834. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.25418/0.43474. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.24792/0.43495. Took 0.16 sec\n",
      "Epoch 29, Loss(train/val) 0.24810/0.42074. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.25252/0.43003. Took 0.18 sec\n",
      "Epoch 31, Loss(train/val) 0.24221/0.42525. Took 0.19 sec\n",
      "Epoch 32, Loss(train/val) 0.23674/0.43325. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.23895/0.42984. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.23306/0.44258. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.23996/0.44169. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.23016/0.43622. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.23919/0.42030. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.23076/0.41746. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.22468/0.42838. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.22733/0.43048. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.22027/0.41074. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.21997/0.41931. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.21915/0.42356. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.21014/0.42319. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.21276/0.42579. Took 0.12 sec\n",
      "Epoch 46, Loss(train/val) 0.21433/0.43223. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.22252/0.44625. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.21588/0.40360. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.20801/0.41991. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.21282/0.40292. Took 0.14 sec\n",
      "Epoch 51, Loss(train/val) 0.20592/0.42372. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.20159/0.43488. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.20194/0.39750. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.20266/0.44037. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.19865/0.43020. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.20050/0.42109. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.18723/0.44461. Took 0.16 sec\n",
      "Epoch 58, Loss(train/val) 0.19879/0.40823. Took 0.15 sec\n",
      "Epoch 59, Loss(train/val) 0.18862/0.42177. Took 0.15 sec\n",
      "Epoch 60, Loss(train/val) 0.19388/0.38199. Took 0.14 sec\n",
      "Epoch 61, Loss(train/val) 0.19417/0.42675. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.19746/0.40176. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.19245/0.42108. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.19007/0.43104. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.18981/0.43111. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.18830/0.41111. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.18877/0.40291. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.17869/0.41854. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.18312/0.40292. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.18415/0.38103. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.17854/0.37969. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.17701/0.40729. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.18041/0.41479. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.17586/0.39512. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.16920/0.38707. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.17673/0.38029. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.17700/0.41673. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.17093/0.40978. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.17627/0.41357. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.16893/0.39549. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.16659/0.38562. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.17607/0.41646. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.18175/0.38669. Took 0.15 sec\n",
      "Epoch 84, Loss(train/val) 0.17283/0.37337. Took 0.15 sec\n",
      "Epoch 85, Loss(train/val) 0.15495/0.37355. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.16660/0.37387. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.16639/0.36036. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.16397/0.36146. Took 0.16 sec\n",
      "Epoch 89, Loss(train/val) 0.16547/0.34613. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.16477/0.36498. Took 0.14 sec\n",
      "Epoch 91, Loss(train/val) 0.15596/0.39882. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.15702/0.38620. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.15217/0.36833. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.15888/0.36276. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.15344/0.38781. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.15268/0.36272. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.16444/0.35985. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.15658/0.35968. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.14818/0.35965. Took 0.13 sec\n",
      "ACC: 0.71875, MCC: 0.4425941852276055\n",
      "Epoch 0, Loss(train/val) 0.49525/0.48019. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.47496/0.43628. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.44117/0.38195. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.40078/0.35308. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.37448/0.34069. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.36382/0.32713. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.35399/0.31970. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.34499/0.31954. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.33304/0.32338. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.33980/0.31819. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.32521/0.31858. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.33047/0.31006. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.31797/0.31569. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.31841/0.33649. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.31139/0.32870. Took 0.15 sec\n",
      "Epoch 15, Loss(train/val) 0.30546/0.33284. Took 0.16 sec\n",
      "Epoch 16, Loss(train/val) 0.29786/0.33354. Took 0.20 sec\n",
      "Epoch 17, Loss(train/val) 0.29509/0.32454. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.28119/0.31128. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.28370/0.34048. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.28946/0.32629. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.30875/0.32313. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.28266/0.31766. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.28426/0.29580. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.27483/0.31271. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.26515/0.32064. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.26348/0.31490. Took 0.15 sec\n",
      "Epoch 27, Loss(train/val) 0.27262/0.30197. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.26940/0.31978. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.26710/0.29995. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.24359/0.30902. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.25677/0.29071. Took 0.16 sec\n",
      "Epoch 32, Loss(train/val) 0.24792/0.28459. Took 0.17 sec\n",
      "Epoch 33, Loss(train/val) 0.24681/0.28136. Took 0.17 sec\n",
      "Epoch 34, Loss(train/val) 0.24433/0.29059. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.24135/0.28470. Took 0.16 sec\n",
      "Epoch 36, Loss(train/val) 0.23374/0.27750. Took 0.16 sec\n",
      "Epoch 37, Loss(train/val) 0.22498/0.27888. Took 0.18 sec\n",
      "Epoch 38, Loss(train/val) 0.22052/0.29921. Took 0.17 sec\n",
      "Epoch 39, Loss(train/val) 0.22567/0.28545. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.22695/0.28920. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.21724/0.31641. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.21574/0.28835. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.21859/0.30772. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.20528/0.28156. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) 0.20326/0.29593. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.20603/0.28182. Took 0.17 sec\n",
      "Epoch 47, Loss(train/val) 0.19953/0.30173. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.20334/0.29900. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.21069/0.29845. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.19860/0.27823. Took 0.14 sec\n",
      "Epoch 51, Loss(train/val) 0.19420/0.28153. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.18667/0.27928. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.18714/0.28229. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.19222/0.28144. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.20761/0.31013. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.18501/0.28253. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.19992/0.29896. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.19221/0.27338. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.19950/0.29428. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.18981/0.26407. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.18938/0.26136. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.18349/0.26071. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.18373/0.26099. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.17354/0.26397. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.17483/0.26714. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.18522/0.26643. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.19148/0.26150. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.17697/0.26658. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.17028/0.26354. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.16744/0.26425. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.17182/0.26688. Took 0.17 sec\n",
      "Epoch 72, Loss(train/val) 0.16771/0.24761. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.17072/0.24782. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.17155/0.25648. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.16472/0.25913. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.15832/0.24755. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.15171/0.25278. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.16111/0.23991. Took 0.14 sec\n",
      "Epoch 79, Loss(train/val) 0.16002/0.25292. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.15449/0.27324. Took 0.14 sec\n",
      "Epoch 81, Loss(train/val) 0.16665/0.27397. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.15808/0.29028. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.16066/0.26575. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.15447/0.26185. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.15038/0.25450. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.14802/0.24144. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.15324/0.25026. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.15900/0.25098. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.14753/0.25001. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.14685/0.24927. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.14946/0.25762. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.15142/0.24806. Took 0.12 sec\n",
      "Epoch 93, Loss(train/val) 0.13851/0.25305. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.13985/0.25907. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.14173/0.28361. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.14363/0.25889. Took 0.14 sec\n",
      "Epoch 97, Loss(train/val) 0.13236/0.24065. Took 0.12 sec\n",
      "Epoch 98, Loss(train/val) 0.13807/0.24153. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.13544/0.26665. Took 0.13 sec\n",
      "ACC: 0.59375, MCC: 0.2112099364561225\n",
      "Epoch 0, Loss(train/val) 0.49467/0.49159. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.47376/0.48211. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.44004/0.44801. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.40416/0.41717. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.38430/0.39619. Took 0.16 sec\n",
      "Epoch 5, Loss(train/val) 0.37071/0.38590. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.36383/0.37828. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.36152/0.37264. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.35570/0.36847. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.35238/0.35207. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.35787/0.38893. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.34705/0.34655. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.34041/0.40190. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.33738/0.39151. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.33328/0.38188. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.34023/0.36567. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.34223/0.35876. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.33292/0.37948. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.32791/0.40929. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.32406/0.40269. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.31929/0.39324. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.31707/0.41030. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.32019/0.40946. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.31505/0.39161. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.30710/0.40547. Took 0.15 sec\n",
      "Epoch 25, Loss(train/val) 0.31356/0.40708. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.31122/0.39381. Took 0.13 sec\n",
      "Epoch 27, Loss(train/val) 0.30538/0.40766. Took 0.13 sec\n",
      "Epoch 28, Loss(train/val) 0.29971/0.39489. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.29911/0.39951. Took 0.13 sec\n",
      "Epoch 30, Loss(train/val) 0.29630/0.44115. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.30179/0.40324. Took 0.16 sec\n",
      "Epoch 32, Loss(train/val) 0.29069/0.40694. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.28520/0.40612. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.29162/0.40966. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.30735/0.39141. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.28976/0.38167. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.28476/0.38759. Took 0.16 sec\n",
      "Epoch 38, Loss(train/val) 0.28916/0.39175. Took 0.15 sec\n",
      "Epoch 39, Loss(train/val) 0.29897/0.37754. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.28160/0.38993. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.28507/0.41266. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.27385/0.39045. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.26958/0.39863. Took 0.12 sec\n",
      "Epoch 44, Loss(train/val) 0.26785/0.38077. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.27197/0.40245. Took 0.12 sec\n",
      "Epoch 46, Loss(train/val) 0.26378/0.39503. Took 0.12 sec\n",
      "Epoch 47, Loss(train/val) 0.28365/0.45066. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.29071/0.39452. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.27499/0.38710. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.27217/0.38128. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.26257/0.39148. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.27491/0.38127. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.26454/0.38473. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.26055/0.39315. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.25933/0.38574. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.25576/0.39907. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.24646/0.36604. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.24970/0.34507. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.24043/0.36415. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.24414/0.37422. Took 0.14 sec\n",
      "Epoch 61, Loss(train/val) 0.23184/0.35787. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.23851/0.39064. Took 0.12 sec\n",
      "Epoch 63, Loss(train/val) 0.24194/0.35777. Took 0.12 sec\n",
      "Epoch 64, Loss(train/val) 0.24097/0.40476. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.23232/0.36883. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.22441/0.38849. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.21647/0.38039. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.22664/0.40757. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.22863/0.40443. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.22555/0.35602. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.22620/0.38062. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.22189/0.35900. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.21484/0.36242. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.21764/0.39088. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.21714/0.39005. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.22076/0.38367. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.21617/0.42580. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.21724/0.41678. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.20472/0.38807. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.21770/0.41474. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.22240/0.40259. Took 0.12 sec\n",
      "Epoch 82, Loss(train/val) 0.20599/0.41320. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.21313/0.40084. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.20822/0.39646. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.20993/0.41140. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.19523/0.40312. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.20016/0.39801. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.20836/0.43120. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.20505/0.43307. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.20212/0.40457. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.20929/0.39594. Took 0.12 sec\n",
      "Epoch 92, Loss(train/val) 0.19728/0.43159. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.19558/0.41723. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.19030/0.41512. Took 0.12 sec\n",
      "Epoch 95, Loss(train/val) 0.19363/0.42455. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.19714/0.42388. Took 0.12 sec\n",
      "Epoch 97, Loss(train/val) 0.18467/0.42875. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.18622/0.42956. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.18417/0.44238. Took 0.14 sec\n",
      "ACC: 0.625, MCC: 0.24458021863776128\n",
      "Epoch 0, Loss(train/val) 0.49352/0.48917. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.47307/0.47064. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.43860/0.44104. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.39802/0.42035. Took 0.12 sec\n",
      "Epoch 4, Loss(train/val) 0.37738/0.42389. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.36585/0.40988. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.35863/0.42159. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.34840/0.41557. Took 0.12 sec\n",
      "Epoch 8, Loss(train/val) 0.34504/0.40492. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.34415/0.41080. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.33483/0.41132. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.32671/0.41282. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.31942/0.41343. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.31458/0.42110. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.30488/0.41845. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.30068/0.41775. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.29540/0.44185. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.28994/0.40893. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.28235/0.43045. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.27922/0.44217. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.27287/0.44684. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.27025/0.46110. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.26353/0.43505. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.26588/0.42591. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.26363/0.42066. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.25731/0.44775. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.25347/0.45170. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.24840/0.44474. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.24881/0.45486. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.24560/0.43474. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.23787/0.46165. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.23412/0.45741. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.24079/0.47367. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.23949/0.43700. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.22679/0.46071. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.22467/0.45215. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.22035/0.46576. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.22602/0.46919. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.21179/0.46213. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.21524/0.43749. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.20970/0.49098. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.20992/0.45329. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.21203/0.45551. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.20575/0.44972. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.20100/0.46545. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.19675/0.45630. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.20667/0.46117. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.20072/0.44030. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.20142/0.44152. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.19122/0.45801. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.19375/0.46521. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.19224/0.46267. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.18574/0.43628. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.18894/0.43964. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.18271/0.45283. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.18346/0.44453. Took 0.12 sec\n",
      "Epoch 56, Loss(train/val) 0.18270/0.45783. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.17924/0.45128. Took 0.12 sec\n",
      "Epoch 58, Loss(train/val) 0.18937/0.45131. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.17063/0.45069. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.17525/0.45175. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.17227/0.46123. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.17497/0.47616. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.16565/0.48336. Took 0.12 sec\n",
      "Epoch 64, Loss(train/val) 0.16456/0.45501. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.16428/0.44236. Took 0.12 sec\n",
      "Epoch 66, Loss(train/val) 0.18300/0.44979. Took 0.12 sec\n",
      "Epoch 67, Loss(train/val) 0.16302/0.45974. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.16037/0.49594. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.16501/0.50235. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.16549/0.52581. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.15928/0.48548. Took 0.12 sec\n",
      "Epoch 72, Loss(train/val) 0.15543/0.46533. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.15050/0.47501. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.14889/0.45815. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.14622/0.45036. Took 0.12 sec\n",
      "Epoch 76, Loss(train/val) 0.15422/0.45537. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.14807/0.49662. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.14946/0.48209. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.15307/0.46431. Took 0.12 sec\n",
      "Epoch 80, Loss(train/val) 0.14197/0.46169. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.15047/0.52616. Took 0.12 sec\n",
      "Epoch 82, Loss(train/val) 0.14808/0.46762. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.14984/0.44004. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.13986/0.52554. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.14526/0.53124. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.14321/0.49356. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.13676/0.51983. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.14144/0.51384. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.13506/0.50569. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.14354/0.51744. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.13534/0.50024. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.13877/0.50052. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.13688/0.51510. Took 0.12 sec\n",
      "Epoch 94, Loss(train/val) 0.13169/0.54210. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.12687/0.51061. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.13084/0.52347. Took 0.12 sec\n",
      "Epoch 97, Loss(train/val) 0.13423/0.56559. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.13112/0.54779. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.12935/0.51298. Took 0.13 sec\n",
      "ACC: 0.609375, MCC: 0.25050552967964446\n",
      "Epoch 0, Loss(train/val) 0.49177/0.49371. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.46806/0.48175. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.43007/0.46657. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.39557/0.45665. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.37551/0.43520. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.36374/0.41533. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.34993/0.40503. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.34597/0.40607. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.34552/0.41774. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.33995/0.39556. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.33826/0.40325. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.32787/0.40283. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.32399/0.40522. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.32060/0.41477. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.31824/0.41068. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.31960/0.41673. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.31134/0.40556. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.30418/0.41048. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.30182/0.39710. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.29238/0.41720. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.29404/0.41839. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.29276/0.42561. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.28407/0.40570. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.28234/0.41795. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.28044/0.40807. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.27445/0.40384. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.27163/0.40478. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.27224/0.36925. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.26236/0.38677. Took 0.13 sec\n",
      "Epoch 29, Loss(train/val) 0.26566/0.41166. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.26629/0.40172. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.25638/0.39436. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.24470/0.39468. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.23963/0.38643. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.24483/0.39795. Took 0.16 sec\n",
      "Epoch 35, Loss(train/val) 0.23803/0.40360. Took 0.13 sec\n",
      "Epoch 36, Loss(train/val) 0.23770/0.39503. Took 0.13 sec\n",
      "Epoch 37, Loss(train/val) 0.23592/0.40034. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.23676/0.39394. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.23402/0.38154. Took 0.12 sec\n",
      "Epoch 40, Loss(train/val) 0.22595/0.38620. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.22310/0.39041. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.21954/0.38432. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.22365/0.39062. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.21704/0.38302. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.21447/0.37968. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.21448/0.38485. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.21205/0.38927. Took 0.12 sec\n",
      "Epoch 48, Loss(train/val) 0.20918/0.37827. Took 0.12 sec\n",
      "Epoch 49, Loss(train/val) 0.21253/0.39560. Took 0.12 sec\n",
      "Epoch 50, Loss(train/val) 0.20297/0.39989. Took 0.12 sec\n",
      "Epoch 51, Loss(train/val) 0.20211/0.39239. Took 0.12 sec\n",
      "Epoch 52, Loss(train/val) 0.20778/0.39368. Took 0.12 sec\n",
      "Epoch 53, Loss(train/val) 0.19589/0.37452. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.19606/0.35871. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.19676/0.38616. Took 0.12 sec\n",
      "Epoch 56, Loss(train/val) 0.19411/0.37483. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.19217/0.37869. Took 0.12 sec\n",
      "Epoch 58, Loss(train/val) 0.19116/0.40030. Took 0.14 sec\n",
      "Epoch 59, Loss(train/val) 0.18293/0.42874. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.18599/0.38590. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.19206/0.39561. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.18386/0.38645. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.17930/0.42951. Took 0.12 sec\n",
      "Epoch 64, Loss(train/val) 0.17444/0.39527. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.17645/0.40855. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.18069/0.39367. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.17709/0.41263. Took 0.12 sec\n",
      "Epoch 68, Loss(train/val) 0.17292/0.40490. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.17309/0.41574. Took 0.12 sec\n",
      "Epoch 70, Loss(train/val) 0.17075/0.39726. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.16417/0.39532. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.16530/0.38229. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.16715/0.40429. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.16745/0.40713. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.16000/0.40378. Took 0.12 sec\n",
      "Epoch 76, Loss(train/val) 0.17138/0.40707. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.16114/0.41167. Took 0.12 sec\n",
      "Epoch 78, Loss(train/val) 0.16718/0.42153. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.16099/0.42097. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.15600/0.41797. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.15791/0.41769. Took 0.12 sec\n",
      "Epoch 82, Loss(train/val) 0.15670/0.42899. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.15700/0.41902. Took 0.12 sec\n",
      "Epoch 84, Loss(train/val) 0.15891/0.39063. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.15362/0.40483. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.14784/0.41156. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.15111/0.39965. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.15028/0.42419. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.15273/0.42542. Took 0.12 sec\n",
      "Epoch 90, Loss(train/val) 0.14886/0.42845. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.14765/0.39362. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.14419/0.39970. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.14762/0.41602. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.13840/0.41673. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.14108/0.40454. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.14580/0.40993. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.13843/0.41608. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.14558/0.40863. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.13626/0.42088. Took 0.12 sec\n",
      "ACC: 0.71875, MCC: 0.4290823322857326\n",
      "Epoch 0, Loss(train/val) 0.49466/0.47780. Took 0.13 sec\n",
      "Epoch 1, Loss(train/val) 0.47345/0.43791. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.43866/0.37883. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.40371/0.34618. Took 0.12 sec\n",
      "Epoch 4, Loss(train/val) 0.37995/0.34188. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.36841/0.33296. Took 0.15 sec\n",
      "Epoch 6, Loss(train/val) 0.36071/0.33346. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.35154/0.35233. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.35018/0.32827. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.34379/0.36310. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.33092/0.37216. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.32416/0.35972. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.31544/0.37245. Took 0.16 sec\n",
      "Epoch 13, Loss(train/val) 0.30537/0.33505. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.29988/0.38251. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.28605/0.41174. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.29207/0.39680. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.29494/0.34796. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.28721/0.39315. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.29074/0.37906. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.28465/0.37471. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.27260/0.37062. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.27837/0.39659. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.27369/0.38463. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.27718/0.36602. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.26426/0.38025. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.25997/0.39000. Took 0.13 sec\n",
      "Epoch 27, Loss(train/val) 0.26018/0.37613. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.25359/0.37706. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.24817/0.38056. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.24420/0.37868. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.24402/0.37058. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.23480/0.37333. Took 0.13 sec\n",
      "Epoch 33, Loss(train/val) 0.23824/0.36999. Took 0.13 sec\n",
      "Epoch 34, Loss(train/val) 0.23152/0.37283. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.23259/0.38550. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.22284/0.34585. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.22776/0.36944. Took 0.15 sec\n",
      "Epoch 38, Loss(train/val) 0.22325/0.38747. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.22240/0.37625. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.21671/0.37176. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.21531/0.37231. Took 0.12 sec\n",
      "Epoch 42, Loss(train/val) 0.21264/0.36538. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.21242/0.36743. Took 0.12 sec\n",
      "Epoch 44, Loss(train/val) 0.20337/0.37319. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.21120/0.38098. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.20706/0.38527. Took 0.12 sec\n",
      "Epoch 47, Loss(train/val) 0.20723/0.35416. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.20299/0.36149. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.20044/0.36411. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.19006/0.37725. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.19720/0.37181. Took 0.12 sec\n",
      "Epoch 52, Loss(train/val) 0.18828/0.35667. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) 0.19170/0.35335. Took 0.12 sec\n",
      "Epoch 54, Loss(train/val) 0.18803/0.33570. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.18796/0.34082. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.18686/0.34177. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.17996/0.34077. Took 0.12 sec\n",
      "Epoch 58, Loss(train/val) 0.19531/0.34095. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.18239/0.34491. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.18102/0.37864. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.18300/0.35128. Took 0.12 sec\n",
      "Epoch 62, Loss(train/val) 0.18179/0.34433. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.17681/0.34304. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.17225/0.33600. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.16971/0.34586. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.17761/0.34937. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.16497/0.33866. Took 0.12 sec\n",
      "Epoch 68, Loss(train/val) 0.17738/0.34974. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.17003/0.36051. Took 0.12 sec\n",
      "Epoch 70, Loss(train/val) 0.16521/0.35300. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.16705/0.34227. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.16948/0.33845. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.16358/0.33804. Took 0.12 sec\n",
      "Epoch 74, Loss(train/val) 0.15582/0.34335. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.15619/0.34797. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.16070/0.33658. Took 0.12 sec\n",
      "Epoch 77, Loss(train/val) 0.16319/0.33900. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.15572/0.33763. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.15239/0.34030. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.15088/0.33997. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.15130/0.35194. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.16203/0.35339. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.15293/0.37193. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.15202/0.37492. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.14296/0.37033. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.14815/0.36219. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.14560/0.37418. Took 0.12 sec\n",
      "Epoch 88, Loss(train/val) 0.15523/0.36686. Took 0.12 sec\n",
      "Epoch 89, Loss(train/val) 0.14449/0.34455. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.14558/0.37294. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.14648/0.36564. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.14521/0.35052. Took 0.15 sec\n",
      "Epoch 93, Loss(train/val) 0.14167/0.36792. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.14111/0.37697. Took 0.12 sec\n",
      "Epoch 95, Loss(train/val) 0.13587/0.36359. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.13827/0.37187. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.14240/0.36631. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.14296/0.36184. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.13661/0.36408. Took 0.12 sec\n",
      "ACC: 0.640625, MCC: 0.2847473987257497\n",
      "Epoch 0, Loss(train/val) 0.49086/0.48124. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.46719/0.44682. Took 0.12 sec\n",
      "Epoch 2, Loss(train/val) 0.42954/0.41724. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.39653/0.39971. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.38178/0.39599. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.37001/0.39131. Took 0.12 sec\n",
      "Epoch 6, Loss(train/val) 0.35910/0.38114. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.35375/0.39594. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.35258/0.38805. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.33904/0.38876. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.33322/0.38015. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.32596/0.37369. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.31889/0.37354. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.31370/0.36667. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.30770/0.35704. Took 0.15 sec\n",
      "Epoch 15, Loss(train/val) 0.30629/0.35268. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.29453/0.34539. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.29426/0.35586. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.29088/0.38395. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.28916/0.38159. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.28311/0.36858. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.28474/0.37052. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.28231/0.34822. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.28041/0.42522. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.26898/0.40300. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.27216/0.40886. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.26453/0.42925. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.26537/0.40727. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.27331/0.40919. Took 0.16 sec\n",
      "Epoch 29, Loss(train/val) 0.25747/0.40513. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.25463/0.43963. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.26034/0.37932. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.25052/0.42108. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.24670/0.47292. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.24134/0.40869. Took 0.17 sec\n",
      "Epoch 35, Loss(train/val) 0.24000/0.41311. Took 0.15 sec\n",
      "Epoch 36, Loss(train/val) 0.23892/0.43891. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.24355/0.43970. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.23612/0.39691. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.22782/0.40665. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.23240/0.40830. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.22714/0.41659. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.22445/0.44375. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.22661/0.45402. Took 0.12 sec\n",
      "Epoch 44, Loss(train/val) 0.22144/0.39473. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.21377/0.42214. Took 0.12 sec\n",
      "Epoch 46, Loss(train/val) 0.23029/0.34133. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.21909/0.41077. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.22427/0.36412. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.20704/0.36000. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.21035/0.42297. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.21609/0.38065. Took 0.12 sec\n",
      "Epoch 52, Loss(train/val) 0.20704/0.38118. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.19918/0.37871. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.20862/0.34221. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.20673/0.38805. Took 0.12 sec\n",
      "Epoch 56, Loss(train/val) 0.20353/0.39240. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.21552/0.36843. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.19749/0.41018. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.19711/0.35904. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.20460/0.42591. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.19658/0.47788. Took 0.12 sec\n",
      "Epoch 62, Loss(train/val) 0.18821/0.43875. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.18908/0.42749. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.18562/0.43096. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.18162/0.35382. Took 0.12 sec\n",
      "Epoch 66, Loss(train/val) 0.18645/0.38880. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.19153/0.42533. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.19553/0.35951. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.18471/0.42958. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.17766/0.42722. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.19394/0.38744. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.17245/0.38529. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.18187/0.43420. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.17814/0.41127. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.17278/0.38870. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.16900/0.37523. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.17256/0.44552. Took 0.12 sec\n",
      "Epoch 78, Loss(train/val) 0.17382/0.35717. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.16014/0.36283. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.16568/0.38885. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.17253/0.46215. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.16559/0.46295. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.17472/0.41701. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.16516/0.42156. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.17047/0.35100. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.16314/0.38791. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.16994/0.43777. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.16950/0.45439. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.16851/0.42102. Took 0.12 sec\n",
      "Epoch 90, Loss(train/val) 0.16126/0.42547. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.15530/0.46915. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.15677/0.43329. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.15969/0.35930. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.16416/0.37811. Took 0.14 sec\n",
      "Epoch 95, Loss(train/val) 0.16287/0.38274. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.15260/0.40674. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.16000/0.41606. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.15933/0.38336. Took 0.14 sec\n",
      "Epoch 99, Loss(train/val) 0.16033/0.43505. Took 0.14 sec\n",
      "ACC: 0.71875, MCC: 0.4425941852276055\n",
      "Epoch 0, Loss(train/val) 0.48838/0.47824. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.47048/0.44619. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.44279/0.40168. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.41077/0.37143. Took 0.12 sec\n",
      "Epoch 4, Loss(train/val) 0.38538/0.35965. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.36558/0.35354. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.34568/0.34247. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.33544/0.34637. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.32867/0.32897. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.32722/0.32949. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.31248/0.31176. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.30549/0.31024. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.30151/0.30534. Took 0.19 sec\n",
      "Epoch 13, Loss(train/val) 0.29343/0.29852. Took 0.16 sec\n",
      "Epoch 14, Loss(train/val) 0.29248/0.28824. Took 0.15 sec\n",
      "Epoch 15, Loss(train/val) 0.28899/0.30043. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.29899/0.29894. Took 0.16 sec\n",
      "Epoch 17, Loss(train/val) 0.28515/0.30715. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.27655/0.33133. Took 0.15 sec\n",
      "Epoch 19, Loss(train/val) 0.27396/0.28632. Took 0.15 sec\n",
      "Epoch 20, Loss(train/val) 0.27043/0.28543. Took 0.16 sec\n",
      "Epoch 21, Loss(train/val) 0.26151/0.28410. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.26789/0.31017. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.26011/0.27977. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.26465/0.30069. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.26447/0.28727. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.25137/0.29563. Took 0.16 sec\n",
      "Epoch 27, Loss(train/val) 0.24699/0.28755. Took 0.16 sec\n",
      "Epoch 28, Loss(train/val) 0.25445/0.28243. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.24798/0.30875. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.24928/0.30417. Took 0.18 sec\n",
      "Epoch 31, Loss(train/val) 0.24925/0.29438. Took 0.16 sec\n",
      "Epoch 32, Loss(train/val) 0.23729/0.28953. Took 0.16 sec\n",
      "Epoch 33, Loss(train/val) 0.23643/0.28407. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.23203/0.30322. Took 0.16 sec\n",
      "Epoch 35, Loss(train/val) 0.23639/0.27115. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.23513/0.28300. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.22517/0.29100. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.22488/0.28727. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.22200/0.30032. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.22454/0.29495. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.21993/0.29280. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.21155/0.29632. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.21940/0.29166. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.22021/0.30138. Took 0.16 sec\n",
      "Epoch 45, Loss(train/val) 0.21831/0.29263. Took 0.16 sec\n",
      "Epoch 46, Loss(train/val) 0.21216/0.31018. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.21224/0.30406. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.20400/0.30880. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.20673/0.29390. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.20519/0.29958. Took 0.15 sec\n",
      "Epoch 51, Loss(train/val) 0.20654/0.28201. Took 0.16 sec\n",
      "Epoch 52, Loss(train/val) 0.19856/0.29190. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.19221/0.28731. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.20119/0.29650. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.20746/0.29369. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.19477/0.30922. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.19007/0.29933. Took 0.16 sec\n",
      "Epoch 58, Loss(train/val) 0.19437/0.29806. Took 0.15 sec\n",
      "Epoch 59, Loss(train/val) 0.18618/0.30204. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.18971/0.29434. Took 0.14 sec\n",
      "Epoch 61, Loss(train/val) 0.18446/0.30445. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.18484/0.29977. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.18354/0.30093. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.18313/0.29229. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.17671/0.29083. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.17155/0.29653. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.17294/0.30328. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.17593/0.29806. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.18568/0.30723. Took 0.15 sec\n",
      "Epoch 70, Loss(train/val) 0.17784/0.29447. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.17287/0.29022. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.17249/0.28625. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.17687/0.29143. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.16809/0.28228. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) 0.16774/0.30330. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.16898/0.29809. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.16085/0.29892. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.16246/0.32004. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.16245/0.31218. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.16334/0.29077. Took 0.14 sec\n",
      "Epoch 81, Loss(train/val) 0.16777/0.31672. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.15877/0.31251. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.15928/0.32392. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.15738/0.32144. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.15558/0.31258. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.15450/0.32254. Took 0.15 sec\n",
      "Epoch 87, Loss(train/val) 0.14948/0.32376. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.15277/0.30280. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.14284/0.31741. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.14196/0.31056. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.14734/0.31959. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.14964/0.30421. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.14631/0.30425. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.14127/0.28915. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.14178/0.29509. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.14046/0.31374. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.14108/0.29957. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.14309/0.28990. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.14698/0.30190. Took 0.13 sec\n",
      "ACC: 0.703125, MCC: 0.41130179815941625\n",
      "Epoch 0, Loss(train/val) 0.49525/0.48879. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.47726/0.46324. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.44693/0.43344. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.40948/0.41521. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.38635/0.40639. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.36921/0.40335. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.35491/0.37651. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.34560/0.34550. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.33082/0.31575. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.32463/0.31688. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.31596/0.34693. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.31174/0.28968. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.29720/0.28778. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.29214/0.33122. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.30239/0.27381. Took 0.15 sec\n",
      "Epoch 15, Loss(train/val) 0.30219/0.32819. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.28844/0.32316. Took 0.15 sec\n",
      "Epoch 17, Loss(train/val) 0.28214/0.26328. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.28520/0.25617. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.28131/0.27401. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.27672/0.31105. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.27191/0.27924. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.28064/0.26059. Took 0.16 sec\n",
      "Epoch 23, Loss(train/val) 0.26530/0.36212. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.26077/0.25507. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.26385/0.28562. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.25788/0.28311. Took 0.13 sec\n",
      "Epoch 27, Loss(train/val) 0.25330/0.29368. Took 0.13 sec\n",
      "Epoch 28, Loss(train/val) 0.23922/0.29583. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.24910/0.31538. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.23921/0.24708. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.25215/0.28420. Took 0.13 sec\n",
      "Epoch 32, Loss(train/val) 0.23932/0.31093. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.23774/0.29212. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.24349/0.34812. Took 0.13 sec\n",
      "Epoch 35, Loss(train/val) 0.23044/0.34876. Took 0.15 sec\n",
      "Epoch 36, Loss(train/val) 0.22747/0.42274. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.22760/0.41318. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.21849/0.42724. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.21792/0.40123. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.21866/0.43009. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.21613/0.35604. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.21253/0.38062. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.21841/0.37117. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.22216/0.43355. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.20912/0.38842. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.20782/0.41820. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.21394/0.42117. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.20201/0.44974. Took 0.12 sec\n",
      "Epoch 49, Loss(train/val) 0.21097/0.40288. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.20159/0.44581. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.19117/0.37090. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.19869/0.33205. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.19234/0.33185. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.19697/0.36535. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.19187/0.36452. Took 0.15 sec\n",
      "Epoch 56, Loss(train/val) 0.18351/0.39780. Took 0.15 sec\n",
      "Epoch 57, Loss(train/val) 0.18849/0.44725. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.17986/0.41713. Took 0.14 sec\n",
      "Epoch 59, Loss(train/val) 0.18423/0.32534. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.18974/0.45325. Took 0.16 sec\n",
      "Epoch 61, Loss(train/val) 0.17926/0.36359. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.18294/0.38795. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.18446/0.35295. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.18509/0.37095. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.18595/0.41609. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.19169/0.40181. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) 0.17156/0.44059. Took 0.15 sec\n",
      "Epoch 68, Loss(train/val) 0.17722/0.37587. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.17316/0.34272. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.16480/0.40393. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.17437/0.33400. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.16532/0.38556. Took 0.15 sec\n",
      "Epoch 73, Loss(train/val) 0.16983/0.39620. Took 0.15 sec\n",
      "Epoch 74, Loss(train/val) 0.16159/0.40602. Took 0.17 sec\n",
      "Epoch 75, Loss(train/val) 0.16865/0.41140. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.17206/0.38699. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.15658/0.38860. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.15992/0.43781. Took 0.14 sec\n",
      "Epoch 79, Loss(train/val) 0.16751/0.46167. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.15897/0.44215. Took 0.14 sec\n",
      "Epoch 81, Loss(train/val) 0.16068/0.39455. Took 0.18 sec\n",
      "Epoch 82, Loss(train/val) 0.16831/0.36558. Took 0.16 sec\n",
      "Epoch 83, Loss(train/val) 0.15377/0.38939. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.15917/0.38401. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.15147/0.38729. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.15241/0.36388. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.15779/0.45711. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.16693/0.41876. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.15672/0.40380. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.14851/0.44288. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.15260/0.40604. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.15708/0.43275. Took 0.15 sec\n",
      "Epoch 93, Loss(train/val) 0.15254/0.40248. Took 0.15 sec\n",
      "Epoch 94, Loss(train/val) 0.15124/0.40816. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.14391/0.43586. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.14842/0.42604. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.13973/0.43257. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.14548/0.42192. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.13818/0.42623. Took 0.13 sec\n",
      "ACC: 0.375, MCC: 0.012036178313589637\n",
      "Epoch 0, Loss(train/val) 0.49155/0.49832. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.47113/0.47159. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.44141/0.39511. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.40783/0.34005. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.38851/0.32157. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.37539/0.32343. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.36123/0.32849. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.35153/0.32525. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.33224/0.31801. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.33515/0.31782. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.32487/0.42107. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.31526/0.35623. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.30774/0.48418. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.30326/0.46539. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.28980/0.43156. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.28954/0.46012. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.27998/0.51967. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.28112/0.45498. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.27552/0.31179. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.28158/0.51060. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.27180/0.45934. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.25991/0.50659. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.26432/0.49025. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.26299/0.47307. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.25237/0.51156. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.24836/0.50224. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.25723/0.49485. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.25590/0.52634. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.24578/0.49940. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.24793/0.47671. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.24670/0.46099. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.25259/0.51147. Took 0.13 sec\n",
      "Epoch 32, Loss(train/val) 0.24701/0.47580. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.24741/0.46899. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.23469/0.47921. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.24101/0.50070. Took 0.15 sec\n",
      "Epoch 36, Loss(train/val) 0.24300/0.47866. Took 0.13 sec\n",
      "Epoch 37, Loss(train/val) 0.22396/0.47492. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.23404/0.46273. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.22204/0.52267. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.23776/0.46443. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.22133/0.47788. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.21717/0.47522. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.21682/0.48105. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.21092/0.48921. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) 0.21223/0.49084. Took 0.12 sec\n",
      "Epoch 46, Loss(train/val) 0.20787/0.49881. Took 0.12 sec\n",
      "Epoch 47, Loss(train/val) 0.20459/0.49377. Took 0.12 sec\n",
      "Epoch 48, Loss(train/val) 0.20939/0.46578. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.21666/0.52319. Took 0.12 sec\n",
      "Epoch 50, Loss(train/val) 0.20376/0.47634. Took 0.12 sec\n",
      "Epoch 51, Loss(train/val) 0.20762/0.48902. Took 0.15 sec\n",
      "Epoch 52, Loss(train/val) 0.20014/0.48316. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) 0.19890/0.50271. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.19434/0.45894. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.19072/0.52989. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.19161/0.43703. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.19678/0.50115. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.19115/0.51971. Took 0.14 sec\n",
      "Epoch 59, Loss(train/val) 0.18323/0.42694. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.18536/0.51636. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.18861/0.48833. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.18733/0.38940. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.18543/0.51963. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.17592/0.52000. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.17575/0.47656. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.17903/0.51408. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.17045/0.46236. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.16788/0.50871. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.16882/0.42947. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.17159/0.55494. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.16440/0.55471. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.15689/0.54316. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.15393/0.54624. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.16694/0.44431. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.17024/0.57452. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.15924/0.54582. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.15129/0.54515. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.15096/0.56277. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.15820/0.49514. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.15858/0.50309. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.15574/0.47449. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.15419/0.45659. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.14581/0.51969. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.15150/0.39541. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.15839/0.49951. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.15010/0.50376. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.14063/0.48620. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.14960/0.36521. Took 0.14 sec\n",
      "Epoch 89, Loss(train/val) 0.14362/0.48747. Took 0.15 sec\n",
      "Epoch 90, Loss(train/val) 0.13554/0.44279. Took 0.14 sec\n",
      "Epoch 91, Loss(train/val) 0.13677/0.46925. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.14281/0.38466. Took 0.15 sec\n",
      "Epoch 93, Loss(train/val) 0.14869/0.51691. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.13380/0.52652. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.13164/0.48673. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.13375/0.46166. Took 0.14 sec\n",
      "Epoch 97, Loss(train/val) 0.13105/0.50227. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.13082/0.52450. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.12739/0.42814. Took 0.13 sec\n",
      "ACC: 0.6875, MCC: 0.3578300267477955\n",
      "Epoch 0, Loss(train/val) 0.49363/0.49546. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.47542/0.48692. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.43997/0.45599. Took 0.15 sec\n",
      "Epoch 3, Loss(train/val) 0.39674/0.40155. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.37843/0.38038. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.36081/0.36595. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.34418/0.39339. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.34413/0.37366. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.32190/0.37003. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.31056/0.37540. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.29613/0.34968. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.29823/0.38362. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.28879/0.36591. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.28596/0.37686. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.29711/0.43205. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.29288/0.33209. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.28077/0.33792. Took 0.16 sec\n",
      "Epoch 17, Loss(train/val) 0.27190/0.36910. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.27496/0.38221. Took 0.15 sec\n",
      "Epoch 19, Loss(train/val) 0.27546/0.38943. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.26090/0.37200. Took 0.15 sec\n",
      "Epoch 21, Loss(train/val) 0.25709/0.38356. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.25669/0.36080. Took 0.15 sec\n",
      "Epoch 23, Loss(train/val) 0.25644/0.38070. Took 0.17 sec\n",
      "Epoch 24, Loss(train/val) 0.24983/0.38318. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.24786/0.37586. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.25233/0.38787. Took 0.17 sec\n",
      "Epoch 27, Loss(train/val) 0.24241/0.40022. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.23998/0.37501. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.23582/0.40760. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.23856/0.37883. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.22722/0.39725. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.23737/0.38544. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.21733/0.41807. Took 0.13 sec\n",
      "Epoch 34, Loss(train/val) 0.22680/0.37239. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.22029/0.40833. Took 0.16 sec\n",
      "Epoch 36, Loss(train/val) 0.22016/0.40868. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.22786/0.40854. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.20756/0.39208. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.22315/0.37514. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.20493/0.38176. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.22164/0.38065. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.21101/0.41201. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.20375/0.42727. Took 0.12 sec\n",
      "Epoch 44, Loss(train/val) 0.21470/0.43693. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.20944/0.45155. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.20022/0.45124. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.20506/0.45529. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.19698/0.41099. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.20376/0.42019. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.19538/0.44506. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.20356/0.39334. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.19987/0.40547. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.19546/0.41056. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.18562/0.42554. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.19178/0.38621. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.18660/0.40086. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.19004/0.38507. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.18512/0.40009. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.18694/0.40085. Took 0.15 sec\n",
      "Epoch 60, Loss(train/val) 0.19345/0.39883. Took 0.16 sec\n",
      "Epoch 61, Loss(train/val) 0.18483/0.44901. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.18910/0.41641. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.18272/0.40948. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.18674/0.42607. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.17778/0.41621. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.17761/0.41256. Took 0.12 sec\n",
      "Epoch 67, Loss(train/val) 0.17357/0.42511. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.17945/0.40658. Took 0.14 sec\n",
      "Epoch 69, Loss(train/val) 0.17787/0.37267. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.17018/0.40993. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.17432/0.41687. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.17361/0.39632. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.16542/0.38198. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.17074/0.41356. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.16980/0.42703. Took 0.12 sec\n",
      "Epoch 76, Loss(train/val) 0.17607/0.42416. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.16506/0.39837. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.16702/0.42984. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.15789/0.42533. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.17664/0.38895. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.17291/0.43100. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.16251/0.40095. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) 0.16809/0.40129. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.16274/0.38750. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.15532/0.43837. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.15571/0.38974. Took 0.12 sec\n",
      "Epoch 87, Loss(train/val) 0.16786/0.41440. Took 0.12 sec\n",
      "Epoch 88, Loss(train/val) 0.16431/0.44468. Took 0.12 sec\n",
      "Epoch 89, Loss(train/val) 0.15661/0.37513. Took 0.15 sec\n",
      "Epoch 90, Loss(train/val) 0.15807/0.43048. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.16635/0.37562. Took 0.12 sec\n",
      "Epoch 92, Loss(train/val) 0.17161/0.41651. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.15600/0.39795. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.15738/0.37966. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.15105/0.42014. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.15358/0.43918. Took 0.14 sec\n",
      "Epoch 97, Loss(train/val) 0.15528/0.37560. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.15085/0.41890. Took 0.12 sec\n",
      "Epoch 99, Loss(train/val) 0.14412/0.42535. Took 0.12 sec\n",
      "ACC: 0.6875, MCC: 0.3847946634416459\n",
      "Epoch 0, Loss(train/val) 0.49308/0.48162. Took 0.13 sec\n",
      "Epoch 1, Loss(train/val) 0.47584/0.45332. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.44962/0.40999. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.41621/0.37504. Took 0.12 sec\n",
      "Epoch 4, Loss(train/val) 0.39597/0.35439. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.37740/0.34405. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.36477/0.33109. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.34995/0.32347. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.33824/0.31426. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.33625/0.31286. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.32612/0.39743. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.31897/0.30124. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.30868/0.34068. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.30149/0.35204. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.30063/0.32161. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.30044/0.42822. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.28856/0.39960. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.29038/0.37728. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.29643/0.35794. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.29277/0.25299. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.29389/0.26421. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.28935/0.29738. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.29101/0.25379. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.28875/0.32543. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.28418/0.33844. Took 0.15 sec\n",
      "Epoch 25, Loss(train/val) 0.27415/0.27483. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.27136/0.33116. Took 0.13 sec\n",
      "Epoch 27, Loss(train/val) 0.25966/0.38944. Took 0.13 sec\n",
      "Epoch 28, Loss(train/val) 0.26943/0.35717. Took 0.17 sec\n",
      "Epoch 29, Loss(train/val) 0.26604/0.33351. Took 0.20 sec\n",
      "Epoch 30, Loss(train/val) 0.27524/0.29657. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.26514/0.41415. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.26475/0.39405. Took 0.19 sec\n",
      "Epoch 33, Loss(train/val) 0.25772/0.41438. Took 0.17 sec\n",
      "Epoch 34, Loss(train/val) 0.24942/0.39690. Took 0.18 sec\n",
      "Epoch 35, Loss(train/val) 0.24215/0.34613. Took 0.19 sec\n",
      "Epoch 36, Loss(train/val) 0.25413/0.39966. Took 0.20 sec\n",
      "Epoch 37, Loss(train/val) 0.24450/0.37035. Took 0.19 sec\n",
      "Epoch 38, Loss(train/val) 0.24042/0.39023. Took 0.18 sec\n",
      "Epoch 39, Loss(train/val) 0.24817/0.41714. Took 0.19 sec\n",
      "Epoch 40, Loss(train/val) 0.23814/0.40127. Took 0.21 sec\n",
      "Epoch 41, Loss(train/val) 0.25329/0.40460. Took 0.19 sec\n",
      "Epoch 42, Loss(train/val) 0.24879/0.38737. Took 0.15 sec\n",
      "Epoch 43, Loss(train/val) 0.24276/0.39185. Took 0.15 sec\n",
      "Epoch 44, Loss(train/val) 0.23699/0.38653. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) 0.22792/0.37798. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.23100/0.40988. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.23132/0.41454. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.22259/0.39311. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.22588/0.36766. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.23697/0.45006. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.23539/0.42869. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.21749/0.40566. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.21108/0.45255. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.21826/0.39298. Took 0.15 sec\n",
      "Epoch 55, Loss(train/val) 0.23240/0.39971. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.22309/0.37069. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.22385/0.38598. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.21268/0.33356. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.21467/0.42518. Took 0.16 sec\n",
      "Epoch 60, Loss(train/val) 0.20140/0.36716. Took 0.16 sec\n",
      "Epoch 61, Loss(train/val) 0.21162/0.42486. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.20179/0.41273. Took 0.15 sec\n",
      "Epoch 63, Loss(train/val) 0.20495/0.42711. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.20132/0.42186. Took 0.16 sec\n",
      "Epoch 65, Loss(train/val) 0.20352/0.41055. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.19712/0.40713. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.19408/0.38515. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.20211/0.37097. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.20047/0.41640. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.19986/0.37474. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.19968/0.37960. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.18847/0.40550. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.19295/0.42202. Took 0.15 sec\n",
      "Epoch 74, Loss(train/val) 0.19473/0.42533. Took 0.15 sec\n",
      "Epoch 75, Loss(train/val) 0.19868/0.42947. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.20466/0.42077. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.18854/0.43376. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.19165/0.42794. Took 0.14 sec\n",
      "Epoch 79, Loss(train/val) 0.19074/0.44984. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.18632/0.42960. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.19357/0.42816. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.19147/0.38863. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.18745/0.40800. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.18087/0.40483. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.18804/0.41043. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.18331/0.41584. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.17723/0.40562. Took 0.15 sec\n",
      "Epoch 88, Loss(train/val) 0.19743/0.39813. Took 0.15 sec\n",
      "Epoch 89, Loss(train/val) 0.18049/0.39712. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.18491/0.38600. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.18219/0.44221. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.17285/0.39259. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.18564/0.40833. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.18474/0.39157. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.17477/0.40948. Took 0.15 sec\n",
      "Epoch 96, Loss(train/val) 0.17830/0.43149. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.17820/0.41093. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.17904/0.41508. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.18596/0.40189. Took 0.14 sec\n",
      "ACC: 0.765625, MCC: 0.53177225801525\n",
      "Epoch 0, Loss(train/val) 0.48908/0.50271. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.45373/0.49731. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.42646/0.46498. Took 0.15 sec\n",
      "Epoch 3, Loss(train/val) 0.40258/0.43489. Took 0.15 sec\n",
      "Epoch 4, Loss(train/val) 0.38662/0.42076. Took 0.17 sec\n",
      "Epoch 5, Loss(train/val) 0.37572/0.40762. Took 0.18 sec\n",
      "Epoch 6, Loss(train/val) 0.36425/0.40910. Took 0.15 sec\n",
      "Epoch 7, Loss(train/val) 0.35469/0.40011. Took 0.15 sec\n",
      "Epoch 8, Loss(train/val) 0.34591/0.39821. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.33808/0.39651. Took 0.16 sec\n",
      "Epoch 10, Loss(train/val) 0.32795/0.38906. Took 0.17 sec\n",
      "Epoch 11, Loss(train/val) 0.32352/0.37935. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.31547/0.38220. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.31289/0.39235. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.30533/0.38760. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.29556/0.38345. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.28888/0.37562. Took 0.16 sec\n",
      "Epoch 17, Loss(train/val) 0.28484/0.37462. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.27852/0.38082. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.27433/0.38490. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.27304/0.35648. Took 0.15 sec\n",
      "Epoch 21, Loss(train/val) 0.27311/0.38822. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.26625/0.36754. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.25938/0.37760. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.26016/0.37801. Took 0.15 sec\n",
      "Epoch 25, Loss(train/val) 0.24990/0.37720. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.25089/0.42556. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.25529/0.40411. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.25725/0.44583. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.24314/0.38487. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.24612/0.42560. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.24144/0.44023. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.24067/0.42875. Took 0.19 sec\n",
      "Epoch 33, Loss(train/val) 0.24438/0.40959. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.23649/0.40418. Took 0.17 sec\n",
      "Epoch 35, Loss(train/val) 0.23315/0.44059. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.23244/0.45130. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.24027/0.39636. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.23666/0.37446. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.23063/0.37141. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.22345/0.37884. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.22714/0.39535. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.22527/0.41313. Took 0.15 sec\n",
      "Epoch 43, Loss(train/val) 0.21859/0.43104. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.22726/0.42384. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.21269/0.41220. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.21175/0.42269. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.21082/0.42653. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.21012/0.41582. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.21098/0.45929. Took 0.12 sec\n",
      "Epoch 50, Loss(train/val) 0.20090/0.41695. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.21171/0.42718. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.20073/0.42104. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.19455/0.40175. Took 0.15 sec\n",
      "Epoch 54, Loss(train/val) 0.19698/0.45226. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.19764/0.46645. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.18747/0.43615. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.19230/0.45547. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.19281/0.47654. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.18984/0.45105. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.19291/0.44847. Took 0.14 sec\n",
      "Epoch 61, Loss(train/val) 0.18344/0.50902. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.19118/0.43324. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.18889/0.45035. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.18536/0.45740. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.18509/0.46298. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.18289/0.44872. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.18254/0.45794. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.17462/0.44619. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.18057/0.44842. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.17541/0.43434. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.17398/0.44316. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.16945/0.45352. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.17177/0.49653. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.17120/0.45890. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.17410/0.44825. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.16982/0.43754. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.16933/0.44095. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.16776/0.44501. Took 0.14 sec\n",
      "Epoch 79, Loss(train/val) 0.15774/0.44416. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.16628/0.43741. Took 0.14 sec\n",
      "Epoch 81, Loss(train/val) 0.16432/0.47231. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.16756/0.44567. Took 0.15 sec\n",
      "Epoch 83, Loss(train/val) 0.16179/0.43956. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.16079/0.46625. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.16375/0.46059. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.15959/0.47166. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.16657/0.46277. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.16017/0.44593. Took 0.15 sec\n",
      "Epoch 89, Loss(train/val) 0.15408/0.42588. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.16294/0.45570. Took 0.15 sec\n",
      "Epoch 91, Loss(train/val) 0.15594/0.47899. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.17984/0.46321. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.16154/0.42025. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.16086/0.47766. Took 0.15 sec\n",
      "Epoch 95, Loss(train/val) 0.15431/0.44721. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.15127/0.43859. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.14556/0.42699. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.13994/0.45800. Took 0.16 sec\n",
      "Epoch 99, Loss(train/val) 0.14804/0.44410. Took 0.14 sec\n",
      "ACC: 0.625, MCC: 0.24932120796616944\n",
      "Epoch 0, Loss(train/val) 0.49402/0.49223. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.46601/0.47973. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.43139/0.46619. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.40208/0.44492. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.38363/0.41609. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.37284/0.39303. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.36312/0.40670. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.35687/0.40412. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.35034/0.40500. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.34638/0.40892. Took 0.15 sec\n",
      "Epoch 10, Loss(train/val) 0.33651/0.40319. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.33814/0.40686. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.32865/0.42537. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.32218/0.43295. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.31632/0.41896. Took 0.15 sec\n",
      "Epoch 15, Loss(train/val) 0.31041/0.42418. Took 0.17 sec\n",
      "Epoch 16, Loss(train/val) 0.29965/0.41959. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.29650/0.37385. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.29172/0.37782. Took 0.15 sec\n",
      "Epoch 19, Loss(train/val) 0.28446/0.41405. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.27967/0.39109. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.28012/0.41600. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.27748/0.44980. Took 0.16 sec\n",
      "Epoch 23, Loss(train/val) 0.27925/0.43752. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.27061/0.45528. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.26998/0.46332. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.26131/0.42768. Took 0.15 sec\n",
      "Epoch 27, Loss(train/val) 0.25611/0.46772. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.26392/0.46644. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.25971/0.46612. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.26506/0.47313. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.25849/0.46674. Took 0.17 sec\n",
      "Epoch 32, Loss(train/val) 0.26012/0.46641. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.24351/0.46025. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.24774/0.47125. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.24278/0.46511. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.25117/0.47737. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.23702/0.38012. Took 0.15 sec\n",
      "Epoch 38, Loss(train/val) 0.24651/0.46525. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.24070/0.42106. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.23578/0.44318. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.23565/0.40892. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.23794/0.47034. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.23007/0.46527. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.24184/0.44645. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) 0.22652/0.46192. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.23566/0.47163. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.22600/0.48027. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.22783/0.47380. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.22235/0.48601. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.25259/0.46001. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.21951/0.47335. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.22192/0.48492. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.21194/0.47812. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.21379/0.48079. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.21087/0.46508. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.20846/0.39887. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.21118/0.47364. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.20866/0.48648. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.21110/0.40944. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.20737/0.46192. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.20944/0.46475. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.21091/0.48998. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.20416/0.45304. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.19848/0.49266. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.20090/0.47895. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.19628/0.47990. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.20409/0.49012. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.19820/0.48389. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.19041/0.44313. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.19825/0.47098. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.20184/0.47946. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.19101/0.47514. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.19725/0.40623. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.18234/0.44970. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.18211/0.49243. Took 0.12 sec\n",
      "Epoch 76, Loss(train/val) 0.18361/0.43700. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.18852/0.50593. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.17899/0.49238. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.17478/0.44662. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.18230/0.47008. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.17367/0.45748. Took 0.12 sec\n",
      "Epoch 82, Loss(train/val) 0.17918/0.47796. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.17603/0.43297. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.17211/0.39014. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.16721/0.40028. Took 0.12 sec\n",
      "Epoch 86, Loss(train/val) 0.16647/0.40428. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.16350/0.43261. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.16893/0.41164. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.15711/0.44927. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.16699/0.46787. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.16777/0.45872. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.16304/0.41453. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.16292/0.46643. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.15624/0.45084. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.15080/0.44483. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.15608/0.43662. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.15441/0.46527. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.15733/0.44851. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.15953/0.45999. Took 0.12 sec\n",
      "ACC: 0.609375, MCC: 0.28991037829690375\n",
      "Epoch 0, Loss(train/val) 0.49482/0.49332. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.47405/0.47448. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.44339/0.42698. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.40729/0.37792. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.38233/0.35743. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.36638/0.34551. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.35957/0.34835. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.35339/0.32707. Took 0.12 sec\n",
      "Epoch 8, Loss(train/val) 0.35137/0.33503. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.33914/0.34151. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.33808/0.31949. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.32989/0.33830. Took 0.15 sec\n",
      "Epoch 12, Loss(train/val) 0.32900/0.33530. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.32411/0.33058. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.32339/0.34319. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.31613/0.32765. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.32449/0.33498. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.31836/0.32016. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.31260/0.31944. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.30970/0.33378. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.30179/0.32529. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.29780/0.32253. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.29171/0.33290. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.29893/0.33379. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.28749/0.30976. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.28709/0.31766. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.28528/0.32536. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.28333/0.30877. Took 0.13 sec\n",
      "Epoch 28, Loss(train/val) 0.27748/0.31871. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.27454/0.30241. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.26801/0.33202. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.26949/0.34726. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.27014/0.32915. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.26709/0.31673. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.26037/0.35385. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.26375/0.35685. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.26124/0.34940. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.25749/0.36545. Took 0.15 sec\n",
      "Epoch 38, Loss(train/val) 0.25641/0.34342. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.25929/0.33975. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.25124/0.35213. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.25007/0.36975. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.25732/0.34563. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.24464/0.34834. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.24565/0.35280. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.23892/0.38382. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.24166/0.38790. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.23529/0.39076. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.23547/0.36644. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.22659/0.35805. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.22303/0.35299. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.22119/0.35336. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.22116/0.36445. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) 0.21872/0.36635. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.21481/0.35795. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.21601/0.35851. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.22031/0.36615. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.22158/0.36796. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.21417/0.36133. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.21326/0.36829. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.20935/0.38699. Took 0.16 sec\n",
      "Epoch 61, Loss(train/val) 0.20712/0.38879. Took 0.15 sec\n",
      "Epoch 62, Loss(train/val) 0.20866/0.38384. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.21379/0.38802. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.21432/0.36677. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.21241/0.38422. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.20378/0.38246. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.20795/0.38263. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.20022/0.38241. Took 0.14 sec\n",
      "Epoch 69, Loss(train/val) 0.19067/0.38922. Took 0.16 sec\n",
      "Epoch 70, Loss(train/val) 0.19015/0.38154. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.19684/0.38259. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.19884/0.36422. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.19324/0.35427. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.19325/0.37689. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) 0.18377/0.38175. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.17817/0.37133. Took 0.15 sec\n",
      "Epoch 77, Loss(train/val) 0.17680/0.37641. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.17840/0.36885. Took 0.15 sec\n",
      "Epoch 79, Loss(train/val) 0.17562/0.37838. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.17273/0.37624. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.16867/0.37192. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.16833/0.36346. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.17113/0.37315. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.16404/0.37434. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.18050/0.36849. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.16879/0.37568. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.17049/0.36046. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.17376/0.39562. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.16273/0.36356. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.16319/0.36955. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.16685/0.35086. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.16067/0.38645. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.16064/0.37396. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.16919/0.36159. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.16280/0.37180. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.15498/0.36594. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.17568/0.34928. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.16771/0.38196. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.16484/0.40036. Took 0.13 sec\n",
      "ACC: 0.640625, MCC: 0.3069288458707305\n",
      "Epoch 0, Loss(train/val) 0.49172/0.48011. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.46000/0.44338. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.42409/0.41024. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.39619/0.38978. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.37488/0.38473. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.36673/0.36652. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.35727/0.35515. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.34898/0.36271. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.34466/0.36249. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.33854/0.35575. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.33028/0.34786. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.32732/0.34123. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.32351/0.34713. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.32168/0.33516. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.31953/0.32532. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.31342/0.31888. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.30842/0.32468. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.30492/0.32680. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.30389/0.33807. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.30173/0.33891. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.29797/0.34370. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.29063/0.34102. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.28873/0.34709. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.29175/0.33577. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.28086/0.33393. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.27929/0.32989. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.27793/0.33621. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.27895/0.33157. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.27378/0.33143. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.26785/0.33493. Took 0.13 sec\n",
      "Epoch 30, Loss(train/val) 0.26242/0.34324. Took 0.17 sec\n",
      "Epoch 31, Loss(train/val) 0.26617/0.34208. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.26452/0.33876. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.25515/0.32028. Took 0.13 sec\n",
      "Epoch 34, Loss(train/val) 0.25320/0.32871. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.25010/0.33491. Took 0.16 sec\n",
      "Epoch 36, Loss(train/val) 0.25061/0.34365. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.25066/0.35626. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.24318/0.32724. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.23861/0.36012. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.23596/0.36539. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.23361/0.36830. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.22975/0.36463. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.23284/0.36499. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.22826/0.36293. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.23180/0.37508. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.21979/0.38093. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.21273/0.37565. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.21656/0.37886. Took 0.15 sec\n",
      "Epoch 49, Loss(train/val) 0.20867/0.37742. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.22029/0.40188. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.21218/0.39029. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.20041/0.38279. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.20005/0.38105. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.19912/0.39647. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.19469/0.38526. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.20059/0.36566. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.20377/0.39960. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.19024/0.37441. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.19005/0.37436. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.18792/0.37517. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.18792/0.35861. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.18336/0.38792. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.18635/0.40103. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.17430/0.41050. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.17316/0.41543. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.17246/0.41626. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.18242/0.41716. Took 0.12 sec\n",
      "Epoch 68, Loss(train/val) 0.17187/0.43972. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.16875/0.42561. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.16305/0.41578. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.16561/0.40495. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.16725/0.42070. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.17042/0.39037. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.16333/0.41349. Took 0.12 sec\n",
      "Epoch 75, Loss(train/val) 0.16666/0.38455. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.16210/0.36417. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.15610/0.35563. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.16380/0.35112. Took 0.14 sec\n",
      "Epoch 79, Loss(train/val) 0.17345/0.37988. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.16286/0.36998. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.16331/0.37034. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.16369/0.35001. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.15288/0.37226. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.15422/0.35207. Took 0.16 sec\n",
      "Epoch 85, Loss(train/val) 0.16758/0.37623. Took 0.16 sec\n",
      "Epoch 86, Loss(train/val) 0.15298/0.35453. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.15556/0.37807. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.15055/0.34995. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.16384/0.34321. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.15179/0.33926. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.14707/0.36794. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.15003/0.36628. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.14800/0.36757. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.15229/0.35599. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.14969/0.35546. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.14112/0.36205. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.14355/0.37250. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.14763/0.37576. Took 0.12 sec\n",
      "Epoch 99, Loss(train/val) 0.14226/0.35977. Took 0.16 sec\n",
      "ACC: 0.5625, MCC: 0.08655029717602476\n",
      "Epoch 0, Loss(train/val) 0.49039/0.48269. Took 0.13 sec\n",
      "Epoch 1, Loss(train/val) 0.46582/0.46313. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.43686/0.44572. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.40345/0.43743. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.38119/0.42741. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.36620/0.42314. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.36582/0.41739. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.35064/0.41832. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.34096/0.41883. Took 0.15 sec\n",
      "Epoch 9, Loss(train/val) 0.33681/0.42457. Took 0.16 sec\n",
      "Epoch 10, Loss(train/val) 0.33375/0.42746. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.32913/0.42651. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.32325/0.42663. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.32458/0.41725. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.32014/0.41001. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.31655/0.40985. Took 0.17 sec\n",
      "Epoch 16, Loss(train/val) 0.31466/0.40829. Took 0.16 sec\n",
      "Epoch 17, Loss(train/val) 0.30553/0.41714. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.29530/0.41082. Took 0.15 sec\n",
      "Epoch 19, Loss(train/val) 0.29688/0.40277. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.29584/0.41704. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.28744/0.41770. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.28775/0.40774. Took 0.18 sec\n",
      "Epoch 23, Loss(train/val) 0.28252/0.40741. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.28000/0.41340. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.27754/0.39958. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.27145/0.40965. Took 0.17 sec\n",
      "Epoch 27, Loss(train/val) 0.26755/0.39435. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.26107/0.40718. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.26342/0.40351. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.25467/0.40525. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.25270/0.39301. Took 0.13 sec\n",
      "Epoch 32, Loss(train/val) 0.25568/0.41011. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.25911/0.40403. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.25912/0.40130. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.24776/0.40443. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.24917/0.41506. Took 0.13 sec\n",
      "Epoch 37, Loss(train/val) 0.24357/0.41136. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.23880/0.40969. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.23934/0.38590. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.23798/0.40743. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.23060/0.41265. Took 0.12 sec\n",
      "Epoch 42, Loss(train/val) 0.22861/0.40539. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.22698/0.41356. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.22485/0.40550. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.22312/0.42700. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.22877/0.39490. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.22762/0.41609. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.21699/0.42104. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.21894/0.41588. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.21685/0.40564. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.21398/0.40059. Took 0.15 sec\n",
      "Epoch 52, Loss(train/val) 0.21427/0.42304. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.20809/0.42717. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.20935/0.42713. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.20713/0.43196. Took 0.16 sec\n",
      "Epoch 56, Loss(train/val) 0.21140/0.42424. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.21093/0.43525. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.20669/0.43990. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.20722/0.39101. Took 0.12 sec\n",
      "Epoch 60, Loss(train/val) 0.20033/0.45313. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.19919/0.42018. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.19700/0.43802. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.19346/0.43262. Took 0.15 sec\n",
      "Epoch 64, Loss(train/val) 0.20249/0.42698. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.20223/0.36079. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.20207/0.43720. Took 0.16 sec\n",
      "Epoch 67, Loss(train/val) 0.19755/0.41720. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.19888/0.43147. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.18848/0.38721. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.18899/0.41528. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.18322/0.42603. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.21262/0.42803. Took 0.16 sec\n",
      "Epoch 73, Loss(train/val) 0.18938/0.42994. Took 0.16 sec\n",
      "Epoch 74, Loss(train/val) 0.18465/0.41710. Took 0.15 sec\n",
      "Epoch 75, Loss(train/val) 0.17848/0.41568. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.18060/0.41183. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.18234/0.42569. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.18216/0.44646. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.18060/0.42998. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.17082/0.44911. Took 0.14 sec\n",
      "Epoch 81, Loss(train/val) 0.17668/0.43400. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.17026/0.43520. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.16191/0.43427. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.16692/0.43754. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.16584/0.44315. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.15569/0.44372. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.16339/0.44957. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.16170/0.41745. Took 0.14 sec\n",
      "Epoch 89, Loss(train/val) 0.16022/0.42974. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.16434/0.43202. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.16514/0.45535. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.17033/0.45769. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.16326/0.45674. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.15969/0.44469. Took 0.15 sec\n",
      "Epoch 95, Loss(train/val) 0.16287/0.44587. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.15367/0.45585. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.14956/0.42844. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.15664/0.45185. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.15553/0.43072. Took 0.13 sec\n",
      "ACC: 0.5625, MCC: 0.1929364015162026\n",
      "Epoch 0, Loss(train/val) 0.49014/0.49784. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.46171/0.49310. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.42531/0.48590. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.39560/0.47881. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.38012/0.48486. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.36153/0.48395. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.35779/0.47873. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.34735/0.47962. Took 0.16 sec\n",
      "Epoch 8, Loss(train/val) 0.34421/0.48165. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.34911/0.48208. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.33848/0.47392. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.33506/0.47621. Took 0.16 sec\n",
      "Epoch 12, Loss(train/val) 0.33407/0.47652. Took 0.19 sec\n",
      "Epoch 13, Loss(train/val) 0.32955/0.47730. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.32211/0.47174. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.32198/0.47057. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.31888/0.46142. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.31671/0.46672. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.31209/0.45843. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.31496/0.45764. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.30694/0.46221. Took 0.17 sec\n",
      "Epoch 21, Loss(train/val) 0.30418/0.46033. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.30045/0.45534. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.30195/0.43841. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.29652/0.44473. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.29314/0.43503. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.28516/0.43357. Took 0.15 sec\n",
      "Epoch 27, Loss(train/val) 0.29404/0.43448. Took 0.17 sec\n",
      "Epoch 28, Loss(train/val) 0.28165/0.44160. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.27702/0.43531. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.27631/0.44201. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.27467/0.40779. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.27306/0.40452. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.27185/0.40808. Took 0.16 sec\n",
      "Epoch 34, Loss(train/val) 0.26901/0.41040. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.26191/0.42715. Took 0.13 sec\n",
      "Epoch 36, Loss(train/val) 0.26393/0.42202. Took 0.13 sec\n",
      "Epoch 37, Loss(train/val) 0.26161/0.41389. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.25107/0.41871. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.24957/0.42198. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.24269/0.43517. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.25650/0.42115. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.24070/0.40724. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.23774/0.41726. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.23442/0.38930. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.23227/0.38945. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.23496/0.44528. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.22988/0.38845. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.22802/0.42708. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.21760/0.40502. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.21680/0.42164. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.21142/0.38734. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.20907/0.39773. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.20651/0.39504. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.20811/0.40750. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.20861/0.41896. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.20110/0.40481. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.20371/0.40038. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.20237/0.39803. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.19898/0.39689. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.19895/0.39608. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.19336/0.41219. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.19223/0.40469. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.18520/0.39924. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.18268/0.41198. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.19014/0.40511. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.18675/0.41046. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.19048/0.42182. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.18786/0.40110. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.19642/0.40108. Took 0.12 sec\n",
      "Epoch 70, Loss(train/val) 0.18407/0.38850. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.17716/0.39681. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.18100/0.40650. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.17147/0.39725. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.17302/0.39899. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.17305/0.40226. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.17187/0.39945. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.16954/0.41568. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.17372/0.39911. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.17146/0.40658. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.16379/0.40925. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.16629/0.40409. Took 0.15 sec\n",
      "Epoch 82, Loss(train/val) 0.16845/0.40098. Took 0.17 sec\n",
      "Epoch 83, Loss(train/val) 0.16004/0.41076. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.16384/0.40420. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.16731/0.40779. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.16526/0.40663. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.16256/0.40469. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.16315/0.39254. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.15375/0.40915. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.16056/0.43283. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.16002/0.40211. Took 0.15 sec\n",
      "Epoch 92, Loss(train/val) 0.16731/0.42403. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.16109/0.39481. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.16077/0.41011. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.15990/0.39678. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.16269/0.41853. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.16847/0.43137. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.17106/0.40906. Took 0.15 sec\n",
      "Epoch 99, Loss(train/val) 0.15689/0.40260. Took 0.13 sec\n",
      "ACC: 0.671875, MCC: 0.31006389322000766\n",
      "Epoch 0, Loss(train/val) 0.49152/0.48048. Took 0.13 sec\n",
      "Epoch 1, Loss(train/val) 0.46794/0.44829. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.43153/0.41659. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.40199/0.39427. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.38598/0.37088. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.37705/0.37316. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.36849/0.36975. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.35933/0.38036. Took 0.12 sec\n",
      "Epoch 8, Loss(train/val) 0.35251/0.37205. Took 0.12 sec\n",
      "Epoch 9, Loss(train/val) 0.34777/0.37334. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.34718/0.36656. Took 0.15 sec\n",
      "Epoch 11, Loss(train/val) 0.34071/0.34943. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.33786/0.36476. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.34755/0.34932. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.33349/0.35399. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.32131/0.34945. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.31790/0.34596. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.31524/0.32939. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.30374/0.32396. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.30393/0.33787. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.29948/0.31883. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.29740/0.33428. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.29114/0.33012. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.29015/0.34376. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.28755/0.34143. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.27963/0.33655. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.28005/0.34166. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.28034/0.31173. Took 0.13 sec\n",
      "Epoch 28, Loss(train/val) 0.27576/0.34454. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.27595/0.32108. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.27970/0.33196. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.26985/0.33472. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.27178/0.32858. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.27004/0.31596. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.26212/0.32307. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.27102/0.33887. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.26121/0.34227. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.27062/0.32991. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.27041/0.34015. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.25648/0.33135. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.25994/0.34587. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.26508/0.32245. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.25499/0.34078. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.25137/0.30642. Took 0.12 sec\n",
      "Epoch 44, Loss(train/val) 0.24327/0.31151. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.23346/0.33160. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.24499/0.32856. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.24722/0.32118. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.23961/0.31928. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.23381/0.31203. Took 0.12 sec\n",
      "Epoch 50, Loss(train/val) 0.22854/0.30933. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.23078/0.31166. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.22430/0.31316. Took 0.12 sec\n",
      "Epoch 53, Loss(train/val) 0.22450/0.31753. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.22853/0.32329. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.21741/0.29945. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.22074/0.29718. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.21383/0.30511. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.21340/0.29405. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.20537/0.30493. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.20507/0.29512. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.20671/0.29731. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.20160/0.29638. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.19798/0.29181. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.19664/0.30856. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.18783/0.29132. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.18724/0.28584. Took 0.12 sec\n",
      "Epoch 67, Loss(train/val) 0.18718/0.28618. Took 0.12 sec\n",
      "Epoch 68, Loss(train/val) 0.18294/0.28249. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.19162/0.27627. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.18381/0.28946. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.18484/0.30787. Took 0.12 sec\n",
      "Epoch 72, Loss(train/val) 0.19318/0.28240. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.18172/0.28282. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.17598/0.28477. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.17530/0.28329. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.17426/0.29248. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.17939/0.29911. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.17397/0.29070. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.17542/0.29598. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.16786/0.29380. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.17407/0.28832. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.17683/0.28794. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.16776/0.29456. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.17065/0.28126. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.16884/0.27994. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.16561/0.27729. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.16495/0.28893. Took 0.12 sec\n",
      "Epoch 88, Loss(train/val) 0.16305/0.28551. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.16466/0.28977. Took 0.12 sec\n",
      "Epoch 90, Loss(train/val) 0.16541/0.27777. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.16395/0.28157. Took 0.12 sec\n",
      "Epoch 92, Loss(train/val) 0.15222/0.28623. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.16007/0.28794. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.16076/0.28802. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.15874/0.29225. Took 0.12 sec\n",
      "Epoch 96, Loss(train/val) 0.15437/0.30127. Took 0.12 sec\n",
      "Epoch 97, Loss(train/val) 0.15553/0.29411. Took 0.12 sec\n",
      "Epoch 98, Loss(train/val) 0.15377/0.29126. Took 0.12 sec\n",
      "Epoch 99, Loss(train/val) 0.15023/0.29616. Took 0.12 sec\n",
      "ACC: 0.671875, MCC: 0.348024598442583\n",
      "Epoch 0, Loss(train/val) 0.49653/0.49220. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.47696/0.47140. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.45131/0.43256. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.42033/0.38310. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.39311/0.35103. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.37498/0.32431. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.36313/0.32527. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.35781/0.33482. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.34914/0.30981. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.33883/0.35139. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.33462/0.35266. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.32633/0.35577. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.32136/0.34128. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.30972/0.32424. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.30590/0.32269. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.29810/0.33543. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.29329/0.32541. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.28942/0.35515. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.28751/0.34076. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.28222/0.35544. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.27906/0.37567. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.26673/0.37262. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.26668/0.36835. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.26872/0.36794. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.28255/0.38499. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.26385/0.39366. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.25920/0.39907. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.26918/0.40036. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.25716/0.38191. Took 0.16 sec\n",
      "Epoch 29, Loss(train/val) 0.25719/0.37206. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.25154/0.40601. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.24643/0.40847. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.24272/0.41847. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.24107/0.42109. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.23652/0.41905. Took 0.16 sec\n",
      "Epoch 35, Loss(train/val) 0.23474/0.42539. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.23318/0.39291. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.24470/0.41130. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.23240/0.40615. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.23268/0.42559. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.23154/0.41074. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.23175/0.43160. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.22500/0.42234. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.21742/0.40491. Took 0.12 sec\n",
      "Epoch 44, Loss(train/val) 0.22272/0.41618. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.22659/0.42120. Took 0.12 sec\n",
      "Epoch 46, Loss(train/val) 0.21793/0.41394. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.21836/0.41530. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.22124/0.45147. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.22057/0.40770. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.21170/0.41496. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.20240/0.42253. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.20363/0.41632. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.20370/0.40738. Took 0.12 sec\n",
      "Epoch 54, Loss(train/val) 0.20852/0.40550. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.19872/0.40157. Took 0.12 sec\n",
      "Epoch 56, Loss(train/val) 0.18837/0.43218. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.19266/0.42033. Took 0.12 sec\n",
      "Epoch 58, Loss(train/val) 0.19230/0.43444. Took 0.12 sec\n",
      "Epoch 59, Loss(train/val) 0.20492/0.41470. Took 0.12 sec\n",
      "Epoch 60, Loss(train/val) 0.19129/0.40448. Took 0.12 sec\n",
      "Epoch 61, Loss(train/val) 0.18716/0.40619. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.19066/0.42915. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.18889/0.43472. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.19259/0.41488. Took 0.12 sec\n",
      "Epoch 65, Loss(train/val) 0.18757/0.41533. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.18775/0.43330. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.18174/0.42492. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.17981/0.41632. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.18230/0.40510. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.17590/0.39343. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.18907/0.41807. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.17327/0.41937. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.17510/0.40928. Took 0.12 sec\n",
      "Epoch 74, Loss(train/val) 0.17848/0.41716. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.17178/0.41536. Took 0.12 sec\n",
      "Epoch 76, Loss(train/val) 0.17050/0.41339. Took 0.12 sec\n",
      "Epoch 77, Loss(train/val) 0.16884/0.40980. Took 0.12 sec\n",
      "Epoch 78, Loss(train/val) 0.16745/0.41709. Took 0.12 sec\n",
      "Epoch 79, Loss(train/val) 0.16654/0.40634. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.16080/0.38956. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.17433/0.38484. Took 0.12 sec\n",
      "Epoch 82, Loss(train/val) 0.16913/0.40683. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.17265/0.39601. Took 0.12 sec\n",
      "Epoch 84, Loss(train/val) 0.16785/0.38592. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.16869/0.39643. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.16646/0.38766. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.16371/0.40498. Took 0.12 sec\n",
      "Epoch 88, Loss(train/val) 0.15798/0.40756. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.16277/0.39174. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.15867/0.39909. Took 0.12 sec\n",
      "Epoch 91, Loss(train/val) 0.15383/0.40441. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.15355/0.39935. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.15120/0.39829. Took 0.12 sec\n",
      "Epoch 94, Loss(train/val) 0.15248/0.40473. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.15048/0.39749. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.15507/0.39002. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.15443/0.38261. Took 0.12 sec\n",
      "Epoch 98, Loss(train/val) 0.15325/0.40739. Took 0.12 sec\n",
      "Epoch 99, Loss(train/val) 0.14923/0.40125. Took 0.14 sec\n",
      "ACC: 0.546875, MCC: 0.12156613477096616\n",
      "Epoch 0, Loss(train/val) 0.49388/0.49285. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.47432/0.48337. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.43792/0.47822. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.39576/0.47606. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.37482/0.47581. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.36410/0.45484. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.35538/0.43152. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.34617/0.43045. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.34016/0.42707. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.33800/0.42341. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.33551/0.42597. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.32901/0.42250. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.33079/0.41769. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.33474/0.47859. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.33747/0.40394. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.32601/0.43344. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.32305/0.44160. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.31828/0.41036. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.30635/0.42121. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.31050/0.42300. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.30048/0.43091. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.29711/0.42281. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.29838/0.42159. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.29261/0.42695. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.29159/0.42880. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.29006/0.43920. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.29187/0.42689. Took 0.13 sec\n",
      "Epoch 27, Loss(train/val) 0.28820/0.41293. Took 0.13 sec\n",
      "Epoch 28, Loss(train/val) 0.28396/0.42237. Took 0.13 sec\n",
      "Epoch 29, Loss(train/val) 0.27608/0.40921. Took 0.13 sec\n",
      "Epoch 30, Loss(train/val) 0.26891/0.41319. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.27789/0.41493. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.27249/0.41060. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.27058/0.42605. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.26595/0.42232. Took 0.16 sec\n",
      "Epoch 35, Loss(train/val) 0.26003/0.41348. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.26229/0.41517. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.25965/0.41624. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.25350/0.41911. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.25290/0.42927. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.24950/0.43335. Took 0.16 sec\n",
      "Epoch 41, Loss(train/val) 0.24881/0.42617. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.24752/0.43630. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.23932/0.39696. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.23825/0.39759. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.23128/0.40402. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.24058/0.42128. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.23193/0.41304. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.22553/0.40402. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.22548/0.42351. Took 0.12 sec\n",
      "Epoch 50, Loss(train/val) 0.22605/0.42720. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.22379/0.42494. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.21889/0.41773. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.22082/0.43682. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.21243/0.43206. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.21260/0.41701. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.22735/0.41023. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.21563/0.42388. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.21104/0.42438. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.20818/0.42211. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.20594/0.41871. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.20069/0.43103. Took 0.12 sec\n",
      "Epoch 62, Loss(train/val) 0.19362/0.43475. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.19086/0.42355. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.19803/0.43401. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.18161/0.43038. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.18788/0.42206. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.19581/0.42889. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.18774/0.42478. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.18797/0.42427. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.18354/0.41539. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.18859/0.42133. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.18175/0.41600. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.18009/0.41427. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.17063/0.44635. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.17389/0.44005. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.16757/0.42271. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.17192/0.43269. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.17001/0.43126. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.16792/0.40449. Took 0.12 sec\n",
      "Epoch 80, Loss(train/val) 0.17438/0.43908. Took 0.12 sec\n",
      "Epoch 81, Loss(train/val) 0.17597/0.43882. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.17019/0.41311. Took 0.12 sec\n",
      "Epoch 83, Loss(train/val) 0.16796/0.42232. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.16528/0.42260. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.16384/0.41977. Took 0.12 sec\n",
      "Epoch 86, Loss(train/val) 0.16325/0.42070. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.15751/0.39586. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.17816/0.42824. Took 0.14 sec\n",
      "Epoch 89, Loss(train/val) 0.16916/0.41211. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.16036/0.42341. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.15737/0.41000. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.15516/0.44736. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.15607/0.40247. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.15966/0.42825. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.15189/0.41493. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.14081/0.44202. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.14944/0.44337. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.14366/0.41720. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.15811/0.43670. Took 0.14 sec\n",
      "ACC: 0.703125, MCC: 0.3584218191826503\n",
      "Epoch 0, Loss(train/val) 0.49008/0.47309. Took 0.13 sec\n",
      "Epoch 1, Loss(train/val) 0.46651/0.43125. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.43302/0.40289. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.40083/0.39266. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.38007/0.37770. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.36352/0.37644. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.35313/0.38013. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.34932/0.37461. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.34426/0.37348. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.33554/0.36911. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.32686/0.37300. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.31790/0.37643. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.32289/0.37626. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.30762/0.36300. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.30570/0.37068. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.30653/0.38977. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.30045/0.39043. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.29891/0.39026. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.29212/0.38613. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.29804/0.39214. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.29138/0.40702. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.28419/0.39701. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.28316/0.36765. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.26771/0.37020. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.26897/0.40050. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.25729/0.38039. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.25697/0.38412. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.24887/0.36313. Took 0.13 sec\n",
      "Epoch 28, Loss(train/val) 0.24295/0.36852. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.23846/0.37259. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.23798/0.36247. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.23624/0.36664. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.23769/0.35736. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.24229/0.37978. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.22145/0.37923. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.22840/0.36976. Took 0.13 sec\n",
      "Epoch 36, Loss(train/val) 0.21394/0.38771. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.22536/0.37117. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.21417/0.37218. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.22424/0.37225. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.21354/0.37250. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.19931/0.36180. Took 0.12 sec\n",
      "Epoch 42, Loss(train/val) 0.20418/0.38215. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.21027/0.37803. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.20271/0.37464. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) 0.19605/0.36667. Took 0.12 sec\n",
      "Epoch 46, Loss(train/val) 0.19906/0.36873. Took 0.12 sec\n",
      "Epoch 47, Loss(train/val) 0.19662/0.35792. Took 0.12 sec\n",
      "Epoch 48, Loss(train/val) 0.18397/0.36794. Took 0.12 sec\n",
      "Epoch 49, Loss(train/val) 0.19875/0.37729. Took 0.12 sec\n",
      "Epoch 50, Loss(train/val) 0.19237/0.35122. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.18753/0.36672. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.18791/0.35158. Took 0.12 sec\n",
      "Epoch 53, Loss(train/val) 0.18365/0.36496. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.17964/0.36090. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.17899/0.35983. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.18637/0.36181. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.17875/0.37697. Took 0.15 sec\n",
      "Epoch 58, Loss(train/val) 0.17480/0.36859. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.17456/0.38009. Took 0.12 sec\n",
      "Epoch 60, Loss(train/val) 0.17284/0.37821. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.17506/0.36297. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.17820/0.35946. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.16953/0.37361. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.17162/0.36703. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.17652/0.37817. Took 0.12 sec\n",
      "Epoch 66, Loss(train/val) 0.16598/0.36547. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.17351/0.37773. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.15975/0.37336. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.15473/0.36947. Took 0.12 sec\n",
      "Epoch 70, Loss(train/val) 0.16670/0.36670. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.15913/0.37661. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.15795/0.40202. Took 0.12 sec\n",
      "Epoch 73, Loss(train/val) 0.15984/0.38488. Took 0.12 sec\n",
      "Epoch 74, Loss(train/val) 0.15149/0.38265. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.16005/0.37323. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.14957/0.36703. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.16020/0.37778. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.15677/0.37134. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.15689/0.39201. Took 0.12 sec\n",
      "Epoch 80, Loss(train/val) 0.15692/0.38090. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.15515/0.38602. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.14282/0.37603. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.14816/0.39240. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.14887/0.38546. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.14191/0.40557. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.14468/0.37325. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.14570/0.36871. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.14470/0.36895. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.14361/0.39856. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.14628/0.38416. Took 0.14 sec\n",
      "Epoch 91, Loss(train/val) 0.14840/0.37210. Took 0.12 sec\n",
      "Epoch 92, Loss(train/val) 0.14223/0.39113. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.14858/0.37098. Took 0.12 sec\n",
      "Epoch 94, Loss(train/val) 0.14394/0.39567. Took 0.12 sec\n",
      "Epoch 95, Loss(train/val) 0.13250/0.38977. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.14092/0.38563. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.12751/0.37882. Took 0.12 sec\n",
      "Epoch 98, Loss(train/val) 0.13252/0.37687. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.13420/0.38304. Took 0.13 sec\n",
      "ACC: 0.671875, MCC: 0.3505757849137574\n",
      "Epoch 0, Loss(train/val) 0.49169/0.49073. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.46991/0.46808. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.44144/0.42196. Took 0.17 sec\n",
      "Epoch 3, Loss(train/val) 0.41243/0.38703. Took 0.15 sec\n",
      "Epoch 4, Loss(train/val) 0.39382/0.37692. Took 0.15 sec\n",
      "Epoch 5, Loss(train/val) 0.38400/0.36444. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.37268/0.35573. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.36575/0.32909. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.35677/0.33392. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.34812/0.32387. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.34176/0.32625. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.33921/0.31274. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.33140/0.33965. Took 0.15 sec\n",
      "Epoch 13, Loss(train/val) 0.32328/0.33090. Took 0.16 sec\n",
      "Epoch 14, Loss(train/val) 0.31860/0.33740. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.30637/0.32312. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.30718/0.33694. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.30782/0.29306. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.30502/0.29783. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.29039/0.32168. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.29149/0.28541. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.29168/0.36523. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.27303/0.28319. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.29239/0.28663. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.27342/0.33812. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.27674/0.38828. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.27098/0.34868. Took 0.17 sec\n",
      "Epoch 27, Loss(train/val) 0.26333/0.33078. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.25299/0.34634. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.24302/0.33971. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.23475/0.36882. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.23932/0.36102. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.24146/0.34869. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.23298/0.36226. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.23558/0.35060. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.23786/0.33829. Took 0.15 sec\n",
      "Epoch 36, Loss(train/val) 0.22577/0.37798. Took 0.16 sec\n",
      "Epoch 37, Loss(train/val) 0.22176/0.34808. Took 0.16 sec\n",
      "Epoch 38, Loss(train/val) 0.21656/0.37454. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.21170/0.35816. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.21048/0.35859. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.20583/0.35484. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.21273/0.33687. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.19589/0.34259. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.20329/0.34743. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.19707/0.35464. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.19831/0.36275. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.19101/0.37405. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.18848/0.34647. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.18326/0.34878. Took 0.15 sec\n",
      "Epoch 50, Loss(train/val) 0.18542/0.36739. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.18710/0.34307. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.18694/0.35218. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.17456/0.36613. Took 0.12 sec\n",
      "Epoch 54, Loss(train/val) 0.17790/0.35639. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.16928/0.34761. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.17056/0.33475. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.16438/0.34606. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.15886/0.35658. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.15903/0.34423. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.17218/0.34137. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.16500/0.34283. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.16080/0.34236. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.15548/0.34679. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.16438/0.34061. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.16583/0.34567. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.15126/0.36744. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.14703/0.36320. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.15319/0.35573. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.14874/0.37104. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.14708/0.36010. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.14137/0.36292. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.14831/0.35624. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.14251/0.33448. Took 0.12 sec\n",
      "Epoch 74, Loss(train/val) 0.13848/0.36387. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.14886/0.37176. Took 0.12 sec\n",
      "Epoch 76, Loss(train/val) 0.13644/0.33892. Took 0.12 sec\n",
      "Epoch 77, Loss(train/val) 0.14182/0.34039. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.14015/0.37589. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.14815/0.35565. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.13006/0.34347. Took 0.14 sec\n",
      "Epoch 81, Loss(train/val) 0.12615/0.33104. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.12991/0.34261. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.13404/0.34764. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.12042/0.32674. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.13342/0.34740. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.12660/0.37479. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.12822/0.36445. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.12968/0.35848. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.12560/0.34832. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.12312/0.37076. Took 0.14 sec\n",
      "Epoch 91, Loss(train/val) 0.11835/0.38080. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.12346/0.36111. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.12351/0.34984. Took 0.12 sec\n",
      "Epoch 94, Loss(train/val) 0.11511/0.37655. Took 0.14 sec\n",
      "Epoch 95, Loss(train/val) 0.11494/0.36092. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.10752/0.35627. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.10905/0.37586. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.10615/0.34771. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.10773/0.37369. Took 0.13 sec\n",
      "ACC: 0.546875, MCC: 0.17489193974334719\n",
      "Epoch 0, Loss(train/val) 0.49271/0.49400. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.47396/0.47448. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.44266/0.43135. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.40875/0.39989. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.38770/0.37511. Took 0.15 sec\n",
      "Epoch 5, Loss(train/val) 0.38095/0.35530. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.37259/0.35359. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.36340/0.34469. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.35399/0.34437. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.34785/0.33072. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.34588/0.33181. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.33478/0.33437. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.33437/0.34219. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.32857/0.35155. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.32547/0.33556. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.31692/0.37188. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.30288/0.34554. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.29643/0.38116. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.30325/0.35320. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.29272/0.33002. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.29028/0.39120. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.31409/0.36251. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.28499/0.38072. Took 0.15 sec\n",
      "Epoch 23, Loss(train/val) 0.28883/0.36362. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.27851/0.37821. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.26494/0.39155. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.26567/0.37341. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.26128/0.36283. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.26569/0.37091. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.25952/0.38457. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.25822/0.38775. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.25368/0.38178. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.24618/0.36105. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.25726/0.37575. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.24630/0.38487. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.24075/0.37865. Took 0.16 sec\n",
      "Epoch 36, Loss(train/val) 0.24069/0.35429. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.24149/0.36258. Took 0.15 sec\n",
      "Epoch 38, Loss(train/val) 0.24719/0.34222. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.23308/0.35018. Took 0.15 sec\n",
      "Epoch 40, Loss(train/val) 0.23661/0.34349. Took 0.16 sec\n",
      "Epoch 41, Loss(train/val) 0.23526/0.36316. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.23033/0.35665. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.23457/0.36781. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.24052/0.35301. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.23439/0.34654. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.22292/0.35165. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.21963/0.34137. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.22306/0.34174. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.22034/0.35415. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.21525/0.36025. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.20410/0.36787. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.20464/0.36229. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.20710/0.38866. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.22043/0.36657. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.20642/0.35347. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.20049/0.35473. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.19025/0.35868. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.18943/0.36603. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.20203/0.37159. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.19473/0.36729. Took 0.14 sec\n",
      "Epoch 61, Loss(train/val) 0.20071/0.36568. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.18961/0.35489. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.18951/0.36128. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.19049/0.36714. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.18531/0.36677. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.18336/0.34538. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.18076/0.36650. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.19067/0.34711. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.17843/0.37019. Took 0.12 sec\n",
      "Epoch 70, Loss(train/val) 0.17974/0.37148. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.17913/0.36356. Took 0.12 sec\n",
      "Epoch 72, Loss(train/val) 0.18183/0.35840. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.17136/0.35771. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.17494/0.35199. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.18001/0.35356. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.17515/0.35715. Took 0.15 sec\n",
      "Epoch 77, Loss(train/val) 0.16820/0.34738. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.17401/0.35911. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.16311/0.36102. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.16457/0.34816. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.16826/0.36232. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.16244/0.36701. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.16381/0.36362. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.16309/0.36246. Took 0.17 sec\n",
      "Epoch 85, Loss(train/val) 0.17435/0.35554. Took 0.19 sec\n",
      "Epoch 86, Loss(train/val) 0.15725/0.36889. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.17027/0.37039. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.17083/0.35995. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.15643/0.36541. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.16269/0.35952. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.15928/0.36455. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.15461/0.36847. Took 0.15 sec\n",
      "Epoch 93, Loss(train/val) 0.16539/0.36668. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.16607/0.38003. Took 0.15 sec\n",
      "Epoch 95, Loss(train/val) 0.15627/0.35875. Took 0.15 sec\n",
      "Epoch 96, Loss(train/val) 0.15651/0.36166. Took 0.23 sec\n",
      "Epoch 97, Loss(train/val) 0.15722/0.37246. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.14913/0.36303. Took 0.15 sec\n",
      "Epoch 99, Loss(train/val) 0.15722/0.36182. Took 0.16 sec\n",
      "ACC: 0.546875, MCC: 0.09379580992210836\n",
      "Epoch 0, Loss(train/val) 0.49621/0.49968. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.47994/0.50169. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.45004/0.50816. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.40957/0.50932. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.38634/0.50623. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.37295/0.49150. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.35734/0.46556. Took 0.15 sec\n",
      "Epoch 7, Loss(train/val) 0.34060/0.43360. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.34394/0.41839. Took 0.16 sec\n",
      "Epoch 9, Loss(train/val) 0.32297/0.42329. Took 0.15 sec\n",
      "Epoch 10, Loss(train/val) 0.32528/0.41376. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.33917/0.42762. Took 0.16 sec\n",
      "Epoch 12, Loss(train/val) 0.32399/0.43893. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.32238/0.43060. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.32206/0.43266. Took 0.15 sec\n",
      "Epoch 15, Loss(train/val) 0.32042/0.43824. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.31436/0.42939. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.30042/0.40211. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.30746/0.39249. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.30000/0.40001. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.29405/0.40180. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.29149/0.40677. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.28742/0.39627. Took 0.15 sec\n",
      "Epoch 23, Loss(train/val) 0.28080/0.38791. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.27947/0.40704. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.27965/0.41199. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.27771/0.41084. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.26896/0.41797. Took 0.16 sec\n",
      "Epoch 28, Loss(train/val) 0.25697/0.42332. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.25209/0.41007. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.25356/0.42691. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.24180/0.42799. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.24304/0.42812. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.23321/0.43009. Took 0.13 sec\n",
      "Epoch 34, Loss(train/val) 0.23242/0.43149. Took 0.13 sec\n",
      "Epoch 35, Loss(train/val) 0.21978/0.41788. Took 0.13 sec\n",
      "Epoch 36, Loss(train/val) 0.21740/0.43663. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.21956/0.43468. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.22079/0.45128. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.20700/0.43923. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.21741/0.44256. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.20435/0.43849. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.19787/0.44150. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.19780/0.44486. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.19425/0.46514. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) 0.19407/0.45742. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.19079/0.45433. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.19084/0.45880. Took 0.12 sec\n",
      "Epoch 48, Loss(train/val) 0.19208/0.47097. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.18238/0.47305. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.17701/0.46574. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.17695/0.47067. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.17826/0.45245. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.17411/0.45918. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.18313/0.44805. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.17551/0.43878. Took 0.12 sec\n",
      "Epoch 56, Loss(train/val) 0.17624/0.44867. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.17257/0.45050. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.16821/0.44704. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.15922/0.43804. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.16522/0.43648. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.17153/0.44348. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.16271/0.44920. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.15962/0.46034. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.16114/0.48229. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.16141/0.44962. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.15356/0.45797. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.16438/0.44607. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.15256/0.46478. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.15395/0.48047. Took 0.12 sec\n",
      "Epoch 70, Loss(train/val) 0.15484/0.47840. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.15609/0.44901. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.14672/0.45197. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.14857/0.45253. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.14278/0.47013. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.14533/0.46572. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.14226/0.47639. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.13977/0.44773. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.13631/0.47400. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.13260/0.47237. Took 0.12 sec\n",
      "Epoch 80, Loss(train/val) 0.13725/0.44167. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.14186/0.44494. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.13816/0.44257. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.13594/0.45021. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.14427/0.44790. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.14098/0.42762. Took 0.12 sec\n",
      "Epoch 86, Loss(train/val) 0.13747/0.44745. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.13284/0.44402. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.12483/0.42710. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.13586/0.41195. Took 0.15 sec\n",
      "Epoch 90, Loss(train/val) 0.12668/0.41366. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.13228/0.43212. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.13070/0.43070. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.12643/0.40407. Took 0.12 sec\n",
      "Epoch 94, Loss(train/val) 0.13340/0.40824. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.12652/0.43632. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.12275/0.45989. Took 0.14 sec\n",
      "Epoch 97, Loss(train/val) 0.12427/0.41762. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.12521/0.41323. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.12192/0.39702. Took 0.13 sec\n",
      "ACC: 0.640625, MCC: 0.2771645457819533\n",
      "Epoch 0, Loss(train/val) 0.49723/0.49849. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.48393/0.49247. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.45945/0.48175. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.42141/0.47164. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.39706/0.46717. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.37941/0.45816. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.36521/0.45655. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.35931/0.45162. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.33874/0.41941. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.32567/0.38851. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.31543/0.38071. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.30507/0.37050. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.30053/0.35785. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.28624/0.35015. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.28801/0.36093. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.26933/0.35845. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.27310/0.36261. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.27593/0.35520. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.26734/0.36391. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.26727/0.36192. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.26591/0.36399. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.25271/0.36944. Took 0.16 sec\n",
      "Epoch 22, Loss(train/val) 0.24954/0.36670. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.25421/0.36979. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.25026/0.38857. Took 0.17 sec\n",
      "Epoch 25, Loss(train/val) 0.24969/0.38891. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.24665/0.39295. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.24449/0.38337. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.23181/0.38622. Took 0.18 sec\n",
      "Epoch 29, Loss(train/val) 0.23466/0.39382. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.23140/0.39004. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.21922/0.38509. Took 0.13 sec\n",
      "Epoch 32, Loss(train/val) 0.21558/0.38263. Took 0.13 sec\n",
      "Epoch 33, Loss(train/val) 0.21715/0.38923. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.21909/0.38415. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.21938/0.39945. Took 0.16 sec\n",
      "Epoch 36, Loss(train/val) 0.21163/0.38956. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.20915/0.39772. Took 0.17 sec\n",
      "Epoch 38, Loss(train/val) 0.21056/0.40088. Took 0.18 sec\n",
      "Epoch 39, Loss(train/val) 0.20935/0.39102. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.20141/0.38213. Took 0.15 sec\n",
      "Epoch 41, Loss(train/val) 0.20510/0.38771. Took 0.15 sec\n",
      "Epoch 42, Loss(train/val) 0.19114/0.39458. Took 0.15 sec\n",
      "Epoch 43, Loss(train/val) 0.20213/0.39579. Took 0.15 sec\n",
      "Epoch 44, Loss(train/val) 0.19335/0.39113. Took 0.15 sec\n",
      "Epoch 45, Loss(train/val) 0.19550/0.39776. Took 0.15 sec\n",
      "Epoch 46, Loss(train/val) 0.18868/0.40602. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.18901/0.39876. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.19560/0.41164. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.19901/0.41965. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.19927/0.41189. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.20043/0.40067. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.19101/0.40723. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) 0.18038/0.40080. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.18872/0.37832. Took 0.18 sec\n",
      "Epoch 55, Loss(train/val) 0.19489/0.39728. Took 0.16 sec\n",
      "Epoch 56, Loss(train/val) 0.19419/0.39535. Took 0.16 sec\n",
      "Epoch 57, Loss(train/val) 0.17704/0.37993. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.17977/0.41092. Took 0.14 sec\n",
      "Epoch 59, Loss(train/val) 0.17696/0.41616. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.17816/0.40114. Took 0.14 sec\n",
      "Epoch 61, Loss(train/val) 0.17231/0.40100. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.16512/0.42895. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.17608/0.41823. Took 0.16 sec\n",
      "Epoch 64, Loss(train/val) 0.16280/0.43082. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.17040/0.41927. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.17101/0.41471. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.15837/0.42130. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.17498/0.39922. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.16382/0.40326. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.15430/0.41085. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.15727/0.42091. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.16246/0.37581. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.15586/0.39420. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.15311/0.40720. Took 0.16 sec\n",
      "Epoch 75, Loss(train/val) 0.15242/0.38831. Took 0.15 sec\n",
      "Epoch 76, Loss(train/val) 0.14719/0.39677. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.15506/0.39030. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.15142/0.40906. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.14901/0.41080. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.14337/0.40466. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.13882/0.40766. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.14355/0.41727. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.14903/0.39851. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.13643/0.40400. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.15064/0.40211. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.14194/0.39505. Took 0.15 sec\n",
      "Epoch 87, Loss(train/val) 0.13680/0.41518. Took 0.15 sec\n",
      "Epoch 88, Loss(train/val) 0.13579/0.40189. Took 0.15 sec\n",
      "Epoch 89, Loss(train/val) 0.13830/0.40274. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.13862/0.40635. Took 0.15 sec\n",
      "Epoch 91, Loss(train/val) 0.13345/0.41563. Took 0.15 sec\n",
      "Epoch 92, Loss(train/val) 0.14406/0.37462. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.12710/0.38964. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.12709/0.40629. Took 0.15 sec\n",
      "Epoch 95, Loss(train/val) 0.14537/0.41126. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.12702/0.40437. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.12416/0.41433. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.13379/0.41636. Took 0.16 sec\n",
      "Epoch 99, Loss(train/val) 0.13302/0.41159. Took 0.14 sec\n",
      "ACC: 0.765625, MCC: 0.531509589558614\n",
      "Epoch 0, Loss(train/val) 0.49575/0.47874. Took 0.16 sec\n",
      "Epoch 1, Loss(train/val) 0.48055/0.44353. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.45301/0.39546. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.41485/0.37735. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.39059/0.36538. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.37275/0.34092. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.36111/0.32845. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.34415/0.30771. Took 0.15 sec\n",
      "Epoch 8, Loss(train/val) 0.32517/0.29040. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.31950/0.33076. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.31651/0.29774. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.30177/0.30245. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.30159/0.32205. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.28902/0.28729. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.29084/0.32799. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.29584/0.28225. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.28023/0.24508. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.26549/0.26621. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.26810/0.28662. Took 0.16 sec\n",
      "Epoch 19, Loss(train/val) 0.26341/0.26423. Took 0.15 sec\n",
      "Epoch 20, Loss(train/val) 0.26024/0.26647. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.26036/0.28143. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.25431/0.24526. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.25933/0.27727. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.26486/0.25877. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.24350/0.28428. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.24074/0.26559. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.25459/0.27316. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.24110/0.28668. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.24268/0.29581. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.23082/0.29801. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.22762/0.28282. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.22390/0.27735. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.22681/0.30592. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.22030/0.28061. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.21283/0.30896. Took 0.15 sec\n",
      "Epoch 36, Loss(train/val) 0.21847/0.31371. Took 0.17 sec\n",
      "Epoch 37, Loss(train/val) 0.22629/0.28988. Took 0.15 sec\n",
      "Epoch 38, Loss(train/val) 0.21431/0.33606. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.21174/0.31475. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.21692/0.32618. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.21708/0.33199. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.21377/0.33374. Took 0.15 sec\n",
      "Epoch 43, Loss(train/val) 0.22590/0.33206. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.20441/0.33700. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.21017/0.32425. Took 0.12 sec\n",
      "Epoch 46, Loss(train/val) 0.21172/0.31430. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.20108/0.30684. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.19958/0.34777. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.19320/0.29600. Took 0.16 sec\n",
      "Epoch 50, Loss(train/val) 0.20810/0.31071. Took 0.14 sec\n",
      "Epoch 51, Loss(train/val) 0.19435/0.30017. Took 0.15 sec\n",
      "Epoch 52, Loss(train/val) 0.20100/0.31504. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) 0.20057/0.31161. Took 0.15 sec\n",
      "Epoch 54, Loss(train/val) 0.19655/0.32005. Took 0.15 sec\n",
      "Epoch 55, Loss(train/val) 0.17936/0.33608. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.19135/0.36134. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.18811/0.35539. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.20901/0.30410. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.19629/0.31119. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.18300/0.34222. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.18149/0.31251. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.18679/0.35355. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.16740/0.31954. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.18253/0.30348. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.17387/0.34207. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.17449/0.36109. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) 0.19491/0.35439. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.16830/0.30896. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.17092/0.34590. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.17058/0.35958. Took 0.15 sec\n",
      "Epoch 71, Loss(train/val) 0.15899/0.36324. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.16732/0.36063. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.16950/0.34311. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.16450/0.34627. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.16564/0.34684. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.16433/0.33391. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.16021/0.32728. Took 0.16 sec\n",
      "Epoch 78, Loss(train/val) 0.16341/0.35169. Took 0.14 sec\n",
      "Epoch 79, Loss(train/val) 0.16021/0.34581. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.15267/0.34260. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.15112/0.33382. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.14345/0.33100. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.14843/0.32572. Took 0.12 sec\n",
      "Epoch 84, Loss(train/val) 0.15090/0.33522. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.15032/0.32987. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.15650/0.33888. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.14755/0.35028. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.14563/0.32403. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.14739/0.34055. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.13694/0.34963. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.14496/0.34580. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.14322/0.33327. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.14634/0.34981. Took 0.15 sec\n",
      "Epoch 94, Loss(train/val) 0.14348/0.33169. Took 0.14 sec\n",
      "Epoch 95, Loss(train/val) 0.14247/0.34250. Took 0.15 sec\n",
      "Epoch 96, Loss(train/val) 0.13238/0.32350. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.14252/0.32221. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.13631/0.32381. Took 0.15 sec\n",
      "Epoch 99, Loss(train/val) 0.13538/0.33742. Took 0.14 sec\n",
      "ACC: 0.671875, MCC: 0.31142879922688105\n",
      "Epoch 0, Loss(train/val) 0.49474/0.48350. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.47467/0.45366. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.44420/0.42918. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.41563/0.42021. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.39950/0.40551. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.38387/0.39483. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.37285/0.36594. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.35994/0.34555. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.35669/0.34755. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.34532/0.31866. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.33182/0.31834. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.31548/0.31978. Took 0.15 sec\n",
      "Epoch 12, Loss(train/val) 0.31427/0.35856. Took 0.16 sec\n",
      "Epoch 13, Loss(train/val) 0.32852/0.32882. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.30320/0.34177. Took 0.16 sec\n",
      "Epoch 15, Loss(train/val) 0.29814/0.30727. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.29557/0.32892. Took 0.15 sec\n",
      "Epoch 17, Loss(train/val) 0.27858/0.33342. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.30031/0.32299. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.28757/0.32546. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.28328/0.30841. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.28903/0.30172. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.28663/0.29937. Took 0.15 sec\n",
      "Epoch 23, Loss(train/val) 0.27517/0.30216. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.27164/0.32285. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.27649/0.35763. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.29505/0.37275. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.27371/0.34523. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.26768/0.31284. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.27240/0.36893. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.25585/0.36442. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.26360/0.36315. Took 0.17 sec\n",
      "Epoch 32, Loss(train/val) 0.25883/0.35044. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.24641/0.32863. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.26398/0.27180. Took 0.19 sec\n",
      "Epoch 35, Loss(train/val) 0.26622/0.32588. Took 0.17 sec\n",
      "Epoch 36, Loss(train/val) 0.25816/0.28942. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.25581/0.33226. Took 0.16 sec\n",
      "Epoch 38, Loss(train/val) 0.23700/0.33709. Took 0.16 sec\n",
      "Epoch 39, Loss(train/val) 0.23893/0.33525. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.23645/0.33483. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.23902/0.32996. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.23512/0.32433. Took 0.15 sec\n",
      "Epoch 43, Loss(train/val) 0.23120/0.33261. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.23445/0.32672. Took 0.17 sec\n",
      "Epoch 45, Loss(train/val) 0.23045/0.32209. Took 0.15 sec\n",
      "Epoch 46, Loss(train/val) 0.21869/0.32699. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.23312/0.38260. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.23647/0.32888. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.21832/0.32765. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.22298/0.32588. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.21822/0.33623. Took 0.12 sec\n",
      "Epoch 52, Loss(train/val) 0.21222/0.31154. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) 0.22769/0.33455. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.22488/0.32711. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.21475/0.33588. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.21190/0.33591. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.21574/0.32854. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.21518/0.35637. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.22432/0.31764. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.20717/0.32826. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.22497/0.33582. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.20963/0.29266. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.22239/0.32555. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.20651/0.34002. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.21094/0.33113. Took 0.17 sec\n",
      "Epoch 66, Loss(train/val) 0.20311/0.33920. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) 0.19939/0.35331. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.20817/0.34821. Took 0.14 sec\n",
      "Epoch 69, Loss(train/val) 0.21251/0.35476. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.19389/0.32139. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.18725/0.32695. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.19440/0.33492. Took 0.15 sec\n",
      "Epoch 73, Loss(train/val) 0.19921/0.32781. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.18916/0.32367. Took 0.15 sec\n",
      "Epoch 75, Loss(train/val) 0.19052/0.33281. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.19161/0.34019. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.18671/0.32084. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.19704/0.30486. Took 0.15 sec\n",
      "Epoch 79, Loss(train/val) 0.19401/0.34444. Took 0.15 sec\n",
      "Epoch 80, Loss(train/val) 0.18628/0.34739. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.18175/0.31617. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.19231/0.32119. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) 0.17348/0.33531. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.18734/0.31728. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.18552/0.37529. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.18966/0.37312. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.18814/0.33298. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.18063/0.32439. Took 0.15 sec\n",
      "Epoch 89, Loss(train/val) 0.17537/0.34035. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.19006/0.34935. Took 0.14 sec\n",
      "Epoch 91, Loss(train/val) 0.18584/0.33594. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.17439/0.32092. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.18117/0.33398. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.17170/0.32064. Took 0.15 sec\n",
      "Epoch 95, Loss(train/val) 0.17267/0.34428. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.17644/0.33025. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.17232/0.31368. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.17139/0.30580. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.17621/0.31282. Took 0.15 sec\n",
      "ACC: 0.65625, MCC: 0.31159465034477757\n",
      "Epoch 0, Loss(train/val) 0.49530/0.48850. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.47768/0.46499. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.44875/0.43056. Took 0.15 sec\n",
      "Epoch 3, Loss(train/val) 0.41522/0.41077. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.39153/0.37462. Took 0.16 sec\n",
      "Epoch 5, Loss(train/val) 0.37410/0.36554. Took 0.15 sec\n",
      "Epoch 6, Loss(train/val) 0.35801/0.35567. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.33768/0.36617. Took 0.15 sec\n",
      "Epoch 8, Loss(train/val) 0.34225/0.38566. Took 0.17 sec\n",
      "Epoch 9, Loss(train/val) 0.33116/0.35612. Took 0.15 sec\n",
      "Epoch 10, Loss(train/val) 0.30798/0.35501. Took 0.18 sec\n",
      "Epoch 11, Loss(train/val) 0.30520/0.34768. Took 0.15 sec\n",
      "Epoch 12, Loss(train/val) 0.30156/0.34600. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.28743/0.33631. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.28514/0.34998. Took 0.15 sec\n",
      "Epoch 15, Loss(train/val) 0.29432/0.33110. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.27873/0.33576. Took 0.15 sec\n",
      "Epoch 17, Loss(train/val) 0.28371/0.33054. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.27414/0.32520. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.28048/0.32569. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.26762/0.31908. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.27814/0.31656. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.26446/0.36719. Took 0.16 sec\n",
      "Epoch 23, Loss(train/val) 0.26935/0.32525. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.25974/0.32339. Took 0.16 sec\n",
      "Epoch 25, Loss(train/val) 0.25926/0.31947. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.25280/0.31636. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.25960/0.31752. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.24971/0.32803. Took 0.18 sec\n",
      "Epoch 29, Loss(train/val) 0.24551/0.32952. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.25423/0.33806. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.24425/0.36018. Took 0.16 sec\n",
      "Epoch 32, Loss(train/val) 0.25574/0.35096. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.23897/0.34021. Took 0.13 sec\n",
      "Epoch 34, Loss(train/val) 0.23407/0.32788. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.23443/0.36232. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.23045/0.37467. Took 0.13 sec\n",
      "Epoch 37, Loss(train/val) 0.23205/0.35824. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.23341/0.33914. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.21753/0.31988. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.22269/0.33541. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.22545/0.33666. Took 0.15 sec\n",
      "Epoch 42, Loss(train/val) 0.21904/0.34127. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.22693/0.35265. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.21286/0.33544. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.22212/0.30768. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.20161/0.33630. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.21517/0.31329. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.20894/0.31220. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.20436/0.33672. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.20378/0.33185. Took 0.14 sec\n",
      "Epoch 51, Loss(train/val) 0.21091/0.34029. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.20670/0.32489. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) 0.19872/0.32033. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.20576/0.30728. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.20447/0.35078. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.19204/0.33589. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.20215/0.31675. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.19384/0.34651. Took 0.14 sec\n",
      "Epoch 59, Loss(train/val) 0.19481/0.35423. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.19646/0.34005. Took 0.14 sec\n",
      "Epoch 61, Loss(train/val) 0.18454/0.36915. Took 0.15 sec\n",
      "Epoch 62, Loss(train/val) 0.19366/0.32129. Took 0.15 sec\n",
      "Epoch 63, Loss(train/val) 0.18640/0.33366. Took 0.15 sec\n",
      "Epoch 64, Loss(train/val) 0.17318/0.33210. Took 0.16 sec\n",
      "Epoch 65, Loss(train/val) 0.17960/0.31688. Took 0.15 sec\n",
      "Epoch 66, Loss(train/val) 0.18477/0.37636. Took 0.15 sec\n",
      "Epoch 67, Loss(train/val) 0.18491/0.36563. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.17660/0.36930. Took 0.14 sec\n",
      "Epoch 69, Loss(train/val) 0.17580/0.33285. Took 0.15 sec\n",
      "Epoch 70, Loss(train/val) 0.17131/0.36262. Took 0.17 sec\n",
      "Epoch 71, Loss(train/val) 0.16420/0.37299. Took 0.17 sec\n",
      "Epoch 72, Loss(train/val) 0.17265/0.33817. Took 0.15 sec\n",
      "Epoch 73, Loss(train/val) 0.16689/0.34293. Took 0.15 sec\n",
      "Epoch 74, Loss(train/val) 0.16277/0.35748. Took 0.15 sec\n",
      "Epoch 75, Loss(train/val) 0.16301/0.33351. Took 0.15 sec\n",
      "Epoch 76, Loss(train/val) 0.16784/0.34197. Took 0.15 sec\n",
      "Epoch 77, Loss(train/val) 0.16331/0.34107. Took 0.17 sec\n",
      "Epoch 78, Loss(train/val) 0.17261/0.35528. Took 0.15 sec\n",
      "Epoch 79, Loss(train/val) 0.17772/0.37132. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.16012/0.30923. Took 0.15 sec\n",
      "Epoch 81, Loss(train/val) 0.15705/0.34417. Took 0.15 sec\n",
      "Epoch 82, Loss(train/val) 0.16417/0.34493. Took 0.15 sec\n",
      "Epoch 83, Loss(train/val) 0.16450/0.31945. Took 0.15 sec\n",
      "Epoch 84, Loss(train/val) 0.16006/0.32576. Took 0.15 sec\n",
      "Epoch 85, Loss(train/val) 0.15397/0.37037. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.16103/0.30371. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.15916/0.30512. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.14813/0.30420. Took 0.15 sec\n",
      "Epoch 89, Loss(train/val) 0.15351/0.33301. Took 0.15 sec\n",
      "Epoch 90, Loss(train/val) 0.15591/0.26165. Took 0.14 sec\n",
      "Epoch 91, Loss(train/val) 0.16073/0.34352. Took 0.15 sec\n",
      "Epoch 92, Loss(train/val) 0.15457/0.35515. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.15367/0.28717. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.15513/0.34063. Took 0.14 sec\n",
      "Epoch 95, Loss(train/val) 0.15405/0.29755. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.15216/0.36517. Took 0.16 sec\n",
      "Epoch 97, Loss(train/val) 0.15270/0.33605. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.14201/0.32738. Took 0.14 sec\n",
      "Epoch 99, Loss(train/val) 0.15475/0.31491. Took 0.15 sec\n",
      "ACC: 0.625, MCC: 0.3018706893286188\n",
      "Epoch 0, Loss(train/val) 0.49425/0.47250. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.47732/0.43556. Took 0.15 sec\n",
      "Epoch 2, Loss(train/val) 0.44729/0.38146. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.41382/0.35014. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.39166/0.34145. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.37297/0.34213. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.36240/0.34934. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.35360/0.35052. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.34413/0.35108. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.32940/0.33066. Took 0.19 sec\n",
      "Epoch 10, Loss(train/val) 0.32230/0.34804. Took 0.16 sec\n",
      "Epoch 11, Loss(train/val) 0.30216/0.32386. Took 0.15 sec\n",
      "Epoch 12, Loss(train/val) 0.30862/0.32500. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.29381/0.32625. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.28383/0.31067. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.28240/0.31467. Took 0.16 sec\n",
      "Epoch 16, Loss(train/val) 0.27736/0.31524. Took 0.15 sec\n",
      "Epoch 17, Loss(train/val) 0.27662/0.32956. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.29837/0.32857. Took 0.15 sec\n",
      "Epoch 19, Loss(train/val) 0.28906/0.32836. Took 0.16 sec\n",
      "Epoch 20, Loss(train/val) 0.26914/0.29119. Took 0.15 sec\n",
      "Epoch 21, Loss(train/val) 0.27283/0.30003. Took 0.16 sec\n",
      "Epoch 22, Loss(train/val) 0.25831/0.29263. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.25707/0.27708. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.25757/0.29566. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.25429/0.28154. Took 0.16 sec\n",
      "Epoch 26, Loss(train/val) 0.25014/0.32305. Took 0.15 sec\n",
      "Epoch 27, Loss(train/val) 0.25993/0.32264. Took 0.16 sec\n",
      "Epoch 28, Loss(train/val) 0.25450/0.28206. Took 0.18 sec\n",
      "Epoch 29, Loss(train/val) 0.25078/0.31273. Took 0.16 sec\n",
      "Epoch 30, Loss(train/val) 0.24412/0.29196. Took 0.17 sec\n",
      "Epoch 31, Loss(train/val) 0.23050/0.28664. Took 0.17 sec\n",
      "Epoch 32, Loss(train/val) 0.23699/0.28583. Took 0.16 sec\n",
      "Epoch 33, Loss(train/val) 0.23199/0.30191. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.23018/0.29196. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.23073/0.28044. Took 0.15 sec\n",
      "Epoch 36, Loss(train/val) 0.22125/0.31140. Took 0.16 sec\n",
      "Epoch 37, Loss(train/val) 0.23915/0.32050. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.22604/0.30121. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.22336/0.30048. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.21931/0.30474. Took 0.15 sec\n",
      "Epoch 41, Loss(train/val) 0.22163/0.29141. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.21039/0.32246. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.21616/0.30069. Took 0.15 sec\n",
      "Epoch 44, Loss(train/val) 0.21022/0.30540. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.19971/0.30005. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.21229/0.31371. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.21148/0.30434. Took 0.15 sec\n",
      "Epoch 48, Loss(train/val) 0.19747/0.31353. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.20643/0.30491. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.20092/0.33020. Took 0.15 sec\n",
      "Epoch 51, Loss(train/val) 0.20336/0.29749. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.20901/0.30969. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) 0.21064/0.30763. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.19349/0.29245. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.20277/0.29342. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.19408/0.30353. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.19244/0.29506. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.19534/0.29488. Took 0.14 sec\n",
      "Epoch 59, Loss(train/val) 0.19457/0.28069. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.19220/0.29013. Took 0.15 sec\n",
      "Epoch 61, Loss(train/val) 0.18930/0.30991. Took 0.15 sec\n",
      "Epoch 62, Loss(train/val) 0.18956/0.28964. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.18672/0.29953. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.18734/0.28315. Took 0.15 sec\n",
      "Epoch 65, Loss(train/val) 0.18187/0.30661. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.17795/0.29672. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.18004/0.29825. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.18198/0.29038. Took 0.14 sec\n",
      "Epoch 69, Loss(train/val) 0.18795/0.26881. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.18126/0.28256. Took 0.12 sec\n",
      "Epoch 71, Loss(train/val) 0.19437/0.30644. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.18505/0.28921. Took 0.12 sec\n",
      "Epoch 73, Loss(train/val) 0.18109/0.28871. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.19105/0.27743. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) 0.17047/0.29912. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.18331/0.29641. Took 0.12 sec\n",
      "Epoch 77, Loss(train/val) 0.17690/0.30107. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.18518/0.28991. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.17259/0.27334. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.16622/0.27868. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.16814/0.28688. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.17345/0.28446. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) 0.17392/0.28303. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.16495/0.29822. Took 0.12 sec\n",
      "Epoch 85, Loss(train/val) 0.17780/0.28406. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.17327/0.28922. Took 0.12 sec\n",
      "Epoch 87, Loss(train/val) 0.15221/0.29684. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.17666/0.28154. Took 0.12 sec\n",
      "Epoch 89, Loss(train/val) 0.16853/0.28336. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.17131/0.28058. Took 0.12 sec\n",
      "Epoch 91, Loss(train/val) 0.16236/0.28446. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.16101/0.28049. Took 0.12 sec\n",
      "Epoch 93, Loss(train/val) 0.15756/0.28074. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.16068/0.28515. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.15730/0.29013. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.15730/0.30280. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.15704/0.28003. Took 0.12 sec\n",
      "Epoch 98, Loss(train/val) 0.15968/0.28973. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.15719/0.28569. Took 0.13 sec\n",
      "ACC: 0.6875, MCC: 0.375\n",
      "Epoch 0, Loss(train/val) 0.49080/0.48914. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.46954/0.46904. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.43512/0.43024. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.40670/0.41073. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.39155/0.40080. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.37782/0.38888. Took 0.12 sec\n",
      "Epoch 6, Loss(train/val) 0.36189/0.39489. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.33619/0.41370. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.32172/0.39944. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.30573/0.35414. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.29989/0.44668. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.29098/0.37520. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.28835/0.47580. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.29195/0.36296. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.27515/0.36974. Took 0.15 sec\n",
      "Epoch 15, Loss(train/val) 0.26564/0.36718. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.27260/0.38147. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.25904/0.36741. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.25132/0.37706. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.26318/0.37927. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.25045/0.37162. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.25018/0.36920. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.24362/0.36849. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.24223/0.37431. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.24711/0.36565. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.24173/0.38258. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.23450/0.36156. Took 0.13 sec\n",
      "Epoch 27, Loss(train/val) 0.23448/0.35286. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.22797/0.35190. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.24284/0.39452. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.23316/0.38091. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.22071/0.37028. Took 0.13 sec\n",
      "Epoch 32, Loss(train/val) 0.22397/0.36209. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.21987/0.38479. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.22185/0.38876. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.20646/0.37607. Took 0.13 sec\n",
      "Epoch 36, Loss(train/val) 0.21398/0.38795. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.21505/0.38928. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.20776/0.40030. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.19398/0.37318. Took 0.15 sec\n",
      "Epoch 40, Loss(train/val) 0.20607/0.40403. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.20172/0.37070. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.19634/0.41091. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.19905/0.40232. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.20218/0.41290. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.19816/0.39100. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.19296/0.40589. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.18994/0.39650. Took 0.12 sec\n",
      "Epoch 48, Loss(train/val) 0.18550/0.39993. Took 0.12 sec\n",
      "Epoch 49, Loss(train/val) 0.18776/0.38705. Took 0.12 sec\n",
      "Epoch 50, Loss(train/val) 0.19098/0.43329. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.18883/0.37270. Took 0.12 sec\n",
      "Epoch 52, Loss(train/val) 0.18285/0.41586. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) 0.18554/0.41046. Took 0.12 sec\n",
      "Epoch 54, Loss(train/val) 0.18700/0.40140. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.17914/0.39697. Took 0.12 sec\n",
      "Epoch 56, Loss(train/val) 0.18128/0.38866. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.18807/0.39685. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.17525/0.37779. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.18265/0.39257. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.18011/0.40593. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.17525/0.40376. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.18062/0.40885. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.18231/0.41246. Took 0.12 sec\n",
      "Epoch 64, Loss(train/val) 0.18322/0.44188. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.17468/0.41875. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.17518/0.41874. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.16955/0.43215. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.17525/0.39977. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.17176/0.41435. Took 0.12 sec\n",
      "Epoch 70, Loss(train/val) 0.16944/0.41104. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.17393/0.40676. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.17158/0.39542. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.16186/0.40623. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.16479/0.42423. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.17019/0.41817. Took 0.12 sec\n",
      "Epoch 76, Loss(train/val) 0.16101/0.42349. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.16374/0.43933. Took 0.12 sec\n",
      "Epoch 78, Loss(train/val) 0.16193/0.41743. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.17296/0.39938. Took 0.12 sec\n",
      "Epoch 80, Loss(train/val) 0.17739/0.44467. Took 0.12 sec\n",
      "Epoch 81, Loss(train/val) 0.15952/0.39594. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.17022/0.39355. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.16489/0.40416. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.15758/0.39613. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.16031/0.47577. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.15866/0.39114. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.15639/0.43323. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.15438/0.43384. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.14748/0.42785. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.15335/0.43215. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.15057/0.42926. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.14437/0.42197. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.15317/0.42558. Took 0.12 sec\n",
      "Epoch 94, Loss(train/val) 0.15424/0.45746. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.15139/0.42207. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.14834/0.42085. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.15434/0.45289. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.14576/0.41758. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.15554/0.43284. Took 0.13 sec\n",
      "ACC: 0.671875, MCC: 0.3400501664684957\n",
      "Epoch 0, Loss(train/val) 0.49528/0.49034. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.47802/0.46815. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.44687/0.41890. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.40973/0.37948. Took 0.12 sec\n",
      "Epoch 4, Loss(train/val) 0.39064/0.38239. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.37319/0.34655. Took 0.12 sec\n",
      "Epoch 6, Loss(train/val) 0.36248/0.33966. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.35386/0.34290. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.32870/0.32396. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.31393/0.33391. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.30024/0.34211. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.28397/0.39547. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.29892/0.33679. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.27860/0.34399. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.28254/0.34631. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.27153/0.34465. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.26739/0.35955. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.26077/0.40489. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.25748/0.38308. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.26152/0.39551. Took 0.15 sec\n",
      "Epoch 20, Loss(train/val) 0.25523/0.41856. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.26924/0.38440. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.25556/0.43142. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.25786/0.40477. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.24712/0.43238. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.24220/0.41165. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.24379/0.43889. Took 0.13 sec\n",
      "Epoch 27, Loss(train/val) 0.23570/0.41657. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.23876/0.44983. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.22679/0.42191. Took 0.13 sec\n",
      "Epoch 30, Loss(train/val) 0.22680/0.41268. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.22941/0.43453. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.22356/0.40176. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.22405/0.42062. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.22463/0.41068. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.22313/0.45181. Took 0.15 sec\n",
      "Epoch 36, Loss(train/val) 0.23561/0.43515. Took 0.13 sec\n",
      "Epoch 37, Loss(train/val) 0.22500/0.44534. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.23142/0.38769. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.21430/0.41841. Took 0.12 sec\n",
      "Epoch 40, Loss(train/val) 0.21450/0.41251. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.20973/0.43815. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.20317/0.44131. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.20948/0.41005. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.21526/0.42100. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.21624/0.41378. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.20211/0.42671. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.19474/0.42708. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.19003/0.42759. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.20173/0.40364. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.18940/0.44002. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.19174/0.42383. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.18759/0.43067. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.19431/0.40725. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.18744/0.41133. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.18454/0.41578. Took 0.12 sec\n",
      "Epoch 56, Loss(train/val) 0.19223/0.39946. Took 0.12 sec\n",
      "Epoch 57, Loss(train/val) 0.17872/0.41849. Took 0.12 sec\n",
      "Epoch 58, Loss(train/val) 0.19484/0.37802. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.19605/0.39727. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.20619/0.40615. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.19397/0.39345. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.17958/0.36558. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.17939/0.39227. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.18192/0.37003. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.17947/0.37337. Took 0.12 sec\n",
      "Epoch 66, Loss(train/val) 0.17483/0.35863. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.18140/0.35771. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.17553/0.36039. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.17747/0.38645. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.16799/0.37020. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.16216/0.37566. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.16308/0.38951. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.16672/0.38639. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.16596/0.37062. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.16001/0.40006. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.16446/0.36762. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.16053/0.38067. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.16268/0.36481. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.16527/0.38535. Took 0.12 sec\n",
      "Epoch 80, Loss(train/val) 0.15175/0.33637. Took 0.12 sec\n",
      "Epoch 81, Loss(train/val) 0.15554/0.36325. Took 0.12 sec\n",
      "Epoch 82, Loss(train/val) 0.15507/0.37698. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.15301/0.36866. Took 0.12 sec\n",
      "Epoch 84, Loss(train/val) 0.16213/0.36261. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.15444/0.33577. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.13997/0.35384. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.15797/0.31127. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.15646/0.33379. Took 0.14 sec\n",
      "Epoch 89, Loss(train/val) 0.16149/0.33054. Took 0.12 sec\n",
      "Epoch 90, Loss(train/val) 0.14500/0.30633. Took 0.12 sec\n",
      "Epoch 91, Loss(train/val) 0.14577/0.30630. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.15048/0.32143. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.15506/0.31119. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.15559/0.30001. Took 0.14 sec\n",
      "Epoch 95, Loss(train/val) 0.15905/0.34521. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.15516/0.33466. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.14348/0.33565. Took 0.12 sec\n",
      "Epoch 98, Loss(train/val) 0.14325/0.36884. Took 0.12 sec\n",
      "Epoch 99, Loss(train/val) 0.14123/0.32467. Took 0.12 sec\n",
      "ACC: 0.59375, MCC: 0.19364916731037085\n",
      "Epoch 0, Loss(train/val) 0.49006/0.47797. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.46993/0.44682. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.43981/0.41740. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.41338/0.40862. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.39611/0.39618. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.38285/0.39126. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.37274/0.38549. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.35662/0.37294. Took 0.16 sec\n",
      "Epoch 8, Loss(train/val) 0.34207/0.33345. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.33791/0.32581. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.33127/0.32547. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.33133/0.34466. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.31376/0.29483. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.31248/0.30315. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.30778/0.32582. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.30678/0.29246. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.28911/0.28049. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.30104/0.30513. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.29568/0.26462. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.29232/0.28195. Took 0.15 sec\n",
      "Epoch 20, Loss(train/val) 0.27911/0.29587. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.28029/0.28286. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.28527/0.29115. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.27446/0.28064. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.27770/0.32549. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.27889/0.28823. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.27589/0.30851. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.27934/0.30455. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.27718/0.31016. Took 0.13 sec\n",
      "Epoch 29, Loss(train/val) 0.27619/0.30634. Took 0.13 sec\n",
      "Epoch 30, Loss(train/val) 0.26505/0.29034. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.27226/0.31294. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.26324/0.31639. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.24547/0.30887. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.25365/0.31303. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.24888/0.30819. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.23956/0.31139. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.25072/0.32635. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.24701/0.33735. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.25136/0.32537. Took 0.12 sec\n",
      "Epoch 40, Loss(train/val) 0.25781/0.32769. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.24043/0.32786. Took 0.12 sec\n",
      "Epoch 42, Loss(train/val) 0.23961/0.31945. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.24145/0.35782. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.23300/0.34057. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.23692/0.34556. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.23181/0.33179. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.21910/0.33695. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.23072/0.33912. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.22163/0.32339. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.22001/0.31733. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.23456/0.33817. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.22537/0.37186. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.21724/0.32110. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.21448/0.35499. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.21377/0.33383. Took 0.12 sec\n",
      "Epoch 56, Loss(train/val) 0.22082/0.34927. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.21945/0.32561. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.21108/0.34447. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.21784/0.34580. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.21725/0.37636. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.21511/0.35770. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.20162/0.31402. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.20685/0.35210. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.20949/0.34827. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.20379/0.34819. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.19536/0.34271. Took 0.12 sec\n",
      "Epoch 67, Loss(train/val) 0.19905/0.34987. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.19958/0.33786. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.20218/0.32532. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.18495/0.32876. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.19342/0.32573. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.19028/0.33848. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.18142/0.33395. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.19384/0.34120. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.18335/0.33676. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.17995/0.32996. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.17332/0.31670. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.18130/0.34164. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.19132/0.33831. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.18249/0.36718. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.18573/0.34714. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.17793/0.37950. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.17621/0.37622. Took 0.12 sec\n",
      "Epoch 84, Loss(train/val) 0.17882/0.33738. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.17367/0.31959. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.16646/0.35051. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.17011/0.35084. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.16942/0.37102. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.17512/0.36237. Took 0.12 sec\n",
      "Epoch 90, Loss(train/val) 0.16884/0.33945. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.16393/0.35122. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.16419/0.33532. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.16789/0.35182. Took 0.12 sec\n",
      "Epoch 94, Loss(train/val) 0.16687/0.36275. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.17227/0.35276. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.16620/0.37179. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.16466/0.33337. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.15890/0.32666. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.16954/0.33545. Took 0.13 sec\n",
      "ACC: 0.703125, MCC: 0.4197552742803491\n",
      "Epoch 0, Loss(train/val) 0.49186/0.47973. Took 0.13 sec\n",
      "Epoch 1, Loss(train/val) 0.46583/0.44187. Took 0.12 sec\n",
      "Epoch 2, Loss(train/val) 0.42956/0.39029. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.40117/0.34534. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.38909/0.31321. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.37344/0.31632. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.36755/0.30645. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.36258/0.28921. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.35342/0.27842. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.34857/0.29320. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.33917/0.28685. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.33519/0.26791. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.32622/0.27884. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.31598/0.28742. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.30846/0.30080. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.30426/0.28589. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.29656/0.31513. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.28962/0.29541. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.29271/0.28470. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.29383/0.31822. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.28845/0.33164. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.28141/0.32011. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.27713/0.32952. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.26773/0.31408. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.26821/0.31711. Took 0.15 sec\n",
      "Epoch 25, Loss(train/val) 0.27135/0.32765. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.26207/0.32842. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.25746/0.32926. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.25933/0.31933. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.25030/0.35329. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.24219/0.32224. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.24808/0.31394. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.24259/0.32767. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.23901/0.32183. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.23854/0.35817. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.24391/0.32191. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.23434/0.36689. Took 0.16 sec\n",
      "Epoch 37, Loss(train/val) 0.22946/0.39069. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.24403/0.35347. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.23283/0.32908. Took 0.12 sec\n",
      "Epoch 40, Loss(train/val) 0.23155/0.32446. Took 0.12 sec\n",
      "Epoch 41, Loss(train/val) 0.22398/0.34574. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.21681/0.36748. Took 0.12 sec\n",
      "Epoch 43, Loss(train/val) 0.22667/0.37943. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.21567/0.37119. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.21239/0.36612. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.21763/0.33067. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.21138/0.38094. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.21395/0.37052. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.21105/0.39031. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.21226/0.36855. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.20059/0.37642. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.19905/0.36974. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.19951/0.37812. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.20650/0.37391. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.20330/0.37323. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.20605/0.32744. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.19854/0.31756. Took 0.12 sec\n",
      "Epoch 58, Loss(train/val) 0.19490/0.37329. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.19340/0.34351. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.19635/0.31124. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.19053/0.32558. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.20120/0.34277. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.19495/0.36273. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.18925/0.36597. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.18830/0.35043. Took 0.12 sec\n",
      "Epoch 66, Loss(train/val) 0.18715/0.38425. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.18767/0.32880. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.19436/0.32202. Took 0.12 sec\n",
      "Epoch 69, Loss(train/val) 0.18348/0.33005. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.18282/0.32203. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.18468/0.32319. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.18707/0.32739. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.19105/0.31840. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.19129/0.32871. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.19777/0.36451. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.18967/0.39814. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.18069/0.38364. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.17733/0.38223. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.18259/0.38569. Took 0.12 sec\n",
      "Epoch 80, Loss(train/val) 0.18268/0.34937. Took 0.14 sec\n",
      "Epoch 81, Loss(train/val) 0.17699/0.36775. Took 0.12 sec\n",
      "Epoch 82, Loss(train/val) 0.18221/0.31357. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.18045/0.32744. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.17195/0.35877. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.17602/0.32185. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.18063/0.33215. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.17132/0.34986. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.17339/0.30353. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.17368/0.37165. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.17264/0.36480. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.17456/0.37942. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.16943/0.40638. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.17143/0.40974. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.16919/0.42149. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.16122/0.37094. Took 0.12 sec\n",
      "Epoch 96, Loss(train/val) 0.16227/0.37901. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.16163/0.36361. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.15821/0.35961. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.16407/0.34453. Took 0.13 sec\n",
      "ACC: 0.71875, MCC: 0.45184805705753195\n",
      "Epoch 0, Loss(train/val) 0.49420/0.49559. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.46838/0.48749. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.43214/0.48107. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.40293/0.48323. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.38198/0.45261. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.37163/0.45138. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.36316/0.44427. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.36051/0.37505. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.35344/0.38616. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.34531/0.34760. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.34441/0.37271. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.32839/0.33562. Took 0.15 sec\n",
      "Epoch 12, Loss(train/val) 0.32309/0.35851. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.30951/0.32977. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.29938/0.37487. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.30002/0.31829. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.29143/0.30458. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.28089/0.30772. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.27448/0.32354. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.26599/0.30855. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.26953/0.30739. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.26433/0.30505. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.26213/0.32659. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.25077/0.29792. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.24992/0.30909. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.25779/0.30962. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.26644/0.35415. Took 0.15 sec\n",
      "Epoch 27, Loss(train/val) 0.26720/0.28775. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.25653/0.36549. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.24289/0.36515. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.24482/0.33063. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.24192/0.32346. Took 0.13 sec\n",
      "Epoch 32, Loss(train/val) 0.23132/0.31731. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.23626/0.30817. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.23072/0.32612. Took 0.13 sec\n",
      "Epoch 35, Loss(train/val) 0.23514/0.34084. Took 0.13 sec\n",
      "Epoch 36, Loss(train/val) 0.23327/0.32088. Took 0.13 sec\n",
      "Epoch 37, Loss(train/val) 0.21983/0.31796. Took 0.12 sec\n",
      "Epoch 38, Loss(train/val) 0.22540/0.32540. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.22670/0.30399. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.21620/0.34742. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.21861/0.36714. Took 0.12 sec\n",
      "Epoch 42, Loss(train/val) 0.22088/0.31191. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.22159/0.37278. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.21783/0.30293. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.22726/0.35773. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.21977/0.34860. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.21417/0.37140. Took 0.12 sec\n",
      "Epoch 48, Loss(train/val) 0.20538/0.34258. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.20981/0.37419. Took 0.12 sec\n",
      "Epoch 50, Loss(train/val) 0.21099/0.36969. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.20284/0.36514. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.21800/0.36608. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.20171/0.36623. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.20239/0.36186. Took 0.12 sec\n",
      "Epoch 55, Loss(train/val) 0.19992/0.36025. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.19643/0.34946. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.19676/0.30842. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.19748/0.32904. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.19600/0.33812. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.19089/0.36268. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.19763/0.31336. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.19047/0.34851. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.19761/0.30176. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.18581/0.33959. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.18613/0.34633. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.19406/0.33520. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.18710/0.31885. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.18563/0.34195. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.17991/0.36243. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.18692/0.33460. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.18198/0.33787. Took 0.12 sec\n",
      "Epoch 72, Loss(train/val) 0.18264/0.33369. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.18167/0.31642. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.17699/0.34163. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.17548/0.34266. Took 0.12 sec\n",
      "Epoch 76, Loss(train/val) 0.17925/0.33228. Took 0.12 sec\n",
      "Epoch 77, Loss(train/val) 0.17373/0.34577. Took 0.12 sec\n",
      "Epoch 78, Loss(train/val) 0.17638/0.37355. Took 0.12 sec\n",
      "Epoch 79, Loss(train/val) 0.18351/0.29225. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.17663/0.36296. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.17200/0.31635. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.17194/0.30594. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) 0.17136/0.35443. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.16084/0.34261. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.16187/0.33314. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.16809/0.33258. Took 0.12 sec\n",
      "Epoch 87, Loss(train/val) 0.16511/0.35563. Took 0.12 sec\n",
      "Epoch 88, Loss(train/val) 0.16612/0.34637. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.16708/0.37615. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.16892/0.34392. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.15897/0.38210. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.15738/0.36666. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.15486/0.39489. Took 0.12 sec\n",
      "Epoch 94, Loss(train/val) 0.15569/0.35742. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.16084/0.35415. Took 0.12 sec\n",
      "Epoch 96, Loss(train/val) 0.14704/0.38439. Took 0.12 sec\n",
      "Epoch 97, Loss(train/val) 0.15452/0.34140. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.15908/0.37081. Took 0.12 sec\n",
      "Epoch 99, Loss(train/val) 0.15291/0.35398. Took 0.13 sec\n",
      "ACC: 0.609375, MCC: 0.21664795696917594\n",
      "Epoch 0, Loss(train/val) 0.49074/0.48492. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.46491/0.46411. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.43063/0.46016. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.39859/0.46396. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.37688/0.46510. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.36624/0.46793. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.36004/0.46438. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.34787/0.46280. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.34120/0.46517. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.33498/0.43995. Took 0.15 sec\n",
      "Epoch 10, Loss(train/val) 0.32127/0.43644. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.31178/0.39672. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.29656/0.39884. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.30725/0.38472. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.29261/0.39725. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.29452/0.41195. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.28662/0.39262. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.27782/0.39896. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.27274/0.40187. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.26950/0.38556. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.27330/0.37427. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.27636/0.39159. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.26841/0.36381. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.26495/0.39163. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.25751/0.39465. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.25916/0.37762. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.26548/0.41444. Took 0.16 sec\n",
      "Epoch 27, Loss(train/val) 0.26221/0.38057. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.24530/0.37253. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.24047/0.37826. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.24972/0.37717. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.24717/0.37147. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.24299/0.37725. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.23807/0.38069. Took 0.16 sec\n",
      "Epoch 34, Loss(train/val) 0.23405/0.38165. Took 0.13 sec\n",
      "Epoch 35, Loss(train/val) 0.23339/0.39487. Took 0.12 sec\n",
      "Epoch 36, Loss(train/val) 0.23627/0.38819. Took 0.13 sec\n",
      "Epoch 37, Loss(train/val) 0.23008/0.38537. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.22063/0.39226. Took 0.12 sec\n",
      "Epoch 39, Loss(train/val) 0.22985/0.37839. Took 0.12 sec\n",
      "Epoch 40, Loss(train/val) 0.22594/0.37877. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.22970/0.37257. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.22159/0.36298. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.22216/0.38765. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.21082/0.37463. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.21190/0.38015. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.21783/0.38764. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.21576/0.39588. Took 0.12 sec\n",
      "Epoch 48, Loss(train/val) 0.21815/0.40914. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.21582/0.36126. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.20975/0.38856. Took 0.14 sec\n",
      "Epoch 51, Loss(train/val) 0.21246/0.38029. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.21059/0.37507. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.20952/0.36875. Took 0.12 sec\n",
      "Epoch 54, Loss(train/val) 0.20991/0.35327. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.20138/0.35331. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.20680/0.36157. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.20854/0.37874. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.20101/0.38346. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.19564/0.37435. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.19660/0.36002. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.19598/0.36837. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.19041/0.35324. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.19161/0.34753. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.18994/0.38593. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.20057/0.35972. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.18562/0.37068. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.19231/0.35859. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.19022/0.36136. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.19415/0.35682. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.19581/0.36043. Took 0.12 sec\n",
      "Epoch 71, Loss(train/val) 0.18894/0.34294. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.18783/0.35962. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.18352/0.35714. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.18851/0.32996. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.18721/0.37215. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.18217/0.34450. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.18251/0.35587. Took 0.12 sec\n",
      "Epoch 78, Loss(train/val) 0.17761/0.35902. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.17927/0.35757. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.18287/0.32948. Took 0.14 sec\n",
      "Epoch 81, Loss(train/val) 0.18500/0.36608. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.17929/0.36050. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.18011/0.36199. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.18465/0.34221. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.18005/0.36341. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.17244/0.33733. Took 0.12 sec\n",
      "Epoch 87, Loss(train/val) 0.17617/0.35306. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.17943/0.37881. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.17592/0.35900. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.17099/0.34728. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.16794/0.36279. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.16915/0.35798. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.16703/0.36186. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.17666/0.32850. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.16235/0.36444. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.17304/0.35158. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.17146/0.36609. Took 0.12 sec\n",
      "Epoch 98, Loss(train/val) 0.17146/0.31456. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.17030/0.35033. Took 0.13 sec\n",
      "ACC: 0.671875, MCC: 0.33435877499548305\n",
      "Epoch 0, Loss(train/val) 0.48939/0.45351. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.45630/0.37942. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.41647/0.31880. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.39102/0.29523. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.37798/0.28885. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.36516/0.28426. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.35829/0.28449. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.35236/0.27825. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.35021/0.27762. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.33362/0.27282. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.32880/0.26784. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.31862/0.27531. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.31263/0.26683. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.30793/0.26568. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.30431/0.27911. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.29926/0.26318. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.30305/0.30391. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.29967/0.24763. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.29679/0.29310. Took 0.15 sec\n",
      "Epoch 19, Loss(train/val) 0.29273/0.25324. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.28211/0.25657. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.28022/0.25729. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.27441/0.24471. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.26919/0.28434. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.26922/0.27345. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.26842/0.27872. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.25994/0.28930. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.26470/0.27190. Took 0.13 sec\n",
      "Epoch 28, Loss(train/val) 0.25908/0.26580. Took 0.13 sec\n",
      "Epoch 29, Loss(train/val) 0.25224/0.28782. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.25367/0.26771. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.25611/0.26863. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.25157/0.26548. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.25004/0.24671. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.25217/0.23859. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.25017/0.26580. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.23383/0.28103. Took 0.16 sec\n",
      "Epoch 37, Loss(train/val) 0.25209/0.34002. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.23434/0.27216. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.23091/0.27745. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.23242/0.25525. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.23138/0.22491. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.22534/0.22194. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.22762/0.22737. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.23223/0.24313. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.21852/0.22689. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.22224/0.27030. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.21907/0.29418. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.21427/0.25392. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.20656/0.23101. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.21469/0.22472. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.21050/0.24262. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.19671/0.23031. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.20214/0.23274. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.20418/0.22377. Took 0.12 sec\n",
      "Epoch 55, Loss(train/val) 0.20162/0.22647. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.19463/0.22213. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.20096/0.23711. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.19537/0.24875. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.19339/0.24629. Took 0.12 sec\n",
      "Epoch 60, Loss(train/val) 0.18698/0.23974. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.18760/0.27417. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.18993/0.24440. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.18456/0.22631. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.18316/0.21955. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.18253/0.22176. Took 0.12 sec\n",
      "Epoch 66, Loss(train/val) 0.18318/0.22482. Took 0.12 sec\n",
      "Epoch 67, Loss(train/val) 0.17768/0.23096. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.17083/0.22517. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.17589/0.22260. Took 0.12 sec\n",
      "Epoch 70, Loss(train/val) 0.17982/0.23143. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.17224/0.22476. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.17255/0.24056. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.17311/0.22352. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.17189/0.22220. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.17503/0.21876. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.17164/0.21262. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.16276/0.22592. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.16073/0.27568. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.15684/0.23063. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.15226/0.25293. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.15088/0.25071. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.15835/0.22481. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.14939/0.23832. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.14928/0.26852. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.15089/0.23631. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.15536/0.26532. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.14788/0.20074. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.14077/0.21268. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.13462/0.21961. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.14119/0.21193. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.14548/0.22527. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.15003/0.21779. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.14007/0.22997. Took 0.12 sec\n",
      "Epoch 94, Loss(train/val) 0.13926/0.26910. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.13605/0.22152. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.13603/0.19229. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.12892/0.22814. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.13032/0.21372. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.14402/0.19697. Took 0.13 sec\n",
      "ACC: 0.703125, MCC: 0.42313649258810365\n",
      "Epoch 0, Loss(train/val) 0.49275/0.47798. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.46648/0.43448. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.42907/0.38665. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.40037/0.37010. Took 0.12 sec\n",
      "Epoch 4, Loss(train/val) 0.38558/0.36835. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.37279/0.36161. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.37076/0.36647. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.35748/0.35963. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.34926/0.35784. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.33995/0.35229. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.32969/0.34488. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.32020/0.34200. Took 0.15 sec\n",
      "Epoch 12, Loss(train/val) 0.31278/0.32952. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.31014/0.35943. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.29971/0.31738. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.29217/0.31881. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.28692/0.33130. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.28801/0.33268. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.28722/0.30637. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.27754/0.34106. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.27577/0.35580. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.27491/0.33213. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.27355/0.35250. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.26667/0.32207. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.24763/0.31460. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.26371/0.33005. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.24974/0.31254. Took 0.13 sec\n",
      "Epoch 27, Loss(train/val) 0.24616/0.31955. Took 0.13 sec\n",
      "Epoch 28, Loss(train/val) 0.24876/0.32494. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.24783/0.32498. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.24122/0.31618. Took 0.17 sec\n",
      "Epoch 31, Loss(train/val) 0.24158/0.32753. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.23112/0.33055. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.23266/0.31343. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.23199/0.30640. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.22446/0.30158. Took 0.13 sec\n",
      "Epoch 36, Loss(train/val) 0.22690/0.33656. Took 0.16 sec\n",
      "Epoch 37, Loss(train/val) 0.21881/0.32052. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.21391/0.31239. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.21548/0.30023. Took 0.12 sec\n",
      "Epoch 40, Loss(train/val) 0.21098/0.29885. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.21771/0.31640. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.21036/0.32571. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.21069/0.33286. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.21007/0.29963. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.21319/0.30837. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.20864/0.32370. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.20801/0.32038. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.21346/0.32762. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.20303/0.28611. Took 0.12 sec\n",
      "Epoch 50, Loss(train/val) 0.19709/0.29046. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.20160/0.32222. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.19505/0.31574. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.19981/0.31577. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.20426/0.32610. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.20155/0.32657. Took 0.12 sec\n",
      "Epoch 56, Loss(train/val) 0.19523/0.31507. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.18793/0.30630. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.18939/0.30454. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.18826/0.28298. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.18777/0.29797. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.19040/0.28214. Took 0.12 sec\n",
      "Epoch 62, Loss(train/val) 0.18430/0.28971. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.18668/0.28758. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.18680/0.28439. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.19254/0.29535. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.18904/0.32693. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.17962/0.31008. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.18961/0.34316. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.17948/0.30757. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.17494/0.31905. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.17920/0.29207. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.17290/0.29673. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.18235/0.31330. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.17275/0.35201. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.17483/0.30256. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.16873/0.31898. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.17001/0.30417. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.16544/0.30224. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.16971/0.30218. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.16690/0.31030. Took 0.14 sec\n",
      "Epoch 81, Loss(train/val) 0.16425/0.28675. Took 0.12 sec\n",
      "Epoch 82, Loss(train/val) 0.17230/0.32840. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.16381/0.31195. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.16906/0.32729. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.15527/0.31341. Took 0.12 sec\n",
      "Epoch 86, Loss(train/val) 0.16092/0.32768. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.15830/0.33192. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.15363/0.32958. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.15081/0.31760. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.16036/0.34207. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.15477/0.33169. Took 0.12 sec\n",
      "Epoch 92, Loss(train/val) 0.15269/0.32851. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.16865/0.34399. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.15565/0.33940. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.15592/0.31767. Took 0.12 sec\n",
      "Epoch 96, Loss(train/val) 0.15158/0.34025. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.15649/0.33254. Took 0.12 sec\n",
      "Epoch 98, Loss(train/val) 0.14779/0.32507. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.15533/0.33477. Took 0.13 sec\n",
      "ACC: 0.59375, MCC: 0.29095718698132317\n",
      "Epoch 0, Loss(train/val) 0.48993/0.47354. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.46043/0.44394. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.42632/0.43239. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.40234/0.41753. Took 0.12 sec\n",
      "Epoch 4, Loss(train/val) 0.39155/0.39615. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.38165/0.36811. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.36893/0.35454. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.36157/0.35745. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.35157/0.35946. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.34518/0.37933. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.34158/0.37155. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.33323/0.36239. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.32981/0.37467. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.32232/0.38354. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.32075/0.36941. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.32061/0.39765. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.30619/0.38386. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.29421/0.39333. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.29528/0.40415. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.29453/0.38734. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.28359/0.38745. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.27669/0.39002. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.28296/0.38391. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.27510/0.39762. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.25916/0.36090. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.25230/0.35604. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.26478/0.37167. Took 0.13 sec\n",
      "Epoch 27, Loss(train/val) 0.26539/0.39268. Took 0.13 sec\n",
      "Epoch 28, Loss(train/val) 0.25529/0.34848. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.24637/0.41387. Took 0.13 sec\n",
      "Epoch 30, Loss(train/val) 0.25006/0.35300. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.23839/0.33490. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.23438/0.33708. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.22960/0.37431. Took 0.13 sec\n",
      "Epoch 34, Loss(train/val) 0.22580/0.33077. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.22240/0.37344. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.24321/0.38653. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.22329/0.34738. Took 0.15 sec\n",
      "Epoch 38, Loss(train/val) 0.22014/0.39532. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.22097/0.33912. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.20696/0.36012. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.20540/0.35515. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.20311/0.34221. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.20507/0.41889. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.19770/0.33630. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.19852/0.38460. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.19980/0.32153. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.21038/0.32932. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.19408/0.38558. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.20607/0.38859. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.18556/0.40578. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.19391/0.40728. Took 0.12 sec\n",
      "Epoch 52, Loss(train/val) 0.19096/0.40393. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.18030/0.41622. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.18453/0.43865. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.17699/0.38180. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.17984/0.41799. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.17283/0.39968. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.16605/0.40955. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.16783/0.42824. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.17133/0.37468. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.17952/0.40084. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.16973/0.41731. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.17540/0.37773. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.18451/0.42641. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.17686/0.42900. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.16925/0.40634. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.16929/0.40888. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.15521/0.39980. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.15824/0.42057. Took 0.12 sec\n",
      "Epoch 70, Loss(train/val) 0.15379/0.42493. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.14844/0.42094. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.15959/0.37311. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.15776/0.43472. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.15983/0.36838. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.15344/0.44565. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.15302/0.39801. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.14181/0.40339. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.14705/0.41459. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.14644/0.40944. Took 0.12 sec\n",
      "Epoch 80, Loss(train/val) 0.15307/0.41136. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.14244/0.36422. Took 0.12 sec\n",
      "Epoch 82, Loss(train/val) 0.13655/0.40998. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.14163/0.41083. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.14832/0.37612. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.14688/0.35126. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.14457/0.34886. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.14600/0.35394. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.14188/0.38221. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.13710/0.35104. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.13585/0.35978. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.13586/0.40530. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.13409/0.36966. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.13197/0.38850. Took 0.12 sec\n",
      "Epoch 94, Loss(train/val) 0.13331/0.30954. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.13229/0.38408. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.12741/0.39790. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.12562/0.35468. Took 0.12 sec\n",
      "Epoch 98, Loss(train/val) 0.14133/0.40145. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.13833/0.42732. Took 0.12 sec\n",
      "ACC: 0.6875, MCC: 0.40711742805652384\n",
      "Epoch 0, Loss(train/val) 0.48728/0.49130. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.45318/0.47300. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.41828/0.40803. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.39303/0.37399. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.37564/0.35452. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.36479/0.34675. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.35764/0.32523. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.34457/0.30483. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.33958/0.29714. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.33719/0.29487. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.32900/0.29324. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.32728/0.29674. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.31419/0.30692. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.31052/0.32259. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.29708/0.30981. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.30064/0.31921. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.29551/0.33019. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.28116/0.38493. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.28287/0.39053. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.27552/0.31212. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.26442/0.37367. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.27248/0.36372. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.26044/0.39793. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.26139/0.33438. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.25888/0.38536. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.25545/0.34831. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.25657/0.39843. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.26033/0.33588. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.28133/0.37348. Took 0.13 sec\n",
      "Epoch 29, Loss(train/val) 0.26863/0.36287. Took 0.13 sec\n",
      "Epoch 30, Loss(train/val) 0.25151/0.35416. Took 0.13 sec\n",
      "Epoch 31, Loss(train/val) 0.24226/0.39986. Took 0.13 sec\n",
      "Epoch 32, Loss(train/val) 0.24262/0.38357. Took 0.16 sec\n",
      "Epoch 33, Loss(train/val) 0.24241/0.36671. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.23139/0.42052. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.23559/0.35972. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.23203/0.40121. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.23900/0.37324. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.23060/0.38144. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.22625/0.38087. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.22733/0.37480. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.22366/0.38063. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.22508/0.36126. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.21090/0.37311. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.21190/0.34275. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.20990/0.36418. Took 0.12 sec\n",
      "Epoch 46, Loss(train/val) 0.20249/0.36290. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.19592/0.33466. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.20889/0.35779. Took 0.12 sec\n",
      "Epoch 49, Loss(train/val) 0.20382/0.35511. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.19965/0.32892. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.20058/0.33619. Took 0.12 sec\n",
      "Epoch 52, Loss(train/val) 0.19932/0.34223. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.19300/0.34416. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.19812/0.32805. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.20063/0.35268. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.18931/0.34556. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.19729/0.34435. Took 0.12 sec\n",
      "Epoch 58, Loss(train/val) 0.19796/0.36078. Took 0.12 sec\n",
      "Epoch 59, Loss(train/val) 0.18861/0.35770. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.19046/0.35070. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.19112/0.37249. Took 0.12 sec\n",
      "Epoch 62, Loss(train/val) 0.18613/0.33098. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.18212/0.33661. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.18207/0.34006. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.17729/0.35688. Took 0.12 sec\n",
      "Epoch 66, Loss(train/val) 0.18354/0.34852. Took 0.12 sec\n",
      "Epoch 67, Loss(train/val) 0.17171/0.34448. Took 0.12 sec\n",
      "Epoch 68, Loss(train/val) 0.16810/0.35424. Took 0.12 sec\n",
      "Epoch 69, Loss(train/val) 0.17569/0.35053. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.17048/0.35955. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.17490/0.37292. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.17484/0.35025. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.16718/0.34721. Took 0.12 sec\n",
      "Epoch 74, Loss(train/val) 0.16639/0.34850. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.17036/0.34402. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.16777/0.35432. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.17257/0.35427. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.17121/0.33356. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.16128/0.36168. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.16330/0.34026. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.16874/0.34692. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.15475/0.35460. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.15740/0.34715. Took 0.12 sec\n",
      "Epoch 84, Loss(train/val) 0.17114/0.34803. Took 0.12 sec\n",
      "Epoch 85, Loss(train/val) 0.16018/0.34019. Took 0.12 sec\n",
      "Epoch 86, Loss(train/val) 0.15216/0.34398. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.15728/0.33309. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.15310/0.33361. Took 0.12 sec\n",
      "Epoch 89, Loss(train/val) 0.15663/0.35007. Took 0.12 sec\n",
      "Epoch 90, Loss(train/val) 0.15939/0.35074. Took 0.12 sec\n",
      "Epoch 91, Loss(train/val) 0.15328/0.32390. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.15948/0.34390. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.15506/0.33620. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.16053/0.37841. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.15097/0.34619. Took 0.12 sec\n",
      "Epoch 96, Loss(train/val) 0.15794/0.34523. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.15267/0.35335. Took 0.12 sec\n",
      "Epoch 98, Loss(train/val) 0.14769/0.35167. Took 0.12 sec\n",
      "Epoch 99, Loss(train/val) 0.14675/0.36424. Took 0.13 sec\n",
      "ACC: 0.625, MCC: 0.36156610866311306\n",
      "Epoch 0, Loss(train/val) 0.49086/0.49277. Took 0.13 sec\n",
      "Epoch 1, Loss(train/val) 0.47004/0.48394. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.43886/0.47433. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.40547/0.46730. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.37849/0.46482. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.35745/0.46384. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.34886/0.46590. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.34805/0.46504. Took 0.12 sec\n",
      "Epoch 8, Loss(train/val) 0.33341/0.45307. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.33129/0.45012. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.34011/0.42359. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.31825/0.43487. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.32270/0.43428. Took 0.15 sec\n",
      "Epoch 13, Loss(train/val) 0.30969/0.43639. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.31035/0.41606. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.31321/0.44008. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.31452/0.42735. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.29498/0.38290. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.30245/0.38162. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.29428/0.34377. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.29829/0.43199. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.28596/0.39473. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.27433/0.39094. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.28723/0.37001. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.27861/0.37954. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.26894/0.36354. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.26655/0.36815. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.25952/0.36078. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.27214/0.37646. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.25251/0.35005. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.25549/0.37023. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.25498/0.36399. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.25239/0.35874. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.23776/0.36345. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.24659/0.35824. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.23785/0.35645. Took 0.15 sec\n",
      "Epoch 36, Loss(train/val) 0.23506/0.36896. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.23499/0.36398. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.22440/0.36678. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.23110/0.35819. Took 0.12 sec\n",
      "Epoch 40, Loss(train/val) 0.23173/0.36365. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.22015/0.35231. Took 0.12 sec\n",
      "Epoch 42, Loss(train/val) 0.20661/0.36770. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.21543/0.37014. Took 0.12 sec\n",
      "Epoch 44, Loss(train/val) 0.21628/0.36592. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.21826/0.36898. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.20961/0.36317. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.19901/0.35344. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.20815/0.37229. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.20116/0.36383. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.19866/0.37893. Took 0.14 sec\n",
      "Epoch 51, Loss(train/val) 0.18714/0.37609. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.20275/0.39086. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.20128/0.40946. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.20646/0.37445. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.18839/0.36152. Took 0.12 sec\n",
      "Epoch 56, Loss(train/val) 0.18887/0.37515. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.17981/0.39923. Took 0.12 sec\n",
      "Epoch 58, Loss(train/val) 0.19811/0.37448. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.17863/0.36488. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.18258/0.36626. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.17342/0.38688. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.18037/0.38907. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.16975/0.38050. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.17323/0.36378. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.17032/0.37767. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.17744/0.38954. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.16393/0.36430. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.16320/0.39855. Took 0.14 sec\n",
      "Epoch 69, Loss(train/val) 0.16450/0.38263. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.15935/0.40344. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.16198/0.35983. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.15748/0.35742. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.16972/0.33586. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.16251/0.34729. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.15839/0.40361. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.14926/0.37146. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.16208/0.36166. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.16233/0.38561. Took 0.14 sec\n",
      "Epoch 79, Loss(train/val) 0.15201/0.40468. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.15323/0.38810. Took 0.14 sec\n",
      "Epoch 81, Loss(train/val) 0.15402/0.41651. Took 0.19 sec\n",
      "Epoch 82, Loss(train/val) 0.14852/0.37897. Took 0.17 sec\n",
      "Epoch 83, Loss(train/val) 0.14604/0.36107. Took 0.15 sec\n",
      "Epoch 84, Loss(train/val) 0.14880/0.35240. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.14285/0.35005. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.15060/0.33549. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.14791/0.39343. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.14436/0.33857. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.14426/0.37713. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.15858/0.36514. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.13980/0.34669. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.14182/0.34734. Took 0.15 sec\n",
      "Epoch 93, Loss(train/val) 0.15007/0.37327. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.15227/0.31809. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.14749/0.33227. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.13437/0.37072. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.14099/0.35378. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.14422/0.34023. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.13806/0.36017. Took 0.13 sec\n",
      "ACC: 0.703125, MCC: 0.4020770079059607\n",
      "Epoch 0, Loss(train/val) 0.49270/0.48278. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.47273/0.46761. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.44163/0.45033. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.40856/0.44818. Took 0.12 sec\n",
      "Epoch 4, Loss(train/val) 0.38463/0.43234. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.36519/0.46048. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.35622/0.44911. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.34845/0.42312. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.34396/0.47878. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.33847/0.45726. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.34404/0.41230. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.32869/0.43569. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.32268/0.44650. Took 0.16 sec\n",
      "Epoch 13, Loss(train/val) 0.32079/0.45971. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.32890/0.50370. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.32773/0.46509. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.31105/0.47199. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.30161/0.47263. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.29705/0.45544. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.29647/0.43338. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.28317/0.46353. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.28806/0.44304. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.28708/0.45835. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.28629/0.45328. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.27931/0.43513. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.28290/0.44520. Took 0.16 sec\n",
      "Epoch 26, Loss(train/val) 0.29791/0.48289. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.28283/0.46934. Took 0.13 sec\n",
      "Epoch 28, Loss(train/val) 0.27603/0.46685. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.26736/0.47876. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.27390/0.47984. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.27086/0.47558. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.25618/0.47952. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.26331/0.46291. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.26586/0.43781. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.26693/0.40588. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.25955/0.43435. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.25404/0.46031. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.25292/0.44797. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.24875/0.45942. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.24991/0.44265. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.24415/0.46067. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.25336/0.45018. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.23589/0.46766. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.23616/0.48225. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.23357/0.45942. Took 0.12 sec\n",
      "Epoch 46, Loss(train/val) 0.22631/0.47902. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.22880/0.49341. Took 0.12 sec\n",
      "Epoch 48, Loss(train/val) 0.23870/0.49704. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.24207/0.48024. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.23496/0.46089. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.22378/0.47075. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.22111/0.47705. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.22518/0.45299. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.22142/0.46356. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.21664/0.44982. Took 0.12 sec\n",
      "Epoch 56, Loss(train/val) 0.21932/0.41592. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.20778/0.46474. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.21453/0.49865. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.21627/0.45902. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.22590/0.38954. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.23772/0.38644. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.22349/0.40757. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.20417/0.44780. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.20866/0.41738. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.21410/0.44327. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.20410/0.45441. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.20686/0.45521. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.20340/0.42869. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.21195/0.38515. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.20853/0.42412. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.21537/0.43921. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.19953/0.46375. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.20310/0.46813. Took 0.12 sec\n",
      "Epoch 74, Loss(train/val) 0.20409/0.46348. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.19826/0.45152. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.20109/0.44377. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.19488/0.44583. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.19861/0.47192. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.19498/0.46308. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.18894/0.46484. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.19305/0.47489. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.19097/0.47733. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.18370/0.47492. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.19190/0.46795. Took 0.12 sec\n",
      "Epoch 85, Loss(train/val) 0.19211/0.48216. Took 0.12 sec\n",
      "Epoch 86, Loss(train/val) 0.18939/0.46595. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.18043/0.46594. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.19191/0.46896. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.19884/0.46773. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.19431/0.46399. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.18694/0.45982. Took 0.15 sec\n",
      "Epoch 92, Loss(train/val) 0.19189/0.45834. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.19426/0.46409. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.18732/0.45253. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.17662/0.45393. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.18591/0.45201. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.18599/0.45404. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.18109/0.45618. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.17800/0.46051. Took 0.13 sec\n",
      "ACC: 0.640625, MCC: 0.3323218506999783\n",
      "Epoch 0, Loss(train/val) 0.49339/0.47038. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.47240/0.42457. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.44047/0.39139. Took 0.15 sec\n",
      "Epoch 3, Loss(train/val) 0.41042/0.38339. Took 0.15 sec\n",
      "Epoch 4, Loss(train/val) 0.39735/0.36908. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.37601/0.36697. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.35731/0.37414. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.33699/0.37214. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.33121/0.36074. Took 0.15 sec\n",
      "Epoch 9, Loss(train/val) 0.31957/0.36125. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.31235/0.35524. Took 0.16 sec\n",
      "Epoch 11, Loss(train/val) 0.31530/0.35894. Took 0.18 sec\n",
      "Epoch 12, Loss(train/val) 0.31060/0.35841. Took 0.17 sec\n",
      "Epoch 13, Loss(train/val) 0.30293/0.35946. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.29994/0.34945. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.30421/0.36100. Took 0.17 sec\n",
      "Epoch 16, Loss(train/val) 0.29345/0.35697. Took 0.16 sec\n",
      "Epoch 17, Loss(train/val) 0.28989/0.35649. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.28991/0.35390. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.27992/0.35792. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.27727/0.35761. Took 0.15 sec\n",
      "Epoch 21, Loss(train/val) 0.26959/0.35486. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.26859/0.36006. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.27754/0.36323. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.26990/0.35707. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.26455/0.36266. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.26290/0.36055. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.25263/0.35925. Took 0.16 sec\n",
      "Epoch 28, Loss(train/val) 0.25836/0.34996. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.25239/0.37012. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.25834/0.36571. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.25667/0.34992. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.24035/0.37176. Took 0.13 sec\n",
      "Epoch 33, Loss(train/val) 0.24133/0.34309. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.25141/0.36961. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.23925/0.36553. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.23620/0.38491. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.23600/0.33003. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.22992/0.37209. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.22592/0.38032. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.23914/0.32624. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.22528/0.37687. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.22674/0.37156. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.21951/0.35196. Took 0.12 sec\n",
      "Epoch 44, Loss(train/val) 0.21431/0.36427. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.21978/0.37903. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.21861/0.34278. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.21796/0.37018. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.21356/0.36156. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.21117/0.36184. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.21405/0.35042. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.20356/0.37326. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.19803/0.35109. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.19861/0.35594. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.20337/0.35501. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.19451/0.35925. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.18692/0.32535. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.19543/0.34069. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.19180/0.34881. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.17569/0.32681. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.18072/0.33048. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.18818/0.33606. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.18375/0.34784. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.16378/0.35900. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.16502/0.35955. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.16959/0.36652. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.18117/0.35969. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.17024/0.35258. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.17593/0.33118. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.17020/0.33662. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.16436/0.36212. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.16265/0.36505. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.17018/0.36001. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.16266/0.35682. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.15611/0.37333. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.15511/0.37347. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.15821/0.36275. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.15320/0.36338. Took 0.12 sec\n",
      "Epoch 78, Loss(train/val) 0.15072/0.35444. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.15340/0.36047. Took 0.12 sec\n",
      "Epoch 80, Loss(train/val) 0.16009/0.37634. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.14940/0.37048. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.14153/0.36249. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.15198/0.34834. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.14533/0.37713. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.14394/0.35951. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.14947/0.39704. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.14607/0.40089. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.16075/0.40366. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.14849/0.36902. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.14088/0.36793. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.13694/0.36151. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.13890/0.38766. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.13604/0.37669. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.13666/0.37647. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.13647/0.34874. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.13168/0.37913. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.13519/0.35372. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.13665/0.33991. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.12897/0.34128. Took 0.14 sec\n",
      "ACC: 0.71875, MCC: 0.4555869462835626\n",
      "Epoch 0, Loss(train/val) 0.49133/0.48786. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.46837/0.46443. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.43582/0.43057. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.40582/0.41384. Took 0.12 sec\n",
      "Epoch 4, Loss(train/val) 0.38970/0.41299. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.37683/0.41400. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.36628/0.39904. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.35592/0.39188. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.34131/0.38979. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.33136/0.38666. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.31848/0.38311. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.31412/0.39092. Took 0.15 sec\n",
      "Epoch 12, Loss(train/val) 0.30189/0.38346. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.30177/0.38046. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.29288/0.41180. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.29335/0.33455. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.29892/0.41578. Took 0.16 sec\n",
      "Epoch 17, Loss(train/val) 0.27279/0.41503. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.27198/0.44742. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.27338/0.44970. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.27035/0.43988. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.25964/0.43899. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.26666/0.43529. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.25230/0.44380. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.25344/0.38837. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.24935/0.37858. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.24652/0.42325. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.24364/0.41980. Took 0.13 sec\n",
      "Epoch 28, Loss(train/val) 0.23202/0.38837. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.23195/0.39227. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.23310/0.39836. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.22300/0.38321. Took 0.13 sec\n",
      "Epoch 32, Loss(train/val) 0.23221/0.41188. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.22291/0.39438. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.22560/0.39668. Took 0.16 sec\n",
      "Epoch 35, Loss(train/val) 0.22115/0.40454. Took 0.15 sec\n",
      "Epoch 36, Loss(train/val) 0.20763/0.38923. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.21528/0.39343. Took 0.12 sec\n",
      "Epoch 38, Loss(train/val) 0.20320/0.39723. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.20926/0.40842. Took 0.12 sec\n",
      "Epoch 40, Loss(train/val) 0.21549/0.37558. Took 0.12 sec\n",
      "Epoch 41, Loss(train/val) 0.21509/0.39874. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.21016/0.38357. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.20060/0.38158. Took 0.12 sec\n",
      "Epoch 44, Loss(train/val) 0.20265/0.38032. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.18787/0.36400. Took 0.12 sec\n",
      "Epoch 46, Loss(train/val) 0.19846/0.37723. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.18865/0.37945. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.18559/0.36725. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.20748/0.37978. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.20162/0.35848. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.17337/0.35225. Took 0.12 sec\n",
      "Epoch 52, Loss(train/val) 0.17762/0.34212. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.16989/0.37174. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.17715/0.36417. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.18145/0.35344. Took 0.12 sec\n",
      "Epoch 56, Loss(train/val) 0.16672/0.34189. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.16118/0.34694. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.16160/0.34417. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.16115/0.34811. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.15973/0.35164. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.15175/0.34975. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.15616/0.36146. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.16191/0.35288. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.15747/0.34538. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.16392/0.35014. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.15473/0.34851. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) 0.14516/0.35785. Took 0.12 sec\n",
      "Epoch 68, Loss(train/val) 0.15498/0.34707. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.15270/0.35205. Took 0.12 sec\n",
      "Epoch 70, Loss(train/val) 0.14037/0.35015. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.15654/0.32803. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.14963/0.34282. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.14588/0.32899. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.14617/0.32689. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.13757/0.32978. Took 0.12 sec\n",
      "Epoch 76, Loss(train/val) 0.14627/0.32468. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.13331/0.32951. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.13072/0.33547. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.12897/0.32095. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.12714/0.32415. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.12340/0.33070. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.13347/0.33595. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.13170/0.31905. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.12502/0.31059. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.13075/0.30622. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.12846/0.29933. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.13964/0.32719. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.12165/0.29471. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.13230/0.30885. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.12350/0.32537. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.12245/0.32227. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.11659/0.32540. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.11640/0.32033. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.11548/0.31095. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.11524/0.29960. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.11743/0.29568. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.11610/0.31221. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.10942/0.29944. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.11243/0.30854. Took 0.12 sec\n",
      "ACC: 0.640625, MCC: 0.2933526131391837\n",
      "Epoch 0, Loss(train/val) 0.49371/0.48694. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.47302/0.46110. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.43828/0.43175. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.40443/0.42031. Took 0.12 sec\n",
      "Epoch 4, Loss(train/val) 0.38679/0.39053. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.37968/0.38540. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.36446/0.37896. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.35669/0.36068. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.33870/0.36262. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.33188/0.32937. Took 0.12 sec\n",
      "Epoch 10, Loss(train/val) 0.30054/0.31059. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.29802/0.32488. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.29383/0.29297. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.27664/0.34335. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.27943/0.32172. Took 0.15 sec\n",
      "Epoch 15, Loss(train/val) 0.27811/0.33955. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.26878/0.31122. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.25667/0.28852. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.24931/0.30235. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.24580/0.31986. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.23497/0.30536. Took 0.15 sec\n",
      "Epoch 21, Loss(train/val) 0.22754/0.30900. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.22235/0.31066. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.22114/0.31323. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.21214/0.32620. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.21810/0.31918. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.20766/0.30171. Took 0.13 sec\n",
      "Epoch 27, Loss(train/val) 0.21325/0.32851. Took 0.13 sec\n",
      "Epoch 28, Loss(train/val) 0.21326/0.32058. Took 0.13 sec\n",
      "Epoch 29, Loss(train/val) 0.19733/0.32903. Took 0.13 sec\n",
      "Epoch 30, Loss(train/val) 0.20606/0.33342. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.19507/0.31976. Took 0.13 sec\n",
      "Epoch 32, Loss(train/val) 0.18988/0.33057. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.18999/0.28864. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.20028/0.33089. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.20117/0.31462. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.18956/0.31558. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.18431/0.31817. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.18503/0.33875. Took 0.15 sec\n",
      "Epoch 39, Loss(train/val) 0.17313/0.34806. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.18676/0.34206. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.16688/0.32854. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.17826/0.31648. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.17174/0.33872. Took 0.12 sec\n",
      "Epoch 44, Loss(train/val) 0.17771/0.33779. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.15833/0.33911. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.15861/0.33615. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.16390/0.33682. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.15212/0.33959. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.15846/0.33405. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.15707/0.35410. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.15564/0.31378. Took 0.12 sec\n",
      "Epoch 52, Loss(train/val) 0.16675/0.31729. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.14922/0.34280. Took 0.12 sec\n",
      "Epoch 54, Loss(train/val) 0.15417/0.34151. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.15583/0.35151. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.14986/0.34557. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.14840/0.34577. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.15934/0.33733. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.14620/0.34529. Took 0.12 sec\n",
      "Epoch 60, Loss(train/val) 0.15216/0.32513. Took 0.12 sec\n",
      "Epoch 61, Loss(train/val) 0.14580/0.33812. Took 0.12 sec\n",
      "Epoch 62, Loss(train/val) 0.14501/0.35028. Took 0.12 sec\n",
      "Epoch 63, Loss(train/val) 0.14661/0.34899. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.14026/0.33722. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.14392/0.33064. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.13765/0.34038. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.13906/0.32651. Took 0.12 sec\n",
      "Epoch 68, Loss(train/val) 0.13308/0.33896. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.14442/0.35059. Took 0.12 sec\n",
      "Epoch 70, Loss(train/val) 0.13780/0.33294. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.13054/0.34197. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.13733/0.33546. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.13927/0.34358. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.12734/0.33684. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) 0.13900/0.34336. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.12678/0.33396. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.13460/0.33903. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.11721/0.35729. Took 0.15 sec\n",
      "Epoch 79, Loss(train/val) 0.12552/0.34527. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.12810/0.36586. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.12764/0.35427. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.12538/0.33887. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.12062/0.34425. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.12457/0.33432. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.11501/0.33679. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.13116/0.37149. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.11477/0.34878. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.11974/0.33914. Took 0.14 sec\n",
      "Epoch 89, Loss(train/val) 0.12277/0.33014. Took 0.15 sec\n",
      "Epoch 90, Loss(train/val) 0.11236/0.34715. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.11687/0.33617. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.11979/0.33388. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.12189/0.36759. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.11394/0.34875. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.11676/0.35925. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.11279/0.36131. Took 0.14 sec\n",
      "Epoch 97, Loss(train/val) 0.11262/0.36264. Took 0.15 sec\n",
      "Epoch 98, Loss(train/val) 0.11010/0.33891. Took 0.18 sec\n",
      "Epoch 99, Loss(train/val) 0.10341/0.35348. Took 0.15 sec\n",
      "ACC: 0.671875, MCC: 0.3522819383711917\n",
      "Epoch 0, Loss(train/val) 0.48726/0.48497. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.46035/0.45960. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.42234/0.42916. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.39441/0.42114. Took 0.15 sec\n",
      "Epoch 4, Loss(train/val) 0.37693/0.41462. Took 0.15 sec\n",
      "Epoch 5, Loss(train/val) 0.36928/0.40938. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.36107/0.40764. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.35534/0.40544. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.34663/0.40182. Took 0.15 sec\n",
      "Epoch 9, Loss(train/val) 0.33775/0.39117. Took 0.15 sec\n",
      "Epoch 10, Loss(train/val) 0.33025/0.40044. Took 0.16 sec\n",
      "Epoch 11, Loss(train/val) 0.33142/0.40482. Took 0.17 sec\n",
      "Epoch 12, Loss(train/val) 0.32104/0.38951. Took 0.16 sec\n",
      "Epoch 13, Loss(train/val) 0.31474/0.38414. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.31237/0.39399. Took 0.16 sec\n",
      "Epoch 15, Loss(train/val) 0.29319/0.40187. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.28776/0.38401. Took 0.18 sec\n",
      "Epoch 17, Loss(train/val) 0.28616/0.39492. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.27488/0.36874. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.28427/0.37326. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.28132/0.39076. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.27007/0.38093. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.26530/0.38751. Took 0.18 sec\n",
      "Epoch 23, Loss(train/val) 0.25846/0.38763. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.24894/0.38900. Took 0.16 sec\n",
      "Epoch 25, Loss(train/val) 0.23834/0.39677. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.24199/0.39475. Took 0.13 sec\n",
      "Epoch 27, Loss(train/val) 0.23456/0.39896. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.24294/0.39445. Took 0.17 sec\n",
      "Epoch 29, Loss(train/val) 0.23822/0.36551. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.23093/0.38989. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.22570/0.38907. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.22101/0.39275. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.21755/0.39165. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.22304/0.39254. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.22054/0.39816. Took 0.16 sec\n",
      "Epoch 36, Loss(train/val) 0.21708/0.39231. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.21739/0.40111. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.20611/0.38955. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.20278/0.39954. Took 0.15 sec\n",
      "Epoch 40, Loss(train/val) 0.20755/0.39176. Took 0.15 sec\n",
      "Epoch 41, Loss(train/val) 0.18878/0.38699. Took 0.16 sec\n",
      "Epoch 42, Loss(train/val) 0.20164/0.38439. Took 0.15 sec\n",
      "Epoch 43, Loss(train/val) 0.19769/0.38076. Took 0.15 sec\n",
      "Epoch 44, Loss(train/val) 0.19131/0.37603. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.18772/0.37144. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.18843/0.40498. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.18586/0.38680. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.18736/0.37089. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.18197/0.39269. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.17283/0.39732. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.17881/0.39400. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.18185/0.39050. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.17477/0.36739. Took 0.12 sec\n",
      "Epoch 54, Loss(train/val) 0.17509/0.36300. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.16866/0.35217. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.16334/0.37497. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.17171/0.38048. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.16443/0.38053. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.16135/0.38054. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.15855/0.37079. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.15975/0.37631. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.16492/0.37960. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.16212/0.36756. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.15469/0.38227. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.15629/0.38326. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.15151/0.37665. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.15018/0.37302. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.14934/0.38165. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.14788/0.37859. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.14598/0.37904. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.14394/0.38481. Took 0.12 sec\n",
      "Epoch 72, Loss(train/val) 0.14633/0.36862. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.14090/0.37203. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.14979/0.36475. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.14236/0.38297. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.13898/0.37462. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.14398/0.37197. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.13519/0.36939. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.13653/0.37971. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.13014/0.36920. Took 0.14 sec\n",
      "Epoch 81, Loss(train/val) 0.12681/0.37384. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.14545/0.36974. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.13585/0.36885. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.12939/0.38232. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.13515/0.37371. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.13453/0.36336. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.13716/0.35875. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.13208/0.36568. Took 0.14 sec\n",
      "Epoch 89, Loss(train/val) 0.12857/0.38231. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.12440/0.36921. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.12256/0.36865. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.12319/0.36093. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.12442/0.36338. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.12175/0.36614. Took 0.14 sec\n",
      "Epoch 95, Loss(train/val) 0.12502/0.37618. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.11465/0.36800. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.11971/0.37272. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.13114/0.37290. Took 0.14 sec\n",
      "Epoch 99, Loss(train/val) 0.12210/0.37552. Took 0.13 sec\n",
      "ACC: 0.71875, MCC: 0.44539933408304444\n",
      "Epoch 0, Loss(train/val) 0.49149/0.47043. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.46243/0.39987. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.42050/0.31980. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.38990/0.28636. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.37118/0.27209. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.36575/0.27063. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.35796/0.26755. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.34739/0.26736. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.33935/0.27244. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.33211/0.27666. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.32011/0.33997. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.31428/0.32462. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.30446/0.32749. Took 0.16 sec\n",
      "Epoch 13, Loss(train/val) 0.29496/0.30821. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.29449/0.26615. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.29412/0.30413. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.29678/0.29793. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.30048/0.30173. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.27985/0.28729. Took 0.15 sec\n",
      "Epoch 19, Loss(train/val) 0.28180/0.32686. Took 0.15 sec\n",
      "Epoch 20, Loss(train/val) 0.27386/0.30364. Took 0.15 sec\n",
      "Epoch 21, Loss(train/val) 0.27938/0.30537. Took 0.16 sec\n",
      "Epoch 22, Loss(train/val) 0.26861/0.30965. Took 0.15 sec\n",
      "Epoch 23, Loss(train/val) 0.28015/0.31915. Took 0.16 sec\n",
      "Epoch 24, Loss(train/val) 0.27013/0.32397. Took 0.16 sec\n",
      "Epoch 25, Loss(train/val) 0.26994/0.31513. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.26437/0.31863. Took 0.15 sec\n",
      "Epoch 27, Loss(train/val) 0.25308/0.31918. Took 0.16 sec\n",
      "Epoch 28, Loss(train/val) 0.25663/0.27759. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.26042/0.29298. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.25990/0.26823. Took 0.17 sec\n",
      "Epoch 31, Loss(train/val) 0.24609/0.27022. Took 0.16 sec\n",
      "Epoch 32, Loss(train/val) 0.25153/0.30131. Took 0.18 sec\n",
      "Epoch 33, Loss(train/val) 0.24667/0.32524. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.25266/0.34970. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.26990/0.32822. Took 0.20 sec\n",
      "Epoch 36, Loss(train/val) 0.25378/0.33992. Took 0.21 sec\n",
      "Epoch 37, Loss(train/val) 0.25078/0.34418. Took 0.19 sec\n",
      "Epoch 38, Loss(train/val) 0.24407/0.27279. Took 0.18 sec\n",
      "Epoch 39, Loss(train/val) 0.24591/0.27231. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.24061/0.26653. Took 0.15 sec\n",
      "Epoch 41, Loss(train/val) 0.22663/0.33136. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.23991/0.31302. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.22710/0.35324. Took 0.15 sec\n",
      "Epoch 44, Loss(train/val) 0.22702/0.33265. Took 0.15 sec\n",
      "Epoch 45, Loss(train/val) 0.22210/0.31986. Took 0.16 sec\n",
      "Epoch 46, Loss(train/val) 0.21220/0.34675. Took 0.15 sec\n",
      "Epoch 47, Loss(train/val) 0.21273/0.33064. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.21501/0.29325. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.21666/0.31052. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.22201/0.27962. Took 0.16 sec\n",
      "Epoch 51, Loss(train/val) 0.21956/0.29141. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.20713/0.29613. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.21418/0.29509. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.20313/0.34420. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.21123/0.29506. Took 0.17 sec\n",
      "Epoch 56, Loss(train/val) 0.20980/0.29215. Took 0.16 sec\n",
      "Epoch 57, Loss(train/val) 0.19918/0.34835. Took 0.15 sec\n",
      "Epoch 58, Loss(train/val) 0.19833/0.29738. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.19280/0.33032. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.19474/0.33187. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.19207/0.29362. Took 0.15 sec\n",
      "Epoch 62, Loss(train/val) 0.19991/0.28767. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.19105/0.31269. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.18905/0.29243. Took 0.15 sec\n",
      "Epoch 65, Loss(train/val) 0.19297/0.30055. Took 0.17 sec\n",
      "Epoch 66, Loss(train/val) 0.19064/0.29606. Took 0.16 sec\n",
      "Epoch 67, Loss(train/val) 0.19652/0.31730. Took 0.15 sec\n",
      "Epoch 68, Loss(train/val) 0.18847/0.30914. Took 0.19 sec\n",
      "Epoch 69, Loss(train/val) 0.18452/0.28587. Took 0.16 sec\n",
      "Epoch 70, Loss(train/val) 0.18596/0.31824. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.19377/0.32053. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.20508/0.27257. Took 0.16 sec\n",
      "Epoch 73, Loss(train/val) 0.17942/0.29234. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.17196/0.27718. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) 0.18951/0.34135. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.19546/0.28387. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.18497/0.29072. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.16763/0.30640. Took 0.14 sec\n",
      "Epoch 79, Loss(train/val) 0.17415/0.31130. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.17712/0.31620. Took 0.16 sec\n",
      "Epoch 81, Loss(train/val) 0.19737/0.29579. Took 0.20 sec\n",
      "Epoch 82, Loss(train/val) 0.17867/0.31791. Took 0.17 sec\n",
      "Epoch 83, Loss(train/val) 0.19269/0.29539. Took 0.16 sec\n",
      "Epoch 84, Loss(train/val) 0.17270/0.32594. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.17523/0.30506. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.17356/0.28964. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.16824/0.30190. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.16256/0.29235. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.15463/0.29332. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.16033/0.29159. Took 0.14 sec\n",
      "Epoch 91, Loss(train/val) 0.17133/0.30145. Took 0.17 sec\n",
      "Epoch 92, Loss(train/val) 0.16326/0.29979. Took 0.18 sec\n",
      "Epoch 93, Loss(train/val) 0.16456/0.32201. Took 0.16 sec\n",
      "Epoch 94, Loss(train/val) 0.15578/0.30496. Took 0.15 sec\n",
      "Epoch 95, Loss(train/val) 0.15107/0.30898. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.15081/0.29929. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.15132/0.30543. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.15887/0.30799. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.15402/0.32816. Took 0.13 sec\n",
      "ACC: 0.6875, MCC: 0.374902769779907\n",
      "Epoch 0, Loss(train/val) 0.48791/0.47022. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.45558/0.41463. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.41167/0.37426. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.38263/0.36480. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.37046/0.35696. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.36058/0.35258. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.35202/0.35396. Took 0.15 sec\n",
      "Epoch 7, Loss(train/val) 0.34401/0.35079. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.33392/0.34874. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.32875/0.34501. Took 0.16 sec\n",
      "Epoch 10, Loss(train/val) 0.31724/0.34606. Took 0.15 sec\n",
      "Epoch 11, Loss(train/val) 0.31651/0.34239. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.31549/0.33090. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.30285/0.34092. Took 0.16 sec\n",
      "Epoch 14, Loss(train/val) 0.29745/0.33654. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.29096/0.34184. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.29189/0.32596. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.28739/0.34080. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.27605/0.32642. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.27172/0.31712. Took 0.15 sec\n",
      "Epoch 20, Loss(train/val) 0.27250/0.31880. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.26143/0.31802. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.25806/0.28255. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.24284/0.31262. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.23666/0.29725. Took 0.17 sec\n",
      "Epoch 25, Loss(train/val) 0.23532/0.31184. Took 0.16 sec\n",
      "Epoch 26, Loss(train/val) 0.23271/0.29794. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.23513/0.31238. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.22191/0.30024. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.23512/0.30031. Took 0.18 sec\n",
      "Epoch 30, Loss(train/val) 0.24059/0.30380. Took 0.16 sec\n",
      "Epoch 31, Loss(train/val) 0.22954/0.30465. Took 0.16 sec\n",
      "Epoch 32, Loss(train/val) 0.22919/0.31291. Took 0.16 sec\n",
      "Epoch 33, Loss(train/val) 0.21420/0.28416. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.20702/0.29778. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.20354/0.31257. Took 0.15 sec\n",
      "Epoch 36, Loss(train/val) 0.22955/0.31866. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.20065/0.28787. Took 0.15 sec\n",
      "Epoch 38, Loss(train/val) 0.20672/0.31419. Took 0.21 sec\n",
      "Epoch 39, Loss(train/val) 0.20178/0.30751. Took 0.19 sec\n",
      "Epoch 40, Loss(train/val) 0.20098/0.29477. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.18957/0.29777. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.19567/0.29435. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.18875/0.29446. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.18676/0.27814. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.18432/0.27837. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.18237/0.27194. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.18116/0.29280. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.18135/0.25501. Took 0.15 sec\n",
      "Epoch 49, Loss(train/val) 0.17785/0.28000. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.17511/0.29698. Took 0.14 sec\n",
      "Epoch 51, Loss(train/val) 0.16759/0.26244. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.16803/0.26258. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.16919/0.26907. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.16097/0.28170. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.16875/0.28508. Took 0.16 sec\n",
      "Epoch 56, Loss(train/val) 0.16197/0.27722. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.15981/0.28373. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.16164/0.29577. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.15787/0.24795. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.16778/0.28225. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.15942/0.27486. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.15460/0.26127. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.16139/0.29336. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.15684/0.27426. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.16103/0.29583. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.15299/0.27385. Took 0.15 sec\n",
      "Epoch 67, Loss(train/val) 0.14876/0.28348. Took 0.16 sec\n",
      "Epoch 68, Loss(train/val) 0.14157/0.27538. Took 0.17 sec\n",
      "Epoch 69, Loss(train/val) 0.15082/0.29433. Took 0.17 sec\n",
      "Epoch 70, Loss(train/val) 0.14226/0.26694. Took 0.18 sec\n",
      "Epoch 71, Loss(train/val) 0.14635/0.27762. Took 0.17 sec\n",
      "Epoch 72, Loss(train/val) 0.15062/0.26713. Took 0.20 sec\n",
      "Epoch 73, Loss(train/val) 0.13801/0.28848. Took 0.18 sec\n",
      "Epoch 74, Loss(train/val) 0.14785/0.28284. Took 0.17 sec\n",
      "Epoch 75, Loss(train/val) 0.13671/0.28905. Took 0.16 sec\n",
      "Epoch 76, Loss(train/val) 0.14419/0.26958. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.14343/0.27138. Took 0.17 sec\n",
      "Epoch 78, Loss(train/val) 0.14693/0.27554. Took 0.19 sec\n",
      "Epoch 79, Loss(train/val) 0.13620/0.27529. Took 0.17 sec\n",
      "Epoch 80, Loss(train/val) 0.14148/0.27863. Took 0.16 sec\n",
      "Epoch 81, Loss(train/val) 0.13117/0.26691. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.14011/0.27039. Took 0.15 sec\n",
      "Epoch 83, Loss(train/val) 0.13156/0.28566. Took 0.15 sec\n",
      "Epoch 84, Loss(train/val) 0.13099/0.27078. Took 0.21 sec\n",
      "Epoch 85, Loss(train/val) 0.12765/0.29229. Took 0.18 sec\n",
      "Epoch 86, Loss(train/val) 0.13254/0.25945. Took 0.17 sec\n",
      "Epoch 87, Loss(train/val) 0.13508/0.26839. Took 0.16 sec\n",
      "Epoch 88, Loss(train/val) 0.12177/0.27524. Took 0.18 sec\n",
      "Epoch 89, Loss(train/val) 0.12996/0.27258. Took 0.15 sec\n",
      "Epoch 90, Loss(train/val) 0.12967/0.27910. Took 0.16 sec\n",
      "Epoch 91, Loss(train/val) 0.12059/0.27221. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.12447/0.27777. Took 0.16 sec\n",
      "Epoch 93, Loss(train/val) 0.12273/0.27562. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.12195/0.27438. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.11926/0.25446. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.12145/0.29021. Took 0.14 sec\n",
      "Epoch 97, Loss(train/val) 0.11586/0.26839. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.11805/0.25544. Took 0.15 sec\n",
      "Epoch 99, Loss(train/val) 0.11076/0.26328. Took 0.14 sec\n",
      "ACC: 0.609375, MCC: 0.2851883845210881\n",
      "Epoch 0, Loss(train/val) 0.48712/0.48198. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.45328/0.44692. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.40503/0.39268. Took 0.15 sec\n",
      "Epoch 3, Loss(train/val) 0.37433/0.36465. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.35995/0.35413. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.35033/0.35071. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.33587/0.37142. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.33850/0.35006. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.33401/0.34431. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.32995/0.33987. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.32157/0.36067. Took 0.15 sec\n",
      "Epoch 11, Loss(train/val) 0.31561/0.35571. Took 0.15 sec\n",
      "Epoch 12, Loss(train/val) 0.31229/0.34702. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.30977/0.34290. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.30223/0.34138. Took 0.15 sec\n",
      "Epoch 15, Loss(train/val) 0.30030/0.34378. Took 0.16 sec\n",
      "Epoch 16, Loss(train/val) 0.30302/0.35034. Took 0.18 sec\n",
      "Epoch 17, Loss(train/val) 0.30148/0.34775. Took 0.16 sec\n",
      "Epoch 18, Loss(train/val) 0.29587/0.34820. Took 0.16 sec\n",
      "Epoch 19, Loss(train/val) 0.29666/0.33866. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.29270/0.32926. Took 0.15 sec\n",
      "Epoch 21, Loss(train/val) 0.28649/0.34015. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.27936/0.34281. Took 0.15 sec\n",
      "Epoch 23, Loss(train/val) 0.27298/0.32952. Took 0.16 sec\n",
      "Epoch 24, Loss(train/val) 0.28013/0.33258. Took 0.16 sec\n",
      "Epoch 25, Loss(train/val) 0.26937/0.37624. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.26977/0.36620. Took 0.15 sec\n",
      "Epoch 27, Loss(train/val) 0.26862/0.36812. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.26761/0.36503. Took 0.17 sec\n",
      "Epoch 29, Loss(train/val) 0.26187/0.33096. Took 0.18 sec\n",
      "Epoch 30, Loss(train/val) 0.28872/0.34035. Took 0.17 sec\n",
      "Epoch 31, Loss(train/val) 0.26341/0.37331. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.26160/0.35349. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.25326/0.34489. Took 0.16 sec\n",
      "Epoch 34, Loss(train/val) 0.26599/0.36088. Took 0.17 sec\n",
      "Epoch 35, Loss(train/val) 0.24840/0.35412. Took 0.16 sec\n",
      "Epoch 36, Loss(train/val) 0.24297/0.35472. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.24025/0.34022. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.23664/0.33688. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.22866/0.32958. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.23333/0.31173. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.23381/0.34105. Took 0.16 sec\n",
      "Epoch 42, Loss(train/val) 0.22385/0.36483. Took 0.15 sec\n",
      "Epoch 43, Loss(train/val) 0.24076/0.34565. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.23174/0.32297. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.22875/0.33171. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.22677/0.34887. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.22643/0.33382. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.21830/0.33227. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.22633/0.34567. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.21551/0.35516. Took 0.14 sec\n",
      "Epoch 51, Loss(train/val) 0.20954/0.34962. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.20875/0.34111. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.21556/0.32510. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.21247/0.35225. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.20702/0.33693. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.20921/0.34866. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.21382/0.34287. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.19920/0.34299. Took 0.14 sec\n",
      "Epoch 59, Loss(train/val) 0.20621/0.34234. Took 0.16 sec\n",
      "Epoch 60, Loss(train/val) 0.20062/0.34746. Took 0.14 sec\n",
      "Epoch 61, Loss(train/val) 0.20264/0.30661. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.19710/0.31558. Took 0.15 sec\n",
      "Epoch 63, Loss(train/val) 0.19786/0.32543. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.19468/0.32044. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.19903/0.33373. Took 0.15 sec\n",
      "Epoch 66, Loss(train/val) 0.19999/0.31986. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.19464/0.32195. Took 0.12 sec\n",
      "Epoch 68, Loss(train/val) 0.19031/0.30200. Took 0.14 sec\n",
      "Epoch 69, Loss(train/val) 0.19613/0.30668. Took 0.15 sec\n",
      "Epoch 70, Loss(train/val) 0.19004/0.31539. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.19015/0.29965. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.18783/0.29759. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.18730/0.31811. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.18462/0.31371. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.18888/0.31705. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.18457/0.31271. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.17942/0.31450. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.17804/0.31671. Took 0.15 sec\n",
      "Epoch 79, Loss(train/val) 0.17629/0.32479. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.17541/0.31225. Took 0.15 sec\n",
      "Epoch 81, Loss(train/val) 0.17060/0.31119. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.17939/0.30032. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.17055/0.30519. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.16583/0.31665. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.17115/0.30010. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.16657/0.30761. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.17191/0.31055. Took 0.15 sec\n",
      "Epoch 88, Loss(train/val) 0.17586/0.29647. Took 0.14 sec\n",
      "Epoch 89, Loss(train/val) 0.16924/0.31646. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.15878/0.31283. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.15739/0.29732. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.16218/0.29563. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.16775/0.30277. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.15723/0.30825. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.15590/0.30967. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.15854/0.31517. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.16232/0.30628. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.16524/0.29863. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.15873/0.28557. Took 0.13 sec\n",
      "ACC: 0.6875, MCC: 0.3567530340063379\n",
      "Epoch 0, Loss(train/val) 0.48698/0.48182. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.45721/0.44593. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.41587/0.40758. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.39050/0.39442. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.37661/0.38861. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.36758/0.38362. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.35871/0.38895. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.35248/0.37131. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.34272/0.38247. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.33969/0.37428. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.33692/0.38439. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.32314/0.37418. Took 0.15 sec\n",
      "Epoch 12, Loss(train/val) 0.32732/0.37525. Took 0.15 sec\n",
      "Epoch 13, Loss(train/val) 0.32128/0.35981. Took 0.16 sec\n",
      "Epoch 14, Loss(train/val) 0.32248/0.37604. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.31900/0.38892. Took 0.16 sec\n",
      "Epoch 16, Loss(train/val) 0.31770/0.39229. Took 0.15 sec\n",
      "Epoch 17, Loss(train/val) 0.31169/0.37338. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.30712/0.37226. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.29862/0.37134. Took 0.19 sec\n",
      "Epoch 20, Loss(train/val) 0.29906/0.37333. Took 0.15 sec\n",
      "Epoch 21, Loss(train/val) 0.28982/0.36252. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.29634/0.37204. Took 0.16 sec\n",
      "Epoch 23, Loss(train/val) 0.29174/0.36396. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.28164/0.36517. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.28266/0.37815. Took 0.16 sec\n",
      "Epoch 26, Loss(train/val) 0.27592/0.36718. Took 0.17 sec\n",
      "Epoch 27, Loss(train/val) 0.27584/0.37188. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.27163/0.35432. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.28048/0.34518. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.27958/0.37838. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.27274/0.36339. Took 0.17 sec\n",
      "Epoch 32, Loss(train/val) 0.26814/0.35711. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.26277/0.36219. Took 0.16 sec\n",
      "Epoch 34, Loss(train/val) 0.26748/0.35705. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.25713/0.36316. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.25433/0.34576. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.25080/0.34802. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.25188/0.35638. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.24670/0.36307. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.25910/0.34823. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.25446/0.35002. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.24001/0.35830. Took 0.15 sec\n",
      "Epoch 43, Loss(train/val) 0.24684/0.34916. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.24327/0.35728. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.23494/0.35003. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.23265/0.37461. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.24257/0.35777. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.23335/0.35440. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.22910/0.37169. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.22302/0.36077. Took 0.12 sec\n",
      "Epoch 51, Loss(train/val) 0.22562/0.35920. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.21925/0.35495. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.21103/0.36500. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.21596/0.37428. Took 0.15 sec\n",
      "Epoch 55, Loss(train/val) 0.21000/0.35947. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.20726/0.35801. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.20563/0.38429. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.20400/0.36924. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.20478/0.37800. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.20702/0.35641. Took 0.14 sec\n",
      "Epoch 61, Loss(train/val) 0.20347/0.35775. Took 0.15 sec\n",
      "Epoch 62, Loss(train/val) 0.21036/0.35503. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.20344/0.37799. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.20350/0.35281. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.19513/0.35333. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.19963/0.34651. Took 0.15 sec\n",
      "Epoch 67, Loss(train/val) 0.19630/0.35242. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.20111/0.37252. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.19205/0.36417. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.18441/0.36096. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.18530/0.40045. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.19062/0.38619. Took 0.15 sec\n",
      "Epoch 73, Loss(train/val) 0.19985/0.39370. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.19683/0.37261. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.19512/0.40416. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.19622/0.37813. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.19158/0.38724. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.18176/0.37974. Took 0.15 sec\n",
      "Epoch 79, Loss(train/val) 0.17713/0.41386. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.17662/0.36665. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.18122/0.42107. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.18491/0.37299. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.18338/0.37836. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.17631/0.40917. Took 0.15 sec\n",
      "Epoch 85, Loss(train/val) 0.17621/0.37551. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.17980/0.36838. Took 0.12 sec\n",
      "Epoch 87, Loss(train/val) 0.17945/0.36318. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.17253/0.36678. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.17455/0.39360. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.17083/0.35336. Took 0.15 sec\n",
      "Epoch 91, Loss(train/val) 0.16673/0.35998. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.17629/0.37184. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.17258/0.36770. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.16831/0.37410. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.16773/0.37793. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.17417/0.40354. Took 0.14 sec\n",
      "Epoch 97, Loss(train/val) 0.17137/0.39093. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.16599/0.36822. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.16825/0.36541. Took 0.13 sec\n",
      "ACC: 0.78125, MCC: 0.5400515833773143\n",
      "Epoch 0, Loss(train/val) 0.49155/0.48705. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.46584/0.44579. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.42485/0.38086. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.38999/0.33967. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.37441/0.31141. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.36377/0.29817. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.34813/0.27940. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.34092/0.29410. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.33408/0.24954. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.32709/0.26097. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.31991/0.23760. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.30612/0.23950. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.30655/0.22261. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.29308/0.22622. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.29575/0.22645. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.28638/0.23161. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.28686/0.22014. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.27586/0.22413. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.27886/0.21591. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.27885/0.23741. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.26647/0.22246. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.26881/0.21388. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.26870/0.21275. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.26150/0.21109. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.27581/0.27716. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.26827/0.20611. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.26806/0.20460. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.25634/0.20668. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.24512/0.19928. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.24230/0.20206. Took 0.13 sec\n",
      "Epoch 30, Loss(train/val) 0.25612/0.20887. Took 0.13 sec\n",
      "Epoch 31, Loss(train/val) 0.24324/0.20350. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.25332/0.20238. Took 0.16 sec\n",
      "Epoch 33, Loss(train/val) 0.24203/0.20025. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.24792/0.19354. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.25291/0.20243. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.24104/0.19958. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.23426/0.19658. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.23916/0.19970. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.23334/0.19956. Took 0.16 sec\n",
      "Epoch 40, Loss(train/val) 0.23576/0.19568. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.22446/0.19904. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.22947/0.20662. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.21632/0.19772. Took 0.12 sec\n",
      "Epoch 44, Loss(train/val) 0.22309/0.20227. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.22438/0.18845. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.21908/0.19381. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.21737/0.19270. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.21055/0.18055. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.20873/0.19902. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.20475/0.19193. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.21482/0.18567. Took 0.15 sec\n",
      "Epoch 52, Loss(train/val) 0.20845/0.18350. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.20829/0.18060. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.20899/0.19402. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.19671/0.19166. Took 0.12 sec\n",
      "Epoch 56, Loss(train/val) 0.19334/0.19409. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.19562/0.20306. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.18847/0.21043. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.19385/0.20084. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.19390/0.19008. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.19151/0.20105. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.18744/0.20438. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.18753/0.20426. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.18642/0.20339. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.17891/0.18611. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.18255/0.20733. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.18349/0.19593. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.18166/0.22896. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.17633/0.19925. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.17385/0.20103. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.18010/0.20596. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.16992/0.20575. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.17535/0.21376. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.16197/0.22528. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.17073/0.20948. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.16997/0.20977. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.17113/0.22304. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.17322/0.23522. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.16518/0.20935. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.17158/0.21199. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.16818/0.22340. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.17048/0.19829. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.16924/0.22524. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.16486/0.22785. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.15935/0.22723. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.15541/0.20106. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.15589/0.22565. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.16253/0.22708. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.15821/0.20655. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.15569/0.22912. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.15722/0.23060. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.15194/0.22391. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.14998/0.21388. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.14513/0.19025. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.15527/0.21487. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.14767/0.19704. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.15375/0.20997. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.14492/0.23167. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.15536/0.22603. Took 0.14 sec\n",
      "ACC: 0.65625, MCC: 0.3076976944152481\n",
      "Epoch 0, Loss(train/val) 0.49273/0.48346. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.46743/0.43769. Took 0.12 sec\n",
      "Epoch 2, Loss(train/val) 0.42739/0.38021. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.39415/0.36018. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.37492/0.35253. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.36272/0.34426. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.35632/0.31838. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.34513/0.32825. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.33573/0.32129. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.32765/0.31251. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.32079/0.30311. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.31229/0.30021. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.30323/0.31159. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.29332/0.32919. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.29111/0.32844. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.29390/0.31537. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.28084/0.33330. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.27933/0.34276. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.27366/0.33664. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.27407/0.32932. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.26396/0.33523. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.26531/0.35006. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.25544/0.32606. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.25321/0.34002. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.25387/0.33387. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.25653/0.34809. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.25058/0.34620. Took 0.13 sec\n",
      "Epoch 27, Loss(train/val) 0.24422/0.33412. Took 0.13 sec\n",
      "Epoch 28, Loss(train/val) 0.23610/0.35761. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.23095/0.35741. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.23843/0.32553. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.23506/0.32888. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.24024/0.36407. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.22615/0.35587. Took 0.13 sec\n",
      "Epoch 34, Loss(train/val) 0.22687/0.32949. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.22278/0.33599. Took 0.17 sec\n",
      "Epoch 36, Loss(train/val) 0.21332/0.34254. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.21883/0.36139. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.22158/0.34863. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.21157/0.35510. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.20866/0.33020. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.21649/0.36371. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.20784/0.34974. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.20576/0.33526. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.19463/0.34824. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.19567/0.36301. Took 0.12 sec\n",
      "Epoch 46, Loss(train/val) 0.19630/0.36745. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.19658/0.35292. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.18986/0.36305. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.18450/0.36288. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.18570/0.39098. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.19025/0.35488. Took 0.12 sec\n",
      "Epoch 52, Loss(train/val) 0.18722/0.38345. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) 0.18596/0.37842. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.17891/0.38080. Took 0.12 sec\n",
      "Epoch 55, Loss(train/val) 0.17783/0.38224. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.18303/0.40028. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.17418/0.36292. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.17673/0.37312. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.17424/0.39373. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.18303/0.38390. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.17552/0.37645. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.16813/0.39686. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.17337/0.38640. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.16830/0.39441. Took 0.12 sec\n",
      "Epoch 65, Loss(train/val) 0.17163/0.38954. Took 0.12 sec\n",
      "Epoch 66, Loss(train/val) 0.17083/0.39637. Took 0.12 sec\n",
      "Epoch 67, Loss(train/val) 0.17550/0.40027. Took 0.12 sec\n",
      "Epoch 68, Loss(train/val) 0.16549/0.39465. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.16029/0.40556. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.16372/0.40770. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.15754/0.38641. Took 0.12 sec\n",
      "Epoch 72, Loss(train/val) 0.15788/0.39210. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.16174/0.39555. Took 0.12 sec\n",
      "Epoch 74, Loss(train/val) 0.15236/0.40170. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.14714/0.38909. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.15527/0.37466. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.15095/0.37783. Took 0.12 sec\n",
      "Epoch 78, Loss(train/val) 0.14854/0.38485. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.15261/0.38080. Took 0.12 sec\n",
      "Epoch 80, Loss(train/val) 0.14792/0.37432. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.15240/0.39392. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.14954/0.38975. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.14402/0.37788. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.14965/0.36835. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.14183/0.37002. Took 0.12 sec\n",
      "Epoch 86, Loss(train/val) 0.14650/0.36206. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.14114/0.38091. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.14137/0.39383. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.14261/0.39774. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.13807/0.40267. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.14550/0.40066. Took 0.12 sec\n",
      "Epoch 92, Loss(train/val) 0.13819/0.40090. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.14633/0.38066. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.13765/0.38380. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.14008/0.40180. Took 0.12 sec\n",
      "Epoch 96, Loss(train/val) 0.14280/0.40316. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.13520/0.39755. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.13321/0.41572. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.13754/0.40420. Took 0.14 sec\n",
      "ACC: 0.625, MCC: 0.22084711628963774\n",
      "Epoch 0, Loss(train/val) 0.48863/0.47670. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.46394/0.44949. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.43682/0.43284. Took 0.15 sec\n",
      "Epoch 3, Loss(train/val) 0.40956/0.42047. Took 0.15 sec\n",
      "Epoch 4, Loss(train/val) 0.38979/0.40966. Took 0.15 sec\n",
      "Epoch 5, Loss(train/val) 0.37150/0.40024. Took 0.20 sec\n",
      "Epoch 6, Loss(train/val) 0.35309/0.39747. Took 0.18 sec\n",
      "Epoch 7, Loss(train/val) 0.33921/0.39729. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.32475/0.41879. Took 0.15 sec\n",
      "Epoch 9, Loss(train/val) 0.33560/0.41353. Took 0.17 sec\n",
      "Epoch 10, Loss(train/val) 0.32310/0.40287. Took 0.18 sec\n",
      "Epoch 11, Loss(train/val) 0.31312/0.38929. Took 0.19 sec\n",
      "Epoch 12, Loss(train/val) 0.30303/0.40169. Took 0.21 sec\n",
      "Epoch 13, Loss(train/val) 0.29785/0.40682. Took 0.16 sec\n",
      "Epoch 14, Loss(train/val) 0.31390/0.41002. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.30354/0.38687. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.28632/0.38462. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.28172/0.39038. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.30014/0.38770. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.28924/0.38688. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.27977/0.39375. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.27351/0.36709. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.28282/0.38705. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.27133/0.37223. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.26814/0.39307. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.27029/0.37207. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.27879/0.38301. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.25342/0.36150. Took 0.13 sec\n",
      "Epoch 28, Loss(train/val) 0.26430/0.38820. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.25152/0.38030. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.25617/0.37174. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.24391/0.38459. Took 0.17 sec\n",
      "Epoch 32, Loss(train/val) 0.24907/0.36105. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.24894/0.36242. Took 0.13 sec\n",
      "Epoch 34, Loss(train/val) 0.25627/0.37623. Took 0.13 sec\n",
      "Epoch 35, Loss(train/val) 0.24557/0.38595. Took 0.13 sec\n",
      "Epoch 36, Loss(train/val) 0.24049/0.37826. Took 0.13 sec\n",
      "Epoch 37, Loss(train/val) 0.24182/0.36697. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.23833/0.37922. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.23856/0.37683. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.22928/0.38038. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.24469/0.40115. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.24487/0.37622. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.23669/0.37354. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.24161/0.37982. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) 0.22029/0.37910. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.22789/0.37845. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.22441/0.39571. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.22280/0.35494. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.23104/0.39655. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.22654/0.38530. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.22827/0.41295. Took 0.12 sec\n",
      "Epoch 52, Loss(train/val) 0.22088/0.38279. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.22331/0.35856. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.22075/0.39746. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.21644/0.40304. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.21396/0.38661. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.20797/0.37700. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.20316/0.37481. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.19986/0.35135. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.19390/0.38224. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.20084/0.36578. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.19930/0.36711. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.19774/0.38340. Took 0.12 sec\n",
      "Epoch 64, Loss(train/val) 0.21089/0.31849. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.20462/0.38421. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.19515/0.33400. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.19248/0.37261. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.19493/0.36926. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.17690/0.32530. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.20086/0.38088. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.20302/0.39696. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.19083/0.35180. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.18752/0.38117. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.18961/0.32606. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.18041/0.36561. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.17796/0.38028. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.17805/0.37340. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.18611/0.36136. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.17621/0.35917. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.16772/0.38023. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.18427/0.39989. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.18045/0.40057. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.17572/0.40132. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.17751/0.40059. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.18023/0.38873. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.17291/0.38910. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.17293/0.38371. Took 0.12 sec\n",
      "Epoch 88, Loss(train/val) 0.16842/0.39312. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.17068/0.40217. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.17878/0.40987. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.17749/0.40469. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.17053/0.40583. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.17456/0.40885. Took 0.12 sec\n",
      "Epoch 94, Loss(train/val) 0.16670/0.38212. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.16712/0.36423. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.15941/0.37438. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.17475/0.36626. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.17424/0.32786. Took 0.14 sec\n",
      "Epoch 99, Loss(train/val) 0.17303/0.33269. Took 0.13 sec\n",
      "ACC: 0.765625, MCC: 0.5290033557859399\n",
      "Epoch 0, Loss(train/val) 0.49009/0.47783. Took 0.17 sec\n",
      "Epoch 1, Loss(train/val) 0.46670/0.44698. Took 0.15 sec\n",
      "Epoch 2, Loss(train/val) 0.43861/0.42722. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.41503/0.42066. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.39754/0.41969. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.38530/0.41585. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.37370/0.40588. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.35981/0.40687. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.34863/0.39622. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.33383/0.33955. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.30962/0.37767. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.31722/0.35664. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.30510/0.34412. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.29874/0.34838. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.29542/0.34952. Took 0.15 sec\n",
      "Epoch 15, Loss(train/val) 0.29075/0.32245. Took 0.16 sec\n",
      "Epoch 16, Loss(train/val) 0.27963/0.34260. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.28306/0.35788. Took 0.16 sec\n",
      "Epoch 18, Loss(train/val) 0.28401/0.32462. Took 0.15 sec\n",
      "Epoch 19, Loss(train/val) 0.27496/0.32436. Took 0.16 sec\n",
      "Epoch 20, Loss(train/val) 0.26716/0.32114. Took 0.23 sec\n",
      "Epoch 21, Loss(train/val) 0.26400/0.33833. Took 0.18 sec\n",
      "Epoch 22, Loss(train/val) 0.25935/0.33568. Took 0.20 sec\n",
      "Epoch 23, Loss(train/val) 0.26715/0.31512. Took 0.17 sec\n",
      "Epoch 24, Loss(train/val) 0.25768/0.33967. Took 0.16 sec\n",
      "Epoch 25, Loss(train/val) 0.25069/0.30455. Took 0.16 sec\n",
      "Epoch 26, Loss(train/val) 0.23484/0.33580. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.25058/0.33719. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.23925/0.32283. Took 0.18 sec\n",
      "Epoch 29, Loss(train/val) 0.23726/0.33286. Took 0.16 sec\n",
      "Epoch 30, Loss(train/val) 0.23759/0.34777. Took 0.16 sec\n",
      "Epoch 31, Loss(train/val) 0.23329/0.34407. Took 0.16 sec\n",
      "Epoch 32, Loss(train/val) 0.23770/0.37698. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.23778/0.36774. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.23714/0.35620. Took 0.17 sec\n",
      "Epoch 35, Loss(train/val) 0.23056/0.40073. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.22521/0.35799. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.22284/0.38624. Took 0.15 sec\n",
      "Epoch 38, Loss(train/val) 0.20856/0.40972. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.21158/0.35869. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.20732/0.35356. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.20139/0.40028. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.21323/0.36157. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.20094/0.49616. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.20926/0.37734. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.20339/0.35972. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.20634/0.39620. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.20686/0.35791. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.19426/0.44130. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.19488/0.41693. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.19979/0.45068. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.19346/0.43043. Took 0.12 sec\n",
      "Epoch 52, Loss(train/val) 0.20255/0.36838. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.19173/0.44463. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.19241/0.39281. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.18664/0.49800. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.18478/0.39417. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.18902/0.49942. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.18106/0.46186. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.17576/0.48434. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.17287/0.47467. Took 0.17 sec\n",
      "Epoch 61, Loss(train/val) 0.17644/0.37683. Took 0.15 sec\n",
      "Epoch 62, Loss(train/val) 0.17135/0.36840. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.16770/0.37216. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.17861/0.39097. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.16358/0.43348. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.16792/0.41425. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) 0.17382/0.37263. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.17019/0.35974. Took 0.17 sec\n",
      "Epoch 69, Loss(train/val) 0.15537/0.37063. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.16361/0.37732. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.16271/0.39642. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.15944/0.39016. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.15144/0.37704. Took 0.16 sec\n",
      "Epoch 74, Loss(train/val) 0.16338/0.36279. Took 0.16 sec\n",
      "Epoch 75, Loss(train/val) 0.16162/0.38037. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.16555/0.36807. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.16208/0.36945. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.16067/0.38235. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.15646/0.36406. Took 0.12 sec\n",
      "Epoch 80, Loss(train/val) 0.15433/0.38975. Took 0.14 sec\n",
      "Epoch 81, Loss(train/val) 0.15584/0.36753. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.15085/0.37886. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.15198/0.42224. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.16386/0.36297. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.14722/0.37090. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.14509/0.36359. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.14073/0.36544. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.14108/0.35018. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.13891/0.36336. Took 0.12 sec\n",
      "Epoch 90, Loss(train/val) 0.14307/0.35081. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.14579/0.38261. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.13147/0.34838. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.14011/0.43511. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.13744/0.40213. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.13358/0.38693. Took 0.12 sec\n",
      "Epoch 96, Loss(train/val) 0.13218/0.38307. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.13501/0.40204. Took 0.12 sec\n",
      "Epoch 98, Loss(train/val) 0.13125/0.41753. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.13185/0.38104. Took 0.12 sec\n",
      "ACC: 0.640625, MCC: 0.29521161053222866\n",
      "Epoch 0, Loss(train/val) 0.49036/0.50682. Took 0.13 sec\n",
      "Epoch 1, Loss(train/val) 0.46385/0.51793. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.43794/0.50075. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.41684/0.41051. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.39112/0.36225. Took 0.15 sec\n",
      "Epoch 5, Loss(train/val) 0.37114/0.32992. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.35450/0.34462. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.34663/0.39061. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.33010/0.45414. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.31582/0.45111. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.31017/0.45961. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.29977/0.43591. Took 0.15 sec\n",
      "Epoch 12, Loss(train/val) 0.29880/0.38224. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.30914/0.43768. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.29509/0.41512. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.28753/0.38179. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.29250/0.41813. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.27922/0.40321. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.29625/0.46950. Took 0.16 sec\n",
      "Epoch 19, Loss(train/val) 0.28962/0.48225. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.29791/0.43993. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.27430/0.42878. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.27163/0.43924. Took 0.16 sec\n",
      "Epoch 23, Loss(train/val) 0.27238/0.43354. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.26844/0.42522. Took 0.15 sec\n",
      "Epoch 25, Loss(train/val) 0.26440/0.40116. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.25433/0.39407. Took 0.15 sec\n",
      "Epoch 27, Loss(train/val) 0.25388/0.32931. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.25245/0.37865. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.24645/0.39955. Took 0.17 sec\n",
      "Epoch 30, Loss(train/val) 0.24915/0.32433. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.24456/0.31604. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.24242/0.31334. Took 0.13 sec\n",
      "Epoch 33, Loss(train/val) 0.24377/0.34647. Took 0.13 sec\n",
      "Epoch 34, Loss(train/val) 0.23359/0.32148. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.23442/0.32635. Took 0.13 sec\n",
      "Epoch 36, Loss(train/val) 0.24080/0.31952. Took 0.13 sec\n",
      "Epoch 37, Loss(train/val) 0.21801/0.31695. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.22470/0.31384. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.21965/0.31397. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.22461/0.32148. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.22380/0.31264. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.21958/0.33352. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.22670/0.32671. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.21024/0.32874. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.21764/0.33397. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.23152/0.32142. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.21768/0.39372. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.21472/0.37722. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.22583/0.37100. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.21491/0.34212. Took 0.14 sec\n",
      "Epoch 51, Loss(train/val) 0.21532/0.32344. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.20196/0.32062. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.20059/0.33045. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.21362/0.33716. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.19514/0.34981. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.20280/0.32620. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.20024/0.33263. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.20373/0.33720. Took 0.14 sec\n",
      "Epoch 59, Loss(train/val) 0.19589/0.35115. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.19941/0.35025. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.19571/0.33595. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.19072/0.33227. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.19816/0.33280. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.19931/0.32404. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.19487/0.31671. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.19474/0.32392. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) 0.19259/0.33679. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.20292/0.32995. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.18985/0.35968. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.18916/0.32098. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.18988/0.32468. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.17614/0.33446. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.17743/0.32002. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.19179/0.37414. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.18873/0.31295. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.17812/0.33002. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.18140/0.33292. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.17518/0.32321. Took 0.14 sec\n",
      "Epoch 79, Loss(train/val) 0.18280/0.36573. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.17826/0.36846. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.18085/0.34170. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.18257/0.35135. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) 0.17183/0.40348. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.17316/0.34785. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.18282/0.42279. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.17755/0.38593. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.17559/0.39588. Took 0.15 sec\n",
      "Epoch 88, Loss(train/val) 0.17339/0.40464. Took 0.14 sec\n",
      "Epoch 89, Loss(train/val) 0.16962/0.40769. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.17183/0.39798. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.17028/0.40957. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.17892/0.41493. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.16507/0.41185. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.16407/0.41449. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.16157/0.40124. Took 0.12 sec\n",
      "Epoch 96, Loss(train/val) 0.17123/0.42208. Took 0.12 sec\n",
      "Epoch 97, Loss(train/val) 0.16312/0.41130. Took 0.12 sec\n",
      "Epoch 98, Loss(train/val) 0.16537/0.39234. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.16828/0.41727. Took 0.13 sec\n",
      "ACC: 0.671875, MCC: 0.34415953768009666\n",
      "Epoch 0, Loss(train/val) 0.49450/0.47160. Took 0.13 sec\n",
      "Epoch 1, Loss(train/val) 0.47229/0.42572. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.44679/0.38151. Took 0.12 sec\n",
      "Epoch 3, Loss(train/val) 0.41972/0.34765. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.39379/0.32786. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.37455/0.31141. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.35217/0.29133. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.34254/0.27515. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.32546/0.26559. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.31416/0.27159. Took 0.12 sec\n",
      "Epoch 10, Loss(train/val) 0.30632/0.28139. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.30380/0.27388. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.28991/0.28523. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.28961/0.28465. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.28436/0.29011. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.27938/0.27195. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.27673/0.26567. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.26356/0.27819. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.26220/0.27523. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.26578/0.27427. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.25761/0.28341. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.25597/0.27254. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.25439/0.27208. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.24584/0.27279. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.23977/0.29632. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.24253/0.29625. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.23784/0.28531. Took 0.13 sec\n",
      "Epoch 27, Loss(train/val) 0.25037/0.26969. Took 0.13 sec\n",
      "Epoch 28, Loss(train/val) 0.22809/0.29162. Took 0.13 sec\n",
      "Epoch 29, Loss(train/val) 0.22782/0.29470. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.23207/0.30799. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.21768/0.31370. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.22067/0.29523. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.22668/0.25883. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.21190/0.28104. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.21209/0.31704. Took 0.15 sec\n",
      "Epoch 36, Loss(train/val) 0.21038/0.31773. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.22289/0.29515. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.20419/0.31665. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.20413/0.32429. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.19390/0.32000. Took 0.15 sec\n",
      "Epoch 41, Loss(train/val) 0.19774/0.31286. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.19720/0.33376. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.21398/0.32169. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.18182/0.32684. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.19866/0.32390. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.19474/0.33403. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.18742/0.31335. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.18394/0.31481. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.19569/0.30668. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.18035/0.31466. Took 0.12 sec\n",
      "Epoch 51, Loss(train/val) 0.17599/0.31688. Took 0.12 sec\n",
      "Epoch 52, Loss(train/val) 0.17994/0.33310. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.19042/0.32538. Took 0.12 sec\n",
      "Epoch 54, Loss(train/val) 0.17942/0.31950. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.17508/0.33003. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.16893/0.33713. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.16646/0.33579. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.16574/0.32991. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.16247/0.30359. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.16460/0.34271. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.16029/0.33308. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.15536/0.32373. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.15100/0.34328. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.15370/0.33413. Took 0.12 sec\n",
      "Epoch 65, Loss(train/val) 0.15494/0.33478. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.14815/0.33380. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.15705/0.32665. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.15404/0.32859. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.14580/0.33535. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.14934/0.33554. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.14172/0.33982. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.14138/0.34175. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.14028/0.33970. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.13881/0.34135. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.14372/0.34193. Took 0.12 sec\n",
      "Epoch 76, Loss(train/val) 0.14790/0.34133. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.14772/0.33543. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.14565/0.33180. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.13814/0.33714. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.13606/0.33533. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.13817/0.32603. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.13296/0.32082. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.13246/0.32685. Took 0.12 sec\n",
      "Epoch 84, Loss(train/val) 0.13876/0.32757. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.13144/0.32759. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.12945/0.32797. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.13559/0.33146. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.12912/0.32667. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.13160/0.31556. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.13962/0.32639. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.13088/0.32316. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.11761/0.33717. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.13222/0.33213. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.12825/0.31719. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.12679/0.31789. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.12563/0.31034. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.12565/0.31429. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.12761/0.32281. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.12905/0.31586. Took 0.13 sec\n",
      "ACC: 0.609375, MCC: 0.318599024140908\n",
      "Epoch 0, Loss(train/val) 0.49091/0.48446. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.46110/0.45072. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.42058/0.41298. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.39048/0.39621. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.37290/0.38680. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.35630/0.37062. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.34540/0.35579. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.34089/0.35753. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.33077/0.34127. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.32470/0.34870. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.31652/0.32353. Took 0.15 sec\n",
      "Epoch 11, Loss(train/val) 0.31774/0.34309. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.31047/0.31580. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.31122/0.34011. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.31264/0.33680. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.30150/0.31894. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.31099/0.31841. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.31942/0.29557. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.29627/0.31136. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.29283/0.31777. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.28874/0.28030. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.29573/0.31100. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.28313/0.30998. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.28086/0.37964. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.27093/0.36096. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.26984/0.37486. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.27379/0.36367. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.26638/0.37484. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.24940/0.36888. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.27036/0.37013. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.25403/0.37480. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.25043/0.35614. Took 0.13 sec\n",
      "Epoch 32, Loss(train/val) 0.24387/0.37250. Took 0.13 sec\n",
      "Epoch 33, Loss(train/val) 0.25361/0.37043. Took 0.13 sec\n",
      "Epoch 34, Loss(train/val) 0.24000/0.36482. Took 0.13 sec\n",
      "Epoch 35, Loss(train/val) 0.24664/0.37355. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.24573/0.36582. Took 0.13 sec\n",
      "Epoch 37, Loss(train/val) 0.22723/0.36757. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.24462/0.37017. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.22939/0.34585. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.24077/0.36966. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.23628/0.35155. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.22173/0.31577. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.26903/0.36796. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.24796/0.37162. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.22823/0.34666. Took 0.12 sec\n",
      "Epoch 46, Loss(train/val) 0.23151/0.34274. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.21245/0.33824. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.21615/0.34150. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.21852/0.35586. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.21795/0.37317. Took 0.14 sec\n",
      "Epoch 51, Loss(train/val) 0.21931/0.35056. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.21342/0.33840. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.21531/0.36201. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.21521/0.34366. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.20784/0.36355. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.21451/0.35138. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.21101/0.32600. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.20044/0.34137. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.20918/0.34162. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.19964/0.32073. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.19779/0.34770. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.20305/0.32339. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.19949/0.32875. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.20216/0.33381. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.18980/0.32819. Took 0.12 sec\n",
      "Epoch 66, Loss(train/val) 0.18886/0.32190. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.19382/0.33442. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.19504/0.31249. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.18553/0.32361. Took 0.12 sec\n",
      "Epoch 70, Loss(train/val) 0.18357/0.29591. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.18037/0.30972. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.18244/0.31723. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.18576/0.30949. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.18755/0.30442. Took 0.12 sec\n",
      "Epoch 75, Loss(train/val) 0.17643/0.28758. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.18710/0.29629. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.17628/0.29781. Took 0.12 sec\n",
      "Epoch 78, Loss(train/val) 0.17154/0.29757. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.17687/0.28858. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.16898/0.30598. Took 0.14 sec\n",
      "Epoch 81, Loss(train/val) 0.17237/0.31396. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.16367/0.29680. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.16887/0.29962. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.17018/0.32346. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.16150/0.30544. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.16286/0.29966. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.15994/0.31036. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.16373/0.30667. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.16250/0.29523. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.16101/0.28947. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.15514/0.29921. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.15921/0.27505. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.15721/0.29374. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.14949/0.29617. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.15819/0.28622. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.15855/0.28613. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.15056/0.28772. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.14710/0.29496. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.14631/0.30288. Took 0.13 sec\n",
      "ACC: 0.765625, MCC: 0.4856618642571827\n",
      "Epoch 0, Loss(train/val) 0.48944/0.45036. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.46128/0.38947. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.42746/0.36446. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.39968/0.35925. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.37988/0.34366. Took 0.12 sec\n",
      "Epoch 5, Loss(train/val) 0.36970/0.33269. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.35461/0.32773. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.34602/0.31739. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.33416/0.32095. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.32820/0.30616. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.31624/0.30841. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.30857/0.29368. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.30303/0.29434. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.30128/0.31374. Took 0.16 sec\n",
      "Epoch 14, Loss(train/val) 0.29346/0.31472. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.28169/0.31450. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.28555/0.28344. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.29450/0.31003. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.28242/0.29658. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.27058/0.31187. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.27868/0.31070. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.27145/0.29439. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.26030/0.30668. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.27025/0.29489. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.26058/0.32192. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.25921/0.29039. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.25479/0.31268. Took 0.13 sec\n",
      "Epoch 27, Loss(train/val) 0.25625/0.28047. Took 0.13 sec\n",
      "Epoch 28, Loss(train/val) 0.25097/0.28230. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.24275/0.30535. Took 0.13 sec\n",
      "Epoch 30, Loss(train/val) 0.25724/0.27099. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.24370/0.30877. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.24589/0.31175. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.24566/0.27098. Took 0.17 sec\n",
      "Epoch 34, Loss(train/val) 0.24163/0.26207. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.23989/0.30059. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.23796/0.26661. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.23756/0.27424. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.22392/0.28480. Took 0.15 sec\n",
      "Epoch 39, Loss(train/val) 0.22670/0.28465. Took 0.15 sec\n",
      "Epoch 40, Loss(train/val) 0.22979/0.27771. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.22243/0.29457. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.21894/0.29195. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.22323/0.27678. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.22087/0.30136. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.20892/0.28249. Took 0.12 sec\n",
      "Epoch 46, Loss(train/val) 0.21503/0.31559. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.21663/0.25496. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.22442/0.29482. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.21862/0.29356. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.20688/0.32088. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.20686/0.30553. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.20869/0.31243. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.20184/0.29705. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.20707/0.31412. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.20112/0.28325. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.21330/0.29843. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.20116/0.29638. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.19973/0.29414. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.18588/0.27220. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.18916/0.29456. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.18501/0.30227. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.19587/0.30650. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.19281/0.27724. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.19280/0.28804. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.19279/0.29951. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.19359/0.29419. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.18476/0.27098. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.17642/0.29032. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.18351/0.30399. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.18719/0.30062. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.17971/0.28613. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.17949/0.30985. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.19306/0.31103. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.18462/0.33911. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.17152/0.32957. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.17448/0.30288. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.17362/0.31945. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.16885/0.32483. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.17179/0.31097. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.17589/0.32031. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.16546/0.33176. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.17662/0.28479. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.18033/0.29987. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.16322/0.31810. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.17346/0.30853. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.17246/0.31622. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.16389/0.35172. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.15178/0.32641. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.15230/0.32443. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.15430/0.34911. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.14832/0.34118. Took 0.12 sec\n",
      "Epoch 92, Loss(train/val) 0.15319/0.32682. Took 0.12 sec\n",
      "Epoch 93, Loss(train/val) 0.14954/0.31300. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.15064/0.32510. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.14947/0.34035. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.14978/0.36055. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.14939/0.34628. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.15573/0.36228. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.15735/0.34790. Took 0.13 sec\n",
      "ACC: 0.6875, MCC: 0.35935935935935936\n",
      "Epoch 0, Loss(train/val) 0.48963/0.46797. Took 0.13 sec\n",
      "Epoch 1, Loss(train/val) 0.46632/0.42802. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.43207/0.39614. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.39995/0.38563. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.37869/0.35499. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.36082/0.33865. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.35156/0.31158. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.34520/0.31696. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.34697/0.31303. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.33059/0.30756. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.32108/0.30652. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.32222/0.29864. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.31460/0.30948. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.31850/0.32551. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.30557/0.31879. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.30252/0.31189. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.29576/0.30797. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.28814/0.31238. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.28268/0.30966. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.27984/0.29269. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.26847/0.30964. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.27904/0.32636. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.26333/0.34181. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.26454/0.31239. Took 0.16 sec\n",
      "Epoch 24, Loss(train/val) 0.27090/0.34442. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.25945/0.32046. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.27115/0.32737. Took 0.13 sec\n",
      "Epoch 27, Loss(train/val) 0.25149/0.32785. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.24976/0.34796. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.24257/0.34357. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.23726/0.31932. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.22906/0.33115. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.22274/0.34381. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.23293/0.34966. Took 0.13 sec\n",
      "Epoch 34, Loss(train/val) 0.21895/0.36125. Took 0.13 sec\n",
      "Epoch 35, Loss(train/val) 0.21535/0.34759. Took 0.16 sec\n",
      "Epoch 36, Loss(train/val) 0.20969/0.34021. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.21010/0.33491. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.21039/0.36798. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.20184/0.35188. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.20054/0.35184. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.20823/0.37689. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.19515/0.34379. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.20078/0.32598. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.20268/0.38498. Took 0.12 sec\n",
      "Epoch 45, Loss(train/val) 0.20260/0.38291. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.17982/0.35398. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.18397/0.37609. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.18776/0.37687. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.18538/0.37924. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.18910/0.38869. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.19105/0.37619. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.18035/0.35452. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.16849/0.36834. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.16904/0.38031. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.16808/0.36666. Took 0.12 sec\n",
      "Epoch 56, Loss(train/val) 0.16307/0.37821. Took 0.12 sec\n",
      "Epoch 57, Loss(train/val) 0.15549/0.37519. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.16830/0.38152. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.15392/0.38110. Took 0.12 sec\n",
      "Epoch 60, Loss(train/val) 0.15680/0.39059. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.16137/0.38055. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.15044/0.34332. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.15288/0.36444. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.15735/0.37659. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.16710/0.36383. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.15803/0.36933. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.14809/0.38023. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.15095/0.37223. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.14698/0.37106. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.14730/0.35113. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.13975/0.32804. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.13886/0.36002. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.13965/0.37968. Took 0.12 sec\n",
      "Epoch 74, Loss(train/val) 0.12847/0.36509. Took 0.12 sec\n",
      "Epoch 75, Loss(train/val) 0.13645/0.36445. Took 0.12 sec\n",
      "Epoch 76, Loss(train/val) 0.13634/0.36051. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.12690/0.35929. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.13647/0.35036. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.12633/0.35358. Took 0.12 sec\n",
      "Epoch 80, Loss(train/val) 0.14040/0.37681. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.13119/0.36440. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.13313/0.34316. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.12932/0.35156. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.13121/0.33821. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.12421/0.35344. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.11843/0.35887. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.12495/0.35445. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.11669/0.37264. Took 0.12 sec\n",
      "Epoch 89, Loss(train/val) 0.11719/0.37564. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.12018/0.35449. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.13108/0.33936. Took 0.12 sec\n",
      "Epoch 92, Loss(train/val) 0.11980/0.35534. Took 0.12 sec\n",
      "Epoch 93, Loss(train/val) 0.11028/0.35792. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.10963/0.34572. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.11413/0.36340. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.11105/0.34574. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.11726/0.35401. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.11510/0.34185. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.10932/0.35984. Took 0.13 sec\n",
      "ACC: 0.609375, MCC: 0.3232581014421357\n",
      "Epoch 0, Loss(train/val) 0.49287/0.50709. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.47049/0.50846. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.44188/0.47111. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.41180/0.40098. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.39128/0.36390. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.37539/0.36058. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.36329/0.35159. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.35338/0.34930. Took 0.15 sec\n",
      "Epoch 8, Loss(train/val) 0.33722/0.34513. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.32809/0.35024. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.32056/0.36485. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.31398/0.37688. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.30032/0.36172. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.29856/0.36678. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.29301/0.33570. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.28608/0.33899. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.27941/0.33246. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.27854/0.31728. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.27065/0.31436. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.26354/0.34690. Took 0.15 sec\n",
      "Epoch 20, Loss(train/val) 0.26233/0.32516. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.27386/0.34953. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.26497/0.32754. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.26027/0.33416. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.24653/0.31871. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.26764/0.36436. Took 0.16 sec\n",
      "Epoch 26, Loss(train/val) 0.26004/0.33955. Took 0.15 sec\n",
      "Epoch 27, Loss(train/val) 0.24490/0.32096. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.24162/0.33673. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.23571/0.33560. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.22527/0.33615. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.22508/0.32555. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.22826/0.31733. Took 0.13 sec\n",
      "Epoch 33, Loss(train/val) 0.22332/0.33298. Took 0.13 sec\n",
      "Epoch 34, Loss(train/val) 0.21719/0.30380. Took 0.13 sec\n",
      "Epoch 35, Loss(train/val) 0.21004/0.30922. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.22412/0.30857. Took 0.13 sec\n",
      "Epoch 37, Loss(train/val) 0.20238/0.31857. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.20528/0.31863. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.19824/0.30461. Took 0.12 sec\n",
      "Epoch 40, Loss(train/val) 0.21148/0.34239. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.20431/0.33279. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.19459/0.34368. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.19437/0.33562. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.19546/0.31451. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.18976/0.31508. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.19432/0.31021. Took 0.12 sec\n",
      "Epoch 47, Loss(train/val) 0.18541/0.32117. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.18292/0.31327. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.19511/0.32169. Took 0.12 sec\n",
      "Epoch 50, Loss(train/val) 0.18179/0.32400. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.17146/0.31508. Took 0.12 sec\n",
      "Epoch 52, Loss(train/val) 0.18273/0.31416. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.17043/0.30973. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.17240/0.31347. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.17051/0.32430. Took 0.12 sec\n",
      "Epoch 56, Loss(train/val) 0.16346/0.30915. Took 0.12 sec\n",
      "Epoch 57, Loss(train/val) 0.17430/0.33462. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.15462/0.33048. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.16702/0.31860. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.16074/0.33603. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.16055/0.32954. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.15481/0.32235. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.14898/0.33888. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.14829/0.33822. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.15491/0.33510. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.14876/0.32684. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.15152/0.34016. Took 0.12 sec\n",
      "Epoch 68, Loss(train/val) 0.14593/0.33609. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.14691/0.33194. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.14056/0.33511. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.15369/0.31964. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.14289/0.32119. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.14882/0.32156. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.13781/0.32677. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.14054/0.33637. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.13871/0.33612. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.13163/0.34057. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.13319/0.31556. Took 0.12 sec\n",
      "Epoch 79, Loss(train/val) 0.13536/0.33079. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.13025/0.32336. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.13185/0.33308. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.13357/0.34888. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.12193/0.34691. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.12103/0.33493. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.12666/0.34755. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.12560/0.31694. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.12590/0.34156. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.12168/0.33539. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.12159/0.31855. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.12333/0.32170. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.12038/0.33152. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.11650/0.33411. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.11243/0.32259. Took 0.12 sec\n",
      "Epoch 94, Loss(train/val) 0.11633/0.31550. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.12159/0.33513. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.10933/0.34515. Took 0.12 sec\n",
      "Epoch 97, Loss(train/val) 0.11121/0.32866. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.11335/0.32448. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.10608/0.32549. Took 0.13 sec\n",
      "ACC: 0.734375, MCC: 0.46584907198285247\n",
      "Epoch 0, Loss(train/val) 0.49520/0.49691. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.47121/0.47430. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.43360/0.44396. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.40135/0.40800. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.37971/0.39318. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.35670/0.38096. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.35016/0.34637. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.34355/0.35730. Took 0.12 sec\n",
      "Epoch 8, Loss(train/val) 0.33749/0.34087. Took 0.12 sec\n",
      "Epoch 9, Loss(train/val) 0.33008/0.34940. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.32494/0.33834. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.31957/0.32661. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.31489/0.32150. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.31038/0.32262. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.30284/0.32373. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.29009/0.31131. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.29432/0.32207. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.28860/0.30301. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.28208/0.30158. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.27850/0.29025. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.27383/0.26559. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.28013/0.28862. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.25700/0.35689. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.25438/0.29475. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.27140/0.29202. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.24776/0.27803. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.24425/0.32451. Took 0.13 sec\n",
      "Epoch 27, Loss(train/val) 0.24569/0.32589. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.23543/0.34030. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.24288/0.30379. Took 0.13 sec\n",
      "Epoch 30, Loss(train/val) 0.22547/0.35243. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.21485/0.34130. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.21730/0.35245. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.20652/0.37931. Took 0.16 sec\n",
      "Epoch 34, Loss(train/val) 0.21602/0.37181. Took 0.13 sec\n",
      "Epoch 35, Loss(train/val) 0.20742/0.34443. Took 0.13 sec\n",
      "Epoch 36, Loss(train/val) 0.20055/0.35090. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.19395/0.36117. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.20540/0.34834. Took 0.15 sec\n",
      "Epoch 39, Loss(train/val) 0.19592/0.34951. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.19006/0.33041. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.19269/0.34522. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.18559/0.32695. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.19046/0.35933. Took 0.12 sec\n",
      "Epoch 44, Loss(train/val) 0.18577/0.36485. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.18441/0.34297. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.18123/0.34660. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.17386/0.34579. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.17537/0.34372. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.17172/0.35366. Took 0.12 sec\n",
      "Epoch 50, Loss(train/val) 0.17019/0.35562. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.16578/0.35503. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.17406/0.35472. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.17148/0.35801. Took 0.12 sec\n",
      "Epoch 54, Loss(train/val) 0.17056/0.32710. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.17369/0.37857. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.18714/0.35726. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.19258/0.36774. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.17176/0.37402. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.17225/0.36526. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.16365/0.37164. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.15371/0.36110. Took 0.12 sec\n",
      "Epoch 62, Loss(train/val) 0.15833/0.39743. Took 0.12 sec\n",
      "Epoch 63, Loss(train/val) 0.16222/0.39223. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.14711/0.36472. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.14920/0.39158. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.15242/0.34527. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.14655/0.35412. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.14980/0.34922. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.14747/0.33125. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.14595/0.40388. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.14861/0.35100. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.15554/0.35317. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.15003/0.38032. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.15052/0.35140. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.14502/0.35289. Took 0.12 sec\n",
      "Epoch 76, Loss(train/val) 0.13860/0.35585. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.14481/0.41128. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.14547/0.33305. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.14860/0.34286. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.13540/0.35948. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.13609/0.41968. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.14429/0.36058. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.13175/0.35504. Took 0.12 sec\n",
      "Epoch 84, Loss(train/val) 0.13500/0.35494. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.14519/0.33096. Took 0.12 sec\n",
      "Epoch 86, Loss(train/val) 0.14764/0.39369. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.12783/0.39169. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.12413/0.36352. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.12615/0.38154. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.13147/0.33194. Took 0.14 sec\n",
      "Epoch 91, Loss(train/val) 0.12470/0.39299. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.14019/0.37442. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.12780/0.32674. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.13178/0.35837. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.12262/0.36246. Took 0.12 sec\n",
      "Epoch 96, Loss(train/val) 0.12218/0.40802. Took 0.12 sec\n",
      "Epoch 97, Loss(train/val) 0.12577/0.40234. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.12720/0.33249. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.12846/0.34533. Took 0.13 sec\n",
      "ACC: 0.640625, MCC: 0.2771507137113173\n",
      "Epoch 0, Loss(train/val) 0.49664/0.49084. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.47426/0.46530. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.43800/0.43305. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.39577/0.40996. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.37320/0.38504. Took 0.15 sec\n",
      "Epoch 5, Loss(train/val) 0.36007/0.37726. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.34418/0.37112. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.34594/0.37270. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.33420/0.37212. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.32867/0.36363. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.32855/0.35727. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.32412/0.36707. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.31879/0.36344. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.31083/0.36006. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.30668/0.35614. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.30786/0.37449. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.30849/0.36981. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.30134/0.38275. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.29203/0.39634. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.28926/0.37740. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.29237/0.36850. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.28977/0.36900. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.27715/0.38434. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.27298/0.38338. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.26655/0.38718. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.26396/0.41036. Took 0.17 sec\n",
      "Epoch 26, Loss(train/val) 0.26153/0.39638. Took 0.15 sec\n",
      "Epoch 27, Loss(train/val) 0.25724/0.41893. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.25608/0.39916. Took 0.13 sec\n",
      "Epoch 29, Loss(train/val) 0.25461/0.39665. Took 0.13 sec\n",
      "Epoch 30, Loss(train/val) 0.24896/0.39255. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.24220/0.40029. Took 0.16 sec\n",
      "Epoch 32, Loss(train/val) 0.24003/0.37613. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.24802/0.40188. Took 0.13 sec\n",
      "Epoch 34, Loss(train/val) 0.24579/0.41846. Took 0.13 sec\n",
      "Epoch 35, Loss(train/val) 0.23363/0.37714. Took 0.13 sec\n",
      "Epoch 36, Loss(train/val) 0.24111/0.38966. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.23046/0.37394. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.22896/0.38895. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.23282/0.40656. Took 0.12 sec\n",
      "Epoch 40, Loss(train/val) 0.23395/0.37726. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.22104/0.39888. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.22084/0.37793. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.21750/0.39271. Took 0.15 sec\n",
      "Epoch 44, Loss(train/val) 0.22049/0.38040. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.21792/0.37173. Took 0.12 sec\n",
      "Epoch 46, Loss(train/val) 0.20460/0.39114. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.20836/0.36597. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.21264/0.38728. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.20851/0.38867. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.21380/0.37494. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.20044/0.40976. Took 0.15 sec\n",
      "Epoch 52, Loss(train/val) 0.20351/0.37333. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.19912/0.36953. Took 0.12 sec\n",
      "Epoch 54, Loss(train/val) 0.21371/0.39552. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.19550/0.37198. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.20101/0.35303. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.20078/0.39713. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.19427/0.35682. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.19285/0.36965. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.18709/0.39897. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.18674/0.37292. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.18356/0.36005. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.19211/0.40475. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.18629/0.40745. Took 0.12 sec\n",
      "Epoch 65, Loss(train/val) 0.18088/0.39425. Took 0.12 sec\n",
      "Epoch 66, Loss(train/val) 0.19147/0.41680. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.17902/0.35101. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.19527/0.36429. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.19158/0.41551. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.18071/0.39349. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.18290/0.36468. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.17277/0.41675. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.17365/0.38923. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.17466/0.37706. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.16847/0.37919. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.16905/0.40969. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.17296/0.40136. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.16466/0.39994. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.16460/0.37955. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.16753/0.39535. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.16727/0.40056. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.17329/0.37331. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.16971/0.40391. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.16458/0.39044. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.15286/0.38481. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.15898/0.38685. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.15388/0.36146. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.18785/0.35852. Took 0.12 sec\n",
      "Epoch 89, Loss(train/val) 0.18321/0.36993. Took 0.12 sec\n",
      "Epoch 90, Loss(train/val) 0.16561/0.41093. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.15767/0.41197. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.15552/0.35698. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.16982/0.39734. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.16253/0.40234. Took 0.14 sec\n",
      "Epoch 95, Loss(train/val) 0.14884/0.37459. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.15204/0.38457. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.15452/0.36122. Took 0.12 sec\n",
      "Epoch 98, Loss(train/val) 0.15619/0.38607. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.14038/0.39014. Took 0.15 sec\n",
      "ACC: 0.65625, MCC: 0.3118279569892473\n",
      "Epoch 0, Loss(train/val) 0.49329/0.49713. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.46902/0.48784. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.44034/0.44922. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.41623/0.39096. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.39510/0.36555. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.37698/0.35619. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.35841/0.34692. Took 0.15 sec\n",
      "Epoch 7, Loss(train/val) 0.34500/0.34310. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.34014/0.35003. Took 0.15 sec\n",
      "Epoch 9, Loss(train/val) 0.32564/0.34319. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.32227/0.36510. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.31360/0.36775. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.30561/0.36721. Took 0.15 sec\n",
      "Epoch 13, Loss(train/val) 0.30773/0.43596. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.29977/0.40504. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.29057/0.40784. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.28959/0.42057. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.29597/0.39151. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.30580/0.43357. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.28696/0.42518. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.28433/0.36174. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.29020/0.32512. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.28575/0.32883. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.29122/0.31415. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.28645/0.40395. Took 0.15 sec\n",
      "Epoch 25, Loss(train/val) 0.26857/0.41861. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.27226/0.40648. Took 0.13 sec\n",
      "Epoch 27, Loss(train/val) 0.27456/0.49952. Took 0.13 sec\n",
      "Epoch 28, Loss(train/val) 0.28784/0.40162. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.26774/0.39384. Took 0.13 sec\n",
      "Epoch 30, Loss(train/val) 0.26389/0.40237. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.25264/0.39193. Took 0.16 sec\n",
      "Epoch 32, Loss(train/val) 0.25117/0.38799. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.24604/0.37585. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.24448/0.41160. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.24907/0.32211. Took 0.13 sec\n",
      "Epoch 36, Loss(train/val) 0.24160/0.38919. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.24095/0.42159. Took 0.15 sec\n",
      "Epoch 38, Loss(train/val) 0.23376/0.34786. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.23133/0.35678. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.23469/0.38461. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.22400/0.36093. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.22570/0.35969. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.21783/0.36771. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.21597/0.38775. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.21747/0.35762. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.21674/0.38633. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.21055/0.36775. Took 0.12 sec\n",
      "Epoch 48, Loss(train/val) 0.21415/0.38737. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.20689/0.39533. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.22031/0.36612. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.20436/0.42964. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.20013/0.39119. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.19317/0.41150. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.19790/0.42176. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.19767/0.36446. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.19644/0.42420. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.19166/0.42246. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.19374/0.37378. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.20237/0.44970. Took 0.12 sec\n",
      "Epoch 60, Loss(train/val) 0.19112/0.36060. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.19837/0.40195. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.19164/0.32873. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.19142/0.43559. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.18669/0.43090. Took 0.12 sec\n",
      "Epoch 65, Loss(train/val) 0.18023/0.44307. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.17864/0.36366. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.17687/0.39840. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.17616/0.40146. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.18428/0.40430. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.17845/0.41209. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.17261/0.42231. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.17476/0.37853. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.17158/0.44107. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.17156/0.42760. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.17240/0.44822. Took 0.15 sec\n",
      "Epoch 76, Loss(train/val) 0.16933/0.42962. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.15940/0.42126. Took 0.12 sec\n",
      "Epoch 78, Loss(train/val) 0.16373/0.45650. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.16592/0.43640. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.15755/0.43818. Took 0.12 sec\n",
      "Epoch 81, Loss(train/val) 0.15745/0.38712. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.16437/0.40476. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.15755/0.42967. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.16382/0.43512. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.15930/0.48530. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.15639/0.38498. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.15948/0.45998. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.15391/0.43733. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.16186/0.47872. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.15541/0.43661. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.15360/0.50234. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.14858/0.43984. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.14860/0.48541. Took 0.12 sec\n",
      "Epoch 94, Loss(train/val) 0.15224/0.41114. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.14861/0.50389. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.14997/0.43383. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.13953/0.44621. Took 0.12 sec\n",
      "Epoch 98, Loss(train/val) 0.14592/0.42468. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.14193/0.40762. Took 0.12 sec\n",
      "ACC: 0.640625, MCC: 0.25559287624842536\n",
      "Epoch 0, Loss(train/val) 0.49367/0.47913. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.47510/0.45253. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.45140/0.43642. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.42279/0.42184. Took 0.12 sec\n",
      "Epoch 4, Loss(train/val) 0.39882/0.40300. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.37760/0.39417. Took 0.12 sec\n",
      "Epoch 6, Loss(train/val) 0.35909/0.37767. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.34250/0.37256. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.32319/0.32853. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.30960/0.29909. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.29997/0.28428. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.29309/0.29987. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.29622/0.30348. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.28812/0.29967. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.27829/0.31959. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.28773/0.30710. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.27547/0.31427. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.28454/0.30738. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.26007/0.30255. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.25599/0.29286. Took 0.15 sec\n",
      "Epoch 20, Loss(train/val) 0.25134/0.30727. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.25752/0.31148. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.24942/0.29077. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.24923/0.29448. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.24566/0.29547. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.25870/0.31600. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.23902/0.30802. Took 0.13 sec\n",
      "Epoch 27, Loss(train/val) 0.25227/0.29762. Took 0.13 sec\n",
      "Epoch 28, Loss(train/val) 0.23732/0.29855. Took 0.13 sec\n",
      "Epoch 29, Loss(train/val) 0.24397/0.31337. Took 0.13 sec\n",
      "Epoch 30, Loss(train/val) 0.24083/0.29868. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.22895/0.30557. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.24092/0.30141. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.23618/0.32004. Took 0.13 sec\n",
      "Epoch 34, Loss(train/val) 0.24124/0.30887. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.23112/0.30159. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.23342/0.31930. Took 0.17 sec\n",
      "Epoch 37, Loss(train/val) 0.22993/0.30056. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.22794/0.31235. Took 0.15 sec\n",
      "Epoch 39, Loss(train/val) 0.21725/0.31973. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.21998/0.31267. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.21533/0.29746. Took 0.15 sec\n",
      "Epoch 42, Loss(train/val) 0.22925/0.30342. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.22542/0.31222. Took 0.12 sec\n",
      "Epoch 44, Loss(train/val) 0.21221/0.31590. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.21024/0.30546. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.21142/0.30915. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.20967/0.29890. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.20658/0.30011. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.21657/0.31152. Took 0.12 sec\n",
      "Epoch 50, Loss(train/val) 0.20639/0.30689. Took 0.12 sec\n",
      "Epoch 51, Loss(train/val) 0.20879/0.33207. Took 0.12 sec\n",
      "Epoch 52, Loss(train/val) 0.19805/0.28827. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.19857/0.30546. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.20729/0.29625. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.20336/0.32585. Took 0.12 sec\n",
      "Epoch 56, Loss(train/val) 0.20528/0.32052. Took 0.12 sec\n",
      "Epoch 57, Loss(train/val) 0.19221/0.32452. Took 0.12 sec\n",
      "Epoch 58, Loss(train/val) 0.18862/0.32504. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.19550/0.31433. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.18467/0.31283. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.19773/0.30960. Took 0.12 sec\n",
      "Epoch 62, Loss(train/val) 0.19532/0.32228. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.18699/0.32397. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.18702/0.29325. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.19358/0.33595. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.18434/0.31279. Took 0.12 sec\n",
      "Epoch 67, Loss(train/val) 0.18735/0.32201. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.17861/0.33035. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.18170/0.32748. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.18815/0.31935. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.18542/0.32401. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.16742/0.31661. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.18729/0.31913. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.17521/0.32995. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.17998/0.31576. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.17829/0.31249. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.17870/0.31470. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.16358/0.32820. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.18525/0.32860. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.17171/0.33757. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.16513/0.32658. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.17275/0.33451. Took 0.12 sec\n",
      "Epoch 83, Loss(train/val) 0.17057/0.33443. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.17583/0.32095. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.16938/0.31760. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.16439/0.31971. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.16481/0.32832. Took 0.12 sec\n",
      "Epoch 88, Loss(train/val) 0.15945/0.32699. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.16192/0.33265. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.16022/0.33380. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.16252/0.34220. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.16080/0.33602. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.15455/0.33575. Took 0.12 sec\n",
      "Epoch 94, Loss(train/val) 0.16765/0.33339. Took 0.12 sec\n",
      "Epoch 95, Loss(train/val) 0.17308/0.33823. Took 0.12 sec\n",
      "Epoch 96, Loss(train/val) 0.16049/0.33446. Took 0.14 sec\n",
      "Epoch 97, Loss(train/val) 0.15170/0.34171. Took 0.12 sec\n",
      "Epoch 98, Loss(train/val) 0.15659/0.34510. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.16181/0.32544. Took 0.13 sec\n",
      "ACC: 0.609375, MCC: 0.22877657129023765\n",
      "Epoch 0, Loss(train/val) 0.48983/0.49824. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.46946/0.48625. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.44371/0.45978. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.41770/0.41921. Took 0.12 sec\n",
      "Epoch 4, Loss(train/val) 0.39531/0.39035. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.37734/0.38390. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.35969/0.38649. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.34759/0.38051. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.33558/0.37615. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.33169/0.38234. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.32359/0.36895. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.32153/0.36581. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.31061/0.37819. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.30098/0.39644. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.29543/0.37958. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.28518/0.34627. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.28149/0.34720. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.27365/0.37071. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.26697/0.35554. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.27068/0.35835. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.25721/0.39004. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.26216/0.36335. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.26332/0.34028. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.25052/0.38553. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.26156/0.39589. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.27462/0.34284. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.25424/0.35956. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.26905/0.38031. Took 0.13 sec\n",
      "Epoch 28, Loss(train/val) 0.24327/0.36233. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.23284/0.36339. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.23674/0.38077. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.23120/0.36137. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.22556/0.36916. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.23019/0.35926. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.21907/0.35083. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.22807/0.36316. Took 0.15 sec\n",
      "Epoch 36, Loss(train/val) 0.21075/0.34368. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.20843/0.35337. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.21093/0.35605. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.21347/0.34939. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.20719/0.35134. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.20291/0.33856. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.20660/0.33677. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.20360/0.32488. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.19793/0.35013. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.19477/0.34016. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.20293/0.34332. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.19442/0.35579. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.19178/0.32074. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.19104/0.35832. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.18745/0.34118. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.18478/0.34453. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.18909/0.33640. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.18325/0.33079. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.17623/0.33154. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.18155/0.32129. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.18359/0.33376. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.17239/0.32627. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.17776/0.34460. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.17529/0.32481. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.17407/0.35689. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.17015/0.32553. Took 0.12 sec\n",
      "Epoch 62, Loss(train/val) 0.17809/0.33201. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.16479/0.34183. Took 0.15 sec\n",
      "Epoch 64, Loss(train/val) 0.17209/0.36112. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.16535/0.32345. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.17068/0.34032. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.15896/0.32566. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.15286/0.32467. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.15657/0.33396. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.15250/0.35447. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.15643/0.34429. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.16808/0.36628. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.16121/0.32193. Took 0.12 sec\n",
      "Epoch 74, Loss(train/val) 0.15828/0.35652. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.15380/0.34215. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.14676/0.33707. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.15160/0.37290. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.15091/0.33936. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.14239/0.35173. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.14626/0.34128. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.14241/0.33425. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.14760/0.33200. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.14015/0.33216. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.13503/0.31930. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.14119/0.33927. Took 0.12 sec\n",
      "Epoch 86, Loss(train/val) 0.13786/0.33491. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.14175/0.33187. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.13443/0.34500. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.13720/0.36688. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.14477/0.34233. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.13108/0.35169. Took 0.12 sec\n",
      "Epoch 92, Loss(train/val) 0.13961/0.32943. Took 0.12 sec\n",
      "Epoch 93, Loss(train/val) 0.13769/0.35032. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.13324/0.35466. Took 0.14 sec\n",
      "Epoch 95, Loss(train/val) 0.16562/0.33857. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.14566/0.35912. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.14177/0.34645. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.13501/0.34867. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.12729/0.34553. Took 0.13 sec\n",
      "ACC: 0.625, MCC: 0.26108374384236455\n",
      "Epoch 0, Loss(train/val) 0.49112/0.48824. Took 0.13 sec\n",
      "Epoch 1, Loss(train/val) 0.46936/0.46943. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.44137/0.46356. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.41586/0.47099. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.39850/0.46870. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.38293/0.46745. Took 0.15 sec\n",
      "Epoch 6, Loss(train/val) 0.37285/0.46141. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.36293/0.43644. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.35401/0.43399. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.34784/0.44024. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.34546/0.42762. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.32880/0.41338. Took 0.15 sec\n",
      "Epoch 12, Loss(train/val) 0.31236/0.42818. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.30096/0.45631. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.28698/0.43906. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.28113/0.41845. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.28254/0.42597. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.27709/0.39802. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.26356/0.41939. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.26115/0.39765. Took 0.16 sec\n",
      "Epoch 20, Loss(train/val) 0.26112/0.41045. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.25075/0.41582. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.24805/0.41436. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.24346/0.41773. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.25371/0.39609. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.24650/0.38346. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.23906/0.41359. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.23496/0.41386. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.23129/0.40552. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.22486/0.39464. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.23134/0.41068. Took 0.13 sec\n",
      "Epoch 31, Loss(train/val) 0.22662/0.39589. Took 0.16 sec\n",
      "Epoch 32, Loss(train/val) 0.23127/0.42143. Took 0.13 sec\n",
      "Epoch 33, Loss(train/val) 0.22377/0.39514. Took 0.13 sec\n",
      "Epoch 34, Loss(train/val) 0.23083/0.40666. Took 0.13 sec\n",
      "Epoch 35, Loss(train/val) 0.21132/0.40686. Took 0.13 sec\n",
      "Epoch 36, Loss(train/val) 0.21850/0.40528. Took 0.13 sec\n",
      "Epoch 37, Loss(train/val) 0.21827/0.39973. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.21462/0.39105. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.21579/0.43189. Took 0.12 sec\n",
      "Epoch 40, Loss(train/val) 0.21422/0.37144. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.21145/0.38796. Took 0.12 sec\n",
      "Epoch 42, Loss(train/val) 0.20129/0.36324. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.19815/0.38442. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.20117/0.36312. Took 0.12 sec\n",
      "Epoch 45, Loss(train/val) 0.19986/0.36017. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.19994/0.36291. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.20652/0.38741. Took 0.12 sec\n",
      "Epoch 48, Loss(train/val) 0.19496/0.36537. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.19400/0.37179. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.19145/0.36183. Took 0.15 sec\n",
      "Epoch 51, Loss(train/val) 0.19028/0.36830. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.17604/0.37820. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) 0.18565/0.36799. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.18752/0.37907. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.17803/0.38763. Took 0.15 sec\n",
      "Epoch 56, Loss(train/val) 0.19347/0.36693. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.17414/0.38202. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.17944/0.36425. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.18460/0.36203. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.18591/0.38209. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.18123/0.36129. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.17950/0.37225. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.18118/0.38657. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.17330/0.36067. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.17641/0.38603. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.17598/0.38257. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.16691/0.36545. Took 0.15 sec\n",
      "Epoch 68, Loss(train/val) 0.16118/0.36630. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.16694/0.36190. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.16039/0.37716. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.16416/0.38098. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.16059/0.38870. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.16299/0.36056. Took 0.15 sec\n",
      "Epoch 74, Loss(train/val) 0.15905/0.37188. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.15099/0.37423. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.16329/0.40016. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.16600/0.36242. Took 0.12 sec\n",
      "Epoch 78, Loss(train/val) 0.15264/0.38721. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.15309/0.37798. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.15906/0.36393. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.15222/0.37298. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.14823/0.35785. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.15271/0.36557. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.15883/0.39300. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.14732/0.36131. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.14702/0.35571. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.14514/0.36438. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.14266/0.35624. Took 0.14 sec\n",
      "Epoch 89, Loss(train/val) 0.14083/0.38205. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.14089/0.38696. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.14299/0.36109. Took 0.15 sec\n",
      "Epoch 92, Loss(train/val) 0.15429/0.37583. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.13620/0.36701. Took 0.12 sec\n",
      "Epoch 94, Loss(train/val) 0.13794/0.38050. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.13791/0.35975. Took 0.12 sec\n",
      "Epoch 96, Loss(train/val) 0.14266/0.37033. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.15613/0.36515. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.13940/0.34670. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.13795/0.37202. Took 0.13 sec\n",
      "ACC: 0.734375, MCC: 0.47722316529373915\n",
      "Epoch 0, Loss(train/val) 0.48797/0.48991. Took 0.13 sec\n",
      "Epoch 1, Loss(train/val) 0.46658/0.46928. Took 0.12 sec\n",
      "Epoch 2, Loss(train/val) 0.44347/0.42924. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.42019/0.39576. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.40183/0.37700. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.38626/0.36583. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.36944/0.35868. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.35795/0.34864. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.33850/0.32386. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.31685/0.28391. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.31321/0.28060. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.29480/0.25489. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.28894/0.29182. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.28384/0.26496. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.28484/0.31247. Took 0.15 sec\n",
      "Epoch 15, Loss(train/val) 0.30815/0.28616. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.28420/0.25179. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.27133/0.30003. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.27020/0.24503. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.26271/0.24705. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.26386/0.24120. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.25924/0.24422. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.25760/0.29249. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.26959/0.28572. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.25912/0.34596. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.25665/0.33714. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.25430/0.26521. Took 0.13 sec\n",
      "Epoch 27, Loss(train/val) 0.27512/0.28996. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.27273/0.24544. Took 0.13 sec\n",
      "Epoch 29, Loss(train/val) 0.25008/0.27118. Took 0.13 sec\n",
      "Epoch 30, Loss(train/val) 0.24924/0.25607. Took 0.13 sec\n",
      "Epoch 31, Loss(train/val) 0.24996/0.25792. Took 0.13 sec\n",
      "Epoch 32, Loss(train/val) 0.24717/0.26541. Took 0.13 sec\n",
      "Epoch 33, Loss(train/val) 0.23940/0.26036. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.24600/0.29518. Took 0.16 sec\n",
      "Epoch 35, Loss(train/val) 0.24139/0.28456. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.24414/0.30732. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.24401/0.28256. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.23958/0.27875. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.24004/0.35030. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.23748/0.36287. Took 0.16 sec\n",
      "Epoch 41, Loss(train/val) 0.21928/0.34228. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.22496/0.31794. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.21594/0.31751. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.22551/0.28155. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) 0.21685/0.31613. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.21334/0.28772. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.21660/0.33102. Took 0.12 sec\n",
      "Epoch 48, Loss(train/val) 0.21754/0.31051. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.21729/0.29426. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.21411/0.28732. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.20619/0.25455. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.21535/0.30025. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.21214/0.27010. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.21226/0.27137. Took 0.12 sec\n",
      "Epoch 55, Loss(train/val) 0.24304/0.25214. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.23428/0.26616. Took 0.12 sec\n",
      "Epoch 57, Loss(train/val) 0.20250/0.33559. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.21771/0.29323. Took 0.14 sec\n",
      "Epoch 59, Loss(train/val) 0.21862/0.27595. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.20570/0.23991. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.20788/0.26633. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.20683/0.30826. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.20646/0.26411. Took 0.12 sec\n",
      "Epoch 64, Loss(train/val) 0.20566/0.25340. Took 0.12 sec\n",
      "Epoch 65, Loss(train/val) 0.20715/0.25767. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.19780/0.26483. Took 0.12 sec\n",
      "Epoch 67, Loss(train/val) 0.19952/0.28257. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.19862/0.27541. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.19454/0.22776. Took 0.12 sec\n",
      "Epoch 70, Loss(train/val) 0.18976/0.24577. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.18856/0.24902. Took 0.12 sec\n",
      "Epoch 72, Loss(train/val) 0.19351/0.23050. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.19151/0.24170. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.18867/0.23629. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.19378/0.25281. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.19283/0.26488. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.19109/0.22862. Took 0.12 sec\n",
      "Epoch 78, Loss(train/val) 0.19334/0.25976. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.19733/0.29217. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.18873/0.25650. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.18222/0.27470. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.19479/0.28092. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.17469/0.31125. Took 0.12 sec\n",
      "Epoch 84, Loss(train/val) 0.18716/0.27966. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.18475/0.29841. Took 0.12 sec\n",
      "Epoch 86, Loss(train/val) 0.17330/0.28453. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.19132/0.29248. Took 0.12 sec\n",
      "Epoch 88, Loss(train/val) 0.17832/0.24904. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.18808/0.31880. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.17870/0.25544. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.16859/0.32785. Took 0.12 sec\n",
      "Epoch 92, Loss(train/val) 0.17879/0.28071. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.17350/0.25514. Took 0.12 sec\n",
      "Epoch 94, Loss(train/val) 0.17148/0.26169. Took 0.12 sec\n",
      "Epoch 95, Loss(train/val) 0.16718/0.22906. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.16901/0.26690. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.18320/0.28306. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.18009/0.31538. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.16891/0.25320. Took 0.13 sec\n",
      "ACC: 0.65625, MCC: 0.3326817993859852\n",
      "Epoch 0, Loss(train/val) 0.49238/0.48251. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.47051/0.45861. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.43902/0.45431. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.41302/0.45356. Took 0.12 sec\n",
      "Epoch 4, Loss(train/val) 0.39805/0.44755. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.38358/0.43931. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.37207/0.43280. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.35594/0.42700. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.34128/0.43107. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.33652/0.41345. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.32384/0.39830. Took 0.15 sec\n",
      "Epoch 11, Loss(train/val) 0.30782/0.39920. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.29995/0.39051. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.30205/0.38612. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.29253/0.38687. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.28075/0.35513. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.28974/0.37086. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.28001/0.41139. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.27366/0.42688. Took 0.15 sec\n",
      "Epoch 19, Loss(train/val) 0.26644/0.40316. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.26451/0.41234. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.25209/0.35744. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.26679/0.40250. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.25369/0.39206. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.24701/0.39175. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.24929/0.39484. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.24333/0.40307. Took 0.13 sec\n",
      "Epoch 27, Loss(train/val) 0.24507/0.40104. Took 0.13 sec\n",
      "Epoch 28, Loss(train/val) 0.23761/0.39953. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.24020/0.41451. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.23291/0.39400. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.23886/0.41862. Took 0.16 sec\n",
      "Epoch 32, Loss(train/val) 0.22446/0.39687. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.22210/0.41498. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.21773/0.44438. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.21751/0.41824. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.21644/0.41208. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.21445/0.43151. Took 0.15 sec\n",
      "Epoch 38, Loss(train/val) 0.20710/0.40366. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.20424/0.41303. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.20560/0.39952. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.20541/0.38101. Took 0.12 sec\n",
      "Epoch 42, Loss(train/val) 0.20419/0.36766. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.19791/0.37754. Took 0.12 sec\n",
      "Epoch 44, Loss(train/val) 0.19019/0.39742. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.18569/0.39678. Took 0.12 sec\n",
      "Epoch 46, Loss(train/val) 0.18349/0.38906. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.18275/0.39320. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.18110/0.36761. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.18638/0.38901. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.17937/0.39079. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.18630/0.36847. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.17426/0.38381. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.17116/0.40773. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.17627/0.40220. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.17183/0.40700. Took 0.12 sec\n",
      "Epoch 56, Loss(train/val) 0.16854/0.39039. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.15694/0.39272. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.16333/0.39431. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.16870/0.38658. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.16108/0.37345. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.16196/0.39455. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.15142/0.36667. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.15653/0.38103. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.15818/0.34722. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.15565/0.38393. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.15496/0.36533. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.14885/0.38528. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.15004/0.36651. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.14736/0.35674. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.14658/0.42083. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.14507/0.40493. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.15634/0.37421. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.14324/0.41590. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.13767/0.40244. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.14216/0.37708. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.13639/0.39305. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.14366/0.37803. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.14433/0.36029. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.13655/0.37775. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.12507/0.36446. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.13161/0.36521. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.13022/0.45234. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.13888/0.38210. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.13479/0.35974. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.13003/0.38296. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.12462/0.38663. Took 0.12 sec\n",
      "Epoch 87, Loss(train/val) 0.12368/0.35753. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.12584/0.35235. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.12608/0.34910. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.12724/0.36873. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.12083/0.37945. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.12117/0.37054. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.12232/0.37560. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.12180/0.35760. Took 0.14 sec\n",
      "Epoch 95, Loss(train/val) 0.12243/0.37364. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.11709/0.36301. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.11260/0.37584. Took 0.12 sec\n",
      "Epoch 98, Loss(train/val) 0.11881/0.34843. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.12028/0.37062. Took 0.13 sec\n",
      "ACC: 0.671875, MCC: 0.3231528059706172\n",
      "Epoch 0, Loss(train/val) 0.49088/0.47095. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.46720/0.41306. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.43157/0.35713. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.40368/0.31551. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.38752/0.27754. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.37518/0.27405. Took 0.12 sec\n",
      "Epoch 6, Loss(train/val) 0.36545/0.31725. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.35512/0.29305. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.33972/0.25252. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.32320/0.25645. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.30903/0.24478. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.30515/0.27053. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.30890/0.27121. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.29495/0.27147. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.28495/0.24233. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.27983/0.22983. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.27616/0.24152. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.26224/0.24240. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.26451/0.21943. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.26057/0.22463. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.25790/0.27713. Took 0.15 sec\n",
      "Epoch 21, Loss(train/val) 0.25219/0.23701. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.25393/0.28044. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.24644/0.27994. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.24560/0.29482. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.24053/0.29772. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.23026/0.27800. Took 0.15 sec\n",
      "Epoch 27, Loss(train/val) 0.22838/0.28312. Took 0.13 sec\n",
      "Epoch 28, Loss(train/val) 0.22551/0.30912. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.22347/0.26289. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.22105/0.28930. Took 0.16 sec\n",
      "Epoch 31, Loss(train/val) 0.22374/0.29985. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.21621/0.31680. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.21108/0.29588. Took 0.13 sec\n",
      "Epoch 34, Loss(train/val) 0.21613/0.28861. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.20656/0.29696. Took 0.15 sec\n",
      "Epoch 36, Loss(train/val) 0.21670/0.32340. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.20295/0.28944. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.20666/0.31083. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.20800/0.30209. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.19589/0.30481. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.19899/0.31773. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.19872/0.29508. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.19070/0.29047. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.19557/0.31049. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.18550/0.30363. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.18318/0.30471. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.19348/0.31158. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.18866/0.28867. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.16971/0.29488. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.17375/0.27666. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.17826/0.29339. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.17456/0.30293. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.16808/0.30576. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.16935/0.32368. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.16854/0.30277. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.16335/0.32280. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.16481/0.32309. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.16100/0.32448. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.15635/0.31965. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.17047/0.32332. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.16823/0.31819. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.17116/0.30691. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.15293/0.30169. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.15814/0.32073. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.16807/0.32017. Took 0.12 sec\n",
      "Epoch 66, Loss(train/val) 0.15139/0.31457. Took 0.12 sec\n",
      "Epoch 67, Loss(train/val) 0.15234/0.28462. Took 0.12 sec\n",
      "Epoch 68, Loss(train/val) 0.14953/0.29461. Took 0.12 sec\n",
      "Epoch 69, Loss(train/val) 0.15308/0.30841. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.14577/0.30985. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.15423/0.28942. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.15279/0.32858. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.15813/0.31015. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.15643/0.30620. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.15608/0.31075. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.14790/0.31894. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.15323/0.32412. Took 0.12 sec\n",
      "Epoch 78, Loss(train/val) 0.14430/0.30814. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.16217/0.29648. Took 0.12 sec\n",
      "Epoch 80, Loss(train/val) 0.14785/0.31299. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.14642/0.32889. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.14919/0.30587. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.14721/0.32702. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.14736/0.33388. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.14881/0.32829. Took 0.12 sec\n",
      "Epoch 86, Loss(train/val) 0.14169/0.30174. Took 0.12 sec\n",
      "Epoch 87, Loss(train/val) 0.14434/0.31102. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.14629/0.31687. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.14016/0.32388. Took 0.12 sec\n",
      "Epoch 90, Loss(train/val) 0.14066/0.34697. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.14372/0.32495. Took 0.12 sec\n",
      "Epoch 92, Loss(train/val) 0.15395/0.32341. Took 0.12 sec\n",
      "Epoch 93, Loss(train/val) 0.14100/0.31767. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.14353/0.30758. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.13978/0.31996. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.14110/0.32379. Took 0.12 sec\n",
      "Epoch 97, Loss(train/val) 0.14297/0.31289. Took 0.12 sec\n",
      "Epoch 98, Loss(train/val) 0.13991/0.33153. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.13659/0.31748. Took 0.14 sec\n",
      "ACC: 0.6875, MCC: 0.37389885714349824\n",
      "Epoch 0, Loss(train/val) 0.49064/0.49107. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.46735/0.47273. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.43455/0.44626. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.40434/0.42786. Took 0.12 sec\n",
      "Epoch 4, Loss(train/val) 0.38327/0.42047. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.36923/0.40550. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.34953/0.40635. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.33814/0.39620. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.31659/0.38798. Took 0.15 sec\n",
      "Epoch 9, Loss(train/val) 0.31220/0.40614. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.31568/0.42756. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.30012/0.37968. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.29280/0.36090. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.28861/0.36310. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.28711/0.33945. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.28098/0.43577. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.28844/0.36421. Took 0.15 sec\n",
      "Epoch 17, Loss(train/val) 0.27793/0.35980. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.27335/0.33560. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.27503/0.36467. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.26715/0.37172. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.26258/0.36872. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.27337/0.36947. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.26346/0.35205. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.25786/0.34148. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.26242/0.36785. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.25659/0.38448. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.25606/0.37005. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.24338/0.37416. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.24479/0.37314. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.24662/0.38140. Took 0.17 sec\n",
      "Epoch 31, Loss(train/val) 0.24149/0.38296. Took 0.13 sec\n",
      "Epoch 32, Loss(train/val) 0.23968/0.38147. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.23477/0.39194. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.23766/0.36568. Took 0.16 sec\n",
      "Epoch 35, Loss(train/val) 0.23361/0.33298. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.23217/0.34296. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.23164/0.35006. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.22206/0.39578. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.22835/0.35399. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.22638/0.36426. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.22634/0.36892. Took 0.12 sec\n",
      "Epoch 42, Loss(train/val) 0.21729/0.43192. Took 0.12 sec\n",
      "Epoch 43, Loss(train/val) 0.22857/0.38411. Took 0.12 sec\n",
      "Epoch 44, Loss(train/val) 0.21069/0.39065. Took 0.12 sec\n",
      "Epoch 45, Loss(train/val) 0.21638/0.37833. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.21426/0.39736. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.21732/0.39725. Took 0.12 sec\n",
      "Epoch 48, Loss(train/val) 0.20913/0.38033. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.20818/0.38479. Took 0.12 sec\n",
      "Epoch 50, Loss(train/val) 0.20962/0.39001. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.21630/0.39553. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.20063/0.40225. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.20616/0.36362. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.20168/0.38024. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.20029/0.36794. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.18731/0.38941. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.21095/0.38032. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.19935/0.39514. Took 0.12 sec\n",
      "Epoch 59, Loss(train/val) 0.20364/0.40352. Took 0.12 sec\n",
      "Epoch 60, Loss(train/val) 0.19006/0.38110. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.19251/0.41632. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.19454/0.37954. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.19225/0.38138. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.18662/0.38691. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.18830/0.40129. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.18852/0.38788. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.18187/0.38299. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.18336/0.41239. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.18511/0.39312. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.18829/0.40068. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.18344/0.39336. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.18624/0.39436. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.17529/0.39068. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.17876/0.37973. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.17927/0.38710. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.17952/0.38252. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.17149/0.40976. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.17271/0.35625. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.17203/0.40303. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.17989/0.37864. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.17675/0.40953. Took 0.12 sec\n",
      "Epoch 82, Loss(train/val) 0.18448/0.40642. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.17171/0.39907. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.16865/0.39015. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.17444/0.36514. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.17393/0.39974. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.17801/0.39666. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.17006/0.39323. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.16940/0.42212. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.17509/0.36708. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.16445/0.42965. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.16084/0.41418. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.16961/0.39469. Took 0.12 sec\n",
      "Epoch 94, Loss(train/val) 0.16542/0.41461. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.17034/0.40757. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.15949/0.39818. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.15742/0.41522. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.15869/0.38740. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.16943/0.39498. Took 0.14 sec\n",
      "ACC: 0.71875, MCC: 0.432512315270936\n",
      "Epoch 0, Loss(train/val) 0.49608/0.48186. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.47933/0.44361. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.44706/0.38740. Took 0.12 sec\n",
      "Epoch 3, Loss(train/val) 0.41432/0.36133. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.38860/0.36008. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.38132/0.36854. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.36684/0.36844. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.36246/0.36510. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.35400/0.36538. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.35448/0.37315. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.35867/0.36627. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.35333/0.35044. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.34369/0.34875. Took 0.15 sec\n",
      "Epoch 13, Loss(train/val) 0.32951/0.35617. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.32634/0.31879. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.31078/0.31943. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.30127/0.34901. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.30421/0.30235. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.30701/0.33316. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.31856/0.33511. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.33863/0.34776. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.31554/0.30700. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.31086/0.30281. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.28912/0.31574. Took 0.16 sec\n",
      "Epoch 24, Loss(train/val) 0.28848/0.34607. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.28619/0.33061. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.28905/0.36502. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.28756/0.43668. Took 0.13 sec\n",
      "Epoch 28, Loss(train/val) 0.28539/0.31005. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.27814/0.39089. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.27145/0.42555. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.26654/0.41063. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.26863/0.41664. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.27293/0.36941. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.26645/0.37744. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.25598/0.33422. Took 0.13 sec\n",
      "Epoch 36, Loss(train/val) 0.25452/0.30525. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.24464/0.29938. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.25220/0.34578. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.24928/0.38683. Took 0.15 sec\n",
      "Epoch 40, Loss(train/val) 0.25004/0.30406. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.24208/0.32482. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.26339/0.31894. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.24972/0.35694. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.25332/0.35396. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.23732/0.36438. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.23444/0.34208. Took 0.12 sec\n",
      "Epoch 47, Loss(train/val) 0.23458/0.34005. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.23815/0.29958. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.23287/0.31227. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.22959/0.33429. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.23359/0.33538. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.22076/0.32383. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.21204/0.32877. Took 0.12 sec\n",
      "Epoch 54, Loss(train/val) 0.22255/0.32811. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.20913/0.34053. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.21414/0.33457. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.21658/0.33633. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.21132/0.32279. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.19941/0.30911. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.20157/0.30360. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.21063/0.32476. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.20073/0.32256. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.20266/0.30680. Took 0.12 sec\n",
      "Epoch 64, Loss(train/val) 0.20110/0.30029. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.20021/0.33573. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.19864/0.34467. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.18980/0.27145. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.19261/0.31621. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.19761/0.30817. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.18305/0.31432. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.19066/0.32329. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.18608/0.31831. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.19809/0.34905. Took 0.12 sec\n",
      "Epoch 74, Loss(train/val) 0.19690/0.35424. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.18892/0.30881. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.18869/0.32967. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.18943/0.32588. Took 0.12 sec\n",
      "Epoch 78, Loss(train/val) 0.18820/0.32926. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.17974/0.31045. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.18279/0.31367. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.17143/0.31908. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.17590/0.32381. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.17885/0.32267. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.17680/0.30522. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.17545/0.35415. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.17684/0.34792. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.18097/0.32535. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.17530/0.33872. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.17165/0.35004. Took 0.12 sec\n",
      "Epoch 90, Loss(train/val) 0.17641/0.32667. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.16982/0.32613. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.16500/0.34528. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.16980/0.33441. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.16614/0.36440. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.16973/0.33043. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.16351/0.33882. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.16228/0.32173. Took 0.12 sec\n",
      "Epoch 98, Loss(train/val) 0.16706/0.32644. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.15415/0.33337. Took 0.13 sec\n",
      "ACC: 0.65625, MCC: 0.33954987505086615\n",
      "Epoch 0, Loss(train/val) 0.49158/0.47841. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.47130/0.44189. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.44032/0.39501. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.40665/0.39314. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.39015/0.37483. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.37677/0.36185. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.36807/0.31177. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.36125/0.29943. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.35624/0.31185. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.34978/0.30769. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.34329/0.31016. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.34059/0.33269. Took 0.15 sec\n",
      "Epoch 12, Loss(train/val) 0.32994/0.34105. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.33054/0.33285. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.32558/0.33262. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.32027/0.32600. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.31739/0.31698. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.30744/0.31816. Took 0.16 sec\n",
      "Epoch 18, Loss(train/val) 0.31194/0.31016. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.29839/0.30915. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.32341/0.30427. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.31187/0.30890. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.29530/0.30179. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.29610/0.31803. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.29434/0.34588. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.29282/0.32933. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.28309/0.31968. Took 0.13 sec\n",
      "Epoch 27, Loss(train/val) 0.27796/0.32860. Took 0.13 sec\n",
      "Epoch 28, Loss(train/val) 0.28160/0.33518. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.27355/0.34246. Took 0.13 sec\n",
      "Epoch 30, Loss(train/val) 0.25754/0.33654. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.25945/0.33055. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.26380/0.33349. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.26956/0.31632. Took 0.16 sec\n",
      "Epoch 34, Loss(train/val) 0.25542/0.31693. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.26337/0.34080. Took 0.13 sec\n",
      "Epoch 36, Loss(train/val) 0.26137/0.30940. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.25754/0.32127. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.24262/0.31686. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.25122/0.30400. Took 0.15 sec\n",
      "Epoch 40, Loss(train/val) 0.24277/0.32778. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.23824/0.31431. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.24316/0.31054. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.24098/0.30852. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.23524/0.29425. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.23563/0.29626. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.23703/0.30015. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.22917/0.32360. Took 0.12 sec\n",
      "Epoch 48, Loss(train/val) 0.23641/0.32769. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.23214/0.33637. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.22302/0.30465. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.23241/0.34270. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.21569/0.31026. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.21488/0.31213. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.21017/0.31030. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.22476/0.31169. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.19774/0.29900. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.20916/0.32570. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.20087/0.31733. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.21646/0.32257. Took 0.12 sec\n",
      "Epoch 60, Loss(train/val) 0.20355/0.33107. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.20525/0.33216. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.20132/0.32100. Took 0.12 sec\n",
      "Epoch 63, Loss(train/val) 0.19310/0.33002. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.19995/0.33746. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.19224/0.32162. Took 0.12 sec\n",
      "Epoch 66, Loss(train/val) 0.19088/0.31818. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.19211/0.31775. Took 0.12 sec\n",
      "Epoch 68, Loss(train/val) 0.19415/0.31359. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.18052/0.33678. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.18578/0.34214. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.18270/0.30751. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.18490/0.30892. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.18648/0.32202. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.17709/0.35312. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.16950/0.33331. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.16937/0.31388. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.17384/0.32376. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.17210/0.35575. Took 0.12 sec\n",
      "Epoch 79, Loss(train/val) 0.16884/0.32958. Took 0.12 sec\n",
      "Epoch 80, Loss(train/val) 0.16621/0.32803. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.16848/0.32121. Took 0.12 sec\n",
      "Epoch 82, Loss(train/val) 0.16332/0.33319. Took 0.12 sec\n",
      "Epoch 83, Loss(train/val) 0.15526/0.34793. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.16137/0.35453. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.16500/0.33910. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.15987/0.35369. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.14877/0.32623. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.15328/0.32678. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.15408/0.32959. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.15676/0.31601. Took 0.12 sec\n",
      "Epoch 91, Loss(train/val) 0.14471/0.31336. Took 0.12 sec\n",
      "Epoch 92, Loss(train/val) 0.14910/0.33810. Took 0.12 sec\n",
      "Epoch 93, Loss(train/val) 0.13575/0.31208. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.14410/0.32971. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.13606/0.31550. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.14436/0.30629. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.13732/0.31855. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.13512/0.31942. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.13440/0.29752. Took 0.13 sec\n",
      "ACC: 0.671875, MCC: 0.33613646607466174\n",
      "Epoch 0, Loss(train/val) 0.49143/0.48929. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.46384/0.46899. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.43164/0.43730. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.40417/0.41443. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.38644/0.40207. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.38284/0.39997. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.38116/0.41485. Took 0.15 sec\n",
      "Epoch 7, Loss(train/val) 0.37161/0.37638. Took 0.15 sec\n",
      "Epoch 8, Loss(train/val) 0.36578/0.36899. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.35980/0.39366. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.35361/0.34688. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.33898/0.34721. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.34153/0.36780. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.32709/0.33752. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.31460/0.34571. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.31535/0.35875. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.30822/0.33078. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.31832/0.36160. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.30791/0.33615. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.29786/0.35901. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.29034/0.33897. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.29516/0.34684. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.29009/0.34570. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.30257/0.37415. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.28796/0.36313. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.29263/0.35822. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.28562/0.35790. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.27308/0.35964. Took 0.17 sec\n",
      "Epoch 28, Loss(train/val) 0.27334/0.34297. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.26764/0.34835. Took 0.13 sec\n",
      "Epoch 30, Loss(train/val) 0.26477/0.28368. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.26716/0.31746. Took 0.13 sec\n",
      "Epoch 32, Loss(train/val) 0.26641/0.34745. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.25500/0.27943. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.27124/0.36532. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.25276/0.38343. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.24973/0.36217. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.24395/0.36122. Took 0.12 sec\n",
      "Epoch 38, Loss(train/val) 0.25315/0.33904. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.24901/0.35645. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.24581/0.34453. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.23304/0.36320. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.23063/0.34771. Took 0.12 sec\n",
      "Epoch 43, Loss(train/val) 0.23343/0.35516. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.22068/0.35702. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.22087/0.33110. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.22062/0.32039. Took 0.12 sec\n",
      "Epoch 47, Loss(train/val) 0.21920/0.33145. Took 0.12 sec\n",
      "Epoch 48, Loss(train/val) 0.22114/0.35344. Took 0.12 sec\n",
      "Epoch 49, Loss(train/val) 0.21687/0.36200. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.21585/0.36254. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.20497/0.35746. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.21425/0.35404. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.20809/0.35515. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.20627/0.35120. Took 0.12 sec\n",
      "Epoch 55, Loss(train/val) 0.20108/0.33775. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.20376/0.32441. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.21338/0.30229. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.20404/0.31981. Took 0.12 sec\n",
      "Epoch 59, Loss(train/val) 0.20569/0.29603. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.20160/0.30662. Took 0.14 sec\n",
      "Epoch 61, Loss(train/val) 0.19394/0.34118. Took 0.12 sec\n",
      "Epoch 62, Loss(train/val) 0.19494/0.36132. Took 0.12 sec\n",
      "Epoch 63, Loss(train/val) 0.19697/0.36177. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.20283/0.36857. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.19586/0.36053. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.19307/0.34701. Took 0.15 sec\n",
      "Epoch 67, Loss(train/val) 0.19216/0.31462. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.19587/0.38058. Took 0.14 sec\n",
      "Epoch 69, Loss(train/val) 0.18002/0.37276. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.18410/0.35451. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.17706/0.36901. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.18336/0.35561. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.18600/0.39208. Took 0.15 sec\n",
      "Epoch 74, Loss(train/val) 0.18599/0.37355. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.17791/0.37273. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.17484/0.34771. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.17628/0.37104. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.17684/0.35236. Took 0.14 sec\n",
      "Epoch 79, Loss(train/val) 0.18523/0.39177. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.17413/0.40495. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.17019/0.39883. Took 0.12 sec\n",
      "Epoch 82, Loss(train/val) 0.17301/0.39741. Took 0.12 sec\n",
      "Epoch 83, Loss(train/val) 0.16838/0.35136. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.15787/0.37371. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.17147/0.40930. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.17139/0.35018. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.17456/0.35762. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.17976/0.39399. Took 0.12 sec\n",
      "Epoch 89, Loss(train/val) 0.17182/0.34465. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.16794/0.38334. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.16314/0.38176. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.17239/0.34309. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.16733/0.41551. Took 0.12 sec\n",
      "Epoch 94, Loss(train/val) 0.17010/0.38798. Took 0.12 sec\n",
      "Epoch 95, Loss(train/val) 0.15785/0.36275. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.16113/0.38033. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.15495/0.39341. Took 0.12 sec\n",
      "Epoch 98, Loss(train/val) 0.14960/0.37374. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.15543/0.38972. Took 0.14 sec\n",
      "ACC: 0.59375, MCC: 0.21919618279730335\n",
      "Epoch 0, Loss(train/val) 0.49361/0.49457. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.47242/0.48461. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.44012/0.45563. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.41101/0.42570. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.39287/0.41088. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.38037/0.41659. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.37208/0.38992. Took 0.12 sec\n",
      "Epoch 7, Loss(train/val) 0.36127/0.40889. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.35438/0.39791. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.34355/0.38862. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.33765/0.39850. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.34072/0.41006. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.33604/0.36169. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.33024/0.38603. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.32931/0.37754. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.32209/0.42278. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.32030/0.37456. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.31105/0.39385. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.30448/0.40947. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.30598/0.40820. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.30346/0.40486. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.30034/0.37775. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.30003/0.43201. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.29479/0.35904. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.30204/0.38335. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.31105/0.39696. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.28576/0.37859. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.28330/0.37596. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.28057/0.32293. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.29298/0.36284. Took 0.16 sec\n",
      "Epoch 30, Loss(train/val) 0.29776/0.41715. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.29307/0.36561. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.28525/0.39508. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.29363/0.34936. Took 0.16 sec\n",
      "Epoch 34, Loss(train/val) 0.27819/0.39873. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.28067/0.39589. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.26564/0.40511. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.26470/0.40983. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.26204/0.37549. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.26410/0.40826. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.26547/0.41716. Took 0.12 sec\n",
      "Epoch 41, Loss(train/val) 0.26069/0.40033. Took 0.12 sec\n",
      "Epoch 42, Loss(train/val) 0.25490/0.41186. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.24900/0.39876. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.25383/0.40443. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.24601/0.39550. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.23477/0.39468. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.25002/0.39387. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.23659/0.39651. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.24787/0.38937. Took 0.12 sec\n",
      "Epoch 50, Loss(train/val) 0.24501/0.39585. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.23938/0.38908. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.22642/0.37816. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.22077/0.38928. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.23316/0.38505. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.21993/0.39442. Took 0.12 sec\n",
      "Epoch 56, Loss(train/val) 0.21850/0.39749. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.21925/0.39683. Took 0.12 sec\n",
      "Epoch 58, Loss(train/val) 0.21746/0.40016. Took 0.14 sec\n",
      "Epoch 59, Loss(train/val) 0.21974/0.40439. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.21143/0.39304. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.21569/0.38439. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.20280/0.39917. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.21121/0.39413. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.20964/0.37523. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.21627/0.39190. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.21085/0.38767. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.21110/0.39314. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.20537/0.38719. Took 0.14 sec\n",
      "Epoch 69, Loss(train/val) 0.19955/0.39165. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.22113/0.38880. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.20813/0.39045. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.19950/0.39428. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.22119/0.39093. Took 0.12 sec\n",
      "Epoch 74, Loss(train/val) 0.20352/0.35826. Took 0.12 sec\n",
      "Epoch 75, Loss(train/val) 0.22981/0.36322. Took 0.12 sec\n",
      "Epoch 76, Loss(train/val) 0.22055/0.32116. Took 0.12 sec\n",
      "Epoch 77, Loss(train/val) 0.20298/0.35639. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.19483/0.35345. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.19995/0.34559. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.19764/0.34832. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.19466/0.33355. Took 0.12 sec\n",
      "Epoch 82, Loss(train/val) 0.22011/0.36523. Took 0.12 sec\n",
      "Epoch 83, Loss(train/val) 0.20971/0.37198. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.18966/0.37792. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.19418/0.36002. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.19619/0.35517. Took 0.12 sec\n",
      "Epoch 87, Loss(train/val) 0.18500/0.34082. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.19390/0.35932. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.18267/0.36656. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.18415/0.38797. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.19520/0.36261. Took 0.12 sec\n",
      "Epoch 92, Loss(train/val) 0.18452/0.38680. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.18633/0.35336. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.19123/0.35216. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.19670/0.37853. Took 0.12 sec\n",
      "Epoch 96, Loss(train/val) 0.18447/0.35692. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.18046/0.37034. Took 0.12 sec\n",
      "Epoch 98, Loss(train/val) 0.19305/0.35839. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.18226/0.36100. Took 0.13 sec\n",
      "ACC: 0.703125, MCC: 0.38105777041717415\n",
      "Epoch 0, Loss(train/val) 0.49147/0.50933. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.46911/0.52232. Took 0.12 sec\n",
      "Epoch 2, Loss(train/val) 0.44048/0.49911. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.41336/0.46143. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.39189/0.45175. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.37231/0.44298. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.36628/0.43449. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.34887/0.42754. Took 0.15 sec\n",
      "Epoch 8, Loss(train/val) 0.33826/0.40568. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.33540/0.41640. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.33447/0.39716. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.33069/0.40127. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.32793/0.39753. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.31722/0.39675. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.30847/0.40540. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.31591/0.47252. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.30437/0.40982. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.32399/0.45818. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.30303/0.43541. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.30236/0.39942. Took 0.15 sec\n",
      "Epoch 20, Loss(train/val) 0.28916/0.42573. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.29460/0.38750. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.28109/0.44046. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.28442/0.41821. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.27047/0.44586. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.26987/0.46791. Took 0.17 sec\n",
      "Epoch 26, Loss(train/val) 0.25378/0.48230. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.25431/0.48339. Took 0.13 sec\n",
      "Epoch 28, Loss(train/val) 0.25381/0.51574. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.25102/0.49519. Took 0.16 sec\n",
      "Epoch 30, Loss(train/val) 0.25293/0.46287. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.24716/0.42936. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.23914/0.45992. Took 0.13 sec\n",
      "Epoch 33, Loss(train/val) 0.24295/0.48053. Took 0.13 sec\n",
      "Epoch 34, Loss(train/val) 0.22803/0.51142. Took 0.13 sec\n",
      "Epoch 35, Loss(train/val) 0.22904/0.44023. Took 0.12 sec\n",
      "Epoch 36, Loss(train/val) 0.22963/0.50166. Took 0.13 sec\n",
      "Epoch 37, Loss(train/val) 0.21931/0.50519. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.22039/0.45704. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.22563/0.44245. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.22178/0.42065. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.22187/0.42784. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.20693/0.43297. Took 0.12 sec\n",
      "Epoch 43, Loss(train/val) 0.20215/0.48522. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.20749/0.44166. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.20200/0.45049. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.19990/0.45119. Took 0.12 sec\n",
      "Epoch 47, Loss(train/val) 0.20558/0.41086. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.20469/0.38954. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.20121/0.39382. Took 0.12 sec\n",
      "Epoch 50, Loss(train/val) 0.19193/0.42626. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.18884/0.38545. Took 0.12 sec\n",
      "Epoch 52, Loss(train/val) 0.18957/0.40207. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.19330/0.40918. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.18471/0.38807. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.19708/0.44995. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.17879/0.45092. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.18013/0.47724. Took 0.12 sec\n",
      "Epoch 58, Loss(train/val) 0.17062/0.41972. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.16303/0.47585. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.17368/0.45555. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.17259/0.50063. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.16876/0.41029. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.16578/0.41069. Took 0.12 sec\n",
      "Epoch 64, Loss(train/val) 0.17938/0.45455. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.16745/0.43373. Took 0.12 sec\n",
      "Epoch 66, Loss(train/val) 0.15636/0.43465. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.16266/0.45322. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.16363/0.40957. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.15803/0.44258. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.15198/0.40181. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.15614/0.41154. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.14690/0.40400. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.14861/0.43322. Took 0.12 sec\n",
      "Epoch 74, Loss(train/val) 0.16230/0.42126. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.15041/0.39165. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.14486/0.40748. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.14669/0.39191. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.15009/0.41953. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.13433/0.39745. Took 0.12 sec\n",
      "Epoch 80, Loss(train/val) 0.14430/0.39920. Took 0.12 sec\n",
      "Epoch 81, Loss(train/val) 0.14538/0.44665. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.14426/0.41245. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.14037/0.42329. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.13985/0.38940. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.14585/0.44016. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.14499/0.45331. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.13486/0.45426. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.13719/0.43463. Took 0.12 sec\n",
      "Epoch 89, Loss(train/val) 0.13699/0.42113. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.13229/0.43185. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.12612/0.40538. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.13026/0.39527. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.12921/0.43713. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.12606/0.40911. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.13485/0.41157. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.12980/0.45019. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.13118/0.43549. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.12939/0.43445. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.13207/0.43148. Took 0.13 sec\n",
      "ACC: 0.53125, MCC: 0.09288407280256479\n",
      "Epoch 0, Loss(train/val) 0.48992/0.49698. Took 0.13 sec\n",
      "Epoch 1, Loss(train/val) 0.46191/0.48786. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.42087/0.47174. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.39813/0.46125. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.38075/0.45606. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.36757/0.45273. Took 0.15 sec\n",
      "Epoch 6, Loss(train/val) 0.35275/0.44671. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.34987/0.44506. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.34551/0.44570. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.33620/0.43278. Took 0.12 sec\n",
      "Epoch 10, Loss(train/val) 0.33024/0.45001. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.32839/0.44335. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.31534/0.44725. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.31408/0.44111. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.32635/0.41551. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.32508/0.44903. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.31350/0.44753. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.30055/0.43761. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.29782/0.43409. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.31170/0.40574. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.29291/0.43211. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.29582/0.39749. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.29877/0.43140. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.30634/0.44238. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.29319/0.43706. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.28658/0.38398. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.28343/0.42476. Took 0.13 sec\n",
      "Epoch 27, Loss(train/val) 0.27975/0.43028. Took 0.13 sec\n",
      "Epoch 28, Loss(train/val) 0.27798/0.40354. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.26742/0.40260. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.26281/0.43745. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.27035/0.40592. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.25964/0.39958. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.25584/0.42114. Took 0.13 sec\n",
      "Epoch 34, Loss(train/val) 0.24860/0.39463. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.24686/0.39758. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.24447/0.40350. Took 0.16 sec\n",
      "Epoch 37, Loss(train/val) 0.23997/0.42313. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.23562/0.43254. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.24165/0.42887. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.23881/0.43325. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.21631/0.44817. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.22642/0.42455. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.22798/0.44136. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.22306/0.43380. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.21285/0.43580. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.21607/0.43577. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.22795/0.42496. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.22752/0.41848. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.21678/0.42092. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.22580/0.45139. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.21259/0.44657. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.21276/0.43443. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.21201/0.44183. Took 0.12 sec\n",
      "Epoch 54, Loss(train/val) 0.20350/0.43813. Took 0.12 sec\n",
      "Epoch 55, Loss(train/val) 0.19757/0.42558. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.19563/0.40870. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.19259/0.41809. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.19066/0.42129. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.18504/0.42593. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.18941/0.41812. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.18737/0.42977. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.19353/0.44114. Took 0.12 sec\n",
      "Epoch 63, Loss(train/val) 0.18830/0.44258. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.17830/0.42911. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.18476/0.44279. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.18298/0.45711. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.17956/0.47421. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.18177/0.44917. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.18064/0.47534. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.17999/0.44986. Took 0.12 sec\n",
      "Epoch 71, Loss(train/val) 0.17130/0.44408. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.18064/0.45840. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.16532/0.46391. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.17186/0.45983. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.16844/0.47149. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.18035/0.45760. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.16817/0.45367. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.16502/0.45213. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.17243/0.44907. Took 0.12 sec\n",
      "Epoch 80, Loss(train/val) 0.17905/0.45687. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.16573/0.43837. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.16890/0.43861. Took 0.12 sec\n",
      "Epoch 83, Loss(train/val) 0.16659/0.46011. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.17296/0.45328. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.17048/0.43380. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.16523/0.45578. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.16566/0.42742. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.15556/0.43228. Took 0.14 sec\n",
      "Epoch 89, Loss(train/val) 0.16231/0.43827. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.16218/0.43705. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.14735/0.44426. Took 0.12 sec\n",
      "Epoch 92, Loss(train/val) 0.14789/0.48222. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.14218/0.47949. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.15119/0.44380. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.15467/0.43672. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.15349/0.44502. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.15599/0.43879. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.15663/0.47943. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.15444/0.45839. Took 0.13 sec\n",
      "ACC: 0.765625, MCC: 0.47017387765700636\n",
      "Epoch 0, Loss(train/val) 0.49277/0.45887. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.47326/0.40565. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.44402/0.35782. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.41441/0.33336. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.39730/0.32558. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.38436/0.32994. Took 0.12 sec\n",
      "Epoch 6, Loss(train/val) 0.37878/0.32192. Took 0.12 sec\n",
      "Epoch 7, Loss(train/val) 0.36905/0.31780. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.36850/0.32036. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.36069/0.30629. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.36153/0.31521. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.35354/0.29089. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.35032/0.28697. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.33974/0.28706. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.34388/0.28876. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.33725/0.27894. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.33222/0.28351. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.32580/0.27992. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.32785/0.27990. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.31088/0.27462. Took 0.15 sec\n",
      "Epoch 20, Loss(train/val) 0.32065/0.26477. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.31657/0.25698. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.30702/0.27659. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.29922/0.27369. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.29734/0.26710. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.29531/0.27194. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.29431/0.28652. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.30354/0.28418. Took 0.13 sec\n",
      "Epoch 28, Loss(train/val) 0.29100/0.28951. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.28226/0.29437. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.28786/0.32856. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.28104/0.29518. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.26787/0.30853. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.27227/0.30223. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.26693/0.29918. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.26961/0.30692. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.25655/0.30345. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.26695/0.30490. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.25613/0.29783. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.24285/0.30502. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.25200/0.35333. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.25118/0.36338. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.26018/0.34955. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.24292/0.34525. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.24536/0.34613. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.23991/0.35045. Took 0.12 sec\n",
      "Epoch 46, Loss(train/val) 0.23070/0.36510. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.23137/0.34955. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.22423/0.34081. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.21699/0.36317. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.22956/0.34700. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.21928/0.32460. Took 0.12 sec\n",
      "Epoch 52, Loss(train/val) 0.21611/0.34577. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.21974/0.34514. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.21468/0.33103. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.21690/0.34630. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.21298/0.35359. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.20223/0.35146. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.20850/0.35881. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.20741/0.35742. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.19845/0.36205. Took 0.12 sec\n",
      "Epoch 61, Loss(train/val) 0.20614/0.33774. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.19601/0.35936. Took 0.12 sec\n",
      "Epoch 63, Loss(train/val) 0.20504/0.35304. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.20062/0.34992. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.18939/0.36474. Took 0.12 sec\n",
      "Epoch 66, Loss(train/val) 0.19570/0.35127. Took 0.12 sec\n",
      "Epoch 67, Loss(train/val) 0.20096/0.34072. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.19057/0.35257. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.18440/0.34040. Took 0.12 sec\n",
      "Epoch 70, Loss(train/val) 0.17774/0.35578. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.18608/0.33104. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.17514/0.35481. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.17911/0.36710. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.17585/0.34966. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.17603/0.36056. Took 0.12 sec\n",
      "Epoch 76, Loss(train/val) 0.17534/0.36716. Took 0.12 sec\n",
      "Epoch 77, Loss(train/val) 0.17665/0.35937. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.17454/0.34608. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.17214/0.35631. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.16996/0.34199. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.16230/0.33672. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.16686/0.32520. Took 0.12 sec\n",
      "Epoch 83, Loss(train/val) 0.16533/0.35875. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.16804/0.33206. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.16819/0.33863. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.16910/0.34927. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.16845/0.35149. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.17208/0.34839. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.16700/0.33192. Took 0.12 sec\n",
      "Epoch 90, Loss(train/val) 0.16120/0.33688. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.16509/0.33947. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.15538/0.35113. Took 0.12 sec\n",
      "Epoch 93, Loss(train/val) 0.15661/0.35899. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.16541/0.34903. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.15741/0.33668. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.15760/0.34947. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.15696/0.34493. Took 0.12 sec\n",
      "Epoch 98, Loss(train/val) 0.15181/0.33473. Took 0.14 sec\n",
      "Epoch 99, Loss(train/val) 0.15727/0.34121. Took 0.13 sec\n",
      "ACC: 0.6875, MCC: 0.3463931368539554\n",
      "Epoch 0, Loss(train/val) 0.49751/0.48508. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.48081/0.46097. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.45523/0.44295. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.42233/0.44107. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.40436/0.42663. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.38983/0.40901. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.37370/0.36531. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.36818/0.34476. Took 0.12 sec\n",
      "Epoch 8, Loss(train/val) 0.36169/0.33405. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.36153/0.31815. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.34965/0.36412. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.34716/0.33139. Took 0.12 sec\n",
      "Epoch 12, Loss(train/val) 0.32978/0.33366. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.32610/0.35716. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.32279/0.32592. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.31231/0.36468. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.30695/0.31537. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.30780/0.32356. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.29355/0.31636. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.29275/0.32027. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.28604/0.31194. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.28459/0.34986. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.26655/0.31301. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.27617/0.32651. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.27192/0.33337. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.26365/0.34608. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.26315/0.33920. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.25568/0.34044. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.25327/0.34378. Took 0.13 sec\n",
      "Epoch 29, Loss(train/val) 0.25655/0.34127. Took 0.13 sec\n",
      "Epoch 30, Loss(train/val) 0.25199/0.33741. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.24877/0.34251. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.24021/0.33250. Took 0.13 sec\n",
      "Epoch 33, Loss(train/val) 0.24074/0.34210. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.22702/0.33907. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.23694/0.33093. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.23099/0.33790. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.22716/0.34785. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.22927/0.34554. Took 0.15 sec\n",
      "Epoch 39, Loss(train/val) 0.21875/0.34518. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.21984/0.33316. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.20253/0.35261. Took 0.15 sec\n",
      "Epoch 42, Loss(train/val) 0.20434/0.33266. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.21034/0.35173. Took 0.12 sec\n",
      "Epoch 44, Loss(train/val) 0.20471/0.34924. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.20360/0.34357. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.20209/0.34890. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.19084/0.34342. Took 0.12 sec\n",
      "Epoch 48, Loss(train/val) 0.19932/0.33463. Took 0.12 sec\n",
      "Epoch 49, Loss(train/val) 0.19635/0.33502. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.19926/0.34535. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.18906/0.34680. Took 0.15 sec\n",
      "Epoch 52, Loss(train/val) 0.19218/0.34946. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.19392/0.33164. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.18704/0.34159. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.17686/0.34500. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.18006/0.34555. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.19329/0.35012. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.17497/0.33520. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.16738/0.35584. Took 0.12 sec\n",
      "Epoch 60, Loss(train/val) 0.17991/0.34130. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.18673/0.34385. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.18275/0.32891. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.17870/0.34954. Took 0.12 sec\n",
      "Epoch 64, Loss(train/val) 0.17233/0.34388. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.17403/0.34079. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.16612/0.34892. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.16819/0.33859. Took 0.12 sec\n",
      "Epoch 68, Loss(train/val) 0.16180/0.37214. Took 0.12 sec\n",
      "Epoch 69, Loss(train/val) 0.16760/0.34567. Took 0.12 sec\n",
      "Epoch 70, Loss(train/val) 0.16136/0.33807. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.15658/0.34439. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.15054/0.34336. Took 0.12 sec\n",
      "Epoch 73, Loss(train/val) 0.16010/0.34677. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.15843/0.36161. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.15264/0.36020. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.15410/0.36359. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.15192/0.35511. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.15115/0.34883. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.14285/0.36452. Took 0.12 sec\n",
      "Epoch 80, Loss(train/val) 0.15433/0.35577. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.14724/0.35013. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.14172/0.34775. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.14158/0.35743. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.14394/0.34265. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.14053/0.34933. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.14768/0.35185. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.14378/0.36247. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.13993/0.35663. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.13600/0.35193. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.13448/0.37348. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.14413/0.37195. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.13656/0.35730. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.14175/0.35656. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.13973/0.35330. Took 0.12 sec\n",
      "Epoch 95, Loss(train/val) 0.13705/0.34325. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.13420/0.34000. Took 0.12 sec\n",
      "Epoch 97, Loss(train/val) 0.13481/0.36128. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.13707/0.36784. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.13079/0.36001. Took 0.13 sec\n",
      "ACC: 0.5625, MCC: 0.15118578920369088\n",
      "Epoch 0, Loss(train/val) 0.49153/0.48845. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.47244/0.47136. Took 0.12 sec\n",
      "Epoch 2, Loss(train/val) 0.44671/0.44619. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.41776/0.41313. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.40307/0.38866. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.38897/0.36708. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.37450/0.36306. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.35966/0.34521. Took 0.15 sec\n",
      "Epoch 8, Loss(train/val) 0.35088/0.33155. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.34335/0.32325. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.33879/0.32392. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.33597/0.31860. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.32631/0.31861. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.33390/0.31956. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.33062/0.31612. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.32069/0.31318. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.31960/0.31034. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.31346/0.29623. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.31094/0.30903. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.30737/0.31351. Took 0.15 sec\n",
      "Epoch 20, Loss(train/val) 0.30664/0.30308. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.30125/0.30560. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.31484/0.29667. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.29845/0.29764. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.30174/0.29717. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.29511/0.29987. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.28804/0.29688. Took 0.13 sec\n",
      "Epoch 27, Loss(train/val) 0.29128/0.27100. Took 0.13 sec\n",
      "Epoch 28, Loss(train/val) 0.28343/0.27055. Took 0.13 sec\n",
      "Epoch 29, Loss(train/val) 0.27179/0.27808. Took 0.13 sec\n",
      "Epoch 30, Loss(train/val) 0.27660/0.27974. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.27498/0.26608. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.26738/0.28999. Took 0.13 sec\n",
      "Epoch 33, Loss(train/val) 0.26500/0.28140. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.25591/0.27389. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.26481/0.26273. Took 0.13 sec\n",
      "Epoch 36, Loss(train/val) 0.25513/0.26410. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.25134/0.26348. Took 0.15 sec\n",
      "Epoch 38, Loss(train/val) 0.25337/0.27923. Took 0.16 sec\n",
      "Epoch 39, Loss(train/val) 0.25679/0.25303. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.24735/0.26144. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.24591/0.25398. Took 0.15 sec\n",
      "Epoch 42, Loss(train/val) 0.24356/0.26484. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.23798/0.26755. Took 0.12 sec\n",
      "Epoch 44, Loss(train/val) 0.24155/0.25160. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.23439/0.25780. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.22824/0.26632. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.22486/0.24789. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.23615/0.26512. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.24701/0.26634. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.24596/0.28793. Took 0.12 sec\n",
      "Epoch 51, Loss(train/val) 0.22873/0.27620. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.21909/0.25445. Took 0.12 sec\n",
      "Epoch 53, Loss(train/val) 0.22376/0.26938. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.21254/0.27901. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.20423/0.29017. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.20945/0.26003. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.20122/0.27455. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.20888/0.27983. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.19646/0.28159. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.19104/0.28366. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.18961/0.26791. Took 0.12 sec\n",
      "Epoch 62, Loss(train/val) 0.18767/0.27712. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.18752/0.27065. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.18070/0.28143. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.17549/0.28226. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.18228/0.28691. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.17501/0.27035. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.17570/0.25195. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.17249/0.26946. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.16889/0.26165. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.16973/0.26328. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.17850/0.25569. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.16597/0.27006. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.16408/0.26197. Took 0.12 sec\n",
      "Epoch 75, Loss(train/val) 0.16884/0.25881. Took 0.15 sec\n",
      "Epoch 76, Loss(train/val) 0.17203/0.25191. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.16053/0.27445. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.15841/0.24443. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.15770/0.23494. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.15972/0.25564. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.15556/0.27240. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.15857/0.24508. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.14740/0.25932. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.14474/0.26440. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.14931/0.24164. Took 0.12 sec\n",
      "Epoch 86, Loss(train/val) 0.13867/0.23722. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.14627/0.27818. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.14409/0.25227. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.14281/0.27148. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.14645/0.26485. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.14322/0.27684. Took 0.12 sec\n",
      "Epoch 92, Loss(train/val) 0.14131/0.25134. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.15000/0.28999. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.14388/0.25336. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.14625/0.30490. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.13955/0.30205. Took 0.14 sec\n",
      "Epoch 97, Loss(train/val) 0.13335/0.27167. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.13249/0.27838. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.13207/0.26826. Took 0.13 sec\n",
      "ACC: 0.515625, MCC: 0.0518191557963571\n",
      "Epoch 0, Loss(train/val) 0.49543/0.49672. Took 0.13 sec\n",
      "Epoch 1, Loss(train/val) 0.48065/0.48208. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.45712/0.44702. Took 0.12 sec\n",
      "Epoch 3, Loss(train/val) 0.42867/0.41282. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.40853/0.39734. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.39264/0.38239. Took 0.12 sec\n",
      "Epoch 6, Loss(train/val) 0.37951/0.36519. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.37501/0.36770. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.36853/0.37094. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.35089/0.36451. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.34429/0.36513. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.33175/0.37009. Took 0.15 sec\n",
      "Epoch 12, Loss(train/val) 0.31890/0.37488. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.32107/0.37830. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.31406/0.37996. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.30276/0.37354. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.29587/0.39027. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.29073/0.37941. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.27459/0.37978. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.27864/0.37830. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.26793/0.37950. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.26461/0.38198. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.26602/0.38312. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.26585/0.37151. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.25653/0.41146. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.24673/0.38796. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.24599/0.39135. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.22991/0.36092. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.23728/0.39074. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.23444/0.37862. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.23417/0.38567. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.21773/0.38816. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.20953/0.40813. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.21765/0.39771. Took 0.13 sec\n",
      "Epoch 34, Loss(train/val) 0.19833/0.39404. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.20404/0.37048. Took 0.16 sec\n",
      "Epoch 36, Loss(train/val) 0.21150/0.38992. Took 0.13 sec\n",
      "Epoch 37, Loss(train/val) 0.20510/0.36115. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.20097/0.38252. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.19939/0.35748. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.19636/0.38475. Took 0.15 sec\n",
      "Epoch 41, Loss(train/val) 0.18773/0.38708. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.19189/0.38864. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.19198/0.37529. Took 0.12 sec\n",
      "Epoch 44, Loss(train/val) 0.18685/0.38752. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.18219/0.37343. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.18068/0.38042. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.18446/0.36520. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.17873/0.38075. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.17936/0.37709. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.17428/0.35102. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.16082/0.36851. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.17436/0.37303. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.16167/0.35768. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.16347/0.35562. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.16137/0.35683. Took 0.12 sec\n",
      "Epoch 56, Loss(train/val) 0.17330/0.39855. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.17473/0.34902. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.15319/0.36814. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.15955/0.37005. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.15542/0.35897. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.16626/0.33918. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.14710/0.36497. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.14583/0.35041. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.14590/0.36031. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.13572/0.35545. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.13970/0.38110. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.13800/0.36810. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.14106/0.34558. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.13648/0.38640. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.12311/0.36255. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.13458/0.33948. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.13530/0.39537. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.13832/0.35953. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.13385/0.40505. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.13478/0.34960. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.13623/0.39791. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.13174/0.35305. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.13175/0.36934. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.11525/0.38861. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.11942/0.35574. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.12110/0.37952. Took 0.12 sec\n",
      "Epoch 82, Loss(train/val) 0.11876/0.35187. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.11662/0.39278. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.11446/0.35621. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.12498/0.38942. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.11387/0.38685. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.11695/0.38604. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.10588/0.36319. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.11711/0.40125. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.10919/0.38111. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.11404/0.38887. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.10980/0.37993. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.11469/0.36732. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.10683/0.39743. Took 0.12 sec\n",
      "Epoch 95, Loss(train/val) 0.12000/0.39600. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.11193/0.37917. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.11275/0.35128. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.10753/0.37402. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.10051/0.38934. Took 0.12 sec\n",
      "ACC: 0.703125, MCC: 0.40796547611801115\n",
      "Epoch 0, Loss(train/val) 0.49530/0.48554. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.47809/0.45918. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.44701/0.42543. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.41596/0.41075. Took 0.15 sec\n",
      "Epoch 4, Loss(train/val) 0.39616/0.39843. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.38353/0.39449. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.37108/0.38948. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.36824/0.38639. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.36031/0.38850. Took 0.15 sec\n",
      "Epoch 9, Loss(train/val) 0.35454/0.39463. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.33453/0.39730. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.33289/0.38047. Took 0.22 sec\n",
      "Epoch 12, Loss(train/val) 0.32752/0.37454. Took 0.16 sec\n",
      "Epoch 13, Loss(train/val) 0.31397/0.37773. Took 0.16 sec\n",
      "Epoch 14, Loss(train/val) 0.30963/0.37804. Took 0.16 sec\n",
      "Epoch 15, Loss(train/val) 0.29877/0.38574. Took 0.16 sec\n",
      "Epoch 16, Loss(train/val) 0.29880/0.37280. Took 0.15 sec\n",
      "Epoch 17, Loss(train/val) 0.28947/0.37755. Took 0.17 sec\n",
      "Epoch 18, Loss(train/val) 0.28862/0.37749. Took 0.16 sec\n",
      "Epoch 19, Loss(train/val) 0.27868/0.37729. Took 0.15 sec\n",
      "Epoch 20, Loss(train/val) 0.27899/0.37532. Took 0.15 sec\n",
      "Epoch 21, Loss(train/val) 0.27454/0.35972. Took 0.16 sec\n",
      "Epoch 22, Loss(train/val) 0.27548/0.37457. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.27088/0.36963. Took 0.17 sec\n",
      "Epoch 24, Loss(train/val) 0.25928/0.36187. Took 0.16 sec\n",
      "Epoch 25, Loss(train/val) 0.26147/0.36529. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.27376/0.36673. Took 0.15 sec\n",
      "Epoch 27, Loss(train/val) 0.26286/0.34917. Took 0.16 sec\n",
      "Epoch 28, Loss(train/val) 0.25409/0.36360. Took 0.18 sec\n",
      "Epoch 29, Loss(train/val) 0.24986/0.36113. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.25239/0.33508. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.24270/0.33228. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.24120/0.33632. Took 0.16 sec\n",
      "Epoch 33, Loss(train/val) 0.24177/0.33997. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.23733/0.33766. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.23400/0.33881. Took 0.15 sec\n",
      "Epoch 36, Loss(train/val) 0.24345/0.35018. Took 0.16 sec\n",
      "Epoch 37, Loss(train/val) 0.23228/0.32559. Took 0.17 sec\n",
      "Epoch 38, Loss(train/val) 0.23093/0.33179. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.22076/0.32781. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.22878/0.31148. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.22873/0.31131. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.22415/0.32436. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.21570/0.34159. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.21695/0.34231. Took 0.15 sec\n",
      "Epoch 45, Loss(train/val) 0.21761/0.33170. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.21167/0.32811. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.21727/0.34065. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.21404/0.31445. Took 0.15 sec\n",
      "Epoch 49, Loss(train/val) 0.21215/0.31458. Took 0.15 sec\n",
      "Epoch 50, Loss(train/val) 0.20661/0.32773. Took 0.14 sec\n",
      "Epoch 51, Loss(train/val) 0.20022/0.32697. Took 0.15 sec\n",
      "Epoch 52, Loss(train/val) 0.19747/0.32487. Took 0.15 sec\n",
      "Epoch 53, Loss(train/val) 0.18901/0.31284. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.20406/0.31480. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.20050/0.32787. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.19415/0.30800. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.20221/0.31587. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.19332/0.33977. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.18735/0.31914. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.19075/0.32655. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.19175/0.31955. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.19453/0.31296. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.17581/0.31880. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.18947/0.32210. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.17032/0.31143. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.17506/0.33294. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.17850/0.30060. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.18232/0.31646. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.17642/0.32073. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.17395/0.29936. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.16951/0.29544. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.17370/0.30031. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.16361/0.32406. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.16942/0.30667. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.16433/0.31597. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.16056/0.31343. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.16088/0.29994. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.15795/0.31154. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.16394/0.32616. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.16753/0.31077. Took 0.12 sec\n",
      "Epoch 81, Loss(train/val) 0.15946/0.31751. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.15592/0.29172. Took 0.15 sec\n",
      "Epoch 83, Loss(train/val) 0.15707/0.32704. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.14870/0.33049. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.15085/0.32785. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.15680/0.31547. Took 0.15 sec\n",
      "Epoch 87, Loss(train/val) 0.14929/0.31101. Took 0.15 sec\n",
      "Epoch 88, Loss(train/val) 0.14722/0.33209. Took 0.15 sec\n",
      "Epoch 89, Loss(train/val) 0.14118/0.33911. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.13859/0.33395. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.15094/0.31747. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.14528/0.32552. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.13799/0.31334. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.14391/0.33425. Took 0.15 sec\n",
      "Epoch 95, Loss(train/val) 0.13537/0.32860. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.13735/0.34529. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.14122/0.33176. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.13490/0.33497. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.13225/0.31599. Took 0.13 sec\n",
      "ACC: 0.734375, MCC: 0.4679398094493303\n",
      "Epoch 0, Loss(train/val) 0.49317/0.48062. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.47356/0.44727. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.44447/0.41104. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.41527/0.38171. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.39158/0.36304. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.37754/0.35017. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.36533/0.34144. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.34767/0.33081. Took 0.15 sec\n",
      "Epoch 8, Loss(train/val) 0.34956/0.32898. Took 0.16 sec\n",
      "Epoch 9, Loss(train/val) 0.33260/0.30857. Took 0.19 sec\n",
      "Epoch 10, Loss(train/val) 0.32926/0.28704. Took 0.17 sec\n",
      "Epoch 11, Loss(train/val) 0.31603/0.28994. Took 0.16 sec\n",
      "Epoch 12, Loss(train/val) 0.32172/0.29129. Took 0.15 sec\n",
      "Epoch 13, Loss(train/val) 0.30776/0.28500. Took 0.16 sec\n",
      "Epoch 14, Loss(train/val) 0.30130/0.28799. Took 0.16 sec\n",
      "Epoch 15, Loss(train/val) 0.30676/0.29308. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.29078/0.29218. Took 0.15 sec\n",
      "Epoch 17, Loss(train/val) 0.29365/0.29837. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.28918/0.29379. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.27479/0.29741. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.27801/0.29452. Took 0.17 sec\n",
      "Epoch 21, Loss(train/val) 0.27745/0.30397. Took 0.16 sec\n",
      "Epoch 22, Loss(train/val) 0.27236/0.29864. Took 0.19 sec\n",
      "Epoch 23, Loss(train/val) 0.26662/0.30770. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.26615/0.29210. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.26976/0.29887. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.26165/0.30219. Took 0.18 sec\n",
      "Epoch 27, Loss(train/val) 0.25959/0.29712. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.25264/0.30079. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.24666/0.30147. Took 0.16 sec\n",
      "Epoch 30, Loss(train/val) 0.24545/0.31047. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.24008/0.29737. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.24516/0.29924. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.23461/0.30758. Took 0.16 sec\n",
      "Epoch 34, Loss(train/val) 0.23743/0.31378. Took 0.16 sec\n",
      "Epoch 35, Loss(train/val) 0.22832/0.31214. Took 0.15 sec\n",
      "Epoch 36, Loss(train/val) 0.23226/0.30538. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.22603/0.31712. Took 0.15 sec\n",
      "Epoch 38, Loss(train/val) 0.22780/0.31057. Took 0.15 sec\n",
      "Epoch 39, Loss(train/val) 0.21493/0.30634. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.22847/0.32437. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.21359/0.31275. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.22439/0.31757. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.23468/0.30804. Took 0.15 sec\n",
      "Epoch 44, Loss(train/val) 0.21929/0.33316. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.21958/0.31005. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.20676/0.31673. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.21369/0.31021. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.21514/0.30783. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.21241/0.32105. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.21345/0.31352. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.20345/0.31586. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.20222/0.31507. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.20757/0.32543. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.20139/0.31357. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.19789/0.32395. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.20192/0.31628. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.20099/0.35288. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.20165/0.31602. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.20157/0.32101. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.19526/0.32483. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.19039/0.32760. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.18908/0.34834. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.19173/0.31818. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.18811/0.32876. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.17862/0.31309. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.18711/0.32459. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.18981/0.31983. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.18162/0.32756. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.17689/0.30922. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.18675/0.31294. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.17357/0.31764. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.18461/0.33028. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.17832/0.30331. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.17878/0.31240. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.18168/0.31323. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.17436/0.32151. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.17073/0.31501. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.16148/0.30390. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.16826/0.33293. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.17797/0.32031. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.16923/0.31517. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.16223/0.31944. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.16380/0.30794. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.16532/0.31737. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.16250/0.32006. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.16747/0.33211. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.16359/0.32948. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.16901/0.30166. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.16256/0.31997. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.16625/0.32651. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.15924/0.29311. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.16341/0.30556. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.15075/0.32447. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.15895/0.32333. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.15233/0.30716. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.15233/0.29894. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.15421/0.29008. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.15617/0.29567. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.15315/0.30744. Took 0.13 sec\n",
      "ACC: 0.625, MCC: 0.3128205128205128\n",
      "Epoch 0, Loss(train/val) 0.49027/0.48024. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.46673/0.45206. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.44194/0.42645. Took 0.15 sec\n",
      "Epoch 3, Loss(train/val) 0.41893/0.42819. Took 0.15 sec\n",
      "Epoch 4, Loss(train/val) 0.39443/0.41336. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.37627/0.40281. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.36452/0.38663. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.35462/0.35154. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.34187/0.34559. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.33217/0.40344. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.33772/0.35239. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.32816/0.40291. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.32185/0.34920. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.30977/0.36369. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.31147/0.38863. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.30571/0.39247. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.30744/0.32392. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.30723/0.33054. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.29896/0.33864. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.29590/0.36380. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.28625/0.42507. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.29720/0.34285. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.28471/0.35631. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.28380/0.38403. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.27642/0.41693. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.30597/0.37825. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.27246/0.37067. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.27261/0.37497. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.26436/0.38107. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.27053/0.36161. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.26913/0.38803. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.26608/0.38795. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.26863/0.40199. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.27225/0.38354. Took 0.13 sec\n",
      "Epoch 34, Loss(train/val) 0.25331/0.37083. Took 0.13 sec\n",
      "Epoch 35, Loss(train/val) 0.26631/0.37324. Took 0.13 sec\n",
      "Epoch 36, Loss(train/val) 0.25538/0.38154. Took 0.13 sec\n",
      "Epoch 37, Loss(train/val) 0.25218/0.39204. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.24832/0.39256. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.24967/0.37815. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.24900/0.35386. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.24762/0.41077. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.24496/0.38696. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.23065/0.39014. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.24496/0.37758. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.23388/0.42202. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.23987/0.40159. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.22788/0.41042. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.22963/0.41164. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.22824/0.39262. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.22333/0.41682. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.23928/0.41565. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.22561/0.37723. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.22165/0.40522. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.23437/0.50615. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.23327/0.36277. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.22502/0.37966. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.23490/0.49491. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.24745/0.41381. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.21983/0.37379. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.22315/0.36747. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.22083/0.37180. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.22191/0.37031. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.21589/0.40604. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.20757/0.39036. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.20938/0.41238. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.20935/0.41112. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.21017/0.40789. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.20328/0.41483. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.20983/0.41503. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.22255/0.39789. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.21505/0.41724. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.20707/0.40346. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.20786/0.39137. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.19283/0.40891. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.20128/0.40073. Took 0.12 sec\n",
      "Epoch 76, Loss(train/val) 0.20412/0.40600. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.19870/0.39193. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.19905/0.40396. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.19380/0.41324. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.19774/0.40674. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.19539/0.41295. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.19302/0.41227. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.19766/0.42422. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.19898/0.42242. Took 0.12 sec\n",
      "Epoch 85, Loss(train/val) 0.18738/0.41693. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.19121/0.41593. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.18606/0.41534. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.18964/0.42384. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.19009/0.40136. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.18901/0.41948. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.19236/0.42079. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.18657/0.41149. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.18365/0.39175. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.19112/0.39987. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.18239/0.41156. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.17694/0.39841. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.18179/0.41456. Took 0.12 sec\n",
      "Epoch 98, Loss(train/val) 0.19047/0.40010. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.17356/0.40551. Took 0.13 sec\n",
      "ACC: 0.671875, MCC: 0.33613646607466174\n",
      "Epoch 0, Loss(train/val) 0.49456/0.48698. Took 0.13 sec\n",
      "Epoch 1, Loss(train/val) 0.47269/0.45815. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.43748/0.42104. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.40541/0.39676. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.38056/0.38727. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.36832/0.38541. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.35607/0.38720. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.35059/0.36020. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.33945/0.36453. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.33497/0.36031. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.33397/0.31743. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.33134/0.36574. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.33935/0.35687. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.32942/0.36494. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.32665/0.34360. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.32456/0.36090. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.32261/0.32894. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.32204/0.36859. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.31206/0.33349. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.30769/0.35549. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.30557/0.32023. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.31129/0.37991. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.30548/0.31620. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.29917/0.33347. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.29383/0.34147. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.29492/0.31486. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.30233/0.31238. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.28730/0.31562. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.28995/0.30644. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.28973/0.33414. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.28411/0.33821. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.28314/0.31475. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.27733/0.33872. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.27475/0.32794. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.27554/0.32124. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.27012/0.34499. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.27156/0.34516. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.26382/0.36276. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.26040/0.35353. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.27010/0.34308. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.25030/0.35088. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.25420/0.35354. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.24439/0.34658. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.24930/0.35636. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.23901/0.35895. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.24101/0.33490. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.23969/0.36219. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.23640/0.33200. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.24284/0.34148. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.24359/0.36572. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.22766/0.36684. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.22621/0.34790. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.23181/0.33841. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.22238/0.34259. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.21947/0.33583. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.22132/0.34257. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.22287/0.35098. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.21615/0.34701. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.21742/0.36030. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.21538/0.36953. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.21361/0.39266. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.20332/0.36677. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.20368/0.39546. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.20132/0.34824. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.20585/0.35335. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.19783/0.35550. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.20345/0.36884. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.20178/0.36265. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.20186/0.35359. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.19582/0.34593. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.20043/0.37565. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.19557/0.36311. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.19228/0.35275. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.19341/0.38100. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.19167/0.35889. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.19541/0.36716. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.18794/0.34188. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.19058/0.35520. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.18969/0.36622. Took 0.14 sec\n",
      "Epoch 79, Loss(train/val) 0.19118/0.39263. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.17776/0.39623. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.18838/0.39258. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.18604/0.36649. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.18241/0.36030. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.18216/0.37074. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.17948/0.33671. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.17892/0.33997. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.18572/0.35523. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.17145/0.36244. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.17251/0.35833. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.17082/0.33580. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.17541/0.36113. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.17507/0.37247. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.18031/0.32855. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.18142/0.32089. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.17537/0.34691. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.16332/0.34513. Took 0.14 sec\n",
      "Epoch 97, Loss(train/val) 0.17053/0.34251. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.16648/0.34524. Took 0.14 sec\n",
      "Epoch 99, Loss(train/val) 0.15642/0.34339. Took 0.16 sec\n",
      "ACC: 0.640625, MCC: 0.18156825980064073\n",
      "Epoch 0, Loss(train/val) 0.48562/0.49310. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.45688/0.47423. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.42821/0.41898. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.40975/0.38527. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.39250/0.37078. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.37973/0.36559. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.36081/0.36172. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.34862/0.36911. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.34165/0.36607. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.33439/0.37787. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.32600/0.37598. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.31493/0.35497. Took 0.16 sec\n",
      "Epoch 12, Loss(train/val) 0.31035/0.37097. Took 0.15 sec\n",
      "Epoch 13, Loss(train/val) 0.30394/0.35027. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.30185/0.35694. Took 0.17 sec\n",
      "Epoch 15, Loss(train/val) 0.30268/0.37824. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.29431/0.37570. Took 0.16 sec\n",
      "Epoch 17, Loss(train/val) 0.29466/0.38801. Took 0.17 sec\n",
      "Epoch 18, Loss(train/val) 0.28556/0.39260. Took 0.15 sec\n",
      "Epoch 19, Loss(train/val) 0.28661/0.39106. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.27595/0.38470. Took 0.15 sec\n",
      "Epoch 21, Loss(train/val) 0.27274/0.37830. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.27410/0.39504. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.27091/0.36051. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.26427/0.38884. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.26158/0.39885. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.25657/0.39121. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.25712/0.39674. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.27206/0.38134. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.26378/0.39338. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.25294/0.39939. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.25588/0.39853. Took 0.16 sec\n",
      "Epoch 32, Loss(train/val) 0.25169/0.40255. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.24987/0.39836. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.24902/0.40095. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.24790/0.35299. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.24765/0.34330. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.24258/0.35854. Took 0.16 sec\n",
      "Epoch 38, Loss(train/val) 0.24043/0.39411. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.23737/0.36319. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.23596/0.37558. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.23422/0.37280. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.22448/0.35634. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.22974/0.34858. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.22859/0.35779. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.22241/0.34143. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.23203/0.39864. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.23475/0.35817. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.23200/0.36227. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.22328/0.36790. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.21393/0.36001. Took 0.14 sec\n",
      "Epoch 51, Loss(train/val) 0.22731/0.40053. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.20976/0.35113. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.22114/0.37892. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.21794/0.35554. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.22627/0.39291. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.21598/0.35316. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.21579/0.36195. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.20268/0.34458. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.20431/0.33840. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.20311/0.38353. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.19465/0.35407. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.20366/0.34833. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.19780/0.36987. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.19514/0.36810. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.20232/0.36137. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.19152/0.39280. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.18642/0.38923. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.19334/0.37279. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.18701/0.40678. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.18622/0.40373. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.19481/0.35861. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.18852/0.36141. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.18100/0.34750. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.18976/0.35862. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.17864/0.36056. Took 0.15 sec\n",
      "Epoch 76, Loss(train/val) 0.19106/0.34249. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.17783/0.36514. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.17989/0.40307. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.18304/0.37228. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.16913/0.35495. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.17149/0.36880. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.16938/0.36915. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.16965/0.35989. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.16898/0.37601. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.17266/0.38427. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.16569/0.37781. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.16340/0.38998. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.17039/0.37591. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.16899/0.35923. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.16270/0.36274. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.16196/0.37551. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.16328/0.36318. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.15378/0.36379. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.15814/0.37091. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.15936/0.36522. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.15483/0.35098. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.15888/0.34999. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.15322/0.40481. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.14692/0.40203. Took 0.13 sec\n",
      "ACC: 0.6875, MCC: 0.37254901960784315\n",
      "Epoch 0, Loss(train/val) 0.49083/0.48117. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.46690/0.45905. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.43922/0.44385. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.41604/0.42409. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.39832/0.41209. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.38409/0.40591. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.36638/0.40985. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.36223/0.39591. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.34627/0.36747. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.34187/0.37081. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.34719/0.38673. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.33417/0.36083. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.32091/0.36423. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.31273/0.34991. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.30514/0.33794. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.31284/0.35224. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.29731/0.33324. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.29871/0.33714. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.29981/0.34925. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.28726/0.35565. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.27629/0.33757. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.27798/0.35207. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.27364/0.33283. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.27040/0.32573. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.28046/0.32991. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.26570/0.34775. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.26456/0.32860. Took 0.13 sec\n",
      "Epoch 27, Loss(train/val) 0.25239/0.33818. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.25934/0.33423. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.24736/0.32269. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.25467/0.32840. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.24416/0.32686. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.24419/0.33182. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.25025/0.34468. Took 0.13 sec\n",
      "Epoch 34, Loss(train/val) 0.23546/0.35198. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.23086/0.34993. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.23590/0.37690. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.23727/0.31387. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.23925/0.33827. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.22525/0.37649. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.23799/0.33672. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.23324/0.37488. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.22864/0.38096. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.22368/0.34375. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.21516/0.34379. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) 0.21052/0.33853. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.21196/0.37364. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.20951/0.37781. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.21210/0.38993. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.20513/0.37442. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.20529/0.34365. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.20614/0.37324. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.20019/0.35613. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.20088/0.36535. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.20040/0.33061. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.20311/0.36452. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.19762/0.34009. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.18514/0.35047. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.17645/0.36217. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.19743/0.34696. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.18830/0.35971. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.18029/0.37230. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.18157/0.35376. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.17916/0.36519. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.18502/0.37180. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.18035/0.37027. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.17803/0.36421. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.18891/0.32758. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.19210/0.35649. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.17222/0.36689. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.16564/0.35748. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.16590/0.36569. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.16283/0.35981. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.17457/0.37740. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.17589/0.36921. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.17093/0.33311. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.18898/0.36099. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.16395/0.36144. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.15977/0.36570. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.16583/0.32421. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.14831/0.35365. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.15664/0.34673. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.15985/0.34190. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.16443/0.35298. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.15187/0.34786. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.15429/0.34615. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.15021/0.34427. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.14232/0.35012. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.14159/0.36196. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.15006/0.35023. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.15665/0.34589. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.14511/0.35585. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.15333/0.34278. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.14949/0.33630. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.14329/0.34847. Took 0.14 sec\n",
      "Epoch 95, Loss(train/val) 0.13896/0.33731. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.13904/0.34245. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.13437/0.35835. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.14354/0.36463. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.14104/0.35558. Took 0.13 sec\n",
      "ACC: 0.640625, MCC: 0.27475662250225863\n",
      "Epoch 0, Loss(train/val) 0.49185/0.46981. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.46881/0.42425. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.43864/0.38789. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.41186/0.36452. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.39841/0.34603. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.38453/0.33430. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.37602/0.34506. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.36251/0.34168. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.34903/0.35485. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.33360/0.36435. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.32805/0.36121. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.31763/0.34167. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.32526/0.33704. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.31094/0.34507. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.30805/0.34700. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.30364/0.35265. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.29881/0.34382. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.29518/0.33677. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.29190/0.33105. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.29761/0.33451. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.28097/0.33119. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.28433/0.35246. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.28281/0.34837. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.27856/0.33536. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.28138/0.34240. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.27980/0.34242. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.27540/0.35707. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.27501/0.34629. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.26786/0.35005. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.26202/0.32566. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.26665/0.35086. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.26123/0.35977. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.25743/0.34411. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.25644/0.34784. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.24887/0.34429. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.25252/0.35246. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.24164/0.33353. Took 0.16 sec\n",
      "Epoch 37, Loss(train/val) 0.25146/0.36239. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.24233/0.35276. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.24497/0.34340. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.24110/0.32592. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.23589/0.34333. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.23468/0.35133. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.23281/0.35499. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.22543/0.33321. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.22486/0.36633. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.23241/0.33475. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.23078/0.32710. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.23440/0.32959. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.22807/0.37239. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.23127/0.34580. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.22854/0.34902. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.22178/0.36723. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.22166/0.36236. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.22216/0.35300. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.22410/0.33820. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.21826/0.37222. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.21162/0.37715. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.22249/0.40810. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.24893/0.38599. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.21812/0.36629. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.21339/0.35892. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.22180/0.34072. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.20983/0.36583. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.20341/0.36266. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.20917/0.35308. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.20326/0.38833. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.20904/0.37799. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.20619/0.35600. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.20344/0.36881. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.20102/0.35628. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.20579/0.34081. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.19973/0.38065. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.20179/0.35813. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.18588/0.36526. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.19095/0.37181. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.19963/0.37400. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.19950/0.34962. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.19236/0.36513. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.20164/0.36492. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.18868/0.39274. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.19273/0.37513. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.19278/0.38695. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.19043/0.35926. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.19090/0.37174. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.19470/0.36385. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.18804/0.36487. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.19418/0.34819. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.18374/0.34692. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.18966/0.35363. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.18228/0.38735. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.18540/0.36886. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.18997/0.37918. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.18096/0.37766. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.19219/0.39277. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.18728/0.39244. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.17863/0.39348. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.18432/0.39070. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.17911/0.38541. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.17146/0.36907. Took 0.13 sec\n",
      "ACC: 0.515625, MCC: 0.022628141110071023\n",
      "Epoch 0, Loss(train/val) 0.49388/0.49423. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.47247/0.48284. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.43412/0.46820. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.40354/0.46545. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.37936/0.46980. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.36377/0.46973. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.35929/0.49214. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.34859/0.46768. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.34372/0.47552. Took 0.15 sec\n",
      "Epoch 9, Loss(train/val) 0.33165/0.46603. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.32424/0.46709. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.32042/0.47165. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.31588/0.46538. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.32450/0.45787. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.30996/0.43585. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.30579/0.46151. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.30404/0.46350. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.29530/0.46296. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.29018/0.46043. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.28808/0.46172. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.28466/0.43831. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.27927/0.45421. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.28108/0.43368. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.27345/0.42784. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.28733/0.45401. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.26800/0.44495. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.26287/0.45317. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.26402/0.44417. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.25537/0.44285. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.25553/0.44703. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.25646/0.44483. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.25426/0.43409. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.24735/0.43051. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.24991/0.44025. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.24371/0.46676. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.24334/0.44983. Took 0.15 sec\n",
      "Epoch 36, Loss(train/val) 0.23750/0.44882. Took 0.13 sec\n",
      "Epoch 37, Loss(train/val) 0.23436/0.45912. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.22619/0.44195. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.23173/0.46389. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.23365/0.44083. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.21888/0.46031. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.21380/0.44378. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.21989/0.45283. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.21363/0.42591. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.24116/0.41742. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.21891/0.41293. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.21510/0.43560. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.21236/0.41603. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.21926/0.44231. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.21610/0.42378. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.21886/0.42008. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.20488/0.43982. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.19509/0.43774. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.19610/0.43898. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.19778/0.44355. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.18945/0.42052. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.18238/0.41956. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.18806/0.43102. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.18691/0.40729. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.18255/0.44515. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.18797/0.42793. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.17878/0.44511. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.17929/0.43978. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.17034/0.43658. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.16955/0.40367. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.17403/0.43419. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.17495/0.43644. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.17721/0.44557. Took 0.14 sec\n",
      "Epoch 69, Loss(train/val) 0.16919/0.41563. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.17265/0.42165. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.16802/0.43597. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.16106/0.42514. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.16769/0.43061. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.15928/0.44171. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.16228/0.42039. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.16398/0.42178. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.15343/0.42563. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.16424/0.41972. Took 0.12 sec\n",
      "Epoch 79, Loss(train/val) 0.16361/0.42426. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.15383/0.40260. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.15514/0.41582. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.15427/0.42270. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.15840/0.42717. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.15608/0.41938. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.16436/0.43740. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.15550/0.41747. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.16378/0.43327. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.15228/0.42275. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.16312/0.44347. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.17122/0.38479. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.16069/0.40123. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.16025/0.43131. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.14699/0.41175. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.14674/0.40203. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.15001/0.40495. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.15221/0.40166. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.15232/0.39061. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.15127/0.39468. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.14003/0.40154. Took 0.13 sec\n",
      "ACC: 0.578125, MCC: 0.18149475129798115\n",
      "Epoch 0, Loss(train/val) 0.49458/0.48964. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.47393/0.46945. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.43772/0.44464. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.40698/0.43589. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.38849/0.43397. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.37589/0.42750. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.36684/0.42391. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.36220/0.41884. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.35298/0.42253. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.33515/0.42559. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.33511/0.41599. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.32533/0.38731. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.31873/0.37273. Took 0.15 sec\n",
      "Epoch 13, Loss(train/val) 0.30775/0.38828. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.29239/0.34902. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.28474/0.35116. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.29732/0.33719. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.28498/0.33874. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.28628/0.36368. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.28585/0.35439. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.28004/0.39234. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.27552/0.36692. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.26919/0.36620. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.27558/0.33812. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.27603/0.41150. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.27806/0.38272. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.26591/0.37972. Took 0.15 sec\n",
      "Epoch 27, Loss(train/val) 0.25169/0.39583. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.26422/0.38097. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.25745/0.36967. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.25567/0.34867. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.25272/0.42564. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.25523/0.38412. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.23961/0.35668. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.24276/0.45495. Took 0.13 sec\n",
      "Epoch 35, Loss(train/val) 0.24933/0.38169. Took 0.13 sec\n",
      "Epoch 36, Loss(train/val) 0.24646/0.42622. Took 0.13 sec\n",
      "Epoch 37, Loss(train/val) 0.24264/0.39674. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.23228/0.40872. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.22326/0.39550. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.22623/0.39086. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.22716/0.41192. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.22748/0.38388. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.22359/0.35659. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.22165/0.41703. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.22928/0.36367. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.21455/0.38217. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.22142/0.37187. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.21371/0.38767. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.21527/0.35648. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.21368/0.42341. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.20392/0.37466. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.20282/0.41223. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.20178/0.41266. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.19612/0.35991. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.20803/0.41135. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.20172/0.38310. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.18872/0.39477. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.19217/0.40340. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.19772/0.38281. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.19462/0.40937. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.19587/0.39449. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.17525/0.38926. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.18160/0.39263. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.17589/0.38489. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.18395/0.40098. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.18253/0.38985. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.17229/0.40767. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.17273/0.39698. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.17156/0.39487. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.16537/0.38773. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.16450/0.40107. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.15616/0.36645. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.15135/0.40913. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.15442/0.40358. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.15521/0.41255. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.15139/0.40691. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.15524/0.40817. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.15292/0.42901. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.14858/0.40800. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.16350/0.41332. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.15142/0.41586. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.14631/0.42130. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.14635/0.41466. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.14560/0.40245. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.14805/0.41581. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.13371/0.40592. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.14095/0.40305. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.13953/0.38016. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.13022/0.40210. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.13000/0.39209. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.13795/0.38372. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.12572/0.40012. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.13318/0.39059. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.12596/0.38904. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.11784/0.40151. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.11985/0.39058. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.12548/0.40034. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.12227/0.36573. Took 0.14 sec\n",
      "Epoch 99, Loss(train/val) 0.12095/0.38665. Took 0.14 sec\n",
      "ACC: 0.6875, MCC: 0.37748632692066614\n",
      "Epoch 0, Loss(train/val) 0.49361/0.48840. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.47703/0.46348. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.44992/0.40802. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.42263/0.36310. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.40607/0.35258. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.39413/0.36168. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.38817/0.32485. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.37569/0.31348. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.36897/0.30056. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.35440/0.30004. Took 0.15 sec\n",
      "Epoch 10, Loss(train/val) 0.34115/0.29475. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.33359/0.30576. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.33726/0.29452. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.33385/0.26496. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.32167/0.27271. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.31018/0.30762. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.30298/0.30479. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.30960/0.35927. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.30399/0.27820. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.29419/0.27359. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.29612/0.41320. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.30802/0.36159. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.29205/0.26878. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.29082/0.28121. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.27702/0.26629. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.28076/0.25024. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.28030/0.25911. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.26782/0.27677. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.26881/0.26708. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.26065/0.26585. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.26350/0.28771. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.25477/0.28654. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.26018/0.33130. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.24713/0.26634. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.24981/0.28000. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.23711/0.35166. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.24487/0.30116. Took 0.13 sec\n",
      "Epoch 37, Loss(train/val) 0.24447/0.33242. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.24622/0.33811. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.23378/0.31478. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.23860/0.32788. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.23499/0.32244. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.23517/0.30785. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.23121/0.29153. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.21795/0.29645. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.22385/0.30437. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.22219/0.31736. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.21552/0.29838. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.22739/0.34768. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.20742/0.32767. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.21856/0.34082. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.20968/0.34897. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.21522/0.33138. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.20294/0.32393. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.20283/0.32134. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.20032/0.31090. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.19632/0.31097. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.20396/0.33560. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.19528/0.34751. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.19738/0.37549. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.18937/0.30585. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.19018/0.30504. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.18626/0.30460. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.19992/0.28998. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.19015/0.26133. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.18792/0.28324. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.18652/0.31173. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.18117/0.33377. Took 0.12 sec\n",
      "Epoch 68, Loss(train/val) 0.18797/0.32060. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.19111/0.25938. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.18411/0.30689. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.19024/0.33771. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.17743/0.33016. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.17463/0.25537. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.17677/0.29043. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.17707/0.28679. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.17196/0.31189. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.17346/0.28475. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.17410/0.26420. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.18346/0.27410. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.16943/0.32535. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.17384/0.26848. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.17406/0.26298. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.17829/0.29275. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.16677/0.30478. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.15874/0.29278. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.17141/0.26225. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.17420/0.32685. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.17034/0.28808. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.15716/0.29663. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.15596/0.27255. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.15334/0.25815. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.16153/0.30907. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.15222/0.31179. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.15038/0.28131. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.15386/0.31357. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.14674/0.29498. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.15854/0.31067. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.14372/0.26858. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.14995/0.29648. Took 0.13 sec\n",
      "ACC: 0.671875, MCC: 0.3322807683739742\n",
      "Epoch 0, Loss(train/val) 0.49518/0.49500. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.47932/0.47983. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.44577/0.46004. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.41283/0.45153. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.39547/0.44536. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.38240/0.43110. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.36933/0.44448. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.35912/0.41728. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.34710/0.40249. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.33350/0.36894. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.32072/0.38524. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.30863/0.35769. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.30258/0.37010. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.29842/0.31758. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.29924/0.32118. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.29663/0.33975. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.29569/0.35433. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.28039/0.36510. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.28383/0.35052. Took 0.15 sec\n",
      "Epoch 19, Loss(train/val) 0.26825/0.33939. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.28475/0.37119. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.26616/0.35006. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.27871/0.35650. Took 0.15 sec\n",
      "Epoch 23, Loss(train/val) 0.26705/0.36041. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.27471/0.36703. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.27586/0.35099. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.25946/0.35399. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.25791/0.34775. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.25229/0.35202. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.23796/0.35279. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.24579/0.35793. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.25184/0.35507. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.23516/0.32233. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.25188/0.37172. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.23106/0.35333. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.23724/0.36487. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.22889/0.35916. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.25431/0.37686. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.23731/0.33552. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.23581/0.34876. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.22108/0.37063. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.22020/0.35550. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.21922/0.33430. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.23402/0.36908. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.23567/0.38260. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.22574/0.35863. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.21176/0.34045. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.21326/0.37459. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.20727/0.35414. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.19699/0.36469. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.20072/0.37587. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.20775/0.38512. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.19586/0.38836. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.21143/0.38983. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.19598/0.38129. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.19640/0.39629. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.19336/0.38119. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.19633/0.40325. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.18915/0.39092. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.18924/0.38512. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.18522/0.38792. Took 0.14 sec\n",
      "Epoch 61, Loss(train/val) 0.17851/0.39065. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.17860/0.37452. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.18096/0.37153. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.17738/0.40498. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.17347/0.37289. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.17811/0.41149. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.16783/0.39528. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.17173/0.38981. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.16770/0.41881. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.17063/0.38184. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.16637/0.38820. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.15801/0.40798. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.15996/0.40072. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.16177/0.38829. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.15991/0.39551. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.15369/0.39304. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.15457/0.38511. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.15909/0.37773. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.16025/0.38263. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.16711/0.40125. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.14880/0.41228. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.15822/0.38888. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.14296/0.43281. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.14133/0.42445. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.14611/0.41781. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.15363/0.37186. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.14842/0.40854. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.14923/0.37310. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.14221/0.38892. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.14284/0.40134. Took 0.14 sec\n",
      "Epoch 91, Loss(train/val) 0.13016/0.38481. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.13380/0.39952. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.13032/0.40268. Took 0.12 sec\n",
      "Epoch 94, Loss(train/val) 0.13789/0.42261. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.14568/0.41562. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.13307/0.39914. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.12695/0.40378. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.13276/0.41923. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.12867/0.39744. Took 0.13 sec\n",
      "ACC: 0.65625, MCC: 0.3068118704595474\n",
      "Epoch 0, Loss(train/val) 0.49865/0.49591. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.48707/0.48262. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.46321/0.46352. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.42548/0.45385. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.39728/0.44765. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.38322/0.44633. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.37801/0.44273. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.36475/0.44509. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.34917/0.43671. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.34702/0.44233. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.32946/0.42800. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.32042/0.42051. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.31231/0.41222. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.30719/0.39439. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.29052/0.40380. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.28621/0.39344. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.28104/0.38094. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.27348/0.39423. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.27234/0.39409. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.25515/0.37015. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.25675/0.34086. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.25111/0.34171. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.24546/0.35295. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.23401/0.34495. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.24203/0.33578. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.24643/0.33544. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.22881/0.34259. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.22781/0.34488. Took 0.16 sec\n",
      "Epoch 28, Loss(train/val) 0.22735/0.34981. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.22396/0.33827. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.21716/0.33302. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.21871/0.34828. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.22037/0.34890. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.21178/0.34630. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.20932/0.32571. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.21285/0.34920. Took 0.13 sec\n",
      "Epoch 36, Loss(train/val) 0.20631/0.35579. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.20824/0.33435. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.20750/0.34414. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.20636/0.36344. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.20923/0.33507. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.19908/0.35054. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.18632/0.33413. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.18796/0.33789. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.19543/0.32210. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.18986/0.32865. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.18661/0.33477. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.18091/0.33882. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.18232/0.33500. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.18041/0.33056. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.18398/0.33231. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.17863/0.34438. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.17625/0.34020. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.17360/0.32467. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.16425/0.32223. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.16353/0.31487. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.16794/0.33406. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.17134/0.32512. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.16240/0.32247. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.16794/0.32980. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.16672/0.31773. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.15668/0.31894. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.16146/0.33328. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.16193/0.34119. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.15640/0.32756. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.15481/0.32827. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.16323/0.30991. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.16033/0.31966. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.15209/0.30708. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.15293/0.32502. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.15255/0.30236. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.14776/0.34528. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.15677/0.31088. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.14877/0.32269. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.14515/0.34881. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.14533/0.34432. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.14164/0.33939. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.14181/0.33759. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.14414/0.33032. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.14909/0.32018. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.13862/0.30945. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.13874/0.29452. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.13444/0.32388. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.14799/0.32225. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.14088/0.32949. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.13463/0.32859. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.13434/0.31564. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.13166/0.31890. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.13357/0.31096. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.14983/0.32410. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.13643/0.33007. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.12513/0.33486. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.12707/0.31978. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.13418/0.33616. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.12338/0.31750. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.12816/0.32142. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.12385/0.30663. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.11949/0.31885. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.11875/0.30803. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.12181/0.31828. Took 0.13 sec\n",
      "ACC: 0.625, MCC: 0.2549085439987685\n",
      "Epoch 0, Loss(train/val) 0.49457/0.48317. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.47334/0.45837. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.44023/0.41796. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.40793/0.39374. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.39342/0.37431. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.37969/0.35815. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.37336/0.37295. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.35734/0.34599. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.35185/0.39247. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.33714/0.34556. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.32865/0.33922. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.32258/0.35379. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.31496/0.33965. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.31208/0.35266. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.30642/0.34762. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.30738/0.38199. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.30232/0.32943. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.30624/0.36066. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.28912/0.34490. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.29529/0.34752. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.28982/0.38841. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.28190/0.36265. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.29237/0.35779. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.28254/0.34873. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.27517/0.35024. Took 0.15 sec\n",
      "Epoch 25, Loss(train/val) 0.26216/0.35892. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.27212/0.35236. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.26846/0.35349. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.25988/0.34180. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.26229/0.34727. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.25782/0.35833. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.25484/0.36371. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.24251/0.37188. Took 0.18 sec\n",
      "Epoch 33, Loss(train/val) 0.25653/0.35655. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.24531/0.36202. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.24172/0.35765. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.23464/0.37698. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.23619/0.36831. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.22813/0.38612. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.23676/0.35910. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.23582/0.36793. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.23759/0.36780. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.22194/0.38283. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.22909/0.35340. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.22387/0.33821. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.22272/0.37164. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.22293/0.37207. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.21205/0.35962. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.20900/0.39472. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.22313/0.38047. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.21412/0.39865. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.21157/0.36567. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.22710/0.36751. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.20807/0.37237. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.20746/0.38062. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.20624/0.40195. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.20846/0.38801. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.20287/0.39275. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.20648/0.41547. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.20089/0.40334. Took 0.15 sec\n",
      "Epoch 60, Loss(train/val) 0.19850/0.41718. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.20201/0.40089. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.20204/0.40556. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.19710/0.42344. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.18775/0.42777. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.18517/0.41632. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.18062/0.41845. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.18677/0.41473. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.18617/0.40141. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.18504/0.40394. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.17586/0.39603. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.18465/0.40729. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.17711/0.39412. Took 0.16 sec\n",
      "Epoch 73, Loss(train/val) 0.17617/0.40714. Took 0.16 sec\n",
      "Epoch 74, Loss(train/val) 0.16894/0.38331. Took 0.18 sec\n",
      "Epoch 75, Loss(train/val) 0.17783/0.40100. Took 0.16 sec\n",
      "Epoch 76, Loss(train/val) 0.17997/0.37670. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.17321/0.37888. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.17730/0.39962. Took 0.16 sec\n",
      "Epoch 79, Loss(train/val) 0.16381/0.41947. Took 0.16 sec\n",
      "Epoch 80, Loss(train/val) 0.16935/0.41705. Took 0.14 sec\n",
      "Epoch 81, Loss(train/val) 0.17207/0.40418. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.17151/0.39188. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.17151/0.39730. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.15562/0.41321. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.15568/0.42153. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.17125/0.42184. Took 0.16 sec\n",
      "Epoch 87, Loss(train/val) 0.16191/0.39890. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.15745/0.42435. Took 0.16 sec\n",
      "Epoch 89, Loss(train/val) 0.15647/0.42786. Took 0.16 sec\n",
      "Epoch 90, Loss(train/val) 0.14911/0.41890. Took 0.14 sec\n",
      "Epoch 91, Loss(train/val) 0.15988/0.43116. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.15418/0.43082. Took 0.15 sec\n",
      "Epoch 93, Loss(train/val) 0.15818/0.39754. Took 0.15 sec\n",
      "Epoch 94, Loss(train/val) 0.14820/0.42528. Took 0.16 sec\n",
      "Epoch 95, Loss(train/val) 0.15239/0.41341. Took 0.15 sec\n",
      "Epoch 96, Loss(train/val) 0.15704/0.42462. Took 0.14 sec\n",
      "Epoch 97, Loss(train/val) 0.15570/0.39741. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.15562/0.40884. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.15024/0.38929. Took 0.14 sec\n",
      "ACC: 0.59375, MCC: 0.24417981228316957\n",
      "Epoch 0, Loss(train/val) 0.49433/0.47929. Took 0.16 sec\n",
      "Epoch 1, Loss(train/val) 0.47454/0.45139. Took 0.15 sec\n",
      "Epoch 2, Loss(train/val) 0.44746/0.42893. Took 0.16 sec\n",
      "Epoch 3, Loss(train/val) 0.41623/0.41929. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.39709/0.41364. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.38358/0.40850. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.37826/0.40532. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.36424/0.40283. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.35879/0.39615. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.35076/0.39255. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.34464/0.40007. Took 0.18 sec\n",
      "Epoch 11, Loss(train/val) 0.33254/0.39156. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.32522/0.38745. Took 0.17 sec\n",
      "Epoch 13, Loss(train/val) 0.32548/0.38741. Took 0.16 sec\n",
      "Epoch 14, Loss(train/val) 0.31541/0.36671. Took 0.17 sec\n",
      "Epoch 15, Loss(train/val) 0.30841/0.38493. Took 0.17 sec\n",
      "Epoch 16, Loss(train/val) 0.30926/0.37964. Took 0.17 sec\n",
      "Epoch 17, Loss(train/val) 0.29535/0.35505. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.29678/0.36062. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.29471/0.35595. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.28755/0.35964. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.28356/0.34228. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.27738/0.35592. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.27696/0.34283. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.28408/0.34556. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.27771/0.33757. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.27640/0.36012. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.27094/0.34102. Took 0.13 sec\n",
      "Epoch 28, Loss(train/val) 0.25941/0.35193. Took 0.13 sec\n",
      "Epoch 29, Loss(train/val) 0.26443/0.32276. Took 0.13 sec\n",
      "Epoch 30, Loss(train/val) 0.25851/0.35255. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.25893/0.36264. Took 0.16 sec\n",
      "Epoch 32, Loss(train/val) 0.26034/0.33276. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.25917/0.38776. Took 0.18 sec\n",
      "Epoch 34, Loss(train/val) 0.26060/0.35895. Took 0.18 sec\n",
      "Epoch 35, Loss(train/val) 0.24678/0.34499. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.25749/0.33770. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.24288/0.35755. Took 0.16 sec\n",
      "Epoch 38, Loss(train/val) 0.24475/0.35259. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.24117/0.33565. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.23838/0.35276. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.23302/0.36013. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.24065/0.35186. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.22985/0.35148. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.22972/0.38080. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.22749/0.34116. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.22139/0.37380. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.22087/0.34540. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.23083/0.33633. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.22793/0.39240. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.22038/0.35554. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.21735/0.33228. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.21175/0.37310. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.20568/0.32570. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.21122/0.36822. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.21468/0.35022. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.19736/0.36107. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.20580/0.35334. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.20745/0.41044. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.20507/0.35685. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.19906/0.34108. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.19130/0.36781. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.20327/0.35503. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.19600/0.38179. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.19941/0.33991. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.19357/0.35361. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.19178/0.36311. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.18548/0.36772. Took 0.15 sec\n",
      "Epoch 68, Loss(train/val) 0.19245/0.36316. Took 0.14 sec\n",
      "Epoch 69, Loss(train/val) 0.18641/0.34683. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.18890/0.35779. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.18877/0.37358. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.17949/0.38280. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.18739/0.34900. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.18034/0.36069. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.18029/0.34470. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.17530/0.35940. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.17675/0.36381. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.17687/0.36657. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.17449/0.34711. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.17707/0.35727. Took 0.14 sec\n",
      "Epoch 81, Loss(train/val) 0.16385/0.36646. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.17477/0.38150. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.16964/0.35626. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.17814/0.34943. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.18110/0.36238. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.16934/0.37404. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.17906/0.38354. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.17302/0.39286. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.16445/0.40377. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.16683/0.38314. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.16321/0.36603. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.16986/0.43292. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.18626/0.37716. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.16565/0.37566. Took 0.14 sec\n",
      "Epoch 95, Loss(train/val) 0.16455/0.39658. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.16397/0.38728. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.16241/0.40133. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.15751/0.35535. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.15920/0.37895. Took 0.14 sec\n",
      "ACC: 0.71875, MCC: 0.45701876893374443\n",
      "Epoch 0, Loss(train/val) 0.49296/0.48522. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.47643/0.46554. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.44904/0.43365. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.41486/0.40261. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.38942/0.38954. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.37650/0.38597. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.36074/0.38062. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.35310/0.38200. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.34372/0.37968. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.33323/0.36957. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.32733/0.35707. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.31464/0.36269. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.30769/0.37092. Took 0.15 sec\n",
      "Epoch 13, Loss(train/val) 0.30622/0.36958. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.29796/0.37141. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.29648/0.39325. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.29399/0.37434. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.29293/0.39419. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.29461/0.38772. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.29305/0.36820. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.27452/0.38432. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.27542/0.38900. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.26913/0.39445. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.26315/0.37243. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.26767/0.37883. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.25588/0.37049. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.25524/0.37379. Took 0.13 sec\n",
      "Epoch 27, Loss(train/val) 0.24846/0.39658. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.25381/0.38301. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.24321/0.38815. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.24837/0.37428. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.23730/0.39166. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.24116/0.38731. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.24365/0.38713. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.23011/0.39447. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.23244/0.38750. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.22934/0.38151. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.22874/0.39561. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.22366/0.38399. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.24910/0.37993. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.23497/0.39890. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.22904/0.38662. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.23566/0.40896. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.22178/0.39549. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.21675/0.40361. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.21842/0.39043. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.21727/0.36971. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.22121/0.39436. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.23573/0.41127. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.21365/0.40572. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.20896/0.39929. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.20808/0.39720. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.20401/0.38089. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.21223/0.38839. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.20522/0.40912. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.19863/0.40375. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.21070/0.38381. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.19962/0.40966. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.19858/0.39799. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.19252/0.39364. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.19703/0.39705. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.19427/0.40926. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.19575/0.39513. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.19326/0.40499. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.19484/0.42142. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.19400/0.39701. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.19240/0.39317. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.19621/0.42845. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.18864/0.39222. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.18987/0.38980. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.18639/0.40521. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.19105/0.41494. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.18939/0.41164. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.18349/0.41138. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.18088/0.41880. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.18795/0.41951. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.18330/0.40013. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.17561/0.42274. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.17859/0.41995. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.17385/0.42813. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.17506/0.40126. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.17886/0.39923. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.17656/0.42639. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.17628/0.41550. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.17802/0.43050. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.17133/0.41932. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.17061/0.40186. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.18179/0.43013. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.17137/0.42782. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.17295/0.42000. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.17483/0.40385. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.17194/0.39565. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.17140/0.43234. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.16872/0.42055. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.17546/0.40780. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.16606/0.40686. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.16260/0.40662. Took 0.14 sec\n",
      "Epoch 97, Loss(train/val) 0.16373/0.40797. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.16576/0.40940. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.16443/0.43314. Took 0.13 sec\n",
      "ACC: 0.671875, MCC: 0.366057079101847\n",
      "Epoch 0, Loss(train/val) 0.49753/0.49001. Took 0.13 sec\n",
      "Epoch 1, Loss(train/val) 0.48248/0.47106. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.45787/0.43550. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.42413/0.40209. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.40331/0.39054. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.39010/0.39113. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.37392/0.39131. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.36292/0.37906. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.34340/0.40841. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.33825/0.36539. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.32711/0.41563. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.32086/0.37070. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.30608/0.41527. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.30636/0.34877. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.30509/0.40508. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.31239/0.37202. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.29678/0.38812. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.29102/0.35606. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.27866/0.32707. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.28180/0.37775. Took 0.15 sec\n",
      "Epoch 20, Loss(train/val) 0.28473/0.35402. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.28022/0.36558. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.28723/0.31317. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.27255/0.39761. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.28809/0.30798. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.28107/0.36013. Took 0.16 sec\n",
      "Epoch 26, Loss(train/val) 0.27306/0.34912. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.26261/0.34383. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.25396/0.37802. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.25542/0.33346. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.24398/0.29460. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.25410/0.36134. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.25219/0.29672. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.24863/0.32801. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.24510/0.28511. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.23549/0.28602. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.23416/0.29362. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.24341/0.30057. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.23796/0.28190. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.23992/0.29469. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.23284/0.28024. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.23256/0.31457. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.23056/0.27416. Took 0.15 sec\n",
      "Epoch 43, Loss(train/val) 0.22309/0.27415. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.22532/0.27426. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.21123/0.28626. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.20897/0.26138. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.22015/0.33208. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.22057/0.29875. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.21472/0.29808. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.21612/0.28902. Took 0.14 sec\n",
      "Epoch 51, Loss(train/val) 0.19971/0.30510. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.20963/0.28468. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.20737/0.30978. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.20360/0.31780. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.19577/0.31966. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.20455/0.30681. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.20777/0.29992. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.19671/0.31910. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.19195/0.32359. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.19323/0.32036. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.18761/0.32646. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.19906/0.32252. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.19323/0.32688. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.18513/0.29400. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.18664/0.32521. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.18316/0.34042. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.19050/0.32125. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.17321/0.32254. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.17689/0.32025. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.18064/0.31901. Took 0.12 sec\n",
      "Epoch 71, Loss(train/val) 0.18477/0.29302. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.17615/0.33655. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.18641/0.32859. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.16375/0.32141. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.17406/0.32363. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.17338/0.33501. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.16776/0.33939. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.16972/0.33454. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.16288/0.35007. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.15928/0.34223. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.16541/0.33345. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.16724/0.33693. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.16071/0.33915. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.16698/0.33106. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.16730/0.32507. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.15418/0.34300. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.15627/0.34736. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.15642/0.34428. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.16529/0.31623. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.15341/0.33285. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.15603/0.29965. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.15148/0.31455. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.16101/0.32703. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.16940/0.33163. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.16039/0.30684. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.14826/0.33045. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.15015/0.33593. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.15014/0.31462. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.14526/0.33404. Took 0.13 sec\n",
      "ACC: 0.71875, MCC: 0.3768673314407159\n",
      "Epoch 0, Loss(train/val) 0.49111/0.46660. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.46695/0.40670. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.43359/0.35344. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.40203/0.33050. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.38832/0.32433. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.37806/0.32335. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.37355/0.31973. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.36967/0.31301. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.36409/0.31488. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.35982/0.31403. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.36007/0.31245. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.35093/0.31647. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.34904/0.31328. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.34690/0.31400. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.34242/0.31068. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.33438/0.31100. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.32162/0.31701. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.31747/0.31640. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.31198/0.33381. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.30520/0.31939. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.29085/0.32290. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.29219/0.32941. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.28047/0.31861. Took 0.15 sec\n",
      "Epoch 23, Loss(train/val) 0.27924/0.32828. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.27900/0.30156. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.26897/0.30647. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.26900/0.33783. Took 0.15 sec\n",
      "Epoch 27, Loss(train/val) 0.27058/0.30238. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.26203/0.30393. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.25332/0.31040. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.25170/0.29710. Took 0.13 sec\n",
      "Epoch 31, Loss(train/val) 0.24261/0.30096. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.24983/0.28128. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.24556/0.27627. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.23627/0.26289. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.22978/0.27047. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.22874/0.24395. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.23460/0.24793. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.23361/0.26268. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.23150/0.25057. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.22502/0.24587. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.21247/0.25153. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.21160/0.27148. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.22104/0.27807. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.21577/0.26099. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.20850/0.26061. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.20290/0.26012. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.20136/0.26089. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.19903/0.25845. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.20747/0.24670. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.19986/0.25895. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.20723/0.24569. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.20065/0.26750. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.19335/0.25791. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.18994/0.24891. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.19809/0.26877. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.18706/0.26671. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.18729/0.25462. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.18907/0.26780. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.18983/0.26580. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.17672/0.25745. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.18309/0.26779. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.18849/0.25369. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.17626/0.29151. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.17269/0.27075. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.16458/0.29626. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.17042/0.24999. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.17472/0.25835. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.16788/0.25272. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.15570/0.25892. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.16136/0.25144. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.16612/0.25904. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.16551/0.28656. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.17217/0.27792. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.16151/0.31221. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.15455/0.26697. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.16073/0.29413. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.16389/0.27459. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.15773/0.26638. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.16252/0.28649. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.15880/0.27953. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.14995/0.26556. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.15211/0.26172. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.14255/0.27132. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.14523/0.26098. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.14440/0.27249. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.15121/0.26121. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.14895/0.26883. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.14628/0.27960. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.13717/0.26705. Took 0.12 sec\n",
      "Epoch 90, Loss(train/val) 0.15859/0.25529. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.14252/0.26495. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.14620/0.25738. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.14567/0.28148. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.14503/0.27816. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.14565/0.28827. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.13886/0.27034. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.13396/0.28718. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.12851/0.26610. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.13610/0.25842. Took 0.13 sec\n",
      "ACC: 0.734375, MCC: 0.4932495527630881\n",
      "Epoch 0, Loss(train/val) 0.49053/0.49558. Took 0.13 sec\n",
      "Epoch 1, Loss(train/val) 0.46466/0.49092. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.43657/0.49250. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.41084/0.48895. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.39041/0.49084. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.38437/0.48885. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.37306/0.49476. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.37089/0.47134. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.36490/0.47901. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.36158/0.46439. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.35377/0.45531. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.34977/0.47450. Took 0.15 sec\n",
      "Epoch 12, Loss(train/val) 0.34182/0.45569. Took 0.16 sec\n",
      "Epoch 13, Loss(train/val) 0.33950/0.43405. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.32398/0.39110. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.31293/0.38814. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.30862/0.37729. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.30515/0.33493. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.29241/0.35127. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.29027/0.33710. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.26910/0.34654. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.27748/0.37795. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.27362/0.34715. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.26849/0.37451. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.27059/0.35201. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.26298/0.36426. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.25414/0.35748. Took 0.15 sec\n",
      "Epoch 27, Loss(train/val) 0.26179/0.35485. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.25124/0.36364. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.25439/0.36466. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.25295/0.35107. Took 0.16 sec\n",
      "Epoch 31, Loss(train/val) 0.23849/0.33370. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.24872/0.34541. Took 0.13 sec\n",
      "Epoch 33, Loss(train/val) 0.23257/0.34949. Took 0.13 sec\n",
      "Epoch 34, Loss(train/val) 0.23765/0.35549. Took 0.13 sec\n",
      "Epoch 35, Loss(train/val) 0.21713/0.36056. Took 0.13 sec\n",
      "Epoch 36, Loss(train/val) 0.22763/0.36285. Took 0.13 sec\n",
      "Epoch 37, Loss(train/val) 0.22130/0.35325. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.22600/0.34380. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.22650/0.35605. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.22952/0.33613. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.22523/0.34729. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.22335/0.33956. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.21741/0.33455. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.21421/0.35154. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.21462/0.35713. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.22404/0.33908. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.21077/0.31601. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.20180/0.32963. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.21036/0.32344. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.20433/0.33739. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.20229/0.35241. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.19124/0.33217. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.20240/0.33678. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.21073/0.33654. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.19407/0.33625. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.19364/0.32341. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.20322/0.34457. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.19722/0.32288. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.19169/0.31777. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.18987/0.32933. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.19725/0.29761. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.18647/0.32342. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.18653/0.31919. Took 0.12 sec\n",
      "Epoch 64, Loss(train/val) 0.18806/0.33727. Took 0.12 sec\n",
      "Epoch 65, Loss(train/val) 0.18963/0.30634. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.18667/0.31208. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.18419/0.31190. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.18518/0.30823. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.17441/0.30855. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.17550/0.31745. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.16883/0.30616. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.17884/0.30968. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.17321/0.31258. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.17719/0.33959. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.18012/0.30003. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.17206/0.31630. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.16996/0.30565. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.16533/0.29948. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.17167/0.31746. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.17076/0.32373. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.15788/0.29554. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.15858/0.32477. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.15776/0.29095. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.17805/0.31913. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.15962/0.31138. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.16141/0.32537. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.15563/0.32318. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.15074/0.30572. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.16032/0.31404. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.14835/0.30227. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.14831/0.30528. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.15519/0.30741. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.15286/0.32078. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.16010/0.31387. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.15946/0.32756. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.14468/0.30320. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.13566/0.30763. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.15595/0.32994. Took 0.14 sec\n",
      "Epoch 99, Loss(train/val) 0.14814/0.31759. Took 0.13 sec\n",
      "ACC: 0.6875, MCC: 0.397705839334203\n",
      "Epoch 0, Loss(train/val) 0.48962/0.50195. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.46236/0.50518. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.43184/0.49602. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.40693/0.46919. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.39134/0.45667. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.38192/0.44777. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.37762/0.43758. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.37205/0.42576. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.36091/0.42853. Took 0.16 sec\n",
      "Epoch 9, Loss(train/val) 0.35412/0.42487. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.34663/0.41215. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.34128/0.43557. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.32988/0.42246. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.31887/0.43102. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.31148/0.46337. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.30777/0.44366. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.29473/0.46395. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.30352/0.43773. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.29658/0.45747. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.27812/0.43302. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.27607/0.44429. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.27138/0.43736. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.27040/0.44597. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.26337/0.43134. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.25516/0.43311. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.25696/0.42793. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.24325/0.41162. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.24894/0.42877. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.24247/0.42617. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.24189/0.42479. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.23524/0.43304. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.22855/0.41703. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.23081/0.42188. Took 0.16 sec\n",
      "Epoch 33, Loss(train/val) 0.22484/0.42224. Took 0.13 sec\n",
      "Epoch 34, Loss(train/val) 0.22580/0.41949. Took 0.13 sec\n",
      "Epoch 35, Loss(train/val) 0.21777/0.39664. Took 0.13 sec\n",
      "Epoch 36, Loss(train/val) 0.22548/0.42661. Took 0.13 sec\n",
      "Epoch 37, Loss(train/val) 0.22556/0.42298. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.22539/0.42349. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.21310/0.40857. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.22981/0.42104. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.20926/0.42644. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.20108/0.41052. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.21042/0.41140. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.19992/0.42005. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.20277/0.41594. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.19491/0.41931. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.19247/0.42446. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.19329/0.39976. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.19673/0.42835. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.19920/0.41042. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.18867/0.41408. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.19299/0.42787. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.19782/0.42578. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.19145/0.43069. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.19564/0.42315. Took 0.15 sec\n",
      "Epoch 56, Loss(train/val) 0.18329/0.41704. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.18178/0.39226. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.17943/0.40691. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.17723/0.41409. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.17791/0.41777. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.18026/0.42923. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.17431/0.40875. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.16288/0.42520. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.16994/0.42166. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.16415/0.40792. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.16588/0.41523. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.16344/0.40343. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.16149/0.42344. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.17043/0.40973. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.16090/0.42436. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.15499/0.39501. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.15180/0.40583. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.16691/0.41376. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.16037/0.41154. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.15422/0.40199. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.14834/0.40716. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.15252/0.41673. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.15470/0.42273. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.15675/0.40948. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.15892/0.41385. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.15369/0.39395. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.14896/0.38796. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.14264/0.38064. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.14062/0.38833. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.13742/0.40571. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.14233/0.35924. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.14401/0.39470. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.14399/0.41165. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.13833/0.42911. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.13549/0.40798. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.13478/0.39867. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.13743/0.43905. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.13215/0.40177. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.12631/0.41777. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.12492/0.42159. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.13391/0.39447. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.12599/0.36957. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.13458/0.43444. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.12279/0.41064. Took 0.13 sec\n",
      "ACC: 0.640625, MCC: 0.2882306768491569\n",
      "Epoch 0, Loss(train/val) 0.49278/0.49791. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.47095/0.49349. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.44679/0.48187. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.42580/0.48013. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.40583/0.48224. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.39101/0.47634. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.38426/0.47284. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.36991/0.44931. Took 0.16 sec\n",
      "Epoch 8, Loss(train/val) 0.35290/0.38512. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.34378/0.40209. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.32743/0.36291. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.32175/0.37122. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.30953/0.34815. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.30419/0.38060. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.30022/0.37722. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.29143/0.32950. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.29032/0.37675. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.28114/0.38196. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.27363/0.34966. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.26680/0.37684. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.26547/0.32604. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.26175/0.36341. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.25304/0.34597. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.24631/0.34784. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.23700/0.35558. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.24363/0.31290. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.24001/0.34763. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.24440/0.32140. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.24062/0.34805. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.24058/0.34766. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.23591/0.33893. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.23699/0.36410. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.22541/0.37849. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.22675/0.37199. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.23142/0.35109. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.22981/0.35547. Took 0.13 sec\n",
      "Epoch 36, Loss(train/val) 0.21498/0.35171. Took 0.13 sec\n",
      "Epoch 37, Loss(train/val) 0.22315/0.35284. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.22577/0.34062. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.21633/0.33503. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.22190/0.33886. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.20422/0.34689. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.21259/0.35565. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.20405/0.34690. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.20430/0.35065. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.20864/0.28973. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.20626/0.34275. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.21459/0.32592. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.20306/0.33692. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.20597/0.32588. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.19379/0.34440. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.20300/0.35667. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.19888/0.33468. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.20273/0.36907. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.18349/0.35284. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.18357/0.36612. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.18757/0.31728. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.20150/0.33741. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.18306/0.32219. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.18866/0.36022. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.17729/0.35945. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.17181/0.36416. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.18693/0.34309. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.17892/0.36073. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.18456/0.39611. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.18533/0.36633. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.17831/0.33941. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.17190/0.33653. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.16950/0.35218. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.16645/0.34606. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.16918/0.33480. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.17116/0.31320. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.16657/0.35594. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.16808/0.34324. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.15973/0.34805. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.17612/0.34265. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.16248/0.34494. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.15762/0.34642. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.16130/0.32455. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.17206/0.36209. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.16958/0.34141. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.16269/0.35031. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.15490/0.32976. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.15092/0.35938. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.16361/0.34564. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.15639/0.36150. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.14610/0.35806. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.15721/0.36270. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.15095/0.35538. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.15758/0.35896. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.15251/0.36870. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.14814/0.36237. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.14981/0.34761. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.15795/0.34749. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.15495/0.39322. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.16206/0.36661. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.15503/0.37334. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.15668/0.34049. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.16301/0.31124. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.14715/0.35083. Took 0.13 sec\n",
      "ACC: 0.640625, MCC: 0.28894436110328825\n",
      "Epoch 0, Loss(train/val) 0.49391/0.49104. Took 0.13 sec\n",
      "Epoch 1, Loss(train/val) 0.47609/0.47749. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.45086/0.46589. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.42350/0.46056. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.40342/0.45878. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.38972/0.45410. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.37795/0.45177. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.36991/0.44981. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.36330/0.42219. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.34466/0.40782. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.33995/0.38455. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.32595/0.37558. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.31923/0.36694. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.30432/0.38268. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.29226/0.37767. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.28733/0.35828. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.29030/0.37295. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.27782/0.35872. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.28478/0.36617. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.26576/0.35688. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.26844/0.36774. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.27048/0.36614. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.25980/0.36028. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.26096/0.36623. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.26063/0.37817. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.25308/0.34865. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.24811/0.39697. Took 0.13 sec\n",
      "Epoch 27, Loss(train/val) 0.25077/0.39400. Took 0.13 sec\n",
      "Epoch 28, Loss(train/val) 0.23952/0.37470. Took 0.13 sec\n",
      "Epoch 29, Loss(train/val) 0.24022/0.37774. Took 0.13 sec\n",
      "Epoch 30, Loss(train/val) 0.23326/0.37689. Took 0.13 sec\n",
      "Epoch 31, Loss(train/val) 0.23877/0.38701. Took 0.13 sec\n",
      "Epoch 32, Loss(train/val) 0.22538/0.37967. Took 0.13 sec\n",
      "Epoch 33, Loss(train/val) 0.21826/0.38775. Took 0.13 sec\n",
      "Epoch 34, Loss(train/val) 0.21856/0.38522. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.23001/0.39622. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.21281/0.38989. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.21030/0.38816. Took 0.15 sec\n",
      "Epoch 38, Loss(train/val) 0.21467/0.35713. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.22145/0.41202. Took 0.15 sec\n",
      "Epoch 40, Loss(train/val) 0.22946/0.36933. Took 0.15 sec\n",
      "Epoch 41, Loss(train/val) 0.20353/0.38312. Took 0.15 sec\n",
      "Epoch 42, Loss(train/val) 0.20710/0.42239. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.21044/0.40438. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.19792/0.40668. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) 0.20364/0.42129. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.19544/0.36890. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.19828/0.39758. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.20354/0.37748. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.19389/0.38209. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.18987/0.36262. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.19865/0.38604. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.18323/0.35046. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.20196/0.38320. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.20066/0.38933. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.18505/0.35451. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.18025/0.39406. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.18864/0.39309. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.19147/0.36843. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.18227/0.38603. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.19038/0.35857. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.18212/0.37628. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.16993/0.37705. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.16907/0.36585. Took 0.12 sec\n",
      "Epoch 64, Loss(train/val) 0.18460/0.35059. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.17625/0.35645. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.17204/0.40897. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.16959/0.36257. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.17157/0.37353. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.17208/0.35481. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.15934/0.38305. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.16592/0.35034. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.15669/0.35200. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.16469/0.36206. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.16072/0.36041. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) 0.15749/0.36141. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.16400/0.38026. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.16006/0.35462. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.15682/0.36764. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.15371/0.36550. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.14407/0.38855. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.14810/0.37520. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.14744/0.37898. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.15448/0.36000. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.15438/0.37791. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.15115/0.37709. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.15005/0.37089. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.15131/0.36333. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.15728/0.36378. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.14890/0.39721. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.16059/0.37948. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.16962/0.41113. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.16438/0.40321. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.14973/0.38317. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.15111/0.39781. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.14698/0.39556. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.14814/0.36773. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.14759/0.39179. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.15598/0.38381. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.14756/0.38238. Took 0.13 sec\n",
      "ACC: 0.75, MCC: 0.49265895172303803\n",
      "Epoch 0, Loss(train/val) 0.49190/0.47220. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.47220/0.43628. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.45042/0.40526. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.42491/0.36913. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.40649/0.33201. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.38872/0.29826. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.37351/0.27393. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.35991/0.25196. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.35296/0.25676. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.34170/0.27516. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.32457/0.25380. Took 0.16 sec\n",
      "Epoch 11, Loss(train/val) 0.31112/0.25016. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.29509/0.25835. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.30017/0.28868. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.30042/0.29207. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.29072/0.22433. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.29158/0.23521. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.27674/0.24662. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.27412/0.23867. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.26919/0.24953. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.26229/0.20511. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.27051/0.24116. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.26965/0.20277. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.25853/0.23734. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.25371/0.25439. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.25093/0.26098. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.24988/0.24258. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.24869/0.26453. Took 0.13 sec\n",
      "Epoch 28, Loss(train/val) 0.24188/0.28851. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.24958/0.23077. Took 0.13 sec\n",
      "Epoch 30, Loss(train/val) 0.24111/0.25733. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.23144/0.27156. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.24272/0.23695. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.23260/0.24338. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.22499/0.24861. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.22193/0.24864. Took 0.13 sec\n",
      "Epoch 36, Loss(train/val) 0.22622/0.23639. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.21776/0.26691. Took 0.15 sec\n",
      "Epoch 38, Loss(train/val) 0.23018/0.26747. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.21148/0.26341. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.21591/0.22249. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.21014/0.26594. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.21437/0.24048. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.21775/0.26212. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.21511/0.27249. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.21372/0.21877. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.20661/0.23273. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.20869/0.25043. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.20547/0.21892. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.20120/0.21592. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.20780/0.24714. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.19944/0.22577. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.20197/0.25483. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.20638/0.22641. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.21037/0.25432. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.19089/0.20788. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.18930/0.23309. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.19997/0.23455. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.18490/0.23007. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.18015/0.25760. Took 0.12 sec\n",
      "Epoch 60, Loss(train/val) 0.18806/0.22981. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.18392/0.25741. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.17983/0.22653. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.19424/0.26281. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.18438/0.22571. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.18339/0.20454. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.18536/0.23065. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) 0.17877/0.20704. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.17121/0.23763. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.17890/0.23997. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.16990/0.22014. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.16885/0.24978. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.17535/0.21979. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.17255/0.21985. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.16251/0.24855. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.16116/0.25062. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.15548/0.24608. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.16292/0.24547. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.16374/0.25172. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.16348/0.26219. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.17284/0.27012. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.15715/0.25974. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.17023/0.22259. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.15659/0.24683. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.15460/0.23270. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.16333/0.22096. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.15938/0.23947. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.16059/0.23844. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.15009/0.23449. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.14969/0.26024. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.15457/0.20507. Took 0.14 sec\n",
      "Epoch 91, Loss(train/val) 0.14891/0.19809. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.14995/0.25786. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.14638/0.26613. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.14574/0.23103. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.14651/0.23140. Took 0.12 sec\n",
      "Epoch 96, Loss(train/val) 0.14693/0.20906. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.14510/0.21462. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.13989/0.23901. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.14127/0.18900. Took 0.13 sec\n",
      "ACC: 0.609375, MCC: 0.22795136315904263\n",
      "Epoch 0, Loss(train/val) 0.49092/0.48458. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.46842/0.45737. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.44510/0.43704. Took 0.15 sec\n",
      "Epoch 3, Loss(train/val) 0.41993/0.43028. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.40338/0.42625. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.39124/0.41298. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.38122/0.36985. Took 0.15 sec\n",
      "Epoch 7, Loss(train/val) 0.37030/0.36478. Took 0.16 sec\n",
      "Epoch 8, Loss(train/val) 0.35916/0.34823. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.34743/0.35318. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.33802/0.31369. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.33749/0.31079. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.33079/0.30024. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.32530/0.30559. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.31450/0.29995. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.33844/0.30617. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.32726/0.30662. Took 0.15 sec\n",
      "Epoch 17, Loss(train/val) 0.31323/0.29859. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.31180/0.30619. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.31821/0.31115. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.31092/0.28214. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.31238/0.30132. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.30303/0.32632. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.30750/0.30721. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.30600/0.27133. Took 0.15 sec\n",
      "Epoch 25, Loss(train/val) 0.29950/0.29029. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.30928/0.29900. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.29072/0.31043. Took 0.13 sec\n",
      "Epoch 28, Loss(train/val) 0.30984/0.32479. Took 0.13 sec\n",
      "Epoch 29, Loss(train/val) 0.31166/0.34747. Took 0.13 sec\n",
      "Epoch 30, Loss(train/val) 0.30839/0.33372. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.29246/0.29756. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.29731/0.26371. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.29093/0.29283. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.29247/0.29036. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.27937/0.28768. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.29038/0.29841. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.28020/0.29768. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.29588/0.27166. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.30458/0.34041. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.28363/0.31170. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.28578/0.29904. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.29187/0.29196. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.28377/0.32167. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.27122/0.29947. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.27420/0.29325. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.26504/0.30063. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.26074/0.28847. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.25432/0.28304. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.25783/0.28388. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.25657/0.26555. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.25569/0.26807. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.25485/0.26629. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.25516/0.32240. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.27359/0.29812. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.25121/0.31551. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.25599/0.34636. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.25557/0.29637. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.27815/0.30451. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.27384/0.25929. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.26150/0.26050. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.24880/0.29069. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.24145/0.30690. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.24860/0.27956. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.25945/0.29606. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.24702/0.30033. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.24049/0.29836. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.25111/0.29915. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.23958/0.30028. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.23033/0.29343. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.22302/0.29459. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.21462/0.29493. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.22027/0.29432. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.21942/0.31206. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.22064/0.28522. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.21702/0.30877. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.22792/0.29675. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.23605/0.29073. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.24270/0.28308. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.22217/0.29788. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.22363/0.32965. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.21857/0.29881. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.21984/0.27921. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.23194/0.28711. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.24463/0.31227. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.23316/0.33652. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.21942/0.34337. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.21751/0.32468. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.21472/0.29309. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.21043/0.31996. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.21198/0.32359. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.21823/0.30029. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.20069/0.31571. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.19715/0.30755. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.20383/0.33639. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.20372/0.33727. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.20621/0.31697. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.20000/0.31958. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.21358/0.29128. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.25075/0.31770. Took 0.13 sec\n",
      "ACC: 0.671875, MCC: 0.2092396837740604\n",
      "Epoch 0, Loss(train/val) 0.48858/0.45519. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.46451/0.40322. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.43628/0.38315. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.41355/0.38274. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.39281/0.38058. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.37982/0.37610. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.36144/0.37178. Took 0.15 sec\n",
      "Epoch 7, Loss(train/val) 0.35125/0.36685. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.33116/0.32973. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.33813/0.34360. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.31422/0.34750. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.31520/0.34456. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.32481/0.33606. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.30275/0.33216. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.30106/0.33830. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.29971/0.32423. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.28880/0.32332. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.29143/0.32385. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.27746/0.31979. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.27424/0.32320. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.27536/0.32344. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.26643/0.31094. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.26405/0.31510. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.26008/0.30849. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.25444/0.31962. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.25816/0.31282. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.24525/0.33249. Took 0.15 sec\n",
      "Epoch 27, Loss(train/val) 0.27720/0.32858. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.25306/0.32584. Took 0.13 sec\n",
      "Epoch 29, Loss(train/val) 0.26723/0.32688. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.26030/0.32849. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.25406/0.30979. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.24447/0.32070. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.25269/0.30887. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.25332/0.31618. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.23669/0.33255. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.23346/0.31276. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.23152/0.30991. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.22401/0.31615. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.22193/0.31902. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.22166/0.31797. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.22885/0.35004. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.22079/0.33267. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.21932/0.33997. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.22170/0.32699. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.21443/0.34731. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.21336/0.34127. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.20271/0.31997. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.21737/0.34245. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.21845/0.34724. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.21609/0.31573. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.20898/0.34061. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.21180/0.31360. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.20313/0.29584. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.19178/0.34995. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.21109/0.33418. Took 0.15 sec\n",
      "Epoch 56, Loss(train/val) 0.19832/0.32057. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.19659/0.35044. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.22339/0.36280. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.20934/0.33550. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.19104/0.33872. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.20064/0.33827. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.19881/0.33203. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.18771/0.31251. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.19588/0.31241. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.19894/0.32923. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.19525/0.31751. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.19521/0.35060. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.17688/0.35148. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.18852/0.32499. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.19059/0.29775. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.19765/0.30619. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.19357/0.32334. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.18956/0.32589. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.19026/0.30355. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.18637/0.28360. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.17780/0.29945. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.17525/0.30474. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.18883/0.32727. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.18039/0.31287. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.18201/0.33175. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.18082/0.28271. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.16820/0.27617. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.17022/0.31453. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.16447/0.29490. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.18414/0.32058. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.17754/0.26726. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.16490/0.30928. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.16556/0.30749. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.16683/0.33449. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.16764/0.32457. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.16780/0.30728. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.17010/0.29552. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.16145/0.29167. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.16135/0.30250. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.16318/0.34406. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.16711/0.28473. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.16393/0.29598. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.16701/0.30654. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.15419/0.34714. Took 0.13 sec\n",
      "ACC: 0.65625, MCC: 0.29948753608436857\n",
      "Epoch 0, Loss(train/val) 0.49523/0.48414. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.47093/0.45942. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.44665/0.44310. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.42432/0.41866. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.40232/0.39884. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.39125/0.38152. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.37185/0.37669. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.36313/0.35136. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.35331/0.35884. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.34258/0.34842. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.33166/0.33610. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.32472/0.33111. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.31458/0.31264. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.31188/0.32762. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.30403/0.34823. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.30229/0.34765. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.29950/0.32825. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.29450/0.33306. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.29014/0.36833. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.28415/0.38605. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.28303/0.38378. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.27598/0.40932. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.26890/0.38154. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.26553/0.38092. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.26258/0.38258. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.26518/0.40266. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.25817/0.37727. Took 0.13 sec\n",
      "Epoch 27, Loss(train/val) 0.25656/0.36165. Took 0.13 sec\n",
      "Epoch 28, Loss(train/val) 0.26019/0.38273. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.25259/0.38171. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.24411/0.37893. Took 0.16 sec\n",
      "Epoch 31, Loss(train/val) 0.23928/0.35338. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.24787/0.37836. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.24166/0.37312. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.23499/0.38177. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.23402/0.36355. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.23515/0.36703. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.22968/0.36992. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.21974/0.37720. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.21587/0.39127. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.21415/0.36420. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.20739/0.36514. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.21367/0.40133. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.20618/0.37682. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.20306/0.39002. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.19995/0.37443. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.20180/0.39778. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.19920/0.37839. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.19665/0.42465. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.19862/0.38969. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.19884/0.37652. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.17827/0.39937. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.18893/0.34704. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.18855/0.40129. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.18324/0.36396. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.18014/0.37994. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.18204/0.39096. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.17336/0.38356. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.16869/0.37124. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.16786/0.38893. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.17176/0.37972. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.17046/0.37760. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.16749/0.37066. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.15819/0.35522. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.15939/0.37647. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.15980/0.36805. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.15136/0.39561. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.16957/0.41082. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.15623/0.39003. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.17202/0.37744. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.16321/0.35902. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.16065/0.37726. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.15671/0.33455. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.14657/0.34399. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.14377/0.34186. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.14710/0.34736. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.14653/0.35481. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.14867/0.36346. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.14484/0.37112. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.13854/0.36303. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.13979/0.37000. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.13218/0.36338. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.14249/0.37809. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.13691/0.35486. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.13243/0.34126. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.13385/0.35037. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.13228/0.36064. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.13502/0.33961. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.13480/0.34173. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.12720/0.36260. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.13249/0.34564. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.12338/0.35197. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.12316/0.36085. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.12661/0.35241. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.13168/0.37524. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.11688/0.36388. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.12580/0.34898. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.11876/0.37058. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.12071/0.38209. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.12129/0.35941. Took 0.13 sec\n",
      "ACC: 0.609375, MCC: 0.3318468896580934\n",
      "Epoch 0, Loss(train/val) 0.49360/0.49335. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.47147/0.47953. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.44529/0.46144. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.42189/0.43865. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.39731/0.42481. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.37832/0.42022. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.35979/0.41256. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.33923/0.40731. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.32387/0.41101. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.31713/0.39937. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.29974/0.40541. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.29492/0.39456. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.29478/0.43035. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.28166/0.39702. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.27468/0.40163. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.27048/0.43995. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.26206/0.42470. Took 0.15 sec\n",
      "Epoch 17, Loss(train/val) 0.26024/0.40459. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.25571/0.41015. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.25474/0.43716. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.25448/0.42663. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.24752/0.45287. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.24730/0.39747. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.24207/0.44395. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.22935/0.44623. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.22625/0.41311. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.23280/0.43013. Took 0.13 sec\n",
      "Epoch 27, Loss(train/val) 0.23272/0.45118. Took 0.13 sec\n",
      "Epoch 28, Loss(train/val) 0.22737/0.45709. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.22968/0.41535. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.21160/0.45484. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.21891/0.43464. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.21567/0.43886. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.21129/0.44479. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.21047/0.42312. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.21563/0.47121. Took 0.15 sec\n",
      "Epoch 36, Loss(train/val) 0.21666/0.45265. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.21531/0.40607. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.20694/0.45330. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.20847/0.44062. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.19464/0.42167. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.19644/0.46587. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.20671/0.42485. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.18750/0.43540. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.19201/0.46095. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.18597/0.43887. Took 0.12 sec\n",
      "Epoch 46, Loss(train/val) 0.18251/0.45257. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.18945/0.44326. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.19093/0.44172. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.18672/0.44497. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.18109/0.45286. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.16999/0.44982. Took 0.12 sec\n",
      "Epoch 52, Loss(train/val) 0.17480/0.44534. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.17748/0.45284. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.18011/0.44885. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.18306/0.45178. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.17178/0.45546. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.16802/0.45483. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.17493/0.46311. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.16691/0.45729. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.18589/0.46596. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.16851/0.45686. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.16864/0.46943. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.16785/0.48183. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.16238/0.47295. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.16021/0.45259. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.15946/0.46407. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.15375/0.47918. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.15165/0.48462. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.16328/0.47178. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.15732/0.47648. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.15484/0.46389. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.15693/0.47551. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.15105/0.47140. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.15122/0.47161. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.15051/0.47287. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.14814/0.47106. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.15669/0.47682. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.14760/0.47836. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.14722/0.47187. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.15190/0.47074. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.13622/0.49362. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.13982/0.49827. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.14122/0.48679. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.14549/0.45670. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.14158/0.49551. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.14371/0.49130. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.13525/0.48579. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.13603/0.48420. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.13481/0.47399. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.14445/0.46950. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.12892/0.47640. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.12793/0.48079. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.12485/0.48224. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.13901/0.49055. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.13115/0.49438. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.13025/0.48953. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.13663/0.48896. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.13055/0.46649. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.12844/0.48502. Took 0.13 sec\n",
      "ACC: 0.640625, MCC: 0.3718879583890439\n",
      "Epoch 0, Loss(train/val) 0.49456/0.49345. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.47230/0.48472. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.44424/0.46233. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.41959/0.44096. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.40084/0.43334. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.38596/0.41945. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.36912/0.40930. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.35084/0.40622. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.34633/0.45499. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.32646/0.46630. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.32218/0.45373. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.31139/0.41966. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.31758/0.46415. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.30514/0.45380. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.30320/0.44266. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.29712/0.44308. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.27598/0.44639. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.28112/0.43340. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.28396/0.43883. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.28129/0.43761. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.25694/0.43195. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.26460/0.43268. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.26050/0.45328. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.24754/0.43823. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.24966/0.44397. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.24448/0.46388. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.24481/0.45624. Took 0.13 sec\n",
      "Epoch 27, Loss(train/val) 0.24393/0.46469. Took 0.13 sec\n",
      "Epoch 28, Loss(train/val) 0.23758/0.43980. Took 0.13 sec\n",
      "Epoch 29, Loss(train/val) 0.22846/0.43794. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.23333/0.46200. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.22463/0.43941. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.22481/0.45156. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.21876/0.44823. Took 0.16 sec\n",
      "Epoch 34, Loss(train/val) 0.21582/0.44819. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.20960/0.43487. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.20921/0.44038. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.20388/0.43605. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.20558/0.46370. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.20173/0.44255. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.20260/0.45624. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.20030/0.45507. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.18829/0.45761. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.19349/0.44031. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.18434/0.44550. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.18486/0.44840. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.19790/0.46073. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.18684/0.43543. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.19311/0.46504. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.19371/0.43291. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.18818/0.44038. Took 0.14 sec\n",
      "Epoch 51, Loss(train/val) 0.16678/0.43084. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.17793/0.43477. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.17767/0.43850. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.17595/0.43902. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.16969/0.44950. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.16432/0.46172. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.15629/0.45940. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.16283/0.45024. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.15658/0.45061. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.17452/0.45149. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.16765/0.43318. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.17319/0.43200. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.16150/0.45241. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.15594/0.45962. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.15462/0.46618. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.15741/0.44848. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.15042/0.43789. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.15365/0.45525. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.14880/0.46917. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.14679/0.44203. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.14710/0.45767. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.14685/0.45290. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.14256/0.44939. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.14560/0.43910. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.15244/0.45984. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.14648/0.44912. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.14170/0.45781. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.13344/0.44491. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.13893/0.45798. Took 0.15 sec\n",
      "Epoch 80, Loss(train/val) 0.13327/0.46060. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.14344/0.44773. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.14740/0.46444. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.13050/0.46737. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.13514/0.45849. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.13748/0.46466. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.13332/0.44719. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.12493/0.44687. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.14085/0.42332. Took 0.15 sec\n",
      "Epoch 89, Loss(train/val) 0.14793/0.45353. Took 0.15 sec\n",
      "Epoch 90, Loss(train/val) 0.12862/0.46315. Took 0.14 sec\n",
      "Epoch 91, Loss(train/val) 0.13091/0.46282. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.12763/0.45177. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.12658/0.45189. Took 0.15 sec\n",
      "Epoch 94, Loss(train/val) 0.13117/0.43652. Took 0.14 sec\n",
      "Epoch 95, Loss(train/val) 0.12609/0.44464. Took 0.15 sec\n",
      "Epoch 96, Loss(train/val) 0.12386/0.43964. Took 0.17 sec\n",
      "Epoch 97, Loss(train/val) 0.12033/0.44846. Took 0.19 sec\n",
      "Epoch 98, Loss(train/val) 0.12616/0.44162. Took 0.15 sec\n",
      "Epoch 99, Loss(train/val) 0.12431/0.45992. Took 0.14 sec\n",
      "ACC: 0.671875, MCC: 0.3381532021299023\n",
      "Epoch 0, Loss(train/val) 0.49355/0.47803. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.46853/0.43993. Took 0.15 sec\n",
      "Epoch 2, Loss(train/val) 0.43918/0.40384. Took 0.15 sec\n",
      "Epoch 3, Loss(train/val) 0.41237/0.36974. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.39325/0.34976. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.37622/0.33608. Took 0.17 sec\n",
      "Epoch 6, Loss(train/val) 0.35795/0.34921. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.33900/0.32321. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.32858/0.32862. Took 0.17 sec\n",
      "Epoch 9, Loss(train/val) 0.33105/0.32746. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.31111/0.30423. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.31553/0.29859. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.32099/0.35513. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.31300/0.33597. Took 0.16 sec\n",
      "Epoch 14, Loss(train/val) 0.30278/0.34227. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.28568/0.32029. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.29109/0.33075. Took 0.16 sec\n",
      "Epoch 17, Loss(train/val) 0.27965/0.31541. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.28080/0.33502. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.28008/0.32023. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.26613/0.31269. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.26506/0.32351. Took 0.16 sec\n",
      "Epoch 22, Loss(train/val) 0.25976/0.31536. Took 0.15 sec\n",
      "Epoch 23, Loss(train/val) 0.25316/0.30410. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.25291/0.29387. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.25930/0.31323. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.24036/0.28497. Took 0.15 sec\n",
      "Epoch 27, Loss(train/val) 0.24942/0.28335. Took 0.16 sec\n",
      "Epoch 28, Loss(train/val) 0.23002/0.29395. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.23129/0.30161. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.23038/0.29652. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.23492/0.28587. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.23015/0.29537. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.22734/0.30793. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.22873/0.29718. Took 0.16 sec\n",
      "Epoch 35, Loss(train/val) 0.21773/0.29983. Took 0.15 sec\n",
      "Epoch 36, Loss(train/val) 0.22520/0.30270. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.21631/0.29736. Took 0.15 sec\n",
      "Epoch 38, Loss(train/val) 0.20934/0.30402. Took 0.16 sec\n",
      "Epoch 39, Loss(train/val) 0.20608/0.30657. Took 0.15 sec\n",
      "Epoch 40, Loss(train/val) 0.20435/0.30244. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.21028/0.30182. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.19967/0.30322. Took 0.15 sec\n",
      "Epoch 43, Loss(train/val) 0.19565/0.31346. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.20354/0.30643. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.20399/0.30167. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.20166/0.31244. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.19227/0.31222. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.19293/0.30896. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.19218/0.30869. Took 0.15 sec\n",
      "Epoch 50, Loss(train/val) 0.18365/0.30122. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.18463/0.30355. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.18464/0.30277. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) 0.18996/0.29642. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.18149/0.30839. Took 0.16 sec\n",
      "Epoch 55, Loss(train/val) 0.18246/0.30205. Took 0.15 sec\n",
      "Epoch 56, Loss(train/val) 0.18126/0.29639. Took 0.15 sec\n",
      "Epoch 57, Loss(train/val) 0.18314/0.29716. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.17674/0.29300. Took 0.14 sec\n",
      "Epoch 59, Loss(train/val) 0.17874/0.29467. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.17417/0.30343. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.17585/0.31213. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.16924/0.30770. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.16857/0.29291. Took 0.15 sec\n",
      "Epoch 64, Loss(train/val) 0.17230/0.31260. Took 0.16 sec\n",
      "Epoch 65, Loss(train/val) 0.16483/0.31068. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.16300/0.32051. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) 0.15665/0.31646. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.15672/0.31299. Took 0.17 sec\n",
      "Epoch 69, Loss(train/val) 0.16314/0.31220. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.15558/0.30910. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.15839/0.30451. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.16113/0.31067. Took 0.17 sec\n",
      "Epoch 73, Loss(train/val) 0.15280/0.31805. Took 0.15 sec\n",
      "Epoch 74, Loss(train/val) 0.15374/0.32965. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) 0.14861/0.31639. Took 0.16 sec\n",
      "Epoch 76, Loss(train/val) 0.15283/0.31479. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.15277/0.31705. Took 0.15 sec\n",
      "Epoch 78, Loss(train/val) 0.14603/0.32208. Took 0.18 sec\n",
      "Epoch 79, Loss(train/val) 0.14364/0.32515. Took 0.16 sec\n",
      "Epoch 80, Loss(train/val) 0.13857/0.30961. Took 0.14 sec\n",
      "Epoch 81, Loss(train/val) 0.14506/0.32716. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.13434/0.31537. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) 0.13805/0.32719. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.13878/0.33730. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.13052/0.33693. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.13365/0.32983. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.13526/0.34064. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.14262/0.32920. Took 0.16 sec\n",
      "Epoch 89, Loss(train/val) 0.13854/0.32467. Took 0.19 sec\n",
      "Epoch 90, Loss(train/val) 0.13958/0.33658. Took 0.15 sec\n",
      "Epoch 91, Loss(train/val) 0.13267/0.32689. Took 0.15 sec\n",
      "Epoch 92, Loss(train/val) 0.14287/0.33807. Took 0.15 sec\n",
      "Epoch 93, Loss(train/val) 0.12779/0.35389. Took 0.15 sec\n",
      "Epoch 94, Loss(train/val) 0.13101/0.34918. Took 0.16 sec\n",
      "Epoch 95, Loss(train/val) 0.13776/0.34138. Took 0.16 sec\n",
      "Epoch 96, Loss(train/val) 0.13077/0.32856. Took 0.19 sec\n",
      "Epoch 97, Loss(train/val) 0.13064/0.34507. Took 0.15 sec\n",
      "Epoch 98, Loss(train/val) 0.12790/0.34643. Took 0.15 sec\n",
      "Epoch 99, Loss(train/val) 0.12141/0.34396. Took 0.15 sec\n",
      "ACC: 0.703125, MCC: 0.41360064512297223\n",
      "Epoch 0, Loss(train/val) 0.48875/0.49040. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.46568/0.47217. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.43935/0.44600. Took 0.18 sec\n",
      "Epoch 3, Loss(train/val) 0.41278/0.40974. Took 0.19 sec\n",
      "Epoch 4, Loss(train/val) 0.39905/0.38978. Took 0.17 sec\n",
      "Epoch 5, Loss(train/val) 0.38433/0.38937. Took 0.19 sec\n",
      "Epoch 6, Loss(train/val) 0.36296/0.34479. Took 0.17 sec\n",
      "Epoch 7, Loss(train/val) 0.34883/0.34644. Took 0.16 sec\n",
      "Epoch 8, Loss(train/val) 0.33413/0.36084. Took 0.15 sec\n",
      "Epoch 9, Loss(train/val) 0.32317/0.39033. Took 0.16 sec\n",
      "Epoch 10, Loss(train/val) 0.30759/0.37844. Took 0.16 sec\n",
      "Epoch 11, Loss(train/val) 0.30154/0.36808. Took 0.18 sec\n",
      "Epoch 12, Loss(train/val) 0.29401/0.38129. Took 0.17 sec\n",
      "Epoch 13, Loss(train/val) 0.30611/0.41497. Took 0.18 sec\n",
      "Epoch 14, Loss(train/val) 0.29316/0.38376. Took 0.16 sec\n",
      "Epoch 15, Loss(train/val) 0.26648/0.38641. Took 0.19 sec\n",
      "Epoch 16, Loss(train/val) 0.26720/0.40669. Took 0.17 sec\n",
      "Epoch 17, Loss(train/val) 0.26049/0.38406. Took 0.18 sec\n",
      "Epoch 18, Loss(train/val) 0.26012/0.38044. Took 0.15 sec\n",
      "Epoch 19, Loss(train/val) 0.25409/0.39715. Took 0.17 sec\n",
      "Epoch 20, Loss(train/val) 0.25031/0.39134. Took 0.15 sec\n",
      "Epoch 21, Loss(train/val) 0.25060/0.38731. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.25742/0.40741. Took 0.15 sec\n",
      "Epoch 23, Loss(train/val) 0.23530/0.38084. Took 0.16 sec\n",
      "Epoch 24, Loss(train/val) 0.23669/0.40492. Took 0.15 sec\n",
      "Epoch 25, Loss(train/val) 0.23263/0.40483. Took 0.16 sec\n",
      "Epoch 26, Loss(train/val) 0.22653/0.39568. Took 0.15 sec\n",
      "Epoch 27, Loss(train/val) 0.22045/0.38892. Took 0.17 sec\n",
      "Epoch 28, Loss(train/val) 0.21387/0.40728. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.22254/0.38394. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.21924/0.40276. Took 0.16 sec\n",
      "Epoch 31, Loss(train/val) 0.20637/0.40526. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.21418/0.40599. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.20167/0.38193. Took 0.16 sec\n",
      "Epoch 34, Loss(train/val) 0.20839/0.37710. Took 0.18 sec\n",
      "Epoch 35, Loss(train/val) 0.19291/0.38093. Took 0.16 sec\n",
      "Epoch 36, Loss(train/val) 0.19049/0.39351. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.20305/0.37725. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.20958/0.41164. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.20309/0.40810. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.19369/0.40759. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.19968/0.41213. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.19457/0.38999. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.19102/0.40988. Took 0.15 sec\n",
      "Epoch 44, Loss(train/val) 0.18660/0.42231. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) 0.17322/0.41294. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.17646/0.40135. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.18132/0.41500. Took 0.15 sec\n",
      "Epoch 48, Loss(train/val) 0.17771/0.39595. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.17741/0.41674. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.17774/0.40346. Took 0.16 sec\n",
      "Epoch 51, Loss(train/val) 0.16721/0.41644. Took 0.15 sec\n",
      "Epoch 52, Loss(train/val) 0.17475/0.39679. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.16640/0.41099. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.16383/0.41167. Took 0.16 sec\n",
      "Epoch 55, Loss(train/val) 0.16393/0.40306. Took 0.15 sec\n",
      "Epoch 56, Loss(train/val) 0.17211/0.40594. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.15819/0.40361. Took 0.15 sec\n",
      "Epoch 58, Loss(train/val) 0.16267/0.41422. Took 0.17 sec\n",
      "Epoch 59, Loss(train/val) 0.16465/0.41868. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.15571/0.41361. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.15392/0.40114. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.15033/0.39914. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.15610/0.39793. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.14123/0.38411. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.14784/0.39625. Took 0.15 sec\n",
      "Epoch 66, Loss(train/val) 0.14660/0.39457. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) 0.14050/0.41800. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.13850/0.41561. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.13562/0.41404. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.14441/0.41004. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.14202/0.41340. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.14211/0.41946. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.13247/0.43253. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.13725/0.42173. Took 0.15 sec\n",
      "Epoch 75, Loss(train/val) 0.13324/0.40301. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.13451/0.38778. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.13183/0.41591. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.13671/0.44690. Took 0.16 sec\n",
      "Epoch 79, Loss(train/val) 0.13089/0.41548. Took 0.15 sec\n",
      "Epoch 80, Loss(train/val) 0.13850/0.41479. Took 0.15 sec\n",
      "Epoch 81, Loss(train/val) 0.12577/0.42052. Took 0.15 sec\n",
      "Epoch 82, Loss(train/val) 0.12212/0.39592. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.12476/0.42089. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.12856/0.40681. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.11822/0.41754. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.12740/0.41475. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.11552/0.42255. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.12643/0.41757. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.11621/0.39935. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.11847/0.42435. Took 0.17 sec\n",
      "Epoch 91, Loss(train/val) 0.11304/0.41826. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.11316/0.39643. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.12657/0.41566. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.11214/0.42572. Took 0.15 sec\n",
      "Epoch 95, Loss(train/val) 0.10928/0.41488. Took 0.15 sec\n",
      "Epoch 96, Loss(train/val) 0.10794/0.40105. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.11369/0.41231. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.11120/0.40513. Took 0.14 sec\n",
      "Epoch 99, Loss(train/val) 0.10518/0.41165. Took 0.15 sec\n",
      "ACC: 0.703125, MCC: 0.3913804711258256\n",
      "Epoch 0, Loss(train/val) 0.49004/0.47804. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.46180/0.44094. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.42751/0.40656. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.39547/0.37193. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.37356/0.34294. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.35362/0.33316. Took 0.15 sec\n",
      "Epoch 6, Loss(train/val) 0.33998/0.32470. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.32937/0.31565. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.32461/0.31615. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.31610/0.30254. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.31832/0.31410. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.30637/0.31411. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.29884/0.30798. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.30205/0.31451. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.29481/0.30929. Took 0.16 sec\n",
      "Epoch 15, Loss(train/val) 0.28610/0.30452. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.28952/0.28837. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.27746/0.32759. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.27955/0.31816. Took 0.16 sec\n",
      "Epoch 19, Loss(train/val) 0.27338/0.31844. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.26843/0.33521. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.27022/0.32068. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.25899/0.32351. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.26153/0.32437. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.25653/0.32621. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.25381/0.30988. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.25025/0.31466. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.24073/0.31043. Took 0.13 sec\n",
      "Epoch 28, Loss(train/val) 0.23968/0.30242. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.23601/0.30430. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.23896/0.30632. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.23149/0.32252. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.22770/0.31402. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.22130/0.32112. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.21551/0.33398. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.21653/0.32974. Took 0.16 sec\n",
      "Epoch 36, Loss(train/val) 0.20970/0.34032. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.22180/0.34039. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.21300/0.35950. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.20127/0.35396. Took 0.18 sec\n",
      "Epoch 40, Loss(train/val) 0.20122/0.35240. Took 0.15 sec\n",
      "Epoch 41, Loss(train/val) 0.19839/0.33815. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.18991/0.34641. Took 0.15 sec\n",
      "Epoch 43, Loss(train/val) 0.18666/0.35131. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.19084/0.39562. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) 0.19295/0.36774. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.18492/0.39758. Took 0.15 sec\n",
      "Epoch 47, Loss(train/val) 0.18656/0.37839. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.18011/0.32289. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.18183/0.38703. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.17862/0.39433. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.17071/0.34231. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.17517/0.35007. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) 0.16982/0.34815. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.16832/0.36024. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.16528/0.38080. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.16525/0.35044. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.16386/0.35800. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.15450/0.37524. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.15510/0.38321. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.15733/0.38580. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.15011/0.36235. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.15055/0.38891. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.15557/0.40686. Took 0.16 sec\n",
      "Epoch 64, Loss(train/val) 0.15775/0.40799. Took 0.16 sec\n",
      "Epoch 65, Loss(train/val) 0.15087/0.36933. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.16828/0.39753. Took 0.16 sec\n",
      "Epoch 67, Loss(train/val) 0.16326/0.38000. Took 0.16 sec\n",
      "Epoch 68, Loss(train/val) 0.14848/0.39469. Took 0.16 sec\n",
      "Epoch 69, Loss(train/val) 0.14679/0.38916. Took 0.15 sec\n",
      "Epoch 70, Loss(train/val) 0.14372/0.39886. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.14696/0.37497. Took 0.15 sec\n",
      "Epoch 72, Loss(train/val) 0.14137/0.36529. Took 0.16 sec\n",
      "Epoch 73, Loss(train/val) 0.14011/0.37686. Took 0.15 sec\n",
      "Epoch 74, Loss(train/val) 0.13401/0.36806. Took 0.16 sec\n",
      "Epoch 75, Loss(train/val) 0.13868/0.38519. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.13046/0.35194. Took 0.15 sec\n",
      "Epoch 77, Loss(train/val) 0.14216/0.38043. Took 0.17 sec\n",
      "Epoch 78, Loss(train/val) 0.13774/0.37434. Took 0.17 sec\n",
      "Epoch 79, Loss(train/val) 0.14147/0.38029. Took 0.15 sec\n",
      "Epoch 80, Loss(train/val) 0.14040/0.40924. Took 0.16 sec\n",
      "Epoch 81, Loss(train/val) 0.13986/0.40545. Took 0.15 sec\n",
      "Epoch 82, Loss(train/val) 0.13349/0.38402. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) 0.13817/0.35904. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.13577/0.38820. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.12904/0.36723. Took 0.16 sec\n",
      "Epoch 86, Loss(train/val) 0.12736/0.40513. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.13519/0.39384. Took 0.15 sec\n",
      "Epoch 88, Loss(train/val) 0.12772/0.35345. Took 0.15 sec\n",
      "Epoch 89, Loss(train/val) 0.12726/0.38645. Took 0.15 sec\n",
      "Epoch 90, Loss(train/val) 0.13378/0.39583. Took 0.14 sec\n",
      "Epoch 91, Loss(train/val) 0.13013/0.35954. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.12490/0.37642. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.12416/0.37183. Took 0.15 sec\n",
      "Epoch 94, Loss(train/val) 0.12278/0.34756. Took 0.15 sec\n",
      "Epoch 95, Loss(train/val) 0.12651/0.36486. Took 0.16 sec\n",
      "Epoch 96, Loss(train/val) 0.12861/0.37018. Took 0.15 sec\n",
      "Epoch 97, Loss(train/val) 0.12412/0.37576. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.12855/0.36582. Took 0.15 sec\n",
      "Epoch 99, Loss(train/val) 0.12142/0.39062. Took 0.14 sec\n",
      "ACC: 0.65625, MCC: 0.30164090937813576\n",
      "Epoch 0, Loss(train/val) 0.49535/0.48987. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.47324/0.45945. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.43681/0.39790. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.39800/0.38000. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.37331/0.36466. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.35373/0.37140. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.34345/0.33238. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.32870/0.34539. Took 0.16 sec\n",
      "Epoch 8, Loss(train/val) 0.33015/0.36106. Took 0.15 sec\n",
      "Epoch 9, Loss(train/val) 0.32425/0.35066. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.31980/0.34020. Took 0.16 sec\n",
      "Epoch 11, Loss(train/val) 0.31301/0.33430. Took 0.18 sec\n",
      "Epoch 12, Loss(train/val) 0.30704/0.32801. Took 0.15 sec\n",
      "Epoch 13, Loss(train/val) 0.29918/0.32659. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.29430/0.33798. Took 0.15 sec\n",
      "Epoch 15, Loss(train/val) 0.30026/0.30889. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.28763/0.32293. Took 0.15 sec\n",
      "Epoch 17, Loss(train/val) 0.28673/0.31371. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.28203/0.31395. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.27549/0.31700. Took 0.15 sec\n",
      "Epoch 20, Loss(train/val) 0.26671/0.33164. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.26503/0.31649. Took 0.17 sec\n",
      "Epoch 22, Loss(train/val) 0.25253/0.31542. Took 0.16 sec\n",
      "Epoch 23, Loss(train/val) 0.24894/0.31836. Took 0.16 sec\n",
      "Epoch 24, Loss(train/val) 0.24523/0.31061. Took 0.19 sec\n",
      "Epoch 25, Loss(train/val) 0.24350/0.32095. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.24252/0.32625. Took 0.15 sec\n",
      "Epoch 27, Loss(train/val) 0.23775/0.31715. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.22644/0.31821. Took 0.18 sec\n",
      "Epoch 29, Loss(train/val) 0.22686/0.33970. Took 0.17 sec\n",
      "Epoch 30, Loss(train/val) 0.22037/0.33917. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.21483/0.35274. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.22768/0.31661. Took 0.16 sec\n",
      "Epoch 33, Loss(train/val) 0.21255/0.34225. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.21101/0.33400. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.20748/0.36441. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.20414/0.35042. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.18750/0.33517. Took 0.15 sec\n",
      "Epoch 38, Loss(train/val) 0.18940/0.35217. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.18718/0.34869. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.18338/0.36357. Took 0.15 sec\n",
      "Epoch 41, Loss(train/val) 0.18773/0.35271. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.18986/0.37255. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.18254/0.33180. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.18015/0.34633. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.17591/0.35403. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.17495/0.35498. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.17304/0.36283. Took 0.17 sec\n",
      "Epoch 48, Loss(train/val) 0.17193/0.36492. Took 0.15 sec\n",
      "Epoch 49, Loss(train/val) 0.16399/0.37604. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.17265/0.37594. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.16558/0.35914. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.16559/0.32049. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) 0.16519/0.34720. Took 0.15 sec\n",
      "Epoch 54, Loss(train/val) 0.16336/0.32912. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.16448/0.36216. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.15329/0.35332. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.15665/0.36019. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.15482/0.36868. Took 0.15 sec\n",
      "Epoch 59, Loss(train/val) 0.15256/0.36404. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.15409/0.35550. Took 0.14 sec\n",
      "Epoch 61, Loss(train/val) 0.15417/0.35874. Took 0.15 sec\n",
      "Epoch 62, Loss(train/val) 0.15795/0.38426. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.14942/0.37192. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.14849/0.36281. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.14398/0.36075. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.14381/0.36202. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.13920/0.37379. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.14336/0.36936. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.14323/0.36521. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.14129/0.38855. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.14353/0.35725. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.14020/0.37363. Took 0.15 sec\n",
      "Epoch 73, Loss(train/val) 0.14396/0.36713. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.13936/0.37847. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.13526/0.35394. Took 0.15 sec\n",
      "Epoch 76, Loss(train/val) 0.13797/0.37290. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.13088/0.36555. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.13407/0.38123. Took 0.16 sec\n",
      "Epoch 79, Loss(train/val) 0.13740/0.39356. Took 0.16 sec\n",
      "Epoch 80, Loss(train/val) 0.13284/0.39657. Took 0.14 sec\n",
      "Epoch 81, Loss(train/val) 0.13435/0.39366. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.13066/0.38177. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) 0.12839/0.38963. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.12077/0.36790. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.13353/0.38038. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.13765/0.39009. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.12674/0.38272. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.11995/0.36335. Took 0.14 sec\n",
      "Epoch 89, Loss(train/val) 0.12758/0.37113. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.12287/0.37665. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.12144/0.39474. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.12404/0.37389. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.11792/0.38515. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.12347/0.38173. Took 0.15 sec\n",
      "Epoch 95, Loss(train/val) 0.12530/0.35200. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.11732/0.39115. Took 0.14 sec\n",
      "Epoch 97, Loss(train/val) 0.11688/0.38514. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.11316/0.38893. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.12143/0.38998. Took 0.13 sec\n",
      "ACC: 0.75, MCC: 0.4995112414467253\n",
      "Epoch 0, Loss(train/val) 0.49458/0.48408. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.47405/0.44126. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.43872/0.36930. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.40155/0.32949. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.37598/0.33483. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.36165/0.32524. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.35040/0.31342. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.34457/0.31072. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.33498/0.29407. Took 0.15 sec\n",
      "Epoch 9, Loss(train/val) 0.32878/0.30410. Took 0.15 sec\n",
      "Epoch 10, Loss(train/val) 0.32538/0.27686. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.31824/0.28949. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.30623/0.29118. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.30107/0.30618. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.29274/0.30864. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.28913/0.28483. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.28602/0.28508. Took 0.15 sec\n",
      "Epoch 17, Loss(train/val) 0.27415/0.30196. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.28466/0.32226. Took 0.16 sec\n",
      "Epoch 19, Loss(train/val) 0.26598/0.27899. Took 0.15 sec\n",
      "Epoch 20, Loss(train/val) 0.27653/0.29907. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.26801/0.29233. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.26087/0.30017. Took 0.15 sec\n",
      "Epoch 23, Loss(train/val) 0.25985/0.29299. Took 0.17 sec\n",
      "Epoch 24, Loss(train/val) 0.25967/0.28502. Took 0.16 sec\n",
      "Epoch 25, Loss(train/val) 0.25756/0.30095. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.24785/0.27410. Took 0.17 sec\n",
      "Epoch 27, Loss(train/val) 0.24698/0.28888. Took 0.16 sec\n",
      "Epoch 28, Loss(train/val) 0.25572/0.31256. Took 0.17 sec\n",
      "Epoch 29, Loss(train/val) 0.23941/0.28962. Took 0.16 sec\n",
      "Epoch 30, Loss(train/val) 0.23955/0.31205. Took 0.17 sec\n",
      "Epoch 31, Loss(train/val) 0.23602/0.30860. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.23113/0.27398. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.23185/0.31950. Took 0.16 sec\n",
      "Epoch 34, Loss(train/val) 0.23060/0.28647. Took 0.18 sec\n",
      "Epoch 35, Loss(train/val) 0.21948/0.30840. Took 0.15 sec\n",
      "Epoch 36, Loss(train/val) 0.22076/0.30883. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.21060/0.31947. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.21084/0.31038. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.21087/0.32691. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.20145/0.31436. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.20240/0.32846. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.20774/0.33016. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.20120/0.31677. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.19193/0.31136. Took 0.15 sec\n",
      "Epoch 45, Loss(train/val) 0.20294/0.31670. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.19734/0.29166. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.20344/0.33091. Took 0.15 sec\n",
      "Epoch 48, Loss(train/val) 0.20234/0.32764. Took 0.16 sec\n",
      "Epoch 49, Loss(train/val) 0.20014/0.30773. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.18993/0.31961. Took 0.14 sec\n",
      "Epoch 51, Loss(train/val) 0.19973/0.30877. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.19080/0.32099. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.18602/0.30911. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.18515/0.30183. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.18892/0.31569. Took 0.15 sec\n",
      "Epoch 56, Loss(train/val) 0.18007/0.32466. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.18567/0.31440. Took 0.15 sec\n",
      "Epoch 58, Loss(train/val) 0.18300/0.32453. Took 0.14 sec\n",
      "Epoch 59, Loss(train/val) 0.18682/0.31682. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.18557/0.31530. Took 0.14 sec\n",
      "Epoch 61, Loss(train/val) 0.19529/0.33750. Took 0.15 sec\n",
      "Epoch 62, Loss(train/val) 0.19347/0.30475. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.18479/0.34083. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.17767/0.32219. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.17830/0.31712. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.16470/0.32918. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) 0.16750/0.30209. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.16633/0.31539. Took 0.14 sec\n",
      "Epoch 69, Loss(train/val) 0.15594/0.32344. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.17790/0.32531. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.17448/0.32163. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.17791/0.33227. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.15900/0.33740. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.16732/0.31999. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.16398/0.33260. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.15502/0.32930. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.16375/0.31852. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.16843/0.31176. Took 0.14 sec\n",
      "Epoch 79, Loss(train/val) 0.15709/0.31926. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.16787/0.30103. Took 0.14 sec\n",
      "Epoch 81, Loss(train/val) 0.16808/0.31256. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.15957/0.29093. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) 0.15397/0.28506. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.16316/0.29718. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.15047/0.31761. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.16715/0.28253. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.15515/0.29727. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.15179/0.30747. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.15546/0.30004. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.14865/0.29502. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.15048/0.30431. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.14820/0.30304. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.14651/0.29064. Took 0.15 sec\n",
      "Epoch 94, Loss(train/val) 0.14320/0.32170. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.14946/0.29890. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.14565/0.33719. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.14926/0.31215. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.14849/0.33041. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.14289/0.30470. Took 0.13 sec\n",
      "ACC: 0.671875, MCC: 0.3400501664684957\n",
      "Epoch 0, Loss(train/val) 0.48450/0.50095. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.45281/0.50455. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.42607/0.50081. Took 0.16 sec\n",
      "Epoch 3, Loss(train/val) 0.40468/0.48074. Took 0.16 sec\n",
      "Epoch 4, Loss(train/val) 0.39138/0.45953. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.38076/0.44380. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.37275/0.42848. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.36370/0.41422. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.35834/0.40684. Took 0.15 sec\n",
      "Epoch 9, Loss(train/val) 0.35372/0.39985. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.34898/0.40331. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.34898/0.39102. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.33715/0.39826. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.33343/0.39032. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.32678/0.40585. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.32657/0.38626. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.31605/0.39996. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.31765/0.39949. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.31177/0.38684. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.29924/0.39123. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.30303/0.38360. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.29309/0.40902. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.29238/0.38946. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.29768/0.40025. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.27527/0.42574. Took 0.15 sec\n",
      "Epoch 25, Loss(train/val) 0.27492/0.41966. Took 0.16 sec\n",
      "Epoch 26, Loss(train/val) 0.28212/0.44005. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.28198/0.41874. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.27851/0.42708. Took 0.16 sec\n",
      "Epoch 29, Loss(train/val) 0.26815/0.43036. Took 0.19 sec\n",
      "Epoch 30, Loss(train/val) 0.26226/0.42667. Took 0.18 sec\n",
      "Epoch 31, Loss(train/val) 0.25318/0.43818. Took 0.16 sec\n",
      "Epoch 32, Loss(train/val) 0.25782/0.42131. Took 0.17 sec\n",
      "Epoch 33, Loss(train/val) 0.25875/0.41289. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.25179/0.41728. Took 0.13 sec\n",
      "Epoch 35, Loss(train/val) 0.24085/0.41556. Took 0.13 sec\n",
      "Epoch 36, Loss(train/val) 0.23413/0.41455. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.25761/0.44194. Took 0.17 sec\n",
      "Epoch 38, Loss(train/val) 0.24836/0.43413. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.23189/0.44539. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.23310/0.44389. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.22088/0.44729. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.22964/0.42415. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.23385/0.43848. Took 0.15 sec\n",
      "Epoch 44, Loss(train/val) 0.22824/0.43664. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.22888/0.45001. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.22126/0.44745. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.21341/0.45899. Took 0.15 sec\n",
      "Epoch 48, Loss(train/val) 0.21969/0.46072. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.22056/0.46960. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.21788/0.47689. Took 0.14 sec\n",
      "Epoch 51, Loss(train/val) 0.21578/0.47064. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.20823/0.48877. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.21223/0.49181. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.22998/0.47356. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.20681/0.47826. Took 0.16 sec\n",
      "Epoch 56, Loss(train/val) 0.21257/0.48455. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.20015/0.48385. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.19855/0.46236. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.20841/0.46847. Took 0.15 sec\n",
      "Epoch 60, Loss(train/val) 0.20332/0.46236. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.20034/0.48260. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.19656/0.47545. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.19434/0.47084. Took 0.15 sec\n",
      "Epoch 64, Loss(train/val) 0.19389/0.48099. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.19259/0.48614. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.19359/0.46814. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.19510/0.46077. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.20115/0.46523. Took 0.15 sec\n",
      "Epoch 69, Loss(train/val) 0.18753/0.46763. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.19141/0.47214. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.18737/0.46778. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.18319/0.46589. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.18698/0.46290. Took 0.15 sec\n",
      "Epoch 74, Loss(train/val) 0.19559/0.45677. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) 0.18925/0.46143. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.18467/0.46958. Took 0.15 sec\n",
      "Epoch 77, Loss(train/val) 0.19068/0.46936. Took 0.16 sec\n",
      "Epoch 78, Loss(train/val) 0.18673/0.46697. Took 0.16 sec\n",
      "Epoch 79, Loss(train/val) 0.17745/0.46831. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.18431/0.46675. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.16719/0.46627. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.17368/0.46239. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) 0.17756/0.47394. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.17533/0.46864. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.16487/0.47060. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.17166/0.46924. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.17267/0.46470. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.16841/0.46238. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.16480/0.46962. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.16461/0.47685. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.16788/0.46742. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.16460/0.47541. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.15885/0.46341. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.15481/0.46286. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.15786/0.46693. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.15951/0.47010. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.15718/0.46906. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.15412/0.45854. Took 0.14 sec\n",
      "Epoch 99, Loss(train/val) 0.15496/0.46474. Took 0.15 sec\n",
      "ACC: 0.640625, MCC: 0.4372742745792293\n",
      "Epoch 0, Loss(train/val) 0.48469/0.47562. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.45637/0.44754. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.42820/0.42011. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.40877/0.39812. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.38953/0.38527. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.37886/0.37981. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.36020/0.37327. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.35180/0.36832. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.34629/0.36668. Took 0.15 sec\n",
      "Epoch 9, Loss(train/val) 0.33306/0.35628. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.32216/0.35185. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.31915/0.34947. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.30878/0.34571. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.30296/0.33843. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.30756/0.34856. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.29072/0.32526. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.28395/0.32100. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.28728/0.32392. Took 0.16 sec\n",
      "Epoch 18, Loss(train/val) 0.28012/0.32742. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.27591/0.33674. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.27148/0.34061. Took 0.17 sec\n",
      "Epoch 21, Loss(train/val) 0.27202/0.32041. Took 0.16 sec\n",
      "Epoch 22, Loss(train/val) 0.27089/0.31586. Took 0.15 sec\n",
      "Epoch 23, Loss(train/val) 0.26284/0.34142. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.26392/0.35123. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.25444/0.35420. Took 0.16 sec\n",
      "Epoch 26, Loss(train/val) 0.25316/0.36827. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.25684/0.37383. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.24404/0.35404. Took 0.16 sec\n",
      "Epoch 29, Loss(train/val) 0.25222/0.34584. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.24795/0.31517. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.25713/0.35308. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.25141/0.33334. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.24177/0.31309. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.24515/0.34346. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.23238/0.33549. Took 0.15 sec\n",
      "Epoch 36, Loss(train/val) 0.23854/0.36399. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.22849/0.32465. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.22944/0.34516. Took 0.17 sec\n",
      "Epoch 39, Loss(train/val) 0.22244/0.36375. Took 0.16 sec\n",
      "Epoch 40, Loss(train/val) 0.22435/0.36494. Took 0.15 sec\n",
      "Epoch 41, Loss(train/val) 0.21984/0.36341. Took 0.15 sec\n",
      "Epoch 42, Loss(train/val) 0.22499/0.36215. Took 0.15 sec\n",
      "Epoch 43, Loss(train/val) 0.21108/0.37408. Took 0.15 sec\n",
      "Epoch 44, Loss(train/val) 0.21480/0.36918. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) 0.20942/0.37581. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.21445/0.37165. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.21055/0.38087. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.20687/0.36464. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.20416/0.36421. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.20631/0.34568. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.20147/0.34796. Took 0.15 sec\n",
      "Epoch 52, Loss(train/val) 0.19816/0.35720. Took 0.15 sec\n",
      "Epoch 53, Loss(train/val) 0.20166/0.34135. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.20023/0.34949. Took 0.15 sec\n",
      "Epoch 55, Loss(train/val) 0.20561/0.35510. Took 0.16 sec\n",
      "Epoch 56, Loss(train/val) 0.20254/0.33611. Took 0.15 sec\n",
      "Epoch 57, Loss(train/val) 0.19155/0.35857. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.19423/0.34919. Took 0.15 sec\n",
      "Epoch 59, Loss(train/val) 0.19337/0.34314. Took 0.16 sec\n",
      "Epoch 60, Loss(train/val) 0.19334/0.36587. Took 0.14 sec\n",
      "Epoch 61, Loss(train/val) 0.18757/0.35011. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.18635/0.34848. Took 0.15 sec\n",
      "Epoch 63, Loss(train/val) 0.18791/0.35746. Took 0.15 sec\n",
      "Epoch 64, Loss(train/val) 0.18830/0.33942. Took 0.15 sec\n",
      "Epoch 65, Loss(train/val) 0.18420/0.33517. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.18538/0.34517. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) 0.17530/0.33756. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.17921/0.34406. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.17771/0.34455. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.18286/0.34233. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.16969/0.36007. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.17375/0.34448. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.18640/0.33922. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.17670/0.33242. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) 0.17380/0.33683. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.17301/0.34686. Took 0.16 sec\n",
      "Epoch 77, Loss(train/val) 0.16608/0.32741. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.16637/0.31774. Took 0.15 sec\n",
      "Epoch 79, Loss(train/val) 0.16845/0.33016. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.17131/0.32814. Took 0.14 sec\n",
      "Epoch 81, Loss(train/val) 0.17333/0.34411. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.16140/0.32311. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.17544/0.34051. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.17314/0.34524. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.16368/0.33917. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.15303/0.33890. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.16541/0.36913. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.15378/0.34758. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.15413/0.34438. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.15383/0.33318. Took 0.15 sec\n",
      "Epoch 91, Loss(train/val) 0.16151/0.33527. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.15340/0.35355. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.15165/0.32753. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.14806/0.33825. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.14570/0.33444. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.14882/0.33287. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.14509/0.33963. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.14886/0.32783. Took 0.15 sec\n",
      "Epoch 99, Loss(train/val) 0.14826/0.33816. Took 0.15 sec\n",
      "ACC: 0.515625, MCC: 0.013980301652228746\n",
      "Epoch 0, Loss(train/val) 0.49032/0.51475. Took 0.16 sec\n",
      "Epoch 1, Loss(train/val) 0.46578/0.52852. Took 0.15 sec\n",
      "Epoch 2, Loss(train/val) 0.44254/0.50799. Took 0.15 sec\n",
      "Epoch 3, Loss(train/val) 0.42322/0.45575. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.40428/0.43014. Took 0.15 sec\n",
      "Epoch 5, Loss(train/val) 0.39377/0.41485. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.38201/0.39396. Took 0.17 sec\n",
      "Epoch 7, Loss(train/val) 0.36479/0.37724. Took 0.15 sec\n",
      "Epoch 8, Loss(train/val) 0.35501/0.36810. Took 0.15 sec\n",
      "Epoch 9, Loss(train/val) 0.34433/0.35823. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.33300/0.39637. Took 0.16 sec\n",
      "Epoch 11, Loss(train/val) 0.32496/0.38090. Took 0.15 sec\n",
      "Epoch 12, Loss(train/val) 0.31991/0.39848. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.30972/0.39035. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.30210/0.37624. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.30622/0.40808. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.28784/0.42989. Took 0.15 sec\n",
      "Epoch 17, Loss(train/val) 0.28818/0.43090. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.27779/0.41643. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.27755/0.42324. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.27551/0.41106. Took 0.16 sec\n",
      "Epoch 21, Loss(train/val) 0.26763/0.41282. Took 0.16 sec\n",
      "Epoch 22, Loss(train/val) 0.26496/0.44506. Took 0.15 sec\n",
      "Epoch 23, Loss(train/val) 0.26012/0.39849. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.25252/0.40778. Took 0.17 sec\n",
      "Epoch 25, Loss(train/val) 0.24527/0.39674. Took 0.16 sec\n",
      "Epoch 26, Loss(train/val) 0.25407/0.42044. Took 0.15 sec\n",
      "Epoch 27, Loss(train/val) 0.25245/0.39289. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.24941/0.40845. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.24806/0.42868. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.24098/0.40596. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.24359/0.41242. Took 0.16 sec\n",
      "Epoch 32, Loss(train/val) 0.24121/0.41058. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.23231/0.40902. Took 0.13 sec\n",
      "Epoch 34, Loss(train/val) 0.23327/0.40024. Took 0.13 sec\n",
      "Epoch 35, Loss(train/val) 0.22939/0.42283. Took 0.13 sec\n",
      "Epoch 36, Loss(train/val) 0.23253/0.41005. Took 0.13 sec\n",
      "Epoch 37, Loss(train/val) 0.22610/0.38906. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.22704/0.39702. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.22414/0.41596. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.21711/0.41918. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.20936/0.42198. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.21570/0.41743. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.21178/0.41954. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.20776/0.43042. Took 0.15 sec\n",
      "Epoch 45, Loss(train/val) 0.21850/0.42138. Took 0.16 sec\n",
      "Epoch 46, Loss(train/val) 0.20896/0.42530. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.21361/0.41380. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.20170/0.41336. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.20362/0.39561. Took 0.15 sec\n",
      "Epoch 50, Loss(train/val) 0.21086/0.42163. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.20296/0.41448. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.22218/0.44824. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.21302/0.43216. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.20346/0.43207. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.20122/0.41903. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.19639/0.39888. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.20282/0.43909. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.19954/0.42214. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.20026/0.45389. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.19754/0.43282. Took 0.14 sec\n",
      "Epoch 61, Loss(train/val) 0.19330/0.45724. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.19657/0.45351. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.20306/0.43747. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.19983/0.40351. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.18763/0.38809. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.19262/0.39893. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.19049/0.41557. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.18676/0.40515. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.19848/0.43176. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.18200/0.41447. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.18709/0.41367. Took 0.15 sec\n",
      "Epoch 72, Loss(train/val) 0.17698/0.40280. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.18901/0.41564. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.17988/0.40434. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.17891/0.40321. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.17122/0.40183. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.17462/0.38619. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.17890/0.39975. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.16762/0.40701. Took 0.15 sec\n",
      "Epoch 80, Loss(train/val) 0.16896/0.40725. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.17095/0.41568. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.17378/0.41175. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.16504/0.40357. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.16813/0.40105. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.17027/0.40925. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.16651/0.35760. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.16686/0.40344. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.17313/0.41573. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.16783/0.39483. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.17653/0.39263. Took 0.15 sec\n",
      "Epoch 91, Loss(train/val) 0.16208/0.40378. Took 0.16 sec\n",
      "Epoch 92, Loss(train/val) 0.16246/0.38366. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.15930/0.38007. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.15902/0.38202. Took 0.14 sec\n",
      "Epoch 95, Loss(train/val) 0.16182/0.43042. Took 0.16 sec\n",
      "Epoch 96, Loss(train/val) 0.16576/0.41810. Took 0.14 sec\n",
      "Epoch 97, Loss(train/val) 0.15742/0.42120. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.16314/0.38261. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.16117/0.37695. Took 0.14 sec\n",
      "ACC: 0.625, MCC: 0.18367958959266126\n",
      "Epoch 0, Loss(train/val) 0.48928/0.46332. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.46683/0.42181. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.43979/0.39580. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.41295/0.36480. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.39438/0.33337. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.37840/0.31883. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.36113/0.29371. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.34164/0.29609. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.33676/0.29327. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.32256/0.28265. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.32499/0.28550. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.31359/0.28128. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.31270/0.27235. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.31294/0.28782. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.29647/0.27859. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.29230/0.27920. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.29448/0.27287. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.28508/0.28495. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.28221/0.28201. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.27931/0.28086. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.27129/0.28689. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.26994/0.28616. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.26702/0.27886. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.26393/0.29212. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.25055/0.28211. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.24764/0.27324. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.25307/0.27213. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.25027/0.28245. Took 0.16 sec\n",
      "Epoch 28, Loss(train/val) 0.25375/0.27208. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.23717/0.27599. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.25028/0.29810. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.23720/0.30072. Took 0.16 sec\n",
      "Epoch 32, Loss(train/val) 0.22769/0.29201. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.22759/0.27806. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.22048/0.29608. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.22459/0.28827. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.21779/0.29629. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.21300/0.29252. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.21284/0.30195. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.21541/0.29311. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.21364/0.31335. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.21469/0.28654. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.20971/0.30893. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.21775/0.31619. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.19851/0.31994. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.19588/0.31268. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.19881/0.31136. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.19643/0.30629. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.18911/0.30557. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.19090/0.30246. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.18866/0.30038. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.19688/0.31713. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.19101/0.31973. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.19193/0.30500. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.18855/0.29797. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.19416/0.30803. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.19438/0.32419. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.18242/0.32066. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.18267/0.30938. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.18261/0.31258. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.18163/0.33395. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.17799/0.33773. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.17671/0.31882. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.17285/0.33057. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.16935/0.32555. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.16383/0.31258. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.17886/0.33518. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.16153/0.32603. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.17643/0.32818. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.17627/0.33583. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.16226/0.33454. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.17249/0.32835. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.16258/0.33038. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.16263/0.33588. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.16319/0.32657. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.16109/0.34353. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.16570/0.31961. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.16212/0.31510. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.16843/0.32188. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.15398/0.32802. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.16012/0.34055. Took 0.14 sec\n",
      "Epoch 81, Loss(train/val) 0.15910/0.32684. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.15946/0.33978. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.16007/0.33275. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.16575/0.34333. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.15728/0.33905. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.15143/0.32172. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.15149/0.33490. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.14719/0.32016. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.16134/0.31687. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.16091/0.33015. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.16341/0.31138. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.15724/0.31508. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.16011/0.31744. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.14604/0.32276. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.14180/0.32125. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.14298/0.32353. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.14139/0.32928. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.14691/0.32427. Took 0.14 sec\n",
      "Epoch 99, Loss(train/val) 0.13859/0.36046. Took 0.14 sec\n",
      "ACC: 0.640625, MCC: 0.23811283746238887\n",
      "Epoch 0, Loss(train/val) 0.48901/0.46424. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.46159/0.42715. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.43629/0.40938. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.41115/0.40288. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.39155/0.38929. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.38235/0.39055. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.36947/0.40697. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.35443/0.40606. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.34509/0.40498. Took 0.15 sec\n",
      "Epoch 9, Loss(train/val) 0.33747/0.41585. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.33310/0.38956. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.31625/0.39089. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.33298/0.38593. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.32486/0.38902. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.31785/0.37912. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.30977/0.37155. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.30505/0.37007. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.30573/0.39195. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.29186/0.37955. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.30555/0.39393. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.29567/0.40055. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.29512/0.34318. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.28722/0.33800. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.30688/0.40462. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.29623/0.38319. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.28965/0.35433. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.27955/0.33780. Took 0.15 sec\n",
      "Epoch 27, Loss(train/val) 0.28203/0.35765. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.27597/0.37506. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.27695/0.39104. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.27079/0.37431. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.25564/0.39402. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.25715/0.38510. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.25019/0.36081. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.25139/0.37388. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.24776/0.39371. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.25167/0.35073. Took 0.13 sec\n",
      "Epoch 37, Loss(train/val) 0.24742/0.34932. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.25432/0.34989. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.24305/0.34561. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.24242/0.34801. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.23726/0.34949. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.23785/0.35507. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.23793/0.35418. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.22561/0.34982. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.21731/0.35223. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.22745/0.34952. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.22325/0.34013. Took 0.15 sec\n",
      "Epoch 48, Loss(train/val) 0.21689/0.35777. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.21596/0.35121. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.21781/0.33976. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.21671/0.33339. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.21776/0.33593. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.21082/0.34879. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.20009/0.33871. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.21176/0.33852. Took 0.15 sec\n",
      "Epoch 56, Loss(train/val) 0.20299/0.34721. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.20333/0.34553. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.20912/0.33846. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.20017/0.34060. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.19882/0.34767. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.20495/0.33094. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.18901/0.33744. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.19464/0.33542. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.18763/0.32817. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.19036/0.34028. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.19086/0.34162. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.20192/0.33215. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.19090/0.32927. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.19672/0.34740. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.19795/0.35518. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.19217/0.32684. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.19800/0.32991. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.18489/0.32006. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.18082/0.35026. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.18354/0.33568. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.18457/0.32655. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.18211/0.34290. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.18124/0.34145. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.18281/0.34593. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.17820/0.32645. Took 0.14 sec\n",
      "Epoch 81, Loss(train/val) 0.17568/0.32978. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.18187/0.34118. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.18515/0.32660. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.18500/0.33013. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.17657/0.33903. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.18179/0.34483. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.17186/0.34112. Took 0.15 sec\n",
      "Epoch 88, Loss(train/val) 0.16921/0.33867. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.17965/0.35182. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.18136/0.33333. Took 0.14 sec\n",
      "Epoch 91, Loss(train/val) 0.17504/0.34414. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.18861/0.34640. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.18248/0.35154. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.16746/0.35530. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.17885/0.35266. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.17112/0.33186. Took 0.15 sec\n",
      "Epoch 97, Loss(train/val) 0.16638/0.35044. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.16381/0.33406. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.16529/0.32314. Took 0.13 sec\n",
      "ACC: 0.59375, MCC: 0.1807753815155468\n",
      "Epoch 0, Loss(train/val) 0.49449/0.48596. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.46919/0.44676. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.43552/0.39597. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.40266/0.35734. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.38410/0.35343. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.36808/0.36000. Took 0.15 sec\n",
      "Epoch 6, Loss(train/val) 0.36036/0.36146. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.34857/0.35953. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.34546/0.33650. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.34563/0.35395. Took 0.15 sec\n",
      "Epoch 10, Loss(train/val) 0.33817/0.34117. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.32727/0.35039. Took 0.15 sec\n",
      "Epoch 12, Loss(train/val) 0.31959/0.36316. Took 0.16 sec\n",
      "Epoch 13, Loss(train/val) 0.30662/0.31716. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.33737/0.32350. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.32103/0.33811. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.30148/0.32850. Took 0.15 sec\n",
      "Epoch 17, Loss(train/val) 0.30442/0.33473. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.29675/0.30791. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.30246/0.35027. Took 0.17 sec\n",
      "Epoch 20, Loss(train/val) 0.28324/0.32847. Took 0.16 sec\n",
      "Epoch 21, Loss(train/val) 0.28421/0.32130. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.28543/0.34642. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.26365/0.32567. Took 0.17 sec\n",
      "Epoch 24, Loss(train/val) 0.27135/0.34584. Took 0.15 sec\n",
      "Epoch 25, Loss(train/val) 0.26593/0.32064. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.26057/0.33521. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.25471/0.31976. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.25726/0.32755. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.24680/0.31693. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.24722/0.30827. Took 0.16 sec\n",
      "Epoch 31, Loss(train/val) 0.25389/0.30570. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.24070/0.31990. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.24554/0.32110. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.24202/0.33667. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.23207/0.34502. Took 0.15 sec\n",
      "Epoch 36, Loss(train/val) 0.23487/0.33620. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.23469/0.31758. Took 0.15 sec\n",
      "Epoch 38, Loss(train/val) 0.24344/0.33286. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.22623/0.32650. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.23132/0.31688. Took 0.17 sec\n",
      "Epoch 41, Loss(train/val) 0.22195/0.32439. Took 0.16 sec\n",
      "Epoch 42, Loss(train/val) 0.21622/0.32133. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.22178/0.34240. Took 0.15 sec\n",
      "Epoch 44, Loss(train/val) 0.21112/0.32946. Took 0.15 sec\n",
      "Epoch 45, Loss(train/val) 0.21062/0.31573. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.22153/0.32144. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.21677/0.32470. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.20911/0.29871. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.20684/0.31496. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.20034/0.30159. Took 0.14 sec\n",
      "Epoch 51, Loss(train/val) 0.20828/0.30264. Took 0.15 sec\n",
      "Epoch 52, Loss(train/val) 0.21117/0.30628. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.19665/0.30918. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.19760/0.31277. Took 0.15 sec\n",
      "Epoch 55, Loss(train/val) 0.20738/0.29461. Took 0.15 sec\n",
      "Epoch 56, Loss(train/val) 0.20021/0.31024. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.19973/0.31979. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.19149/0.33202. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.19800/0.33587. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.18893/0.31479. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.18967/0.31218. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.18430/0.32101. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.18427/0.31418. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.17888/0.34143. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.18208/0.34063. Took 0.15 sec\n",
      "Epoch 66, Loss(train/val) 0.17440/0.33619. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.17735/0.33601. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.18244/0.32758. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.17868/0.31894. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.17514/0.31639. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.17621/0.30768. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.17486/0.33024. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.17309/0.31586. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.17071/0.32664. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.17209/0.30716. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.16983/0.32334. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.17141/0.30820. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.17111/0.34256. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.17215/0.31017. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.16463/0.32508. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.15975/0.33081. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.16134/0.34924. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.16380/0.35152. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.15937/0.36171. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.16065/0.33276. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.16474/0.34336. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.15011/0.32358. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.15655/0.31552. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.15466/0.34867. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.15513/0.37811. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.16031/0.33292. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.15181/0.37828. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.15004/0.32090. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.15828/0.38335. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.15201/0.33754. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.15590/0.34494. Took 0.14 sec\n",
      "Epoch 97, Loss(train/val) 0.14862/0.33770. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.14113/0.32183. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.14463/0.35170. Took 0.13 sec\n",
      "ACC: 0.625, MCC: 0.1508209203647733\n",
      "Epoch 0, Loss(train/val) 0.49194/0.46871. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.46862/0.41704. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.43917/0.38392. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.40690/0.40620. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.38733/0.41494. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.36970/0.43085. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.36169/0.41713. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.34623/0.43275. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.33712/0.40596. Took 0.16 sec\n",
      "Epoch 9, Loss(train/val) 0.32171/0.42419. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.32961/0.43340. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.32301/0.41959. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.30944/0.43727. Took 0.16 sec\n",
      "Epoch 13, Loss(train/val) 0.30320/0.44888. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.30414/0.45150. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.29423/0.43042. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.29163/0.41883. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.30807/0.42194. Took 0.16 sec\n",
      "Epoch 18, Loss(train/val) 0.29357/0.43668. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.28760/0.41733. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.27665/0.42009. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.27237/0.42609. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.27222/0.42514. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.28011/0.42532. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.27579/0.41488. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.26428/0.43090. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.25959/0.40426. Took 0.18 sec\n",
      "Epoch 27, Loss(train/val) 0.25111/0.43041. Took 0.16 sec\n",
      "Epoch 28, Loss(train/val) 0.26285/0.43348. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.26267/0.42319. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.25422/0.45563. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.24920/0.43865. Took 0.16 sec\n",
      "Epoch 32, Loss(train/val) 0.24168/0.45050. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.24647/0.44000. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.24822/0.41979. Took 0.13 sec\n",
      "Epoch 35, Loss(train/val) 0.24498/0.42779. Took 0.13 sec\n",
      "Epoch 36, Loss(train/val) 0.24298/0.42451. Took 0.13 sec\n",
      "Epoch 37, Loss(train/val) 0.22674/0.41034. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.22661/0.43082. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.22649/0.41557. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.22575/0.42402. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.23204/0.42151. Took 0.15 sec\n",
      "Epoch 42, Loss(train/val) 0.22563/0.44912. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.21760/0.42243. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.22400/0.38778. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.21670/0.39978. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.20868/0.42763. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.20872/0.41899. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.21291/0.40041. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.20220/0.40924. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.20224/0.41431. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.20122/0.42033. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.19185/0.40719. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.19561/0.39870. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.18816/0.41221. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.19182/0.40732. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.18184/0.40846. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.18600/0.41997. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.18216/0.40235. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.18654/0.40427. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.17383/0.39727. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.18228/0.38242. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.17538/0.42008. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.16623/0.39022. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.16559/0.38554. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.17338/0.41803. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.17484/0.39477. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.16762/0.38369. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.16481/0.42226. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.16334/0.39024. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.16087/0.43487. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.15338/0.38777. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.16048/0.39353. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.15629/0.39844. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.15803/0.43602. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.16239/0.38013. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.16016/0.38640. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.15750/0.40266. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.15413/0.37168. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.14969/0.37271. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.14682/0.40567. Took 0.14 sec\n",
      "Epoch 81, Loss(train/val) 0.15036/0.41163. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.14819/0.38465. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.14385/0.37607. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.14919/0.38313. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.15016/0.38680. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.14768/0.38594. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.14655/0.40280. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.13762/0.37035. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.13871/0.37540. Took 0.15 sec\n",
      "Epoch 90, Loss(train/val) 0.13535/0.36587. Took 0.14 sec\n",
      "Epoch 91, Loss(train/val) 0.14167/0.37524. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.13724/0.37576. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.13786/0.39740. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.13900/0.38328. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.13626/0.37112. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.13414/0.37388. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.13525/0.38266. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.13765/0.39000. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.12851/0.38251. Took 0.14 sec\n",
      "ACC: 0.640625, MCC: 0.29521161053222866\n",
      "Epoch 0, Loss(train/val) 0.49194/0.49900. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.47310/0.49251. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.44988/0.47092. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.42476/0.42890. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.40048/0.39944. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.38024/0.36705. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.36233/0.35304. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.35054/0.34462. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.33173/0.33254. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.31806/0.32290. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.31595/0.32386. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.30864/0.41597. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.31570/0.39406. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.30104/0.31973. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.29160/0.38478. Took 0.15 sec\n",
      "Epoch 15, Loss(train/val) 0.29595/0.37059. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.28749/0.36357. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.28180/0.33382. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.28180/0.28598. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.28165/0.28605. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.27962/0.28838. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.26481/0.31700. Took 0.16 sec\n",
      "Epoch 22, Loss(train/val) 0.26060/0.32164. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.26691/0.26948. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.27016/0.31588. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.25854/0.29345. Took 0.16 sec\n",
      "Epoch 26, Loss(train/val) 0.26326/0.29791. Took 0.13 sec\n",
      "Epoch 27, Loss(train/val) 0.26494/0.28827. Took 0.13 sec\n",
      "Epoch 28, Loss(train/val) 0.25462/0.32776. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.24808/0.31746. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.24593/0.32918. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.23946/0.28367. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.23952/0.28869. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.23559/0.40431. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.23659/0.36576. Took 0.16 sec\n",
      "Epoch 35, Loss(train/val) 0.23420/0.26840. Took 0.15 sec\n",
      "Epoch 36, Loss(train/val) 0.23679/0.33177. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.23481/0.33828. Took 0.15 sec\n",
      "Epoch 38, Loss(train/val) 0.22440/0.35196. Took 0.16 sec\n",
      "Epoch 39, Loss(train/val) 0.22687/0.36662. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.21994/0.33708. Took 0.15 sec\n",
      "Epoch 41, Loss(train/val) 0.21321/0.35836. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.21940/0.37604. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.22163/0.32528. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.21332/0.35173. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) 0.20861/0.38903. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.21386/0.34312. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.21149/0.34206. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.20930/0.31482. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.21161/0.32738. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.19227/0.34206. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.20048/0.34435. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.19009/0.33092. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.19330/0.34015. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.19544/0.30964. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.20072/0.31066. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.18817/0.32961. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.19098/0.36694. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.20291/0.31845. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.19510/0.33681. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.19354/0.35876. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.18650/0.37382. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.18943/0.36629. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.18684/0.41501. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.18373/0.37024. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.17203/0.36800. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.17384/0.36628. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) 0.18635/0.37600. Took 0.15 sec\n",
      "Epoch 68, Loss(train/val) 0.17965/0.38825. Took 0.14 sec\n",
      "Epoch 69, Loss(train/val) 0.17058/0.35916. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.17569/0.36474. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.17460/0.39532. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.17706/0.37004. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.16823/0.38674. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.17210/0.39925. Took 0.16 sec\n",
      "Epoch 75, Loss(train/val) 0.17308/0.39985. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.17466/0.37796. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.17349/0.36848. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.17283/0.37418. Took 0.14 sec\n",
      "Epoch 79, Loss(train/val) 0.17014/0.36059. Took 0.15 sec\n",
      "Epoch 80, Loss(train/val) 0.16985/0.38058. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.16537/0.38220. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.16268/0.38656. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.17341/0.39211. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.16375/0.36305. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.16593/0.34822. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.16374/0.35385. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.16294/0.35394. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.15137/0.35728. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.15425/0.36951. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.15287/0.35541. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.15081/0.39896. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.16080/0.38897. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.15266/0.36562. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.14895/0.37950. Took 0.16 sec\n",
      "Epoch 95, Loss(train/val) 0.15387/0.34677. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.15831/0.38162. Took 0.14 sec\n",
      "Epoch 97, Loss(train/val) 0.15467/0.36053. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.14577/0.36796. Took 0.14 sec\n",
      "Epoch 99, Loss(train/val) 0.15828/0.33401. Took 0.14 sec\n",
      "ACC: 0.578125, MCC: 0.15467466504810498\n",
      "Epoch 0, Loss(train/val) 0.49676/0.49937. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.48033/0.49854. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.45280/0.48986. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.41912/0.48541. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.39639/0.48585. Took 0.16 sec\n",
      "Epoch 5, Loss(train/val) 0.38048/0.48494. Took 0.15 sec\n",
      "Epoch 6, Loss(train/val) 0.36434/0.48534. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.34870/0.47844. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.33913/0.48420. Took 0.15 sec\n",
      "Epoch 9, Loss(train/val) 0.32460/0.45838. Took 0.16 sec\n",
      "Epoch 10, Loss(train/val) 0.31976/0.44085. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.31467/0.45242. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.30547/0.47555. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.30946/0.43031. Took 0.16 sec\n",
      "Epoch 14, Loss(train/val) 0.31058/0.44031. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.30401/0.46837. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.29190/0.44141. Took 0.16 sec\n",
      "Epoch 17, Loss(train/val) 0.29948/0.44815. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.28578/0.46861. Took 0.16 sec\n",
      "Epoch 19, Loss(train/val) 0.27633/0.45131. Took 0.18 sec\n",
      "Epoch 20, Loss(train/val) 0.28180/0.44683. Took 0.17 sec\n",
      "Epoch 21, Loss(train/val) 0.29233/0.45308. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.30936/0.45835. Took 0.17 sec\n",
      "Epoch 23, Loss(train/val) 0.29391/0.43850. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.27551/0.44222. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.27095/0.44537. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.26001/0.46005. Took 0.16 sec\n",
      "Epoch 27, Loss(train/val) 0.26913/0.47432. Took 0.17 sec\n",
      "Epoch 28, Loss(train/val) 0.25686/0.46425. Took 0.23 sec\n",
      "Epoch 29, Loss(train/val) 0.25940/0.45827. Took 0.16 sec\n",
      "Epoch 30, Loss(train/val) 0.25392/0.45246. Took 0.18 sec\n",
      "Epoch 31, Loss(train/val) 0.27153/0.44118. Took 0.16 sec\n",
      "Epoch 32, Loss(train/val) 0.25873/0.45595. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.26029/0.44958. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.24691/0.45030. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.24160/0.45948. Took 0.15 sec\n",
      "Epoch 36, Loss(train/val) 0.24188/0.45483. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.23625/0.46667. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.23725/0.45346. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.22557/0.46861. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.23887/0.43235. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.23825/0.46047. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.23048/0.45921. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.23009/0.44965. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.23417/0.45955. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.22147/0.45955. Took 0.15 sec\n",
      "Epoch 46, Loss(train/val) 0.22570/0.45547. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.23513/0.43314. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.22049/0.46213. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.23291/0.43787. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.22270/0.46770. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.21190/0.44431. Took 0.15 sec\n",
      "Epoch 52, Loss(train/val) 0.21381/0.46247. Took 0.15 sec\n",
      "Epoch 53, Loss(train/val) 0.21744/0.45041. Took 0.15 sec\n",
      "Epoch 54, Loss(train/val) 0.20948/0.44867. Took 0.15 sec\n",
      "Epoch 55, Loss(train/val) 0.20272/0.45549. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.20782/0.44488. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.20388/0.43060. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.20732/0.45238. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.20546/0.45090. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.20125/0.45312. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.20327/0.44538. Took 0.15 sec\n",
      "Epoch 62, Loss(train/val) 0.19041/0.45467. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.20059/0.45513. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.19647/0.46497. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.19730/0.45726. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.19069/0.45272. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.18893/0.47307. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.20240/0.47534. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.19749/0.46819. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.20389/0.44959. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.19272/0.47264. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.19322/0.47204. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.18654/0.46043. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.18640/0.47003. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.18022/0.46532. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.17895/0.45581. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.18572/0.41805. Took 0.16 sec\n",
      "Epoch 78, Loss(train/val) 0.18216/0.45527. Took 0.14 sec\n",
      "Epoch 79, Loss(train/val) 0.17683/0.44056. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.17918/0.44610. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.17560/0.45551. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.18294/0.46689. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.18202/0.45114. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.17696/0.45040. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.17543/0.45479. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.17471/0.42005. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.17198/0.43351. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.17542/0.40654. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.17080/0.41007. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.17073/0.41793. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.17281/0.41299. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.17515/0.43476. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.16781/0.41162. Took 0.15 sec\n",
      "Epoch 94, Loss(train/val) 0.15971/0.41565. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.16704/0.42528. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.16989/0.45280. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.16618/0.41283. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.16654/0.43770. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.15363/0.40786. Took 0.13 sec\n",
      "ACC: 0.75, MCC: 0.5219786367558533\n",
      "Epoch 0, Loss(train/val) 0.49586/0.48782. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.48075/0.46463. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.45974/0.41969. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.43014/0.38162. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.41105/0.36235. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.39756/0.35177. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.38508/0.34493. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.37264/0.33591. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.35862/0.33636. Took 0.15 sec\n",
      "Epoch 9, Loss(train/val) 0.34820/0.33396. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.34113/0.29231. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.31787/0.28285. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.31363/0.29105. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.31908/0.25773. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.30463/0.29625. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.29787/0.26680. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.30061/0.29552. Took 0.17 sec\n",
      "Epoch 17, Loss(train/val) 0.29735/0.28553. Took 0.17 sec\n",
      "Epoch 18, Loss(train/val) 0.27729/0.26933. Took 0.17 sec\n",
      "Epoch 19, Loss(train/val) 0.28185/0.25025. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.28171/0.28553. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.27464/0.25404. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.28081/0.28174. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.27822/0.25731. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.26818/0.26399. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.25972/0.26358. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.25640/0.26751. Took 0.15 sec\n",
      "Epoch 27, Loss(train/val) 0.25242/0.28903. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.26920/0.27463. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.25460/0.26225. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.25211/0.27403. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.23814/0.27035. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.24375/0.26963. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.24157/0.27944. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.23337/0.29752. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.23594/0.25497. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.23158/0.26825. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.22661/0.28530. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.22296/0.26699. Took 0.16 sec\n",
      "Epoch 39, Loss(train/val) 0.22108/0.27605. Took 0.15 sec\n",
      "Epoch 40, Loss(train/val) 0.22058/0.28185. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.22002/0.27293. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.20859/0.27527. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.20000/0.28580. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.21481/0.26491. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) 0.20177/0.29088. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.20729/0.33022. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.20762/0.28931. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.20350/0.29027. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.20541/0.28369. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.19769/0.26218. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.19133/0.28161. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.19341/0.27459. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) 0.18601/0.26322. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.18553/0.28697. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.18764/0.28545. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.18461/0.27748. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.18855/0.26368. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.18137/0.25969. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.18100/0.32099. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.18361/0.29404. Took 0.14 sec\n",
      "Epoch 61, Loss(train/val) 0.17224/0.27907. Took 0.16 sec\n",
      "Epoch 62, Loss(train/val) 0.17198/0.28003. Took 0.15 sec\n",
      "Epoch 63, Loss(train/val) 0.17952/0.35261. Took 0.15 sec\n",
      "Epoch 64, Loss(train/val) 0.17401/0.33456. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.17553/0.28696. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.16216/0.33823. Took 0.15 sec\n",
      "Epoch 67, Loss(train/val) 0.17573/0.27694. Took 0.15 sec\n",
      "Epoch 68, Loss(train/val) 0.16867/0.31749. Took 0.15 sec\n",
      "Epoch 69, Loss(train/val) 0.17033/0.29350. Took 0.15 sec\n",
      "Epoch 70, Loss(train/val) 0.17102/0.29245. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.16802/0.27748. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.16019/0.27307. Took 0.16 sec\n",
      "Epoch 73, Loss(train/val) 0.16265/0.27492. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.16658/0.30812. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.16606/0.27403. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.16606/0.34809. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.16039/0.26908. Took 0.17 sec\n",
      "Epoch 78, Loss(train/val) 0.15549/0.24772. Took 0.15 sec\n",
      "Epoch 79, Loss(train/val) 0.15457/0.33225. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.14921/0.28890. Took 0.14 sec\n",
      "Epoch 81, Loss(train/val) 0.15229/0.32002. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.14339/0.30507. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) 0.15772/0.28965. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.15076/0.32129. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.14894/0.31070. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.13970/0.33974. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.14872/0.32679. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.13546/0.33807. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.14372/0.30442. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.13409/0.34445. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.13962/0.35054. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.13033/0.31483. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.14241/0.29383. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.13209/0.31694. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.13260/0.30416. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.13626/0.36123. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.12929/0.31639. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.12976/0.37675. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.12829/0.32685. Took 0.14 sec\n",
      "ACC: 0.703125, MCC: 0.4344836909079172\n",
      "Epoch 0, Loss(train/val) 0.49066/0.48909. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.46199/0.47276. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.42936/0.46497. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.40002/0.48459. Took 0.15 sec\n",
      "Epoch 4, Loss(train/val) 0.37843/0.49151. Took 0.17 sec\n",
      "Epoch 5, Loss(train/val) 0.36389/0.49022. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.35725/0.48396. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.35402/0.48215. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.34482/0.48430. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.34447/0.48159. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.34523/0.47750. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.33639/0.48264. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.32705/0.47930. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.32826/0.48775. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.32278/0.47503. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.31779/0.48529. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.32081/0.48028. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.31157/0.46661. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.30879/0.47705. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.30043/0.46027. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.29703/0.45158. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.29685/0.40832. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.29253/0.43104. Took 0.15 sec\n",
      "Epoch 23, Loss(train/val) 0.29185/0.39472. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.29118/0.39867. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.28450/0.38280. Took 0.16 sec\n",
      "Epoch 26, Loss(train/val) 0.27930/0.39562. Took 0.15 sec\n",
      "Epoch 27, Loss(train/val) 0.26840/0.42420. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.27758/0.37493. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.28986/0.40914. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.28173/0.37325. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.27034/0.38903. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.26777/0.37522. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.28228/0.39573. Took 0.13 sec\n",
      "Epoch 34, Loss(train/val) 0.26481/0.40451. Took 0.13 sec\n",
      "Epoch 35, Loss(train/val) 0.25788/0.41146. Took 0.15 sec\n",
      "Epoch 36, Loss(train/val) 0.24832/0.42740. Took 0.13 sec\n",
      "Epoch 37, Loss(train/val) 0.24954/0.41043. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.24681/0.39909. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.23770/0.39730. Took 0.15 sec\n",
      "Epoch 40, Loss(train/val) 0.24174/0.38949. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.23294/0.38807. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.24173/0.38439. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.23540/0.36660. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.23925/0.39137. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) 0.23640/0.40936. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.25876/0.39919. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.24236/0.41585. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.23453/0.38625. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.23065/0.42581. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.24532/0.40960. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.21355/0.41882. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.22378/0.40918. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.21612/0.42049. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.21766/0.37547. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.22038/0.39381. Took 0.16 sec\n",
      "Epoch 56, Loss(train/val) 0.20422/0.37625. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.21385/0.36322. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.20582/0.37174. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.21358/0.36037. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.20378/0.37831. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.20230/0.40813. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.20801/0.37549. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.20676/0.40094. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.20640/0.38765. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.19953/0.36802. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.19342/0.37626. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.18201/0.37445. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.18849/0.37352. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.18210/0.37754. Took 0.15 sec\n",
      "Epoch 70, Loss(train/val) 0.19028/0.39301. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.17988/0.38057. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.17542/0.36800. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.17009/0.35922. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.17368/0.35597. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.18735/0.36082. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.17388/0.37593. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.17134/0.36964. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.17724/0.36361. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.16693/0.36864. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.16015/0.37394. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.16981/0.36910. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.16039/0.36896. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.15737/0.37642. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.15995/0.37129. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.15802/0.37920. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.14911/0.36874. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.14672/0.36215. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.16109/0.36426. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.15546/0.38159. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.16274/0.37047. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.15418/0.36979. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.15111/0.36912. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.14614/0.37294. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.14784/0.35930. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.14601/0.35786. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.14883/0.35928. Took 0.14 sec\n",
      "Epoch 97, Loss(train/val) 0.14536/0.34768. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.13745/0.34763. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.14483/0.35320. Took 0.13 sec\n",
      "ACC: 0.671875, MCC: 0.2444144502094572\n",
      "Epoch 0, Loss(train/val) 0.48963/0.45834. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.45652/0.39661. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.42749/0.37408. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.39950/0.38237. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.37805/0.36897. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.35942/0.36039. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.34843/0.35375. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.34211/0.33915. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.33605/0.33408. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.33424/0.33103. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.33355/0.32961. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.32661/0.33441. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.32380/0.33138. Took 0.15 sec\n",
      "Epoch 13, Loss(train/val) 0.31898/0.33039. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.30861/0.33584. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.31318/0.33011. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.30893/0.32980. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.30443/0.33190. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.30336/0.32150. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.29663/0.31763. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.29502/0.32184. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.29272/0.30552. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.29349/0.32601. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.29183/0.31593. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.28942/0.31144. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.28545/0.32235. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.27854/0.31720. Took 0.16 sec\n",
      "Epoch 27, Loss(train/val) 0.28050/0.31938. Took 0.16 sec\n",
      "Epoch 28, Loss(train/val) 0.27673/0.31622. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.27801/0.32114. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.26807/0.31433. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.26951/0.31002. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.26600/0.31590. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.26457/0.31090. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.26069/0.31751. Took 0.13 sec\n",
      "Epoch 35, Loss(train/val) 0.25430/0.32413. Took 0.13 sec\n",
      "Epoch 36, Loss(train/val) 0.25600/0.29805. Took 0.13 sec\n",
      "Epoch 37, Loss(train/val) 0.25002/0.29748. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.24536/0.29819. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.25181/0.29646. Took 0.15 sec\n",
      "Epoch 40, Loss(train/val) 0.24945/0.29578. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.25029/0.29353. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.24291/0.29570. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.23806/0.29602. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.24122/0.29642. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) 0.23376/0.30095. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.23402/0.29727. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.22004/0.29739. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.22906/0.29619. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.23178/0.29966. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.22516/0.29848. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.22657/0.30131. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.21104/0.31789. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.22008/0.30097. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.21657/0.29995. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.21599/0.30111. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.20949/0.30842. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.21418/0.31251. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.20677/0.30662. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.21223/0.30821. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.20321/0.30676. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.21042/0.30897. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.19875/0.31050. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.20113/0.30861. Took 0.15 sec\n",
      "Epoch 64, Loss(train/val) 0.19979/0.31276. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.19980/0.30833. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.19581/0.30706. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.19437/0.30269. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.18782/0.32449. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.18740/0.30852. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.19292/0.30878. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.18475/0.32188. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.18596/0.33146. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.19125/0.35878. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.19780/0.34826. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.18225/0.31815. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.17776/0.31888. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.18061/0.32275. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.18640/0.32041. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.17853/0.33733. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.18623/0.33287. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.18168/0.32720. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.17932/0.37202. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.17416/0.34278. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.16891/0.33307. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.17292/0.35280. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.17598/0.33677. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.17083/0.34646. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.17000/0.37843. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.16600/0.35962. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.16436/0.34411. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.16786/0.42633. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.18041/0.31633. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.15698/0.33142. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.15817/0.36905. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.15792/0.40200. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.14550/0.37442. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.15833/0.37919. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.15170/0.35779. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.15241/0.36058. Took 0.13 sec\n",
      "ACC: 0.640625, MCC: 0.23503396491930537\n",
      "Epoch 0, Loss(train/val) 0.48643/0.46785. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.45327/0.42226. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.42284/0.40033. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.39857/0.41907. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.37760/0.39941. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.36340/0.41153. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.34894/0.39304. Took 0.15 sec\n",
      "Epoch 7, Loss(train/val) 0.33902/0.41175. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.32986/0.37789. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.32575/0.39300. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.32187/0.38996. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.32029/0.41093. Took 0.15 sec\n",
      "Epoch 12, Loss(train/val) 0.31635/0.36250. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.32000/0.40067. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.31411/0.39286. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.31193/0.35848. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.31201/0.38223. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.30212/0.40280. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.29321/0.36451. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.29442/0.38904. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.28982/0.36161. Took 0.16 sec\n",
      "Epoch 21, Loss(train/val) 0.28312/0.37166. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.28341/0.36412. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.27691/0.35458. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.27619/0.37060. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.27656/0.39329. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.27783/0.41390. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.27181/0.36476. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.26664/0.38471. Took 0.16 sec\n",
      "Epoch 29, Loss(train/val) 0.26358/0.39636. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.25965/0.41580. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.26082/0.40607. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.26204/0.41324. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.26114/0.39604. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.25768/0.42444. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.24933/0.42738. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.24752/0.41353. Took 0.13 sec\n",
      "Epoch 37, Loss(train/val) 0.23474/0.42063. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.24715/0.40648. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.23876/0.42802. Took 0.15 sec\n",
      "Epoch 40, Loss(train/val) 0.23935/0.39877. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.23542/0.43094. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.23129/0.42273. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.22556/0.41505. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.22235/0.41439. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.21923/0.43911. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.21233/0.43986. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.21311/0.45591. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.20911/0.40169. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.20780/0.39920. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.21297/0.42460. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.20549/0.42518. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.20202/0.41252. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.19280/0.43900. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.19926/0.41069. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.18926/0.40238. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.18558/0.41928. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.18328/0.43486. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.18971/0.41910. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.18313/0.41485. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.18327/0.43642. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.17575/0.45551. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.17338/0.42643. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.17398/0.42387. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.16958/0.41544. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.16770/0.40625. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.16957/0.44109. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.16445/0.40584. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.16988/0.44059. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.16268/0.44030. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.16138/0.45753. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.15835/0.45684. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.16226/0.44399. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.15979/0.41767. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.16381/0.42207. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.15431/0.42107. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.15583/0.43213. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.14823/0.40721. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.14623/0.41261. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.14636/0.41088. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.15254/0.43513. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.15015/0.42869. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.14469/0.42525. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.14629/0.42643. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.13667/0.42239. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.14341/0.42194. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.14274/0.43877. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.14807/0.44051. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.14655/0.41461. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.13793/0.42432. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.14254/0.41350. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.13446/0.42839. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.13155/0.46113. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.14348/0.43867. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.14352/0.42008. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.13316/0.43912. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.13715/0.45369. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.13104/0.43197. Took 0.15 sec\n",
      "Epoch 98, Loss(train/val) 0.13036/0.42890. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.13256/0.43698. Took 0.13 sec\n",
      "ACC: 0.765625, MCC: 0.5439093717976677\n",
      "Epoch 0, Loss(train/val) 0.48578/0.47399. Took 0.16 sec\n",
      "Epoch 1, Loss(train/val) 0.45429/0.43847. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.42648/0.40119. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.40241/0.35901. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.37734/0.33523. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.35732/0.29814. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.34533/0.29114. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.33276/0.30003. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.33173/0.29052. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.31729/0.29889. Took 0.15 sec\n",
      "Epoch 10, Loss(train/val) 0.33116/0.28966. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.32869/0.28123. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.31986/0.29519. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.31059/0.27611. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.30560/0.27639. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.30670/0.28241. Took 0.16 sec\n",
      "Epoch 16, Loss(train/val) 0.30291/0.27464. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.29900/0.27966. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.29219/0.27705. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.29002/0.28258. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.28909/0.27905. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.28355/0.27751. Took 0.16 sec\n",
      "Epoch 22, Loss(train/val) 0.28124/0.28376. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.28162/0.28346. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.27854/0.27897. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.27377/0.28122. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.26992/0.28790. Took 0.15 sec\n",
      "Epoch 27, Loss(train/val) 0.27073/0.28135. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.26986/0.28524. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.26418/0.28765. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.26656/0.29630. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.26172/0.28627. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.25568/0.28330. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.25455/0.29073. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.25032/0.30367. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.24925/0.29496. Took 0.15 sec\n",
      "Epoch 36, Loss(train/val) 0.24726/0.28559. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.25053/0.28434. Took 0.15 sec\n",
      "Epoch 38, Loss(train/val) 0.23894/0.28624. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.24686/0.28572. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.24080/0.30214. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.24216/0.30501. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.23901/0.30652. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.24638/0.29872. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.23787/0.30973. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.23416/0.31478. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.23082/0.30327. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.23753/0.28201. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.23231/0.30737. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.22759/0.29583. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.22390/0.27990. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.22223/0.28051. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.22124/0.31232. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.21820/0.30532. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.21642/0.29080. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.21531/0.28379. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.21529/0.28879. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.22299/0.29395. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.21576/0.28784. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.21490/0.30990. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.21435/0.28625. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.21137/0.30822. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.20951/0.31996. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.21169/0.28657. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.20888/0.31162. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.20390/0.29505. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.20974/0.29183. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.21366/0.31202. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.20525/0.30543. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.20367/0.31507. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.20241/0.30770. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.20115/0.29466. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.20235/0.29841. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.19469/0.31931. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.19578/0.33366. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.19629/0.28731. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.20559/0.33800. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.19542/0.32228. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.19827/0.31601. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.19407/0.31701. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.18673/0.31762. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.19411/0.29329. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.18985/0.30402. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.18281/0.32401. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.18349/0.31584. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.18024/0.31354. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.17767/0.31136. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.17996/0.28875. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.17877/0.30531. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.17429/0.30552. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.17952/0.32700. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.17568/0.31297. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.17515/0.30650. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.16617/0.30446. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.16589/0.32796. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.17452/0.30693. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.17036/0.29489. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.16460/0.29970. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.16128/0.30655. Took 0.14 sec\n",
      "Epoch 99, Loss(train/val) 0.16038/0.30098. Took 0.13 sec\n",
      "ACC: 0.703125, MCC: 0.1868706368604627\n",
      "Epoch 0, Loss(train/val) 0.49158/0.44981. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.45778/0.36166. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.43178/0.32603. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.41053/0.31926. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.39259/0.31651. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.37225/0.30775. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.35814/0.29901. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.34809/0.29030. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.33995/0.28968. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.33213/0.28380. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.32819/0.28609. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.31674/0.29417. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.31134/0.27564. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.30647/0.28347. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.30531/0.27938. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.30152/0.26820. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.29282/0.26884. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.28542/0.26484. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.28109/0.25144. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.27227/0.23951. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.27671/0.23949. Took 0.16 sec\n",
      "Epoch 21, Loss(train/val) 0.25623/0.23149. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.25370/0.24355. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.25070/0.24176. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.24769/0.25147. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.22862/0.25031. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.23680/0.25279. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.22978/0.25739. Took 0.13 sec\n",
      "Epoch 28, Loss(train/val) 0.21924/0.26316. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.21414/0.27296. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.20277/0.32319. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.20687/0.28913. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.20305/0.26089. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.21260/0.27192. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.20588/0.25978. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.19694/0.26110. Took 0.15 sec\n",
      "Epoch 36, Loss(train/val) 0.19411/0.27186. Took 0.16 sec\n",
      "Epoch 37, Loss(train/val) 0.18396/0.38881. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.18033/0.27169. Took 0.15 sec\n",
      "Epoch 39, Loss(train/val) 0.17815/0.27094. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.17490/0.29342. Took 0.15 sec\n",
      "Epoch 41, Loss(train/val) 0.17734/0.25821. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.17843/0.35984. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.17108/0.37866. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.17005/0.44097. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.17093/0.38156. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.16379/0.33170. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.16541/0.39951. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.15826/0.41351. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.16197/0.41192. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.14915/0.37243. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.15851/0.43519. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.14570/0.36336. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.15225/0.39148. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.14707/0.54028. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.14822/0.47113. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.13986/0.48246. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.14748/0.48733. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.13825/0.52798. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.14605/0.49004. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.12817/0.53007. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.13969/0.50960. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.14292/0.50244. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.12625/0.49352. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.12775/0.50334. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.12250/0.46213. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.11701/0.50879. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) 0.12551/0.50702. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.11321/0.54614. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.12378/0.54163. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.11848/0.50854. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.12276/0.51616. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.12007/0.49764. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.12396/0.48191. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.12180/0.48794. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.11089/0.50526. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.11084/0.48447. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.10771/0.49738. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.10349/0.50674. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.10468/0.55846. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.11543/0.46168. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.11521/0.44413. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.10828/0.47330. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.11852/0.48745. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.10263/0.50965. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.11014/0.45251. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.10653/0.46702. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.09928/0.51537. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.10666/0.46975. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.10078/0.45903. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.09573/0.46654. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.09837/0.46576. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.10197/0.43605. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.09475/0.49570. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.10126/0.48137. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.09809/0.47377. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.09189/0.55245. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.09932/0.50144. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.09424/0.49701. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.08988/0.49935. Took 0.14 sec\n",
      "ACC: 0.6875, MCC: 0.33910215700436014\n",
      "Epoch 0, Loss(train/val) 0.48415/0.44633. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.45182/0.37785. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.42108/0.34535. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.39601/0.31757. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.37757/0.30422. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.36174/0.28487. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.35190/0.27252. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.34630/0.27557. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.33720/0.26795. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.33367/0.26395. Took 0.15 sec\n",
      "Epoch 10, Loss(train/val) 0.32777/0.26586. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.32960/0.26101. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.32334/0.26369. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.32554/0.27473. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.32217/0.29012. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.31933/0.27519. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.31148/0.27783. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.30202/0.28033. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.30088/0.27396. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.29799/0.27489. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.29680/0.27158. Took 0.15 sec\n",
      "Epoch 21, Loss(train/val) 0.28562/0.28025. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.28825/0.27644. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.28247/0.27985. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.27897/0.29456. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.27948/0.28059. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.28046/0.27859. Took 0.13 sec\n",
      "Epoch 27, Loss(train/val) 0.27473/0.28219. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.26884/0.27053. Took 0.16 sec\n",
      "Epoch 29, Loss(train/val) 0.27098/0.28079. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.26483/0.27232. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.26450/0.27722. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.25944/0.27132. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.25252/0.28534. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.25653/0.28423. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.25859/0.28092. Took 0.15 sec\n",
      "Epoch 36, Loss(train/val) 0.26030/0.27487. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.25005/0.28693. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.24760/0.30367. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.25090/0.29463. Took 0.15 sec\n",
      "Epoch 40, Loss(train/val) 0.24824/0.28349. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.24382/0.29155. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.23803/0.27749. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.23401/0.29456. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.22667/0.29300. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.23416/0.30591. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.23330/0.31041. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.22422/0.30377. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.22986/0.28976. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.22161/0.30432. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.21501/0.30842. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.21664/0.31521. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.21291/0.31557. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.21376/0.32722. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.20969/0.32887. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.20833/0.32937. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.20526/0.31779. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.20771/0.30656. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.19314/0.33022. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.20161/0.32227. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.19751/0.32579. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.19707/0.33024. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.18965/0.32055. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.18808/0.32912. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.18788/0.32003. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.18264/0.31517. Took 0.15 sec\n",
      "Epoch 66, Loss(train/val) 0.18372/0.30708. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.17711/0.33554. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.18058/0.31146. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.18253/0.32141. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.18320/0.31687. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.18001/0.30613. Took 0.15 sec\n",
      "Epoch 72, Loss(train/val) 0.17572/0.31695. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.17233/0.31983. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.17050/0.32869. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.17322/0.31697. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.16863/0.30647. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.16509/0.31879. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.16605/0.32962. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.16573/0.32698. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.16319/0.32311. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.17008/0.32241. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.16372/0.32669. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.16481/0.33054. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.15942/0.32710. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.15608/0.32082. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.15490/0.31989. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.15843/0.34755. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.15990/0.33914. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.15598/0.32808. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.15855/0.31052. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.15512/0.31575. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.14932/0.31588. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.14904/0.32804. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.14830/0.33971. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.15073/0.34455. Took 0.15 sec\n",
      "Epoch 96, Loss(train/val) 0.14580/0.32239. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.14471/0.32402. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.14136/0.31173. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.14113/0.32999. Took 0.13 sec\n",
      "ACC: 0.625, MCC: 0.23622863109452616\n",
      "Epoch 0, Loss(train/val) 0.47928/0.47745. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.43697/0.45106. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.41034/0.43723. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.38598/0.42667. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.36308/0.42413. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.34692/0.41601. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.33548/0.42771. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.32918/0.43284. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.32581/0.43290. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.31301/0.44028. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.31132/0.44121. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.31086/0.44528. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.30879/0.45014. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.30567/0.45094. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.30536/0.46070. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.29976/0.46874. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.28946/0.46230. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.28988/0.45153. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.29013/0.45214. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.27851/0.46151. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.27565/0.45268. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.26982/0.45774. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.27674/0.45841. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.26342/0.45152. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.26497/0.46089. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.25598/0.45925. Took 0.16 sec\n",
      "Epoch 26, Loss(train/val) 0.25575/0.45539. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.25420/0.45379. Took 0.13 sec\n",
      "Epoch 28, Loss(train/val) 0.25180/0.44839. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.24787/0.44640. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.24699/0.43818. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.23863/0.44598. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.23341/0.44455. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.23567/0.44362. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.23356/0.44245. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.24183/0.44208. Took 0.15 sec\n",
      "Epoch 36, Loss(train/val) 0.22937/0.43722. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.23632/0.43723. Took 0.15 sec\n",
      "Epoch 38, Loss(train/val) 0.22747/0.43808. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.22929/0.43338. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.22539/0.43351. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.22039/0.44352. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.21788/0.44371. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.21429/0.44938. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.21230/0.44542. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.20530/0.44040. Took 0.15 sec\n",
      "Epoch 46, Loss(train/val) 0.21048/0.44690. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.20435/0.45509. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.21144/0.45246. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.19955/0.46925. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.19790/0.45218. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.20759/0.45606. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.19723/0.44665. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.19413/0.46686. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.18643/0.45937. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.18754/0.45640. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.19294/0.45241. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.18283/0.46463. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.19120/0.46915. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.18334/0.46318. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.19702/0.45457. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.18509/0.45664. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.17710/0.45294. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.18690/0.45872. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.18366/0.45992. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.17698/0.46481. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.17772/0.46285. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.17637/0.46042. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.17827/0.45300. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.17135/0.46465. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.17944/0.46085. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.17008/0.45912. Took 0.15 sec\n",
      "Epoch 72, Loss(train/val) 0.16892/0.45141. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.17190/0.44458. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.17026/0.45458. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.16857/0.46808. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.17526/0.47599. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.17994/0.43086. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.17676/0.46727. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.16713/0.45918. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.16432/0.46381. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.16135/0.47692. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.15711/0.47025. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.15103/0.47663. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.15446/0.47104. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.15024/0.47691. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.15327/0.46822. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.15713/0.46519. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.15900/0.47291. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.15626/0.46640. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.14946/0.46594. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.15668/0.45337. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.17466/0.43920. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.15565/0.46510. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.15234/0.45364. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.14684/0.45328. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.14745/0.45265. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.14894/0.46159. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.14323/0.45886. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.15095/0.46742. Took 0.13 sec\n",
      "ACC: 0.546875, MCC: 0.11623821150544861\n",
      "Epoch 0, Loss(train/val) 0.48256/0.48915. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.44412/0.46980. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.42004/0.45677. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.40729/0.45007. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.39071/0.45394. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.37206/0.45235. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.35442/0.44607. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.34010/0.43678. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.33370/0.42929. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.32719/0.42515. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.32331/0.39827. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.31700/0.40274. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.31169/0.40576. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.30811/0.40881. Took 0.16 sec\n",
      "Epoch 14, Loss(train/val) 0.30482/0.39760. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.30066/0.38522. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.29941/0.40080. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.28907/0.40690. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.28817/0.40798. Took 0.15 sec\n",
      "Epoch 19, Loss(train/val) 0.28186/0.42258. Took 0.15 sec\n",
      "Epoch 20, Loss(train/val) 0.27615/0.42195. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.27408/0.40840. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.26894/0.40632. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.26608/0.41459. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.25444/0.41669. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.25588/0.41869. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.24908/0.40957. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.24285/0.43367. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.24475/0.42261. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.24512/0.40601. Took 0.17 sec\n",
      "Epoch 30, Loss(train/val) 0.24027/0.42779. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.23411/0.42488. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.22830/0.41588. Took 0.16 sec\n",
      "Epoch 33, Loss(train/val) 0.22814/0.41259. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.22473/0.41916. Took 0.13 sec\n",
      "Epoch 35, Loss(train/val) 0.21595/0.42054. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.21968/0.42366. Took 0.13 sec\n",
      "Epoch 37, Loss(train/val) 0.21628/0.42775. Took 0.15 sec\n",
      "Epoch 38, Loss(train/val) 0.20810/0.42571. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.21289/0.41682. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.20559/0.41427. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.20491/0.42087. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.21070/0.40580. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.20601/0.40616. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.20431/0.41099. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.19897/0.42253. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.19976/0.40773. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.18993/0.41304. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.19275/0.41855. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.19142/0.42651. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.18856/0.41764. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.18421/0.41788. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.18976/0.42880. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.17934/0.41946. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.18457/0.41791. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.18297/0.42612. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.17932/0.42198. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.18341/0.41194. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.17863/0.41024. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.17960/0.43639. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.18128/0.40765. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.17285/0.40614. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.17670/0.41883. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.17192/0.42819. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.16713/0.41811. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.16740/0.42159. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.16713/0.40945. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.16594/0.41186. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.16145/0.41458. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.16752/0.39858. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.17044/0.41662. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.16272/0.39860. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.16124/0.39604. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.15916/0.41857. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.15798/0.40180. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.15634/0.41604. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.14868/0.39873. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.15397/0.40538. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.14855/0.42331. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.15637/0.40922. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.14349/0.41563. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.14622/0.39221. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.13717/0.39829. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.13718/0.40775. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.13512/0.40064. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.14378/0.41220. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.13674/0.43588. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.13656/0.40497. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.13251/0.40055. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.13526/0.39498. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.14620/0.40406. Took 0.14 sec\n",
      "Epoch 91, Loss(train/val) 0.13239/0.42671. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.13531/0.39225. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.13917/0.40085. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.13450/0.40204. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.12669/0.37980. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.12840/0.40450. Took 0.14 sec\n",
      "Epoch 97, Loss(train/val) 0.12848/0.39031. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.12473/0.38934. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.12496/0.39831. Took 0.13 sec\n",
      "ACC: 0.609375, MCC: 0.28597530319931225\n",
      "Epoch 0, Loss(train/val) 0.48181/0.49697. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.44400/0.49269. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.42215/0.48001. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.40745/0.45557. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.39151/0.43339. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.37682/0.41578. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.36159/0.38910. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.34480/0.38119. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.33023/0.36581. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.32364/0.35733. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.31770/0.35758. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.31025/0.34709. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.30392/0.34802. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.29601/0.34389. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.29717/0.34761. Took 0.15 sec\n",
      "Epoch 15, Loss(train/val) 0.29401/0.34963. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.28839/0.34100. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.28432/0.33298. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.28333/0.34684. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.27515/0.33147. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.27117/0.33510. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.26995/0.32626. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.27270/0.32478. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.26556/0.31245. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.25898/0.30965. Took 0.15 sec\n",
      "Epoch 25, Loss(train/val) 0.26179/0.33861. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.25580/0.32777. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.25017/0.29363. Took 0.13 sec\n",
      "Epoch 28, Loss(train/val) 0.25733/0.38195. Took 0.13 sec\n",
      "Epoch 29, Loss(train/val) 0.25461/0.31276. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.24303/0.31599. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.25235/0.34356. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.23979/0.33756. Took 0.16 sec\n",
      "Epoch 33, Loss(train/val) 0.23340/0.32018. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.23054/0.31388. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.22995/0.35295. Took 0.15 sec\n",
      "Epoch 36, Loss(train/val) 0.22697/0.31618. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.22564/0.33190. Took 0.16 sec\n",
      "Epoch 38, Loss(train/val) 0.22519/0.30879. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.22427/0.37581. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.22767/0.32757. Took 0.15 sec\n",
      "Epoch 41, Loss(train/val) 0.21926/0.33664. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.21902/0.32720. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.21983/0.35482. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.22201/0.36476. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.22300/0.33417. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.21789/0.41806. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.21066/0.33740. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.20969/0.33230. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.21157/0.32721. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.20286/0.37116. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.19963/0.33376. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.19974/0.34312. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.20917/0.37329. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.20075/0.34067. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.19469/0.32430. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.19427/0.33249. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.19219/0.33322. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.18924/0.34039. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.18832/0.34370. Took 0.15 sec\n",
      "Epoch 60, Loss(train/val) 0.19314/0.34405. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.18369/0.32730. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.18554/0.31924. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.18993/0.33216. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.17958/0.32214. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.17888/0.34408. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.17788/0.32915. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) 0.17170/0.34986. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.18067/0.34891. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.17249/0.36205. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.17198/0.34902. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.17043/0.34597. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.16320/0.35164. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.16961/0.34489. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.16352/0.35520. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.15928/0.35278. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.16916/0.33628. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.16298/0.33147. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.15849/0.33489. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.16153/0.34130. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.16182/0.34683. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.15951/0.35272. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.16057/0.33035. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.16046/0.36178. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.15835/0.35592. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.16307/0.37284. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.15823/0.35629. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.14838/0.36555. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.14303/0.36559. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.15388/0.36449. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.14562/0.35717. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.14973/0.36163. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.14661/0.33871. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.14966/0.36913. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.14533/0.35309. Took 0.14 sec\n",
      "Epoch 95, Loss(train/val) 0.14462/0.36545. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.14753/0.36084. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.14891/0.37667. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.14004/0.38538. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.14520/0.35387. Took 0.14 sec\n",
      "ACC: 0.640625, MCC: 0.30686720460853334\n",
      "Epoch 0, Loss(train/val) 0.48706/0.50074. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.45438/0.50533. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.43135/0.50084. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.41053/0.45686. Took 0.15 sec\n",
      "Epoch 4, Loss(train/val) 0.39521/0.41851. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.37466/0.38523. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.36523/0.40231. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.34826/0.37011. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.34741/0.37151. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.33503/0.32562. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.33200/0.36674. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.33944/0.37239. Took 0.15 sec\n",
      "Epoch 12, Loss(train/val) 0.33424/0.34634. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.34854/0.33535. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.32516/0.35833. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.33047/0.38398. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.31571/0.40279. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.31944/0.39584. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.31024/0.42499. Took 0.15 sec\n",
      "Epoch 19, Loss(train/val) 0.31469/0.39582. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.30984/0.40352. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.30032/0.38707. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.30680/0.39459. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.29804/0.38312. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.30284/0.41748. Took 0.16 sec\n",
      "Epoch 25, Loss(train/val) 0.29623/0.40922. Took 0.16 sec\n",
      "Epoch 26, Loss(train/val) 0.28364/0.41681. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.27997/0.40686. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.28596/0.39824. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.28142/0.39547. Took 0.16 sec\n",
      "Epoch 30, Loss(train/val) 0.26741/0.39707. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.27056/0.43071. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.26795/0.42363. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.26092/0.40621. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.26327/0.42686. Took 0.13 sec\n",
      "Epoch 35, Loss(train/val) 0.25702/0.42837. Took 0.13 sec\n",
      "Epoch 36, Loss(train/val) 0.24939/0.43986. Took 0.13 sec\n",
      "Epoch 37, Loss(train/val) 0.24952/0.42902. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.24695/0.42803. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.25696/0.41912. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.25232/0.43211. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.25368/0.41619. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.23825/0.41189. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.24188/0.41691. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.23618/0.42171. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.23568/0.44874. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.22955/0.41493. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.23921/0.43871. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.23443/0.44661. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.22591/0.44073. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.22625/0.44842. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.22160/0.44018. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.21277/0.43052. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.22521/0.45440. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.22245/0.43334. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.22373/0.43917. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.21885/0.43461. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.21689/0.44240. Took 0.15 sec\n",
      "Epoch 58, Loss(train/val) 0.21000/0.43576. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.21503/0.43302. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.20967/0.42890. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.21204/0.40205. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.21379/0.41207. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.21361/0.42018. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.20471/0.41404. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.19925/0.42382. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.20520/0.41998. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.20009/0.42111. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.20808/0.45556. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.19510/0.44228. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.19810/0.40501. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.20257/0.42712. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.19737/0.44588. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.20226/0.45121. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.19169/0.45682. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.19817/0.43868. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.18816/0.42234. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.19021/0.43613. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.19105/0.41809. Took 0.14 sec\n",
      "Epoch 79, Loss(train/val) 0.18491/0.41125. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.18317/0.45787. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.18677/0.43132. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.18419/0.44163. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.18439/0.43884. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.19076/0.45247. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.17784/0.44046. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.18604/0.44429. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.18009/0.45589. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.17980/0.43452. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.17586/0.41401. Took 0.15 sec\n",
      "Epoch 90, Loss(train/val) 0.17822/0.44478. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.17495/0.41907. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.17702/0.42677. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.17411/0.41516. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.17301/0.43752. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.16461/0.46405. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.17243/0.46460. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.16786/0.47327. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.17397/0.43340. Took 0.14 sec\n",
      "Epoch 99, Loss(train/val) 0.16342/0.44696. Took 0.13 sec\n",
      "ACC: 0.75, MCC: 0.505401342333075\n",
      "Epoch 0, Loss(train/val) 0.49411/0.47683. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.47728/0.43681. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.44847/0.39531. Took 0.15 sec\n",
      "Epoch 3, Loss(train/val) 0.42226/0.37862. Took 0.15 sec\n",
      "Epoch 4, Loss(train/val) 0.40369/0.36836. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.39411/0.36344. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.38437/0.35176. Took 0.17 sec\n",
      "Epoch 7, Loss(train/val) 0.37575/0.33671. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.36554/0.32979. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.35330/0.32490. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.34916/0.32667. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.34347/0.32680. Took 0.15 sec\n",
      "Epoch 12, Loss(train/val) 0.33897/0.31468. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.33149/0.30658. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.32228/0.30447. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.31304/0.31173. Took 0.16 sec\n",
      "Epoch 16, Loss(train/val) 0.30422/0.33074. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.30546/0.30349. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.30067/0.30227. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.29255/0.30844. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.29274/0.30712. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.28555/0.31730. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.29822/0.33625. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.28342/0.30761. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.28126/0.31800. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.27971/0.36638. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.27147/0.38277. Took 0.15 sec\n",
      "Epoch 27, Loss(train/val) 0.28401/0.32994. Took 0.13 sec\n",
      "Epoch 28, Loss(train/val) 0.27258/0.33294. Took 0.13 sec\n",
      "Epoch 29, Loss(train/val) 0.26265/0.35288. Took 0.13 sec\n",
      "Epoch 30, Loss(train/val) 0.26445/0.36405. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.26573/0.33957. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.25536/0.38177. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.26482/0.33790. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.24946/0.33754. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.24388/0.33400. Took 0.16 sec\n",
      "Epoch 36, Loss(train/val) 0.23929/0.34750. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.24315/0.32317. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.23140/0.34561. Took 0.15 sec\n",
      "Epoch 39, Loss(train/val) 0.21800/0.34727. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.22449/0.34988. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.23156/0.34530. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.21705/0.35920. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.21726/0.35494. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.21355/0.34841. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.20969/0.34289. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.20956/0.34171. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.21679/0.34551. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.21316/0.35226. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.20062/0.33959. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.19051/0.36215. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.20098/0.32662. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.20121/0.35667. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.19617/0.34441. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.19298/0.32603. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.18327/0.33721. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.18705/0.32388. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.18693/0.30333. Took 0.15 sec\n",
      "Epoch 58, Loss(train/val) 0.17983/0.29865. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.18078/0.30468. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.17794/0.33521. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.18737/0.32908. Took 0.15 sec\n",
      "Epoch 62, Loss(train/val) 0.17760/0.31841. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.16598/0.31095. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.17072/0.32034. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.16471/0.31958. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.16128/0.33337. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.17207/0.33528. Took 0.15 sec\n",
      "Epoch 68, Loss(train/val) 0.16055/0.31909. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.16210/0.31637. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.16236/0.30939. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.15535/0.32679. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.16086/0.30661. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.15862/0.33577. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.15068/0.33245. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) 0.15306/0.32555. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.15328/0.34122. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.15428/0.31919. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.14503/0.36033. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.14893/0.33057. Took 0.15 sec\n",
      "Epoch 80, Loss(train/val) 0.14632/0.32059. Took 0.14 sec\n",
      "Epoch 81, Loss(train/val) 0.14789/0.34229. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.14880/0.30953. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.15680/0.33022. Took 0.15 sec\n",
      "Epoch 84, Loss(train/val) 0.14807/0.29549. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.14053/0.32673. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.14738/0.30091. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.14493/0.34619. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.14202/0.30915. Took 0.14 sec\n",
      "Epoch 89, Loss(train/val) 0.14575/0.31633. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.13305/0.32749. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.13382/0.30816. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.14501/0.32447. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.13821/0.35579. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.14143/0.33066. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.14038/0.33820. Took 0.15 sec\n",
      "Epoch 96, Loss(train/val) 0.13690/0.35732. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.13506/0.32706. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.12344/0.33963. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.12666/0.34083. Took 0.14 sec\n",
      "ACC: 0.59375, MCC: 0.22677868380553634\n",
      "Epoch 0, Loss(train/val) 0.49384/0.49572. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.47390/0.48695. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.43938/0.47607. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.40997/0.46296. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.39106/0.43925. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.37506/0.41566. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.36018/0.38582. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.34614/0.37859. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.33620/0.35988. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.32858/0.34446. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.31823/0.35119. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.32182/0.34335. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.30622/0.33954. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.30241/0.34512. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.30452/0.35428. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.29521/0.34014. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.29611/0.35247. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.29925/0.35397. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.28666/0.34769. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.28404/0.35746. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.27835/0.34103. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.28381/0.33908. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.28478/0.32434. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.27521/0.34144. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.25820/0.34283. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.27286/0.32865. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.27048/0.33525. Took 0.13 sec\n",
      "Epoch 27, Loss(train/val) 0.25879/0.33936. Took 0.13 sec\n",
      "Epoch 28, Loss(train/val) 0.25118/0.31564. Took 0.13 sec\n",
      "Epoch 29, Loss(train/val) 0.26833/0.30315. Took 0.13 sec\n",
      "Epoch 30, Loss(train/val) 0.26001/0.31193. Took 0.13 sec\n",
      "Epoch 31, Loss(train/val) 0.24911/0.31419. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.24981/0.31297. Took 0.13 sec\n",
      "Epoch 33, Loss(train/val) 0.24778/0.31943. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.24027/0.30831. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.23558/0.32513. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.23565/0.31224. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.23216/0.33396. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.22695/0.30071. Took 0.16 sec\n",
      "Epoch 39, Loss(train/val) 0.22793/0.30856. Took 0.15 sec\n",
      "Epoch 40, Loss(train/val) 0.22790/0.30844. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.22259/0.30320. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.22045/0.30658. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.22121/0.30065. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.22102/0.29986. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) 0.21562/0.30391. Took 0.15 sec\n",
      "Epoch 46, Loss(train/val) 0.20971/0.29766. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.21501/0.30889. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.21561/0.31295. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.20751/0.30880. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.21053/0.30609. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.21030/0.30089. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.20469/0.29613. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.19272/0.29495. Took 0.15 sec\n",
      "Epoch 54, Loss(train/val) 0.20542/0.30845. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.20232/0.30356. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.20346/0.28637. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.19639/0.29310. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.19392/0.28760. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.19191/0.28231. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.19718/0.29904. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.20398/0.28477. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.20436/0.30968. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.19308/0.31073. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.18233/0.29023. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.18235/0.29737. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.18732/0.31237. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.18922/0.33387. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.18732/0.29173. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.18604/0.30686. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.18058/0.29312. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.18267/0.29485. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.17833/0.29742. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.17973/0.30678. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.17976/0.31432. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) 0.17228/0.32049. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.17970/0.29945. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.17761/0.31917. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.17789/0.31163. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.17294/0.31858. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.17368/0.29593. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.16717/0.31359. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.15817/0.31619. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.16894/0.33349. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.16906/0.32212. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.17185/0.31834. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.17918/0.35772. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.17201/0.32517. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.17045/0.34242. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.16132/0.33779. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.16904/0.33151. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.16444/0.34378. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.16126/0.35201. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.16571/0.35033. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.16510/0.36813. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.16066/0.35384. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.16081/0.35594. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.16583/0.34422. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.15419/0.35563. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.15379/0.36030. Took 0.13 sec\n",
      "ACC: 0.640625, MCC: 0.282494169258455\n",
      "Epoch 0, Loss(train/val) 0.49054/0.48335. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.46746/0.45033. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.43502/0.41964. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.40613/0.40850. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.38925/0.39386. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.37647/0.39235. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.36567/0.37383. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.35071/0.37034. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.34199/0.37371. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.32830/0.36953. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.31771/0.31627. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.31399/0.35011. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.29934/0.34416. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.29725/0.34391. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.30255/0.33761. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.28859/0.32772. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.29186/0.33034. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.27597/0.33017. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.28094/0.31359. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.27302/0.30479. Took 0.15 sec\n",
      "Epoch 20, Loss(train/val) 0.27273/0.30842. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.26532/0.32586. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.25921/0.30742. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.25512/0.30006. Took 0.16 sec\n",
      "Epoch 24, Loss(train/val) 0.24848/0.30200. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.25721/0.34698. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.25408/0.30833. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.24980/0.35161. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.25002/0.35274. Took 0.13 sec\n",
      "Epoch 29, Loss(train/val) 0.24399/0.34967. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.24140/0.34660. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.23419/0.34443. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.23624/0.35456. Took 0.17 sec\n",
      "Epoch 33, Loss(train/val) 0.22647/0.34463. Took 0.16 sec\n",
      "Epoch 34, Loss(train/val) 0.23006/0.37601. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.23016/0.36916. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.22252/0.36566. Took 0.16 sec\n",
      "Epoch 37, Loss(train/val) 0.22689/0.33844. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.23525/0.36755. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.22752/0.36182. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.22078/0.36988. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.22421/0.37348. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.22122/0.34081. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.21522/0.40327. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.21783/0.38806. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.20557/0.38229. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.20829/0.39898. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.21033/0.36999. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.20525/0.39437. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.20928/0.38578. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.20432/0.41641. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.19392/0.41012. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.19524/0.38777. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.20028/0.39478. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.18996/0.37417. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.18300/0.40445. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.18945/0.39155. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.18739/0.38388. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.18161/0.39648. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.17835/0.39078. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.18037/0.39640. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.18044/0.39521. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.18454/0.37954. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.17453/0.37192. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.17363/0.37454. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.18307/0.37599. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.17194/0.38163. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.17401/0.38639. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.17366/0.39830. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.16593/0.39341. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.17354/0.38472. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.17592/0.38172. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.17078/0.38050. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.16275/0.38857. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.16796/0.38202. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.16651/0.39451. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.16102/0.40808. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.16092/0.38541. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.16245/0.39726. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.15614/0.38971. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.15197/0.37654. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.16215/0.37712. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.15608/0.37644. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.16983/0.36298. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.15520/0.39759. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.16555/0.38135. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.15807/0.39834. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.16313/0.39884. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.16056/0.39550. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.16070/0.38482. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.15741/0.37295. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.15670/0.39698. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.14743/0.38754. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.15142/0.36827. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.15033/0.37194. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.15642/0.37617. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.15177/0.37165. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.14228/0.39768. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.14741/0.39650. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.14871/0.36974. Took 0.13 sec\n",
      "ACC: 0.5625, MCC: 0.12115833547198933\n",
      "Epoch 0, Loss(train/val) 0.49304/0.48701. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.47255/0.46056. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.43487/0.41251. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.40342/0.39608. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.38423/0.35811. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.37172/0.35060. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.35619/0.34724. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.34832/0.34983. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.33874/0.34643. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.32898/0.33700. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.31772/0.34675. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.31697/0.34485. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.30866/0.35217. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.29876/0.34113. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.29809/0.34759. Took 0.15 sec\n",
      "Epoch 15, Loss(train/val) 0.28945/0.33676. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.28448/0.33605. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.28543/0.32599. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.27507/0.33276. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.27233/0.34394. Took 0.16 sec\n",
      "Epoch 20, Loss(train/val) 0.26726/0.34100. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.26729/0.37734. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.25572/0.34776. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.25765/0.34743. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.25897/0.37021. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.25459/0.36931. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.25569/0.37039. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.23499/0.39621. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.23769/0.39572. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.23416/0.38764. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.23433/0.35923. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.22748/0.38931. Took 0.17 sec\n",
      "Epoch 32, Loss(train/val) 0.23008/0.36211. Took 0.17 sec\n",
      "Epoch 33, Loss(train/val) 0.22859/0.36107. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.23189/0.36806. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.23544/0.38389. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.23105/0.33843. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.22255/0.38337. Took 0.16 sec\n",
      "Epoch 38, Loss(train/val) 0.21963/0.36066. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.20680/0.38085. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.21147/0.38286. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.21396/0.38471. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.20804/0.39867. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.21079/0.39571. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.20801/0.38456. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) 0.20480/0.36925. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.20008/0.39035. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.18972/0.37852. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.19399/0.38607. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.19586/0.38404. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.19951/0.39313. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.19795/0.38432. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.19198/0.38190. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.18974/0.39446. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.19941/0.40619. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.19079/0.39409. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.18536/0.41306. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.18465/0.40848. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.17758/0.41281. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.18541/0.39161. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.17943/0.40980. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.17825/0.40693. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.18256/0.37166. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.18775/0.39676. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.17519/0.41166. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.17176/0.35199. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.18873/0.41017. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.17199/0.40768. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.16861/0.39007. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.15946/0.37295. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.16210/0.40228. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.16265/0.39785. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.15501/0.41192. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.15570/0.42230. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.16031/0.41003. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) 0.15974/0.42190. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.15011/0.40396. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.15183/0.44386. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.15939/0.42346. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.14644/0.44667. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.14949/0.43980. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.14695/0.45235. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.14476/0.42901. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.13817/0.43902. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.14058/0.41977. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.13781/0.41392. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.13460/0.41344. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.13349/0.44360. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.13350/0.43144. Took 0.14 sec\n",
      "Epoch 89, Loss(train/val) 0.13736/0.46148. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.13108/0.45581. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.13885/0.42514. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.13583/0.44081. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.13314/0.42042. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.12602/0.45055. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.13418/0.46342. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.12681/0.44039. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.13358/0.39322. Took 0.15 sec\n",
      "Epoch 98, Loss(train/val) 0.13182/0.44442. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.11715/0.44109. Took 0.13 sec\n",
      "ACC: 0.625, MCC: 0.2748737083745107\n",
      "Epoch 0, Loss(train/val) 0.49322/0.49346. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.46864/0.47696. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.42827/0.44767. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.39814/0.43153. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.37870/0.41548. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.36844/0.40981. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.36100/0.40530. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.35118/0.39570. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.34598/0.39866. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.33545/0.38824. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.32432/0.40397. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.31668/0.43068. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.31356/0.42365. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.30806/0.43513. Took 0.16 sec\n",
      "Epoch 14, Loss(train/val) 0.30677/0.44286. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.29228/0.45225. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.30005/0.46861. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.29063/0.43031. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.28676/0.41854. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.27950/0.44358. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.27983/0.44792. Took 0.15 sec\n",
      "Epoch 21, Loss(train/val) 0.27515/0.42413. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.27600/0.44907. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.27007/0.44733. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.26876/0.44732. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.27524/0.41882. Took 0.16 sec\n",
      "Epoch 26, Loss(train/val) 0.27816/0.41442. Took 0.13 sec\n",
      "Epoch 27, Loss(train/val) 0.27233/0.45213. Took 0.13 sec\n",
      "Epoch 28, Loss(train/val) 0.27118/0.40925. Took 0.13 sec\n",
      "Epoch 29, Loss(train/val) 0.26964/0.44941. Took 0.16 sec\n",
      "Epoch 30, Loss(train/val) 0.28137/0.45510. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.26807/0.46121. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.26069/0.46733. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.26313/0.46406. Took 0.16 sec\n",
      "Epoch 34, Loss(train/val) 0.26645/0.41600. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.27910/0.44108. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.25586/0.42188. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.25282/0.47865. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.25916/0.44836. Took 0.15 sec\n",
      "Epoch 39, Loss(train/val) 0.24793/0.45301. Took 0.15 sec\n",
      "Epoch 40, Loss(train/val) 0.25283/0.44378. Took 0.16 sec\n",
      "Epoch 41, Loss(train/val) 0.24954/0.45546. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.24400/0.44421. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.24407/0.45899. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.25243/0.44918. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.25165/0.44984. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.24775/0.45680. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.24827/0.45838. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.24763/0.45395. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.24781/0.46212. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.24583/0.46498. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.24344/0.43211. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.23560/0.45496. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.23017/0.44954. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.23196/0.46028. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.23469/0.44268. Took 0.15 sec\n",
      "Epoch 56, Loss(train/val) 0.22970/0.43853. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.22762/0.43711. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.22660/0.45487. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.23490/0.43594. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.22790/0.43891. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.22459/0.44305. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.21554/0.46738. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.22825/0.46044. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.21494/0.43572. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.21262/0.45443. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.21975/0.45625. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.21237/0.43676. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.22219/0.44539. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.21790/0.45260. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.21814/0.43778. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.21637/0.47384. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.22072/0.46096. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.21766/0.46073. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.20193/0.43680. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.19514/0.45849. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.20622/0.49315. Took 0.15 sec\n",
      "Epoch 77, Loss(train/val) 0.22170/0.44788. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.21944/0.44134. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.21055/0.47468. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.20657/0.46666. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.21601/0.46908. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.21067/0.50216. Took 0.17 sec\n",
      "Epoch 83, Loss(train/val) 0.20994/0.47484. Took 0.17 sec\n",
      "Epoch 84, Loss(train/val) 0.20348/0.49318. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.20619/0.48949. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.19922/0.50511. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.19621/0.51263. Took 0.15 sec\n",
      "Epoch 88, Loss(train/val) 0.19805/0.48103. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.19646/0.47513. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.18680/0.46072. Took 0.14 sec\n",
      "Epoch 91, Loss(train/val) 0.20337/0.49868. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.19238/0.46273. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.19375/0.48995. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.18490/0.48190. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.19508/0.49766. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.18100/0.49977. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.19563/0.47055. Took 0.15 sec\n",
      "Epoch 98, Loss(train/val) 0.20582/0.48190. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.19298/0.48256. Took 0.13 sec\n",
      "ACC: 0.609375, MCC: 0.22795136315904263\n",
      "Epoch 0, Loss(train/val) 0.49152/0.48693. Took 0.16 sec\n",
      "Epoch 1, Loss(train/val) 0.46676/0.46093. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.42773/0.43667. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.39398/0.41548. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.37469/0.38813. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.35955/0.37187. Took 0.15 sec\n",
      "Epoch 6, Loss(train/val) 0.35198/0.36869. Took 0.15 sec\n",
      "Epoch 7, Loss(train/val) 0.34221/0.37760. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.34402/0.37747. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.33103/0.36405. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.32465/0.36297. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.32438/0.34509. Took 0.19 sec\n",
      "Epoch 12, Loss(train/val) 0.32121/0.33890. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.31241/0.33737. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.31280/0.31868. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.31136/0.32628. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.31151/0.32607. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.30547/0.33438. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.30047/0.32672. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.30318/0.31915. Took 0.16 sec\n",
      "Epoch 20, Loss(train/val) 0.29346/0.32144. Took 0.15 sec\n",
      "Epoch 21, Loss(train/val) 0.28696/0.32021. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.29558/0.31597. Took 0.15 sec\n",
      "Epoch 23, Loss(train/val) 0.29162/0.34224. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.29303/0.35360. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.28642/0.34986. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.28265/0.35401. Took 0.15 sec\n",
      "Epoch 27, Loss(train/val) 0.27018/0.34497. Took 0.19 sec\n",
      "Epoch 28, Loss(train/val) 0.27128/0.33795. Took 0.18 sec\n",
      "Epoch 29, Loss(train/val) 0.26919/0.33758. Took 0.16 sec\n",
      "Epoch 30, Loss(train/val) 0.26155/0.33710. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.26054/0.34263. Took 0.16 sec\n",
      "Epoch 32, Loss(train/val) 0.25838/0.33606. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.24905/0.33714. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.24804/0.34297. Took 0.18 sec\n",
      "Epoch 35, Loss(train/val) 0.24510/0.31929. Took 0.15 sec\n",
      "Epoch 36, Loss(train/val) 0.23783/0.35676. Took 0.17 sec\n",
      "Epoch 37, Loss(train/val) 0.24827/0.33298. Took 0.19 sec\n",
      "Epoch 38, Loss(train/val) 0.24356/0.32804. Took 0.15 sec\n",
      "Epoch 39, Loss(train/val) 0.23382/0.32266. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.23171/0.30796. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.23122/0.31466. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.22762/0.30301. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.23380/0.30173. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.22468/0.31074. Took 0.18 sec\n",
      "Epoch 45, Loss(train/val) 0.22322/0.31691. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.22354/0.28934. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.22957/0.32152. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.22285/0.31562. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.21383/0.29392. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.21331/0.29956. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.20240/0.30883. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.21979/0.29765. Took 0.15 sec\n",
      "Epoch 53, Loss(train/val) 0.20942/0.31543. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.20043/0.29127. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.19575/0.27545. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.19727/0.28234. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.19133/0.30012. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.19179/0.29982. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.18873/0.29344. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.18660/0.30384. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.18995/0.28531. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.18793/0.28018. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.17769/0.28223. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.17670/0.29522. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.17961/0.28484. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.18022/0.29649. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.17253/0.29309. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.17873/0.30710. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.17818/0.28682. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.18081/0.29340. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.16891/0.31237. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.17479/0.31750. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.17622/0.29324. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.17333/0.32728. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.17261/0.32204. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.17297/0.28994. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.16332/0.30427. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.16441/0.30938. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.16481/0.31118. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.17210/0.31553. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.16240/0.29270. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.16146/0.29755. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.17649/0.29162. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.15792/0.28761. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.15851/0.30850. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.15825/0.27724. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.16062/0.27126. Took 0.15 sec\n",
      "Epoch 88, Loss(train/val) 0.15349/0.28532. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.15478/0.26015. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.15027/0.27368. Took 0.15 sec\n",
      "Epoch 91, Loss(train/val) 0.15640/0.27916. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.15203/0.26386. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.14428/0.28079. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.15022/0.25416. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.15740/0.24885. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.15020/0.26515. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.14953/0.28240. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.14093/0.26170. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.14971/0.28625. Took 0.13 sec\n",
      "ACC: 0.703125, MCC: 0.4175920586676743\n",
      "Epoch 0, Loss(train/val) 0.49652/0.49059. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.47692/0.46527. Took 0.15 sec\n",
      "Epoch 2, Loss(train/val) 0.44126/0.42189. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.40462/0.39938. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.38016/0.38989. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.36174/0.38184. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.35523/0.38225. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.34468/0.37741. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.33897/0.36639. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.33294/0.36697. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.32441/0.35883. Took 0.15 sec\n",
      "Epoch 11, Loss(train/val) 0.31688/0.36164. Took 0.16 sec\n",
      "Epoch 12, Loss(train/val) 0.31526/0.34397. Took 0.16 sec\n",
      "Epoch 13, Loss(train/val) 0.30894/0.35670. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.30659/0.35176. Took 0.16 sec\n",
      "Epoch 15, Loss(train/val) 0.29385/0.34121. Took 0.16 sec\n",
      "Epoch 16, Loss(train/val) 0.29455/0.33215. Took 0.17 sec\n",
      "Epoch 17, Loss(train/val) 0.29272/0.34124. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.29096/0.32642. Took 0.17 sec\n",
      "Epoch 19, Loss(train/val) 0.27881/0.32831. Took 0.15 sec\n",
      "Epoch 20, Loss(train/val) 0.28548/0.31008. Took 0.16 sec\n",
      "Epoch 21, Loss(train/val) 0.27400/0.33156. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.26688/0.31939. Took 0.15 sec\n",
      "Epoch 23, Loss(train/val) 0.25855/0.32326. Took 0.17 sec\n",
      "Epoch 24, Loss(train/val) 0.27134/0.36208. Took 0.15 sec\n",
      "Epoch 25, Loss(train/val) 0.26415/0.35522. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.25714/0.31847. Took 0.15 sec\n",
      "Epoch 27, Loss(train/val) 0.26511/0.35157. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.25269/0.32088. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.24116/0.33835. Took 0.18 sec\n",
      "Epoch 30, Loss(train/val) 0.23800/0.31891. Took 0.17 sec\n",
      "Epoch 31, Loss(train/val) 0.23850/0.32154. Took 0.17 sec\n",
      "Epoch 32, Loss(train/val) 0.23660/0.31182. Took 0.17 sec\n",
      "Epoch 33, Loss(train/val) 0.23325/0.33232. Took 0.17 sec\n",
      "Epoch 34, Loss(train/val) 0.23862/0.32559. Took 0.19 sec\n",
      "Epoch 35, Loss(train/val) 0.22386/0.30090. Took 0.15 sec\n",
      "Epoch 36, Loss(train/val) 0.22452/0.31367. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.22209/0.32239. Took 0.17 sec\n",
      "Epoch 38, Loss(train/val) 0.22599/0.31575. Took 0.17 sec\n",
      "Epoch 39, Loss(train/val) 0.21746/0.31191. Took 0.17 sec\n",
      "Epoch 40, Loss(train/val) 0.22224/0.33522. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.22326/0.32818. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.20763/0.34262. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.21146/0.33672. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.20873/0.31443. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.22337/0.32296. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.20699/0.34380. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.20941/0.34493. Took 0.18 sec\n",
      "Epoch 48, Loss(train/val) 0.20890/0.34274. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.20859/0.34750. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.19643/0.35152. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.20247/0.33673. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.20566/0.34483. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.19618/0.34729. Took 0.15 sec\n",
      "Epoch 54, Loss(train/val) 0.19281/0.34966. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.19590/0.35246. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.18780/0.34310. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.19406/0.35298. Took 0.15 sec\n",
      "Epoch 58, Loss(train/val) 0.19634/0.36436. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.18623/0.34785. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.19233/0.35758. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.18710/0.33661. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.18380/0.34242. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.18575/0.35380. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.18658/0.34938. Took 0.17 sec\n",
      "Epoch 65, Loss(train/val) 0.18221/0.34711. Took 0.15 sec\n",
      "Epoch 66, Loss(train/val) 0.18391/0.32146. Took 0.15 sec\n",
      "Epoch 67, Loss(train/val) 0.18801/0.33504. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.18065/0.35638. Took 0.14 sec\n",
      "Epoch 69, Loss(train/val) 0.17582/0.35296. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.17876/0.35206. Took 0.16 sec\n",
      "Epoch 71, Loss(train/val) 0.17355/0.35831. Took 0.16 sec\n",
      "Epoch 72, Loss(train/val) 0.16552/0.34794. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.16781/0.34313. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.18206/0.35948. Took 0.15 sec\n",
      "Epoch 75, Loss(train/val) 0.17775/0.35670. Took 0.17 sec\n",
      "Epoch 76, Loss(train/val) 0.16997/0.35022. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.17042/0.35144. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.17443/0.36391. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.16997/0.35965. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.15725/0.33068. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.17099/0.35149. Took 0.15 sec\n",
      "Epoch 82, Loss(train/val) 0.15973/0.35590. Took 0.15 sec\n",
      "Epoch 83, Loss(train/val) 0.16161/0.35679. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.15613/0.35471. Took 0.15 sec\n",
      "Epoch 85, Loss(train/val) 0.14968/0.33604. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.16287/0.35379. Took 0.15 sec\n",
      "Epoch 87, Loss(train/val) 0.15889/0.34757. Took 0.15 sec\n",
      "Epoch 88, Loss(train/val) 0.14709/0.36076. Took 0.16 sec\n",
      "Epoch 89, Loss(train/val) 0.14977/0.35303. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.14962/0.34730. Took 0.15 sec\n",
      "Epoch 91, Loss(train/val) 0.15240/0.34779. Took 0.16 sec\n",
      "Epoch 92, Loss(train/val) 0.15036/0.36209. Took 0.16 sec\n",
      "Epoch 93, Loss(train/val) 0.14143/0.34421. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.14298/0.37655. Took 0.16 sec\n",
      "Epoch 95, Loss(train/val) 0.13682/0.37427. Took 0.16 sec\n",
      "Epoch 96, Loss(train/val) 0.14280/0.35304. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.14457/0.36550. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.14462/0.36300. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.14481/0.34526. Took 0.17 sec\n",
      "ACC: 0.703125, MCC: 0.4457424941602093\n",
      "Epoch 0, Loss(train/val) 0.48675/0.47462. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.45723/0.41937. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.41510/0.37184. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.39059/0.35068. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.37830/0.33271. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.36693/0.32626. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.36110/0.32385. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.35276/0.32277. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.35504/0.32337. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.34117/0.32713. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.33839/0.33133. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.33611/0.35261. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.32496/0.34055. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.31117/0.33005. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.30903/0.32986. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.29896/0.34273. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.29848/0.34799. Took 0.15 sec\n",
      "Epoch 17, Loss(train/val) 0.28712/0.32757. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.29094/0.35692. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.29234/0.35944. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.29002/0.35538. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.27851/0.35591. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.27296/0.36091. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.26623/0.35989. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.26443/0.36916. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.25999/0.36471. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.25642/0.35759. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.27084/0.36981. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.25695/0.35905. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.26466/0.35224. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.25497/0.37120. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.23992/0.36436. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.23936/0.37345. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.24555/0.36073. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.24268/0.38960. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.23962/0.36934. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.22534/0.37008. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.23542/0.38094. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.23531/0.35319. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.22925/0.37592. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.22535/0.37223. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.21792/0.37122. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.21520/0.36890. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.21800/0.41022. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.21972/0.40800. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.21640/0.41405. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.21363/0.40374. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.19963/0.42643. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.20478/0.40477. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.20083/0.39952. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.20586/0.41624. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.21837/0.40501. Took 0.16 sec\n",
      "Epoch 52, Loss(train/val) 0.20220/0.38753. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.20560/0.39707. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.19668/0.41579. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.19312/0.40583. Took 0.15 sec\n",
      "Epoch 56, Loss(train/val) 0.18122/0.41122. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.18786/0.42460. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.17963/0.43397. Took 0.15 sec\n",
      "Epoch 59, Loss(train/val) 0.18772/0.40743. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.18449/0.40740. Took 0.15 sec\n",
      "Epoch 61, Loss(train/val) 0.19457/0.42753. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.18449/0.40828. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.19739/0.42827. Took 0.15 sec\n",
      "Epoch 64, Loss(train/val) 0.17494/0.43328. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.17646/0.41730. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.18101/0.42833. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.17945/0.41513. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.17211/0.41099. Took 0.14 sec\n",
      "Epoch 69, Loss(train/val) 0.17188/0.41974. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.17619/0.43185. Took 0.16 sec\n",
      "Epoch 71, Loss(train/val) 0.16420/0.42429. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.16196/0.41008. Took 0.15 sec\n",
      "Epoch 73, Loss(train/val) 0.16500/0.40728. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.16512/0.38951. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) 0.16835/0.38922. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.16910/0.37503. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.16469/0.42418. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.16161/0.38969. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.16105/0.38222. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.15603/0.41878. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.15695/0.38712. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.16557/0.41549. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) 0.15343/0.43620. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.15750/0.38593. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.15295/0.38678. Took 0.12 sec\n",
      "Epoch 86, Loss(train/val) 0.14913/0.39746. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.14938/0.40588. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.14240/0.40490. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.14488/0.40117. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.14373/0.40705. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.14288/0.38247. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.13843/0.38934. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.13552/0.39989. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.13338/0.42964. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.14328/0.38217. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.13992/0.43070. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.13759/0.43453. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.13395/0.43228. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.13327/0.41482. Took 0.13 sec\n",
      "ACC: 0.5625, MCC: 0.15244937348544793\n",
      "Epoch 0, Loss(train/val) 0.49252/0.48919. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.46885/0.46871. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.42671/0.43839. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.39545/0.42527. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.37886/0.42170. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.37345/0.42396. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.36298/0.42805. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.35876/0.44211. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.34592/0.46046. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.34221/0.43974. Took 0.15 sec\n",
      "Epoch 10, Loss(train/val) 0.33403/0.46252. Took 0.15 sec\n",
      "Epoch 11, Loss(train/val) 0.33165/0.43832. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.32520/0.45779. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.30963/0.45102. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.30286/0.46768. Took 0.16 sec\n",
      "Epoch 15, Loss(train/val) 0.31149/0.44514. Took 0.16 sec\n",
      "Epoch 16, Loss(train/val) 0.30025/0.43908. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.29437/0.45677. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.30677/0.45000. Took 0.16 sec\n",
      "Epoch 19, Loss(train/val) 0.28629/0.43659. Took 0.16 sec\n",
      "Epoch 20, Loss(train/val) 0.28445/0.43737. Took 0.15 sec\n",
      "Epoch 21, Loss(train/val) 0.28637/0.44827. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.28325/0.44764. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.27673/0.43206. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.27193/0.44018. Took 0.15 sec\n",
      "Epoch 25, Loss(train/val) 0.27527/0.46342. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.27418/0.43457. Took 0.15 sec\n",
      "Epoch 27, Loss(train/val) 0.27780/0.43239. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.26703/0.42755. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.26175/0.42918. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.25620/0.42923. Took 0.16 sec\n",
      "Epoch 31, Loss(train/val) 0.25792/0.43381. Took 0.18 sec\n",
      "Epoch 32, Loss(train/val) 0.26471/0.41949. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.26118/0.42104. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.26580/0.42330. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.26578/0.41906. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.25249/0.41784. Took 0.16 sec\n",
      "Epoch 37, Loss(train/val) 0.24854/0.41309. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.25469/0.42028. Took 0.15 sec\n",
      "Epoch 39, Loss(train/val) 0.24319/0.41701. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.24380/0.42559. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.25432/0.44326. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.24853/0.43339. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.24082/0.43532. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.24440/0.41387. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.25333/0.41248. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.24896/0.41772. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.23378/0.42413. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.22589/0.43452. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.22605/0.42854. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.24714/0.41073. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.22853/0.41337. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.23749/0.40688. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.25412/0.38612. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.25975/0.38532. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.23883/0.39432. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.22008/0.39412. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.22548/0.41031. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.22832/0.42507. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.23039/0.40200. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.23155/0.39181. Took 0.15 sec\n",
      "Epoch 61, Loss(train/val) 0.20810/0.41132. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.22086/0.39938. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.21988/0.40580. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.20769/0.41254. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.21543/0.40940. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.19725/0.41348. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.21591/0.40495. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.22148/0.43711. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.21842/0.41925. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.21521/0.40456. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.20403/0.39068. Took 0.15 sec\n",
      "Epoch 72, Loss(train/val) 0.20454/0.42194. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.20808/0.40348. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.19638/0.40725. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.20648/0.42004. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.21697/0.42436. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.20849/0.44381. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.20991/0.41754. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.20575/0.40384. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.21458/0.41172. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.20217/0.40390. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.19873/0.39707. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) 0.20244/0.39949. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.20470/0.41243. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.21077/0.40560. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.19557/0.40452. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.19948/0.39665. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.20033/0.40478. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.18153/0.40950. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.18849/0.40743. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.19883/0.39804. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.21559/0.43492. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.19395/0.40296. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.18857/0.40681. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.20186/0.39289. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.19696/0.37287. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.19914/0.41135. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.19229/0.40470. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.18798/0.41192. Took 0.14 sec\n",
      "ACC: 0.65625, MCC: 0.3778624445357772\n",
      "Epoch 0, Loss(train/val) 0.49189/0.48618. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.46530/0.46445. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.42154/0.42528. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.39031/0.39051. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.37411/0.36245. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.35992/0.35280. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.35221/0.35862. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.34461/0.32943. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.33831/0.33832. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.32919/0.32654. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.33510/0.32227. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.32722/0.35829. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.32261/0.34530. Took 0.16 sec\n",
      "Epoch 13, Loss(train/val) 0.32619/0.37791. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.31933/0.36560. Took 0.15 sec\n",
      "Epoch 15, Loss(train/val) 0.31631/0.36402. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.31256/0.36372. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.31110/0.37473. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.31356/0.37651. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.30706/0.39641. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.30296/0.38952. Took 0.16 sec\n",
      "Epoch 21, Loss(train/val) 0.29099/0.38074. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.28186/0.39411. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.28231/0.37790. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.27826/0.36235. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.26594/0.42131. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.27695/0.34737. Took 0.16 sec\n",
      "Epoch 27, Loss(train/val) 0.26641/0.36144. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.25643/0.37643. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.25611/0.33860. Took 0.13 sec\n",
      "Epoch 30, Loss(train/val) 0.26355/0.36999. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.24682/0.35854. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.24843/0.37299. Took 0.16 sec\n",
      "Epoch 33, Loss(train/val) 0.23153/0.37442. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.24397/0.40841. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.24898/0.43758. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.23270/0.41075. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.23437/0.38135. Took 0.16 sec\n",
      "Epoch 38, Loss(train/val) 0.23143/0.40091. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.22597/0.38618. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.24245/0.38437. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.24282/0.36231. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.24443/0.32677. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.22968/0.38062. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.22150/0.40572. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.22432/0.41532. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.21634/0.35709. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.20448/0.36479. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.20914/0.42228. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.21442/0.41733. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.21304/0.38814. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.20272/0.41228. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.21003/0.44697. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.19971/0.41892. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.19669/0.40440. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.20563/0.32809. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.20019/0.42377. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.19870/0.44988. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.19549/0.56295. Took 0.14 sec\n",
      "Epoch 59, Loss(train/val) 0.20498/0.38181. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.19059/0.41795. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.19058/0.42189. Took 0.15 sec\n",
      "Epoch 62, Loss(train/val) 0.19226/0.40341. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.19860/0.40038. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.18434/0.38250. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.19040/0.40990. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.19504/0.43035. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.18145/0.38408. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.18196/0.41295. Took 0.14 sec\n",
      "Epoch 69, Loss(train/val) 0.18603/0.42945. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.18929/0.41293. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.18475/0.44098. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.17860/0.42050. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.17637/0.35507. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.18540/0.37206. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.17621/0.37882. Took 0.15 sec\n",
      "Epoch 76, Loss(train/val) 0.17404/0.40900. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.17228/0.38544. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.17296/0.41243. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.16293/0.36452. Took 0.15 sec\n",
      "Epoch 80, Loss(train/val) 0.17162/0.42081. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.17076/0.40569. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.16650/0.40857. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.16659/0.38974. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.17003/0.41645. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.17116/0.38842. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.16214/0.42011. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.15583/0.39899. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.17243/0.40949. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.15528/0.42364. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.15656/0.39254. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.16623/0.42458. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.15546/0.46754. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.16199/0.42723. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.15766/0.39539. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.15339/0.46544. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.15359/0.45437. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.15850/0.42325. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.15130/0.38323. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.14918/0.41753. Took 0.14 sec\n",
      "ACC: 0.65625, MCC: 0.2742268345774339\n",
      "Epoch 0, Loss(train/val) 0.49260/0.49157. Took 0.68 sec\n",
      "Epoch 1, Loss(train/val) 0.47302/0.47341. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.44156/0.43330. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.40545/0.41067. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.38319/0.40692. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.36764/0.39899. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.35363/0.38412. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.33719/0.36849. Took 0.15 sec\n",
      "Epoch 8, Loss(train/val) 0.33255/0.36713. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.31154/0.37768. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.30792/0.38989. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.29939/0.38358. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.29323/0.37959. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.28995/0.37844. Took 0.16 sec\n",
      "Epoch 14, Loss(train/val) 0.28106/0.38328. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.27598/0.38206. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.27770/0.38749. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.27814/0.38881. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.28653/0.37427. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.27008/0.40555. Took 0.16 sec\n",
      "Epoch 20, Loss(train/val) 0.26262/0.36924. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.27247/0.39552. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.26212/0.37063. Took 0.15 sec\n",
      "Epoch 23, Loss(train/val) 0.25938/0.37770. Took 0.16 sec\n",
      "Epoch 24, Loss(train/val) 0.25864/0.38591. Took 0.15 sec\n",
      "Epoch 25, Loss(train/val) 0.25113/0.38267. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.25756/0.39946. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.25014/0.37953. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.23830/0.38411. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.25306/0.37551. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.24325/0.36603. Took 0.13 sec\n",
      "Epoch 31, Loss(train/val) 0.23952/0.38034. Took 0.13 sec\n",
      "Epoch 32, Loss(train/val) 0.24347/0.35953. Took 0.13 sec\n",
      "Epoch 33, Loss(train/val) 0.23701/0.37208. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.24445/0.38342. Took 0.13 sec\n",
      "Epoch 35, Loss(train/val) 0.24380/0.37262. Took 0.13 sec\n",
      "Epoch 36, Loss(train/val) 0.22353/0.36417. Took 0.13 sec\n",
      "Epoch 37, Loss(train/val) 0.23066/0.37345. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.22339/0.37378. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.23061/0.37019. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.23282/0.37564. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.21129/0.37112. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.20999/0.36223. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.20762/0.36476. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.21047/0.37261. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.21614/0.37062. Took 0.15 sec\n",
      "Epoch 46, Loss(train/val) 0.20293/0.37471. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.20197/0.36582. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.21037/0.36474. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.20742/0.37577. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.19948/0.36877. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.19501/0.37568. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.19216/0.36811. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.19768/0.37365. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.20504/0.37404. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.18840/0.36971. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.18675/0.37867. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.18834/0.37527. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.18382/0.39031. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.18878/0.37254. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.19646/0.36474. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.18725/0.36370. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.19768/0.38430. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.18619/0.37932. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.17281/0.37918. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.17964/0.37148. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.17785/0.40470. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.18277/0.37577. Took 0.15 sec\n",
      "Epoch 68, Loss(train/val) 0.19259/0.40815. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.17427/0.39031. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.17914/0.38603. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.17813/0.37134. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.17552/0.41074. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.16951/0.38157. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.16787/0.38289. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.17186/0.38707. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.16513/0.39332. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.17290/0.37823. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.17250/0.36645. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.17232/0.37163. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.17103/0.40128. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.16598/0.38804. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.16997/0.38030. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.15651/0.38692. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.15364/0.37440. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.17117/0.39178. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.16000/0.39840. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.16050/0.38060. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.16319/0.38830. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.15255/0.37574. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.15255/0.36316. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.15288/0.37004. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.15298/0.37187. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.14924/0.37157. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.15593/0.37721. Took 0.14 sec\n",
      "Epoch 95, Loss(train/val) 0.15644/0.37374. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.15412/0.38188. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.15806/0.37356. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.15357/0.36436. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.15526/0.37121. Took 0.14 sec\n",
      "ACC: 0.671875, MCC: 0.34269767738760554\n",
      "Epoch 0, Loss(train/val) 0.49589/0.49216. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.47915/0.47331. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.45053/0.44516. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.41065/0.41818. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.37858/0.40599. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.36304/0.40058. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.34965/0.39248. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.34207/0.38811. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.32961/0.38967. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.31939/0.35739. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.31368/0.38711. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.31889/0.35348. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.30944/0.36128. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.29951/0.36670. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.29398/0.35754. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.27675/0.36536. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.27700/0.37458. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.27426/0.37858. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.27054/0.37761. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.26711/0.37605. Took 0.15 sec\n",
      "Epoch 20, Loss(train/val) 0.26608/0.39178. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.26444/0.37241. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.24899/0.37661. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.25420/0.38093. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.24363/0.38487. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.24756/0.38342. Took 0.16 sec\n",
      "Epoch 26, Loss(train/val) 0.23495/0.38193. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.24753/0.37662. Took 0.13 sec\n",
      "Epoch 28, Loss(train/val) 0.23449/0.37270. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.22829/0.36479. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.22414/0.38287. Took 0.17 sec\n",
      "Epoch 31, Loss(train/val) 0.22546/0.37850. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.22314/0.38925. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.22021/0.39104. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.22009/0.38633. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.21144/0.39507. Took 0.16 sec\n",
      "Epoch 36, Loss(train/val) 0.21225/0.38551. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.21445/0.38200. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.20700/0.38179. Took 0.15 sec\n",
      "Epoch 39, Loss(train/val) 0.21385/0.39281. Took 0.17 sec\n",
      "Epoch 40, Loss(train/val) 0.20382/0.39199. Took 0.15 sec\n",
      "Epoch 41, Loss(train/val) 0.20390/0.41011. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.20488/0.39832. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.19311/0.39974. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.19658/0.40900. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.19095/0.39223. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.18605/0.41356. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.18333/0.39999. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.17657/0.39277. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.18268/0.38651. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.17902/0.40585. Took 0.14 sec\n",
      "Epoch 51, Loss(train/val) 0.18151/0.40383. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.17951/0.37691. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.19110/0.39214. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.18776/0.39525. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.17657/0.38911. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.16607/0.38661. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.16256/0.39362. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.16638/0.40809. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.16578/0.41284. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.15863/0.37704. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.16401/0.38317. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.15816/0.39286. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.16583/0.38832. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.15509/0.38324. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.16326/0.38902. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.16287/0.40156. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.15832/0.39969. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.15673/0.39534. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.15005/0.39312. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.14943/0.41676. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.15011/0.40953. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.14798/0.42285. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.15295/0.43413. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.14855/0.41046. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.15008/0.41973. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.14996/0.37643. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.15095/0.38656. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.14419/0.39020. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.14391/0.40212. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.14303/0.41090. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.14692/0.39347. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.14902/0.40427. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.15191/0.38909. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.14241/0.40027. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.14070/0.38921. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.14253/0.38288. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.13268/0.39472. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.13822/0.38522. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.13958/0.39033. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.13780/0.43366. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.13277/0.41292. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.13332/0.40116. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.13526/0.38164. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.12957/0.37345. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.13102/0.38266. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.13129/0.37323. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.13110/0.35710. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.13373/0.37208. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.13735/0.36981. Took 0.13 sec\n",
      "ACC: 0.703125, MCC: 0.40220105327545247\n",
      "Epoch 0, Loss(train/val) 0.49639/0.48426. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.47662/0.45648. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.44565/0.42394. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.41208/0.40313. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.38578/0.38255. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.36893/0.37535. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.35411/0.36595. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.34677/0.35538. Took 0.15 sec\n",
      "Epoch 8, Loss(train/val) 0.33835/0.35402. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.33329/0.35774. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.32865/0.34109. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.32972/0.36681. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.32279/0.35370. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.31510/0.37307. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.31721/0.31472. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.31507/0.36192. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.30809/0.32034. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.30189/0.35242. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.30289/0.29869. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.29863/0.33930. Took 0.15 sec\n",
      "Epoch 20, Loss(train/val) 0.29296/0.30211. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.28469/0.31158. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.28119/0.31561. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.27918/0.32293. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.27157/0.29792. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.27483/0.29598. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.26543/0.29370. Took 0.13 sec\n",
      "Epoch 27, Loss(train/val) 0.26274/0.29400. Took 0.13 sec\n",
      "Epoch 28, Loss(train/val) 0.25802/0.32068. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.25570/0.30249. Took 0.13 sec\n",
      "Epoch 30, Loss(train/val) 0.25241/0.29479. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.23997/0.29158. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.23967/0.30370. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.23662/0.29676. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.24305/0.31560. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.23280/0.29355. Took 0.18 sec\n",
      "Epoch 36, Loss(train/val) 0.22921/0.28390. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.22815/0.27720. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.21965/0.28855. Took 0.15 sec\n",
      "Epoch 39, Loss(train/val) 0.21581/0.29135. Took 0.16 sec\n",
      "Epoch 40, Loss(train/val) 0.21122/0.28875. Took 0.15 sec\n",
      "Epoch 41, Loss(train/val) 0.21717/0.28550. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.20642/0.28833. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.21312/0.30318. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.21662/0.27910. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.21515/0.28216. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.21183/0.29913. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.20249/0.27519. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.19636/0.30967. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.19271/0.28216. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.20196/0.29205. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.20814/0.37392. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.19589/0.31361. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.19878/0.31154. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.19385/0.32423. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.18802/0.36818. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.18920/0.29013. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.18707/0.33901. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.18463/0.31344. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.18384/0.32279. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.17916/0.28917. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.18451/0.29550. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.18208/0.35292. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.16893/0.34917. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.17388/0.30663. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.17570/0.32288. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.17017/0.28943. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.16973/0.33519. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.16354/0.30041. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.15903/0.32965. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.16555/0.31917. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.16715/0.34948. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.15360/0.34494. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.15285/0.33969. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.15800/0.34586. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) 0.15630/0.31479. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.15613/0.31872. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.15869/0.31593. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.15084/0.31703. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.16015/0.33540. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.15517/0.31639. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.15465/0.37211. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.15134/0.35074. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.14424/0.33695. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.14460/0.35820. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.15166/0.34927. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.15209/0.38761. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.14707/0.30515. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.14688/0.35857. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.14950/0.29860. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.15551/0.30577. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.14656/0.37740. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.14741/0.30602. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.14283/0.37620. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.14782/0.32120. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.14539/0.33870. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.13983/0.35479. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.14295/0.33196. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.13420/0.32839. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.13795/0.34797. Took 0.15 sec\n",
      "ACC: 0.609375, MCC: 0.18123858497615616\n",
      "Epoch 0, Loss(train/val) 0.49501/0.49362. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.47858/0.48336. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.45020/0.47678. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.41660/0.47931. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.39089/0.46608. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.37020/0.44014. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.36065/0.42708. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.34926/0.42260. Took 0.15 sec\n",
      "Epoch 8, Loss(train/val) 0.34200/0.42541. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.33957/0.42668. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.33261/0.42020. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.32643/0.40580. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.30813/0.40792. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.30168/0.35806. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.29218/0.38946. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.29442/0.35527. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.29217/0.39753. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.27578/0.34782. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.28398/0.36746. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.28769/0.39914. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.28868/0.34367. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.27949/0.34878. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.27218/0.36867. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.27657/0.37316. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.27493/0.36590. Took 0.16 sec\n",
      "Epoch 25, Loss(train/val) 0.25689/0.35532. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.25768/0.37061. Took 0.16 sec\n",
      "Epoch 27, Loss(train/val) 0.26202/0.36248. Took 0.16 sec\n",
      "Epoch 28, Loss(train/val) 0.25504/0.36303. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.25834/0.37884. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.24974/0.36526. Took 0.16 sec\n",
      "Epoch 31, Loss(train/val) 0.25597/0.36821. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.25006/0.36303. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.23491/0.35858. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.24204/0.35786. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.24153/0.36310. Took 0.13 sec\n",
      "Epoch 36, Loss(train/val) 0.24469/0.33801. Took 0.13 sec\n",
      "Epoch 37, Loss(train/val) 0.22585/0.33709. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.23625/0.34295. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.23222/0.33026. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.23132/0.32172. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.23125/0.34046. Took 0.16 sec\n",
      "Epoch 42, Loss(train/val) 0.23355/0.30195. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.22765/0.31825. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.20892/0.32637. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.21498/0.35716. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.22829/0.34410. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.22724/0.32021. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.21003/0.32194. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.20411/0.32829. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.20746/0.33051. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.20074/0.34522. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.19516/0.32497. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.21043/0.35031. Took 0.17 sec\n",
      "Epoch 54, Loss(train/val) 0.20109/0.33984. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.20417/0.31797. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.18996/0.32230. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.18911/0.32695. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.18796/0.33677. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.18919/0.35677. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.19270/0.33886. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.18894/0.33418. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.18411/0.34783. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.18594/0.32943. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.18160/0.33829. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.18262/0.33585. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.19435/0.34326. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.17665/0.33490. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.17803/0.30543. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.16931/0.35739. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.17254/0.34571. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.17116/0.29163. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.17610/0.30503. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.17604/0.27129. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.18401/0.32738. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.17384/0.33965. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.18034/0.31564. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.16685/0.29810. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.16917/0.32125. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.15474/0.30979. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.15940/0.31444. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.17025/0.30616. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.16170/0.29173. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.15779/0.29629. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.15479/0.29183. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.15945/0.30666. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.15272/0.30398. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.16060/0.29327. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.15201/0.30027. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.15785/0.31204. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.16438/0.30344. Took 0.14 sec\n",
      "Epoch 91, Loss(train/val) 0.15277/0.29662. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.15214/0.30827. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.15876/0.28874. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.15194/0.27680. Took 0.14 sec\n",
      "Epoch 95, Loss(train/val) 0.14306/0.28987. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.14826/0.27876. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.15115/0.31501. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.14944/0.27937. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.15039/0.29347. Took 0.13 sec\n",
      "ACC: 0.6875, MCC: 0.3757345746510897\n",
      "Epoch 0, Loss(train/val) 0.49200/0.47658. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.46947/0.43235. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.43545/0.38404. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.40735/0.37278. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.38926/0.38237. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.37575/0.37036. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.36183/0.37048. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.35277/0.37121. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.34066/0.35966. Took 0.15 sec\n",
      "Epoch 9, Loss(train/val) 0.32942/0.37015. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.32696/0.36895. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.31927/0.36924. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.31393/0.37680. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.31390/0.36151. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.30104/0.36069. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.29600/0.36212. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.29162/0.35121. Took 0.15 sec\n",
      "Epoch 17, Loss(train/val) 0.28094/0.35207. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.28769/0.34205. Took 0.16 sec\n",
      "Epoch 19, Loss(train/val) 0.27970/0.34947. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.27609/0.35106. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.26797/0.34017. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.26857/0.33881. Took 0.16 sec\n",
      "Epoch 23, Loss(train/val) 0.25643/0.35080. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.25214/0.32681. Took 0.15 sec\n",
      "Epoch 25, Loss(train/val) 0.25152/0.34049. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.24249/0.33349. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.23872/0.35367. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.23966/0.33560. Took 0.16 sec\n",
      "Epoch 29, Loss(train/val) 0.23394/0.33772. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.22584/0.35448. Took 0.17 sec\n",
      "Epoch 31, Loss(train/val) 0.22434/0.36124. Took 0.17 sec\n",
      "Epoch 32, Loss(train/val) 0.22526/0.34872. Took 0.18 sec\n",
      "Epoch 33, Loss(train/val) 0.21620/0.33411. Took 0.17 sec\n",
      "Epoch 34, Loss(train/val) 0.22339/0.33071. Took 0.18 sec\n",
      "Epoch 35, Loss(train/val) 0.20976/0.33876. Took 0.17 sec\n",
      "Epoch 36, Loss(train/val) 0.20621/0.33241. Took 0.16 sec\n",
      "Epoch 37, Loss(train/val) 0.20250/0.33236. Took 0.15 sec\n",
      "Epoch 38, Loss(train/val) 0.19951/0.34206. Took 0.15 sec\n",
      "Epoch 39, Loss(train/val) 0.20481/0.35009. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.20763/0.35131. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.19994/0.35560. Took 0.16 sec\n",
      "Epoch 42, Loss(train/val) 0.19746/0.36939. Took 0.15 sec\n",
      "Epoch 43, Loss(train/val) 0.17991/0.36901. Took 0.15 sec\n",
      "Epoch 44, Loss(train/val) 0.18002/0.35092. Took 0.15 sec\n",
      "Epoch 45, Loss(train/val) 0.18264/0.35027. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.18377/0.35573. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.18346/0.38103. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.19424/0.36013. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.17955/0.35919. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.17597/0.38102. Took 0.15 sec\n",
      "Epoch 51, Loss(train/val) 0.16609/0.36829. Took 0.15 sec\n",
      "Epoch 52, Loss(train/val) 0.16892/0.35529. Took 0.16 sec\n",
      "Epoch 53, Loss(train/val) 0.16093/0.36075. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.15587/0.35991. Took 0.16 sec\n",
      "Epoch 55, Loss(train/val) 0.15703/0.38130. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.16376/0.34966. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.15490/0.36872. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.14675/0.36520. Took 0.14 sec\n",
      "Epoch 59, Loss(train/val) 0.15022/0.36819. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.14436/0.35240. Took 0.14 sec\n",
      "Epoch 61, Loss(train/val) 0.14266/0.36571. Took 0.16 sec\n",
      "Epoch 62, Loss(train/val) 0.14068/0.35939. Took 0.15 sec\n",
      "Epoch 63, Loss(train/val) 0.13910/0.36176. Took 0.16 sec\n",
      "Epoch 64, Loss(train/val) 0.14284/0.35929. Took 0.15 sec\n",
      "Epoch 65, Loss(train/val) 0.12745/0.36482. Took 0.15 sec\n",
      "Epoch 66, Loss(train/val) 0.14372/0.39934. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) 0.12963/0.34631. Took 0.16 sec\n",
      "Epoch 68, Loss(train/val) 0.13728/0.38372. Took 0.14 sec\n",
      "Epoch 69, Loss(train/val) 0.13026/0.35545. Took 0.15 sec\n",
      "Epoch 70, Loss(train/val) 0.13313/0.38607. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.12443/0.38389. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.12997/0.39062. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.12432/0.39805. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.12595/0.38134. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.12605/0.38044. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.12353/0.39913. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.12636/0.37318. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.12494/0.38661. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.11065/0.40119. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.11565/0.38034. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.10905/0.37949. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.11982/0.38672. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.11321/0.36289. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.10359/0.37585. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.10130/0.36400. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.10618/0.36864. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.11228/0.38070. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.11010/0.36391. Took 0.14 sec\n",
      "Epoch 89, Loss(train/val) 0.10474/0.38712. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.10149/0.37727. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.09679/0.37184. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.10706/0.39170. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.09544/0.37041. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.10213/0.37433. Took 0.14 sec\n",
      "Epoch 95, Loss(train/val) 0.10005/0.38001. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.09524/0.38033. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.09751/0.38478. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.09332/0.36769. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.09978/0.36276. Took 0.14 sec\n",
      "ACC: 0.671875, MCC: 0.4014351912950979\n",
      "Epoch 0, Loss(train/val) 0.49469/0.48332. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.47463/0.45232. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.44077/0.41443. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.40736/0.40274. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.38471/0.39081. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.36957/0.39545. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.35106/0.37917. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.33776/0.38027. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.33391/0.39162. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.32377/0.37907. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.32259/0.38858. Took 0.15 sec\n",
      "Epoch 11, Loss(train/val) 0.31694/0.38276. Took 0.15 sec\n",
      "Epoch 12, Loss(train/val) 0.30869/0.38515. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.30463/0.39462. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.29375/0.39551. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.29150/0.37434. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.29401/0.39814. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.28198/0.38510. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.28114/0.40257. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.27939/0.41240. Took 0.15 sec\n",
      "Epoch 20, Loss(train/val) 0.27737/0.40907. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.26900/0.42679. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.26531/0.41415. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.26606/0.38787. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.25861/0.39722. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.25831/0.39349. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.25732/0.40066. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.24469/0.40057. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.24374/0.39059. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.23936/0.39923. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.24455/0.38889. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.24054/0.40189. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.23355/0.39565. Took 0.16 sec\n",
      "Epoch 33, Loss(train/val) 0.23799/0.40548. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.23027/0.38888. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.23382/0.39678. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.22473/0.38560. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.23795/0.37197. Took 0.15 sec\n",
      "Epoch 38, Loss(train/val) 0.23130/0.38829. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.23022/0.38273. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.22438/0.37003. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.25286/0.35168. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.25393/0.36829. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.23166/0.38083. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.22700/0.36587. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.22775/0.36288. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.21817/0.36442. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.22996/0.36839. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.22160/0.37976. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.21399/0.37887. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.23514/0.39715. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.21401/0.37318. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.22984/0.38010. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.20792/0.36611. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.20976/0.37685. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.20243/0.38649. Took 0.15 sec\n",
      "Epoch 56, Loss(train/val) 0.20242/0.37571. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.20671/0.37580. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.20212/0.37669. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.19769/0.36008. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.19909/0.36065. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.19322/0.36849. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.20290/0.42010. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.20707/0.37514. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.19902/0.37236. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.20496/0.37939. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.20230/0.35953. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) 0.19799/0.35748. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.19476/0.36530. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.18703/0.36360. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.19222/0.37569. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.18705/0.36300. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.18542/0.37322. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.18281/0.36067. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.19535/0.35088. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.19064/0.34787. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.19077/0.38087. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.19317/0.36375. Took 0.15 sec\n",
      "Epoch 78, Loss(train/val) 0.18987/0.36941. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.18017/0.38941. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.18794/0.37106. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.18345/0.37990. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.18593/0.37805. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.18285/0.38683. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.17836/0.35885. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.17535/0.35833. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.17708/0.36492. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.17675/0.35451. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.16865/0.36011. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.17911/0.37270. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.17801/0.35532. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.16533/0.37263. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.16911/0.39719. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.17719/0.37381. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.16959/0.37072. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.17771/0.35999. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.17546/0.36541. Took 0.14 sec\n",
      "Epoch 97, Loss(train/val) 0.16986/0.36657. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.16854/0.37310. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.17340/0.37899. Took 0.13 sec\n",
      "ACC: 0.71875, MCC: 0.4024461183935283\n",
      "Epoch 0, Loss(train/val) 0.49361/0.47615. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.47492/0.44625. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.44755/0.41667. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.41324/0.40013. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.38228/0.38198. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.36355/0.37083. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.35045/0.36811. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.34035/0.36425. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.33362/0.36647. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.32527/0.37517. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.31736/0.37098. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.31090/0.40420. Took 0.15 sec\n",
      "Epoch 12, Loss(train/val) 0.31126/0.38681. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.29808/0.39245. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.29469/0.38863. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.29648/0.40210. Took 0.16 sec\n",
      "Epoch 16, Loss(train/val) 0.30210/0.39854. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.29629/0.40021. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.29676/0.41085. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.28411/0.40805. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.28083/0.38645. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.28361/0.37493. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.28704/0.32878. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.28598/0.34669. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.27035/0.40344. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.27281/0.34040. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.27473/0.42983. Took 0.13 sec\n",
      "Epoch 27, Loss(train/val) 0.27229/0.31334. Took 0.13 sec\n",
      "Epoch 28, Loss(train/val) 0.27195/0.36934. Took 0.13 sec\n",
      "Epoch 29, Loss(train/val) 0.26412/0.42348. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.27109/0.42385. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.24785/0.37215. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.24894/0.38042. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.24438/0.37594. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.23387/0.36766. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.24034/0.37644. Took 0.15 sec\n",
      "Epoch 36, Loss(train/val) 0.23490/0.37921. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.24426/0.38743. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.23359/0.35958. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.22345/0.34932. Took 0.15 sec\n",
      "Epoch 40, Loss(train/val) 0.22367/0.33634. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.22351/0.33977. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.22713/0.39123. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.23757/0.33995. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.22486/0.37213. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) 0.21086/0.35224. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.21839/0.34217. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.21161/0.34011. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.21319/0.32809. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.20215/0.36426. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.19511/0.37831. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.20036/0.37166. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.20119/0.40630. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.19569/0.38112. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.19066/0.40048. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.20061/0.36697. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.19236/0.36622. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.19014/0.35458. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.18439/0.35747. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.18494/0.38276. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.19072/0.38930. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.18218/0.38270. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.18664/0.39054. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.18147/0.37574. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.17495/0.38073. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.18877/0.37865. Took 0.15 sec\n",
      "Epoch 66, Loss(train/val) 0.18569/0.36841. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.17761/0.36046. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.17129/0.34964. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.18839/0.38747. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.17227/0.37525. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.17480/0.36908. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.16101/0.38924. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.16902/0.38085. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.16174/0.35085. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.17122/0.38358. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.16709/0.36793. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.16344/0.38202. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.17531/0.37613. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.15718/0.35224. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.15175/0.34625. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.15671/0.35993. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.14441/0.36881. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.14776/0.36094. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.14744/0.35149. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.14403/0.36470. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.14677/0.35469. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.15204/0.34032. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.15486/0.33483. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.14992/0.36178. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.13988/0.34868. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.14234/0.34795. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.14263/0.34964. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.13878/0.31838. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.14966/0.36108. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.15031/0.34296. Took 0.15 sec\n",
      "Epoch 96, Loss(train/val) 0.14968/0.35252. Took 0.14 sec\n",
      "Epoch 97, Loss(train/val) 0.14453/0.35495. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.13993/0.35237. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.13816/0.36373. Took 0.13 sec\n",
      "ACC: 0.625, MCC: 0.27801921874276636\n",
      "Epoch 0, Loss(train/val) 0.49106/0.48816. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.46905/0.46267. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.43716/0.43682. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.40026/0.42254. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.37816/0.40144. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.36408/0.38031. Took 0.15 sec\n",
      "Epoch 6, Loss(train/val) 0.35398/0.37788. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.34544/0.37978. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.33711/0.38829. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.33734/0.38458. Took 0.15 sec\n",
      "Epoch 10, Loss(train/val) 0.32279/0.40286. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.31585/0.40700. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.31753/0.38666. Took 0.15 sec\n",
      "Epoch 13, Loss(train/val) 0.31183/0.39984. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.31642/0.40660. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.30927/0.40874. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.30215/0.41286. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.29323/0.40887. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.28840/0.41023. Took 0.16 sec\n",
      "Epoch 19, Loss(train/val) 0.28573/0.40244. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.27973/0.40542. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.27693/0.41694. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.27225/0.39044. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.28144/0.39279. Took 0.16 sec\n",
      "Epoch 24, Loss(train/val) 0.27048/0.40302. Took 0.15 sec\n",
      "Epoch 25, Loss(train/val) 0.26694/0.39270. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.26061/0.38574. Took 0.13 sec\n",
      "Epoch 27, Loss(train/val) 0.26809/0.41406. Took 0.16 sec\n",
      "Epoch 28, Loss(train/val) 0.25150/0.37474. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.25426/0.38919. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.24400/0.35890. Took 0.17 sec\n",
      "Epoch 31, Loss(train/val) 0.24333/0.40914. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.23781/0.38801. Took 0.16 sec\n",
      "Epoch 33, Loss(train/val) 0.23242/0.38267. Took 0.16 sec\n",
      "Epoch 34, Loss(train/val) 0.23335/0.38335. Took 0.19 sec\n",
      "Epoch 35, Loss(train/val) 0.22875/0.39536. Took 0.18 sec\n",
      "Epoch 36, Loss(train/val) 0.22560/0.38057. Took 0.16 sec\n",
      "Epoch 37, Loss(train/val) 0.23110/0.40255. Took 0.17 sec\n",
      "Epoch 38, Loss(train/val) 0.22796/0.39400. Took 0.17 sec\n",
      "Epoch 39, Loss(train/val) 0.21290/0.40485. Took 0.15 sec\n",
      "Epoch 40, Loss(train/val) 0.20707/0.41119. Took 0.15 sec\n",
      "Epoch 41, Loss(train/val) 0.20383/0.40031. Took 0.15 sec\n",
      "Epoch 42, Loss(train/val) 0.20593/0.40246. Took 0.18 sec\n",
      "Epoch 43, Loss(train/val) 0.19776/0.36450. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.21363/0.40798. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.19925/0.40646. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.19301/0.39149. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.19656/0.40277. Took 0.15 sec\n",
      "Epoch 48, Loss(train/val) 0.19618/0.40600. Took 0.16 sec\n",
      "Epoch 49, Loss(train/val) 0.19048/0.40651. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.18204/0.39183. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.18022/0.41667. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.18784/0.41252. Took 0.15 sec\n",
      "Epoch 53, Loss(train/val) 0.17570/0.41150. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.18653/0.40919. Took 0.16 sec\n",
      "Epoch 55, Loss(train/val) 0.18976/0.41878. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.17842/0.41104. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.18207/0.40430. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.16968/0.40868. Took 0.16 sec\n",
      "Epoch 59, Loss(train/val) 0.17646/0.39393. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.18160/0.40706. Took 0.14 sec\n",
      "Epoch 61, Loss(train/val) 0.17769/0.39712. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.16856/0.39299. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.16950/0.43476. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.17189/0.42176. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.16479/0.42526. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.16493/0.40899. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.15917/0.39110. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.16154/0.40355. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.16414/0.40232. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.15975/0.39590. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.15380/0.41549. Took 0.15 sec\n",
      "Epoch 72, Loss(train/val) 0.15033/0.41012. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.15714/0.41318. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.15299/0.40622. Took 0.16 sec\n",
      "Epoch 75, Loss(train/val) 0.15036/0.42098. Took 0.16 sec\n",
      "Epoch 76, Loss(train/val) 0.14869/0.40765. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.15281/0.40561. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.14439/0.42542. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.14323/0.41249. Took 0.15 sec\n",
      "Epoch 80, Loss(train/val) 0.14570/0.42375. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.15127/0.43440. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.14260/0.41773. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) 0.14291/0.41913. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.13804/0.42016. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.13575/0.42477. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.13766/0.40556. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.13486/0.42156. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.13545/0.43961. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.13502/0.41867. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.13834/0.42979. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.13268/0.41721. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.12510/0.40727. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.13131/0.43067. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.13903/0.42533. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.13079/0.45553. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.13677/0.41353. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.12531/0.45480. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.12713/0.41987. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.13746/0.43393. Took 0.13 sec\n",
      "ACC: 0.6875, MCC: 0.3649046088126948\n",
      "Epoch 0, Loss(train/val) 0.49499/0.49170. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.47697/0.48017. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.44722/0.46064. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.41472/0.45050. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.39341/0.45065. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.38848/0.45101. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.37733/0.44629. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.36807/0.43726. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.36095/0.42864. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.35122/0.41481. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.34119/0.42285. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.33451/0.42005. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.33270/0.40995. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.32900/0.42661. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.32336/0.41646. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.31674/0.39944. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.31690/0.40880. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.31074/0.40382. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.30589/0.40549. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.29695/0.39697. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.29820/0.39629. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.29458/0.36875. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.28463/0.33933. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.29557/0.37712. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.29184/0.37317. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.28659/0.34282. Took 0.16 sec\n",
      "Epoch 26, Loss(train/val) 0.27795/0.34686. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.27127/0.31392. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.27328/0.33728. Took 0.17 sec\n",
      "Epoch 29, Loss(train/val) 0.25980/0.36680. Took 0.16 sec\n",
      "Epoch 30, Loss(train/val) 0.25868/0.33400. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.25482/0.33166. Took 0.13 sec\n",
      "Epoch 32, Loss(train/val) 0.25321/0.29891. Took 0.16 sec\n",
      "Epoch 33, Loss(train/val) 0.24431/0.30142. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.23726/0.30557. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.23097/0.31086. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.23386/0.28748. Took 0.13 sec\n",
      "Epoch 37, Loss(train/val) 0.22980/0.30704. Took 0.15 sec\n",
      "Epoch 38, Loss(train/val) 0.22247/0.32058. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.22727/0.30293. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.21501/0.29862. Took 0.15 sec\n",
      "Epoch 41, Loss(train/val) 0.22112/0.32985. Took 0.16 sec\n",
      "Epoch 42, Loss(train/val) 0.21083/0.29654. Took 0.15 sec\n",
      "Epoch 43, Loss(train/val) 0.21334/0.29188. Took 0.15 sec\n",
      "Epoch 44, Loss(train/val) 0.21503/0.29883. Took 0.15 sec\n",
      "Epoch 45, Loss(train/val) 0.20824/0.30627. Took 0.15 sec\n",
      "Epoch 46, Loss(train/val) 0.19818/0.29491. Took 0.15 sec\n",
      "Epoch 47, Loss(train/val) 0.19408/0.28909. Took 0.15 sec\n",
      "Epoch 48, Loss(train/val) 0.19810/0.29426. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.19875/0.27601. Took 0.15 sec\n",
      "Epoch 50, Loss(train/val) 0.19475/0.30014. Took 0.17 sec\n",
      "Epoch 51, Loss(train/val) 0.19843/0.30359. Took 0.15 sec\n",
      "Epoch 52, Loss(train/val) 0.19237/0.31209. Took 0.16 sec\n",
      "Epoch 53, Loss(train/val) 0.18592/0.29914. Took 0.15 sec\n",
      "Epoch 54, Loss(train/val) 0.18425/0.28332. Took 0.16 sec\n",
      "Epoch 55, Loss(train/val) 0.18363/0.30824. Took 0.17 sec\n",
      "Epoch 56, Loss(train/val) 0.19192/0.32684. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.17701/0.34277. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.18949/0.32349. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.17100/0.34469. Took 0.17 sec\n",
      "Epoch 60, Loss(train/val) 0.17303/0.32527. Took 0.15 sec\n",
      "Epoch 61, Loss(train/val) 0.17985/0.30976. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.17043/0.30945. Took 0.15 sec\n",
      "Epoch 63, Loss(train/val) 0.17013/0.33314. Took 0.15 sec\n",
      "Epoch 64, Loss(train/val) 0.17526/0.30391. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.17428/0.30845. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.16725/0.30269. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) 0.16252/0.32900. Took 0.15 sec\n",
      "Epoch 68, Loss(train/val) 0.15704/0.30412. Took 0.15 sec\n",
      "Epoch 69, Loss(train/val) 0.15813/0.32738. Took 0.15 sec\n",
      "Epoch 70, Loss(train/val) 0.15616/0.30433. Took 0.16 sec\n",
      "Epoch 71, Loss(train/val) 0.16586/0.30882. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.16464/0.32854. Took 0.16 sec\n",
      "Epoch 73, Loss(train/val) 0.15211/0.34058. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.15798/0.31159. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) 0.16079/0.32491. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.15971/0.35889. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.14990/0.36207. Took 0.15 sec\n",
      "Epoch 78, Loss(train/val) 0.14883/0.33587. Took 0.16 sec\n",
      "Epoch 79, Loss(train/val) 0.14716/0.34743. Took 0.16 sec\n",
      "Epoch 80, Loss(train/val) 0.16386/0.32690. Took 0.14 sec\n",
      "Epoch 81, Loss(train/val) 0.16347/0.32837. Took 0.15 sec\n",
      "Epoch 82, Loss(train/val) 0.15686/0.32085. Took 0.18 sec\n",
      "Epoch 83, Loss(train/val) 0.14805/0.31868. Took 0.16 sec\n",
      "Epoch 84, Loss(train/val) 0.14489/0.30921. Took 0.16 sec\n",
      "Epoch 85, Loss(train/val) 0.14303/0.31329. Took 0.16 sec\n",
      "Epoch 86, Loss(train/val) 0.14472/0.34091. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.14992/0.34400. Took 0.15 sec\n",
      "Epoch 88, Loss(train/val) 0.13461/0.31960. Took 0.14 sec\n",
      "Epoch 89, Loss(train/val) 0.14533/0.33381. Took 0.15 sec\n",
      "Epoch 90, Loss(train/val) 0.15134/0.31280. Took 0.15 sec\n",
      "Epoch 91, Loss(train/val) 0.14770/0.33701. Took 0.15 sec\n",
      "Epoch 92, Loss(train/val) 0.13953/0.33316. Took 0.16 sec\n",
      "Epoch 93, Loss(train/val) 0.13876/0.33629. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.13990/0.34530. Took 0.15 sec\n",
      "Epoch 95, Loss(train/val) 0.14547/0.33916. Took 0.15 sec\n",
      "Epoch 96, Loss(train/val) 0.13870/0.35491. Took 0.16 sec\n",
      "Epoch 97, Loss(train/val) 0.13612/0.33807. Took 0.15 sec\n",
      "Epoch 98, Loss(train/val) 0.14724/0.32631. Took 0.15 sec\n",
      "Epoch 99, Loss(train/val) 0.14874/0.34161. Took 0.14 sec\n",
      "ACC: 0.671875, MCC: 0.330845379315203\n",
      "Epoch 0, Loss(train/val) 0.49418/0.47638. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.47597/0.43851. Took 0.16 sec\n",
      "Epoch 2, Loss(train/val) 0.44614/0.37243. Took 0.15 sec\n",
      "Epoch 3, Loss(train/val) 0.41594/0.34029. Took 0.16 sec\n",
      "Epoch 4, Loss(train/val) 0.39861/0.33193. Took 0.16 sec\n",
      "Epoch 5, Loss(train/val) 0.38582/0.32925. Took 0.15 sec\n",
      "Epoch 6, Loss(train/val) 0.37247/0.33050. Took 0.16 sec\n",
      "Epoch 7, Loss(train/val) 0.36041/0.31626. Took 0.17 sec\n",
      "Epoch 8, Loss(train/val) 0.34888/0.31047. Took 0.17 sec\n",
      "Epoch 9, Loss(train/val) 0.33075/0.28901. Took 0.15 sec\n",
      "Epoch 10, Loss(train/val) 0.32301/0.28993. Took 0.17 sec\n",
      "Epoch 11, Loss(train/val) 0.30608/0.27420. Took 0.15 sec\n",
      "Epoch 12, Loss(train/val) 0.30754/0.29373. Took 0.17 sec\n",
      "Epoch 13, Loss(train/val) 0.31838/0.29901. Took 0.16 sec\n",
      "Epoch 14, Loss(train/val) 0.30696/0.29327. Took 0.16 sec\n",
      "Epoch 15, Loss(train/val) 0.30181/0.28330. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.31737/0.30034. Took 0.17 sec\n",
      "Epoch 17, Loss(train/val) 0.29434/0.28138. Took 0.16 sec\n",
      "Epoch 18, Loss(train/val) 0.28834/0.29940. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.27636/0.27565. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.27898/0.28747. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.28019/0.28289. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.26589/0.29967. Took 0.15 sec\n",
      "Epoch 23, Loss(train/val) 0.27523/0.29447. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.27745/0.26266. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.26555/0.30161. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.26840/0.28681. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.26180/0.29874. Took 0.13 sec\n",
      "Epoch 28, Loss(train/val) 0.25965/0.30701. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.24866/0.32292. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.25056/0.31865. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.26089/0.36260. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.24923/0.33048. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.24810/0.31184. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.23783/0.33579. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.23793/0.40393. Took 0.16 sec\n",
      "Epoch 36, Loss(train/val) 0.24749/0.31250. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.24819/0.35004. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.22878/0.35471. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.23750/0.37393. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.23253/0.31903. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.23671/0.43661. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.24253/0.29561. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.23869/0.32698. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.23387/0.31443. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.23334/0.28511. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.23195/0.31423. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.23538/0.31845. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.22489/0.30262. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.22855/0.29338. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.22020/0.35302. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.25773/0.42993. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.24658/0.37733. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.23523/0.27755. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.22406/0.31836. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.23257/0.31138. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.21507/0.28657. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.21414/0.30056. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.21174/0.28933. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.22303/0.29198. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.21168/0.29616. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.21121/0.28402. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.20705/0.28682. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.23832/0.29858. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.22438/0.31759. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.21005/0.30091. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.20867/0.30811. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.20736/0.32909. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.21399/0.30614. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.21383/0.32482. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.20537/0.33073. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.20029/0.31491. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.20603/0.31211. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.19305/0.31129. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.19869/0.31337. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.20942/0.33621. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.19795/0.30767. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.21486/0.32394. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.20310/0.30426. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.20199/0.29632. Took 0.15 sec\n",
      "Epoch 80, Loss(train/val) 0.19437/0.31128. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.20034/0.31170. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.19659/0.31525. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.19674/0.31795. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.18004/0.31044. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.19487/0.32592. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.19309/0.33010. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.18952/0.31475. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.18421/0.32314. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.18674/0.30985. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.18653/0.31828. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.20145/0.34018. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.18683/0.32558. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.18820/0.31782. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.18493/0.32971. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.18730/0.30826. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.18123/0.30650. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.18181/0.32517. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.18278/0.31069. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.18064/0.32971. Took 0.14 sec\n",
      "ACC: 0.71875, MCC: 0.4389051808406647\n",
      "Epoch 0, Loss(train/val) 0.48931/0.45640. Took 0.17 sec\n",
      "Epoch 1, Loss(train/val) 0.46489/0.40392. Took 0.17 sec\n",
      "Epoch 2, Loss(train/val) 0.43292/0.36939. Took 0.19 sec\n",
      "Epoch 3, Loss(train/val) 0.40852/0.37652. Took 0.16 sec\n",
      "Epoch 4, Loss(train/val) 0.39478/0.35586. Took 0.16 sec\n",
      "Epoch 5, Loss(train/val) 0.38497/0.35563. Took 0.19 sec\n",
      "Epoch 6, Loss(train/val) 0.37802/0.34541. Took 0.17 sec\n",
      "Epoch 7, Loss(train/val) 0.36646/0.33036. Took 0.17 sec\n",
      "Epoch 8, Loss(train/val) 0.35817/0.32452. Took 0.17 sec\n",
      "Epoch 9, Loss(train/val) 0.34674/0.32977. Took 0.17 sec\n",
      "Epoch 10, Loss(train/val) 0.34051/0.30604. Took 0.15 sec\n",
      "Epoch 11, Loss(train/val) 0.33760/0.33563. Took 0.18 sec\n",
      "Epoch 12, Loss(train/val) 0.32958/0.31521. Took 0.17 sec\n",
      "Epoch 13, Loss(train/val) 0.31730/0.31648. Took 0.16 sec\n",
      "Epoch 14, Loss(train/val) 0.31815/0.35071. Took 0.15 sec\n",
      "Epoch 15, Loss(train/val) 0.31774/0.32041. Took 0.16 sec\n",
      "Epoch 16, Loss(train/val) 0.30769/0.35786. Took 0.15 sec\n",
      "Epoch 17, Loss(train/val) 0.30259/0.34619. Took 0.17 sec\n",
      "Epoch 18, Loss(train/val) 0.29088/0.38014. Took 0.18 sec\n",
      "Epoch 19, Loss(train/val) 0.29836/0.34963. Took 0.16 sec\n",
      "Epoch 20, Loss(train/val) 0.28537/0.37132. Took 0.16 sec\n",
      "Epoch 21, Loss(train/val) 0.28445/0.41650. Took 0.17 sec\n",
      "Epoch 22, Loss(train/val) 0.27751/0.38587. Took 0.17 sec\n",
      "Epoch 23, Loss(train/val) 0.27859/0.38768. Took 0.18 sec\n",
      "Epoch 24, Loss(train/val) 0.27186/0.43522. Took 0.17 sec\n",
      "Epoch 25, Loss(train/val) 0.27366/0.41227. Took 0.17 sec\n",
      "Epoch 26, Loss(train/val) 0.26864/0.39228. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.25695/0.39235. Took 0.17 sec\n",
      "Epoch 28, Loss(train/val) 0.26938/0.36688. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.26210/0.40138. Took 0.17 sec\n",
      "Epoch 30, Loss(train/val) 0.25657/0.34667. Took 0.18 sec\n",
      "Epoch 31, Loss(train/val) 0.24310/0.39842. Took 0.18 sec\n",
      "Epoch 32, Loss(train/val) 0.25815/0.36429. Took 0.17 sec\n",
      "Epoch 33, Loss(train/val) 0.25160/0.37863. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.24779/0.40095. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.23738/0.39142. Took 0.16 sec\n",
      "Epoch 36, Loss(train/val) 0.23816/0.34880. Took 0.16 sec\n",
      "Epoch 37, Loss(train/val) 0.24732/0.36727. Took 0.16 sec\n",
      "Epoch 38, Loss(train/val) 0.23813/0.35908. Took 0.15 sec\n",
      "Epoch 39, Loss(train/val) 0.23040/0.33729. Took 0.15 sec\n",
      "Epoch 40, Loss(train/val) 0.23355/0.37439. Took 0.17 sec\n",
      "Epoch 41, Loss(train/val) 0.23162/0.36943. Took 0.16 sec\n",
      "Epoch 42, Loss(train/val) 0.22777/0.41548. Took 0.16 sec\n",
      "Epoch 43, Loss(train/val) 0.22785/0.40372. Took 0.16 sec\n",
      "Epoch 44, Loss(train/val) 0.23171/0.43706. Took 0.16 sec\n",
      "Epoch 45, Loss(train/val) 0.22914/0.42265. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.21531/0.36229. Took 0.15 sec\n",
      "Epoch 47, Loss(train/val) 0.22194/0.42571. Took 0.15 sec\n",
      "Epoch 48, Loss(train/val) 0.22028/0.42084. Took 0.15 sec\n",
      "Epoch 49, Loss(train/val) 0.22604/0.42789. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.20420/0.36714. Took 0.15 sec\n",
      "Epoch 51, Loss(train/val) 0.21397/0.40500. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.20886/0.39845. Took 0.15 sec\n",
      "Epoch 53, Loss(train/val) 0.20375/0.42059. Took 0.17 sec\n",
      "Epoch 54, Loss(train/val) 0.20290/0.37558. Took 0.16 sec\n",
      "Epoch 55, Loss(train/val) 0.20749/0.41298. Took 0.15 sec\n",
      "Epoch 56, Loss(train/val) 0.20861/0.39489. Took 0.16 sec\n",
      "Epoch 57, Loss(train/val) 0.19698/0.40412. Took 0.16 sec\n",
      "Epoch 58, Loss(train/val) 0.20466/0.41533. Took 0.15 sec\n",
      "Epoch 59, Loss(train/val) 0.20293/0.40418. Took 0.15 sec\n",
      "Epoch 60, Loss(train/val) 0.19293/0.40100. Took 0.16 sec\n",
      "Epoch 61, Loss(train/val) 0.19006/0.40634. Took 0.16 sec\n",
      "Epoch 62, Loss(train/val) 0.19944/0.41981. Took 0.16 sec\n",
      "Epoch 63, Loss(train/val) 0.19700/0.42196. Took 0.15 sec\n",
      "Epoch 64, Loss(train/val) 0.19045/0.44992. Took 0.15 sec\n",
      "Epoch 65, Loss(train/val) 0.19340/0.38230. Took 0.15 sec\n",
      "Epoch 66, Loss(train/val) 0.19493/0.35621. Took 0.15 sec\n",
      "Epoch 67, Loss(train/val) 0.19222/0.36654. Took 0.16 sec\n",
      "Epoch 68, Loss(train/val) 0.18454/0.34187. Took 0.15 sec\n",
      "Epoch 69, Loss(train/val) 0.18467/0.40232. Took 0.15 sec\n",
      "Epoch 70, Loss(train/val) 0.18722/0.31280. Took 0.15 sec\n",
      "Epoch 71, Loss(train/val) 0.18520/0.39044. Took 0.15 sec\n",
      "Epoch 72, Loss(train/val) 0.18117/0.40820. Took 0.15 sec\n",
      "Epoch 73, Loss(train/val) 0.18661/0.43963. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.19571/0.34585. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) 0.18109/0.31581. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.18997/0.31821. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.18490/0.32629. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.18404/0.32019. Took 0.14 sec\n",
      "Epoch 79, Loss(train/val) 0.17815/0.34031. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.17961/0.31954. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.18269/0.29281. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.17496/0.35760. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) 0.17213/0.32850. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.17352/0.33491. Took 0.15 sec\n",
      "Epoch 85, Loss(train/val) 0.17055/0.31894. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.17330/0.39141. Took 0.17 sec\n",
      "Epoch 87, Loss(train/val) 0.17677/0.36493. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.17408/0.34266. Took 0.14 sec\n",
      "Epoch 89, Loss(train/val) 0.16729/0.33773. Took 0.16 sec\n",
      "Epoch 90, Loss(train/val) 0.16414/0.33812. Took 0.15 sec\n",
      "Epoch 91, Loss(train/val) 0.16334/0.31613. Took 0.15 sec\n",
      "Epoch 92, Loss(train/val) 0.16100/0.35713. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.15375/0.30371. Took 0.15 sec\n",
      "Epoch 94, Loss(train/val) 0.15732/0.36409. Took 0.15 sec\n",
      "Epoch 95, Loss(train/val) 0.16045/0.32061. Took 0.16 sec\n",
      "Epoch 96, Loss(train/val) 0.15818/0.32555. Took 0.15 sec\n",
      "Epoch 97, Loss(train/val) 0.14965/0.33448. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.16075/0.36845. Took 0.14 sec\n",
      "Epoch 99, Loss(train/val) 0.15781/0.34985. Took 0.16 sec\n",
      "ACC: 0.578125, MCC: 0.22473328748774737\n",
      "Epoch 0, Loss(train/val) 0.49477/0.49659. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.47205/0.49155. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.43975/0.48225. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.40554/0.46614. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.38446/0.46031. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.37435/0.46195. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.36716/0.45844. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.36068/0.45745. Took 0.16 sec\n",
      "Epoch 8, Loss(train/val) 0.35490/0.44878. Took 0.18 sec\n",
      "Epoch 9, Loss(train/val) 0.35380/0.46167. Took 0.17 sec\n",
      "Epoch 10, Loss(train/val) 0.34533/0.44425. Took 0.16 sec\n",
      "Epoch 11, Loss(train/val) 0.34350/0.44263. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.33582/0.45289. Took 0.15 sec\n",
      "Epoch 13, Loss(train/val) 0.32676/0.45712. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.32401/0.43665. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.31812/0.45168. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.30997/0.42751. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.30579/0.42865. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.29487/0.43294. Took 0.16 sec\n",
      "Epoch 19, Loss(train/val) 0.28298/0.41935. Took 0.16 sec\n",
      "Epoch 20, Loss(train/val) 0.28830/0.40325. Took 0.16 sec\n",
      "Epoch 21, Loss(train/val) 0.27991/0.39905. Took 0.17 sec\n",
      "Epoch 22, Loss(train/val) 0.26857/0.39316. Took 0.16 sec\n",
      "Epoch 23, Loss(train/val) 0.26616/0.39179. Took 0.16 sec\n",
      "Epoch 24, Loss(train/val) 0.27003/0.38095. Took 0.19 sec\n",
      "Epoch 25, Loss(train/val) 0.26495/0.38453. Took 0.17 sec\n",
      "Epoch 26, Loss(train/val) 0.26603/0.38140. Took 0.17 sec\n",
      "Epoch 27, Loss(train/val) 0.25302/0.36172. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.25802/0.34662. Took 0.17 sec\n",
      "Epoch 29, Loss(train/val) 0.24855/0.36841. Took 0.17 sec\n",
      "Epoch 30, Loss(train/val) 0.24133/0.37441. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.24350/0.37433. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.24345/0.36690. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.24466/0.36807. Took 0.16 sec\n",
      "Epoch 34, Loss(train/val) 0.23842/0.36023. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.23488/0.35715. Took 0.13 sec\n",
      "Epoch 36, Loss(train/val) 0.23788/0.34076. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.23564/0.34533. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.23661/0.35334. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.22947/0.36029. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.22649/0.36175. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.22434/0.34974. Took 0.15 sec\n",
      "Epoch 42, Loss(train/val) 0.22908/0.35353. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.22533/0.34627. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.22013/0.34296. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.21697/0.34564. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.21878/0.32973. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.21665/0.34850. Took 0.15 sec\n",
      "Epoch 48, Loss(train/val) 0.20990/0.35140. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.21320/0.34175. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.21068/0.33874. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.20573/0.34886. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.21137/0.35229. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.22110/0.34317. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.21381/0.32872. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.21042/0.32292. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.19895/0.31662. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.19893/0.31502. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.19842/0.31609. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.19307/0.31213. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.19228/0.31002. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.19223/0.31967. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.19115/0.31157. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.19222/0.30661. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.18552/0.28981. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.18893/0.30051. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.19146/0.30248. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.18854/0.29374. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.18512/0.29999. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.19092/0.32494. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.17698/0.31725. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.17701/0.31370. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.18595/0.30079. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.18208/0.31276. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.17630/0.31470. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.16622/0.31376. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.17353/0.31478. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.17068/0.30739. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.17654/0.29941. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.17597/0.30361. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.16793/0.29009. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.17317/0.28608. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.16449/0.29057. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.15756/0.29973. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.16566/0.30171. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.16466/0.27445. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.16683/0.30119. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.16891/0.33328. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.16187/0.31800. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.16258/0.31595. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.15892/0.32572. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.15383/0.32846. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.15712/0.33864. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.15034/0.31332. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.16222/0.33313. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.15520/0.31870. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.15644/0.30174. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.15093/0.34589. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.15332/0.30997. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.14619/0.32226. Took 0.13 sec\n",
      "ACC: 0.640625, MCC: 0.26226526415648105\n",
      "Epoch 0, Loss(train/val) 0.48935/0.50332. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.46206/0.50993. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.42641/0.48410. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.40145/0.43274. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.38872/0.41551. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.38215/0.39072. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.37418/0.39225. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.37007/0.38322. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.36246/0.38528. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.35170/0.36338. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.35189/0.38462. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.34030/0.39205. Took 0.16 sec\n",
      "Epoch 12, Loss(train/val) 0.32988/0.36384. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.31782/0.37825. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.31879/0.36243. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.31499/0.34873. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.30314/0.38206. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.30638/0.34889. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.29828/0.35244. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.28719/0.34763. Took 0.15 sec\n",
      "Epoch 20, Loss(train/val) 0.28865/0.37432. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.28169/0.36451. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.27746/0.33631. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.27424/0.32150. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.27104/0.32933. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.26470/0.33205. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.26561/0.34129. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.25360/0.31481. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.25600/0.31215. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.26330/0.30967. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.27113/0.33697. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.25211/0.34891. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.24480/0.36251. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.25009/0.35855. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.24702/0.32068. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.25052/0.30993. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.23262/0.35707. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.24277/0.34864. Took 0.16 sec\n",
      "Epoch 38, Loss(train/val) 0.23499/0.33662. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.24284/0.33653. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.22623/0.34458. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.22153/0.34649. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.22452/0.35031. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.21670/0.32757. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.21114/0.31616. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.21559/0.31248. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.20912/0.32501. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.21456/0.31135. Took 0.15 sec\n",
      "Epoch 48, Loss(train/val) 0.21204/0.31406. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.21257/0.33407. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.20369/0.30468. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.20061/0.30005. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.20968/0.29746. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.19875/0.29135. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.20439/0.32414. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.20623/0.31495. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.20386/0.31409. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.20870/0.33038. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.19917/0.36283. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.20161/0.34410. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.19014/0.27271. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.18383/0.25381. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.19480/0.27203. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.19289/0.28158. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.18904/0.32877. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.19799/0.29478. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.19332/0.28024. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.18683/0.31939. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.18345/0.27752. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.17775/0.29132. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.17774/0.29514. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.18232/0.34509. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.17739/0.31928. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.18486/0.30098. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.17155/0.31517. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.17509/0.35049. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.17542/0.31762. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.16597/0.31696. Took 0.15 sec\n",
      "Epoch 78, Loss(train/val) 0.17705/0.31792. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.16859/0.28780. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.17662/0.28448. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.16703/0.29077. Took 0.15 sec\n",
      "Epoch 82, Loss(train/val) 0.17064/0.30538. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.16265/0.28568. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.17188/0.32403. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.16498/0.29811. Took 0.15 sec\n",
      "Epoch 86, Loss(train/val) 0.16624/0.28585. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.16860/0.30209. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.16194/0.30486. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.16725/0.32126. Took 0.15 sec\n",
      "Epoch 90, Loss(train/val) 0.16517/0.31724. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.16560/0.29259. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.15854/0.30434. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.16182/0.29705. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.15569/0.32006. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.15141/0.30121. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.15315/0.29591. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.16659/0.29428. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.15582/0.30436. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.14953/0.29592. Took 0.14 sec\n",
      "ACC: 0.734375, MCC: 0.45295107776545734\n",
      "Epoch 0, Loss(train/val) 0.49327/0.47999. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.47106/0.43737. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.43828/0.39021. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.41008/0.36330. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.39621/0.34278. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.38910/0.33284. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.37907/0.30964. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.36857/0.29057. Took 0.15 sec\n",
      "Epoch 8, Loss(train/val) 0.35573/0.30017. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.34481/0.30856. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.32109/0.32304. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.32001/0.28406. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.30375/0.30638. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.30342/0.29239. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.29399/0.30290. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.32247/0.33736. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.31685/0.28967. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.29779/0.30746. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.31660/0.25908. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.30390/0.29732. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.28516/0.34728. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.29204/0.32825. Took 0.16 sec\n",
      "Epoch 22, Loss(train/val) 0.27558/0.33058. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.27532/0.32307. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.26980/0.36409. Took 0.15 sec\n",
      "Epoch 25, Loss(train/val) 0.27056/0.36358. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.27528/0.38423. Took 0.13 sec\n",
      "Epoch 27, Loss(train/val) 0.25867/0.36510. Took 0.13 sec\n",
      "Epoch 28, Loss(train/val) 0.25649/0.35642. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.26389/0.37318. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.26545/0.36616. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.24704/0.36943. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.24139/0.35662. Took 0.17 sec\n",
      "Epoch 33, Loss(train/val) 0.24163/0.37066. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.24496/0.35569. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.24221/0.36829. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.24625/0.39865. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.23544/0.39218. Took 0.16 sec\n",
      "Epoch 38, Loss(train/val) 0.23566/0.34356. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.22514/0.38183. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.21960/0.36974. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.21979/0.39827. Took 0.15 sec\n",
      "Epoch 42, Loss(train/val) 0.21729/0.39091. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.21791/0.38607. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.22560/0.39759. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.20531/0.40661. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.20586/0.38794. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.20823/0.39041. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.19574/0.41952. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.19373/0.40867. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.20257/0.40891. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.20477/0.38972. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.20073/0.40292. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.18625/0.42317. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.19066/0.41280. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.18496/0.42313. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.19193/0.42496. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.17720/0.43878. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.17337/0.42353. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.18156/0.43612. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.17101/0.44116. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.17441/0.41389. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.16744/0.43098. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.16123/0.43618. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.16553/0.43961. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.15284/0.45197. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.16857/0.43958. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.15756/0.44096. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.15443/0.43215. Took 0.14 sec\n",
      "Epoch 69, Loss(train/val) 0.16070/0.45058. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.16610/0.41403. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.15683/0.40648. Took 0.15 sec\n",
      "Epoch 72, Loss(train/val) 0.15339/0.43055. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.14611/0.44358. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.15652/0.44343. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.14674/0.44716. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.14840/0.42729. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.14189/0.44307. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.14285/0.46292. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.13679/0.45657. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.13604/0.47267. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.13995/0.47470. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.13904/0.47329. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.13783/0.46488. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.13301/0.47179. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.12895/0.47606. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.13058/0.49577. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.13975/0.48285. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.12445/0.49453. Took 0.14 sec\n",
      "Epoch 89, Loss(train/val) 0.13858/0.45605. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.13243/0.47980. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.12512/0.47778. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.11930/0.48107. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.13011/0.46633. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.12120/0.48189. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.11657/0.48486. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.12121/0.48064. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.12241/0.46359. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.12056/0.47468. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.12599/0.47670. Took 0.13 sec\n",
      "ACC: 0.578125, MCC: 0.08921796698522012\n",
      "Epoch 0, Loss(train/val) 0.49093/0.48796. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.46739/0.46099. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.43618/0.44537. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.40885/0.44020. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.39739/0.44102. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.38944/0.43976. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.38324/0.43292. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.37656/0.43114. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.37253/0.42872. Took 0.15 sec\n",
      "Epoch 9, Loss(train/val) 0.36551/0.43072. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.35672/0.42097. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.35132/0.42089. Took 0.16 sec\n",
      "Epoch 12, Loss(train/val) 0.34303/0.38725. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.35328/0.39973. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.33820/0.40369. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.31635/0.35601. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.31252/0.48797. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.32472/0.43427. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.31207/0.47496. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.30245/0.42279. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.30278/0.43563. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.28631/0.40704. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.28734/0.43353. Took 0.15 sec\n",
      "Epoch 23, Loss(train/val) 0.28373/0.39501. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.27532/0.51188. Took 0.15 sec\n",
      "Epoch 25, Loss(train/val) 0.27599/0.41902. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.27932/0.40456. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.27994/0.50211. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.27248/0.44504. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.26759/0.42157. Took 0.17 sec\n",
      "Epoch 30, Loss(train/val) 0.26000/0.46353. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.26217/0.41154. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.26376/0.38047. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.24586/0.45059. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.24172/0.46258. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.24160/0.43701. Took 0.15 sec\n",
      "Epoch 36, Loss(train/val) 0.24831/0.46585. Took 0.13 sec\n",
      "Epoch 37, Loss(train/val) 0.25914/0.45422. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.24554/0.43466. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.23896/0.46396. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.23638/0.46294. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.22442/0.46798. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.22302/0.44180. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.21234/0.44880. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.22620/0.45769. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.21032/0.43618. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.21658/0.44904. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.19399/0.43818. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.20204/0.44530. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.20069/0.44941. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.19850/0.45301. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.21196/0.45080. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.20329/0.52459. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) 0.20116/0.50877. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.19642/0.51092. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.20155/0.51041. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.18907/0.49337. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.19569/0.47304. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.19005/0.47645. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.18433/0.45864. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.19456/0.49966. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.18782/0.46340. Took 0.15 sec\n",
      "Epoch 62, Loss(train/val) 0.18458/0.43830. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.17576/0.41868. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.17443/0.44703. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.17666/0.46339. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.17024/0.41077. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.17178/0.40350. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.17552/0.42279. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.17159/0.41274. Took 0.15 sec\n",
      "Epoch 70, Loss(train/val) 0.17080/0.40927. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.15201/0.41288. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.16211/0.40364. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.15911/0.40132. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.17248/0.41823. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.15044/0.40848. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.16996/0.35638. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.16713/0.42101. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.18649/0.37613. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.16268/0.38656. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.15182/0.38969. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.16017/0.39879. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.14975/0.41882. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.14182/0.39810. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.13588/0.38140. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.14296/0.40371. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.15771/0.38815. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.14854/0.38847. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.14610/0.39809. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.14162/0.41674. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.14885/0.37504. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.13651/0.39552. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.14131/0.45684. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.13795/0.46436. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.14110/0.45648. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.14712/0.44637. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.14699/0.39579. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.12940/0.40089. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.13358/0.40069. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.12782/0.42069. Took 0.14 sec\n",
      "ACC: 0.609375, MCC: 0.21732769392835002\n",
      "Epoch 0, Loss(train/val) 0.49161/0.48578. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.46763/0.46388. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.44194/0.43602. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.41881/0.40904. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.40039/0.38814. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.38684/0.38019. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.37979/0.37457. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.37021/0.37416. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.36353/0.36961. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.34872/0.37123. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.33128/0.36158. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.31582/0.34184. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.31833/0.33896. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.30251/0.33193. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.30034/0.35023. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.31417/0.35264. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.29868/0.34873. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.30390/0.32256. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.28548/0.32481. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.29792/0.31675. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.28247/0.32391. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.27360/0.33216. Took 0.17 sec\n",
      "Epoch 22, Loss(train/val) 0.27522/0.33994. Took 0.17 sec\n",
      "Epoch 23, Loss(train/val) 0.27180/0.33619. Took 0.17 sec\n",
      "Epoch 24, Loss(train/val) 0.27636/0.31883. Took 0.20 sec\n",
      "Epoch 25, Loss(train/val) 0.26141/0.31573. Took 0.16 sec\n",
      "Epoch 26, Loss(train/val) 0.27505/0.32206. Took 0.16 sec\n",
      "Epoch 27, Loss(train/val) 0.27472/0.31801. Took 0.17 sec\n",
      "Epoch 28, Loss(train/val) 0.25699/0.32448. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.26711/0.31952. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.25850/0.29373. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.25814/0.30683. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.24257/0.29864. Took 0.13 sec\n",
      "Epoch 33, Loss(train/val) 0.23885/0.29964. Took 0.13 sec\n",
      "Epoch 34, Loss(train/val) 0.24192/0.33642. Took 0.16 sec\n",
      "Epoch 35, Loss(train/val) 0.24197/0.29742. Took 0.16 sec\n",
      "Epoch 36, Loss(train/val) 0.24193/0.29485. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.22342/0.32474. Took 0.15 sec\n",
      "Epoch 38, Loss(train/val) 0.23682/0.30969. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.22929/0.28393. Took 0.16 sec\n",
      "Epoch 40, Loss(train/val) 0.21519/0.30604. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.24466/0.31257. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.23867/0.27258. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.22293/0.28367. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.21597/0.27173. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) 0.21984/0.30227. Took 0.16 sec\n",
      "Epoch 46, Loss(train/val) 0.22030/0.27362. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.22677/0.32314. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.21651/0.31758. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.20550/0.29627. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.20905/0.31415. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.20956/0.31644. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.20094/0.30947. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.19255/0.30744. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.18964/0.31614. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.19695/0.30053. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.19878/0.33104. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.19332/0.30027. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.19396/0.31848. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.20075/0.31659. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.20409/0.29461. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.19920/0.31878. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.19449/0.30774. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.19659/0.28943. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.20247/0.31197. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.18590/0.31258. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.19627/0.28601. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.19648/0.30526. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.18151/0.28905. Took 0.14 sec\n",
      "Epoch 69, Loss(train/val) 0.18417/0.27481. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.18476/0.30629. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.17343/0.28421. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.17079/0.28317. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.17257/0.29404. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.17954/0.32001. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.17261/0.30301. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.17245/0.28674. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.16404/0.29426. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.17238/0.27831. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.16554/0.27924. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.16773/0.30476. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.17923/0.29522. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.17065/0.31638. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.17281/0.27978. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.16005/0.29765. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.17398/0.31963. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.15909/0.32104. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.16568/0.32177. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.15998/0.32480. Took 0.14 sec\n",
      "Epoch 89, Loss(train/val) 0.17121/0.28269. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.16873/0.28380. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.16523/0.28059. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.15562/0.30648. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.14802/0.29548. Took 0.15 sec\n",
      "Epoch 94, Loss(train/val) 0.15170/0.31127. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.17637/0.27388. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.16050/0.31179. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.15952/0.31888. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.15990/0.29353. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.16976/0.32525. Took 0.13 sec\n",
      "ACC: 0.625, MCC: 0.34151450937027694\n",
      "Epoch 0, Loss(train/val) 0.49197/0.47875. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.46958/0.44499. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.44489/0.41637. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.41823/0.39570. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.39579/0.38023. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.37968/0.36315. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.37209/0.35297. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.36313/0.34494. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.35358/0.34479. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.33723/0.30200. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.32536/0.29229. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.33359/0.32119. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.32105/0.31043. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.31331/0.31341. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.30553/0.31897. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.29407/0.31735. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.30305/0.30265. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.29648/0.31456. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.29804/0.30601. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.28266/0.29787. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.28624/0.31278. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.26813/0.29898. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.26913/0.31704. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.26652/0.30885. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.27228/0.29403. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.25820/0.27560. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.25725/0.31524. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.26192/0.29654. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.26226/0.30897. Took 0.13 sec\n",
      "Epoch 29, Loss(train/val) 0.26422/0.28663. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.26035/0.28398. Took 0.13 sec\n",
      "Epoch 31, Loss(train/val) 0.25260/0.29777. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.24255/0.27640. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.24371/0.29907. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.24259/0.28927. Took 0.16 sec\n",
      "Epoch 35, Loss(train/val) 0.24253/0.27014. Took 0.16 sec\n",
      "Epoch 36, Loss(train/val) 0.24433/0.29326. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.24587/0.29755. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.24383/0.32048. Took 0.15 sec\n",
      "Epoch 39, Loss(train/val) 0.23621/0.29989. Took 0.16 sec\n",
      "Epoch 40, Loss(train/val) 0.22772/0.27819. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.22701/0.27136. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.22491/0.29229. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.22411/0.27226. Took 0.15 sec\n",
      "Epoch 44, Loss(train/val) 0.23160/0.29310. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) 0.22902/0.30240. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.21896/0.27490. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.22519/0.30116. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.20650/0.30653. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.21059/0.31489. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.22099/0.29174. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.21265/0.27691. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.20717/0.30229. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.20282/0.29352. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.21006/0.30620. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.20268/0.29289. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.20152/0.28804. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.19616/0.28573. Took 0.15 sec\n",
      "Epoch 58, Loss(train/val) 0.19366/0.28889. Took 0.14 sec\n",
      "Epoch 59, Loss(train/val) 0.18979/0.30148. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.18763/0.30327. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.18246/0.29039. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.17709/0.31214. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.17412/0.29779. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.18314/0.30633. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.18220/0.29996. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.17630/0.27276. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.18400/0.28662. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.17893/0.29688. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.17835/0.31028. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.17321/0.31654. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.17515/0.29125. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.17851/0.28037. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.15882/0.28956. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.16389/0.33357. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.16547/0.31416. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.18399/0.31295. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.17841/0.30099. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.16460/0.29317. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.15986/0.28427. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.16446/0.28667. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.15634/0.28761. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.16202/0.32910. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.16015/0.29430. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.15560/0.29669. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.15181/0.29865. Took 0.15 sec\n",
      "Epoch 86, Loss(train/val) 0.15434/0.33144. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.15653/0.32747. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.15055/0.31735. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.15968/0.30301. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.14791/0.31271. Took 0.14 sec\n",
      "Epoch 91, Loss(train/val) 0.16677/0.30413. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.17202/0.33908. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.15777/0.30935. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.14181/0.31384. Took 0.14 sec\n",
      "Epoch 95, Loss(train/val) 0.15221/0.31815. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.14264/0.31568. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.13604/0.31919. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.13405/0.31586. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.13458/0.30327. Took 0.13 sec\n",
      "ACC: 0.65625, MCC: 0.30980392156862746\n",
      "Epoch 0, Loss(train/val) 0.49136/0.49501. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.46529/0.49439. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.44262/0.47540. Took 0.15 sec\n",
      "Epoch 3, Loss(train/val) 0.42282/0.42858. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.40377/0.40472. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.38841/0.39367. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.38177/0.38019. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.36910/0.35793. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.36582/0.39958. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.35628/0.36491. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.33845/0.36022. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.32806/0.35329. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.31651/0.37949. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.30939/0.32858. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.30168/0.32928. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.27917/0.30840. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.27821/0.31945. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.26086/0.29248. Took 0.17 sec\n",
      "Epoch 18, Loss(train/val) 0.26073/0.28930. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.24550/0.32890. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.25676/0.34701. Took 0.15 sec\n",
      "Epoch 21, Loss(train/val) 0.25456/0.30845. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.23080/0.29173. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.23680/0.28168. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.23385/0.29150. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.23423/0.31561. Took 0.16 sec\n",
      "Epoch 26, Loss(train/val) 0.23153/0.28749. Took 0.13 sec\n",
      "Epoch 27, Loss(train/val) 0.22423/0.31073. Took 0.13 sec\n",
      "Epoch 28, Loss(train/val) 0.21123/0.31422. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.22018/0.29796. Took 0.16 sec\n",
      "Epoch 30, Loss(train/val) 0.21222/0.25972. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.21051/0.27516. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.22091/0.28118. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.21187/0.30093. Took 0.16 sec\n",
      "Epoch 34, Loss(train/val) 0.20434/0.32811. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.20501/0.27139. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.19522/0.27589. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.19305/0.26948. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.20523/0.27032. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.20036/0.26098. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.18717/0.27012. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.19600/0.29337. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.19585/0.26713. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.18369/0.26832. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.18754/0.25361. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.18721/0.25176. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.18018/0.26452. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.17165/0.25319. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.17910/0.30095. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.18715/0.25302. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.18120/0.25917. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.17163/0.28859. Took 0.15 sec\n",
      "Epoch 52, Loss(train/val) 0.17030/0.27537. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.16696/0.26788. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.17264/0.25431. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.16967/0.24156. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.16327/0.24746. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.15762/0.24365. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.16032/0.27722. Took 0.14 sec\n",
      "Epoch 59, Loss(train/val) 0.15263/0.25614. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.15657/0.26930. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.15020/0.28344. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.14943/0.26982. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.15162/0.27468. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.16046/0.27157. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.15202/0.29925. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.14702/0.24920. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) 0.14461/0.23594. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.14433/0.25162. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.14690/0.26745. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.14181/0.26414. Took 0.15 sec\n",
      "Epoch 71, Loss(train/val) 0.14514/0.23727. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.14400/0.26269. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.13234/0.23996. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.15108/0.27851. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) 0.14348/0.29083. Took 0.15 sec\n",
      "Epoch 76, Loss(train/val) 0.14364/0.28263. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.13548/0.26954. Took 0.15 sec\n",
      "Epoch 78, Loss(train/val) 0.13176/0.27854. Took 0.15 sec\n",
      "Epoch 79, Loss(train/val) 0.13913/0.26239. Took 0.15 sec\n",
      "Epoch 80, Loss(train/val) 0.13041/0.27628. Took 0.14 sec\n",
      "Epoch 81, Loss(train/val) 0.13093/0.24459. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.12518/0.25573. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) 0.12675/0.25033. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.12533/0.26224. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.12453/0.27738. Took 0.15 sec\n",
      "Epoch 86, Loss(train/val) 0.12491/0.27708. Took 0.15 sec\n",
      "Epoch 87, Loss(train/val) 0.12760/0.25670. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.13089/0.24714. Took 0.14 sec\n",
      "Epoch 89, Loss(train/val) 0.11722/0.26867. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.12803/0.23615. Took 0.14 sec\n",
      "Epoch 91, Loss(train/val) 0.12368/0.27710. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.11722/0.25716. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.12125/0.24393. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.11313/0.27833. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.11751/0.27334. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.12151/0.26972. Took 0.14 sec\n",
      "Epoch 97, Loss(train/val) 0.11116/0.27552. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.10834/0.25707. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.11494/0.27190. Took 0.13 sec\n",
      "ACC: 0.578125, MCC: 0.189638899745547\n",
      "Epoch 0, Loss(train/val) 0.49308/0.50209. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.47406/0.50443. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.45482/0.49809. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.43391/0.45918. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.41177/0.40844. Took 0.15 sec\n",
      "Epoch 5, Loss(train/val) 0.38952/0.36776. Took 0.15 sec\n",
      "Epoch 6, Loss(train/val) 0.36860/0.35042. Took 0.21 sec\n",
      "Epoch 7, Loss(train/val) 0.35298/0.33738. Took 0.17 sec\n",
      "Epoch 8, Loss(train/val) 0.32112/0.33220. Took 0.16 sec\n",
      "Epoch 9, Loss(train/val) 0.30888/0.32874. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.30817/0.38044. Took 0.15 sec\n",
      "Epoch 11, Loss(train/val) 0.29882/0.38250. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.29548/0.36596. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.28977/0.32855. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.27628/0.34764. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.26856/0.35368. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.27213/0.34227. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.26351/0.37340. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.26262/0.38883. Took 0.17 sec\n",
      "Epoch 19, Loss(train/val) 0.26264/0.37710. Took 0.18 sec\n",
      "Epoch 20, Loss(train/val) 0.24411/0.39915. Took 0.15 sec\n",
      "Epoch 21, Loss(train/val) 0.24720/0.41527. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.24929/0.40823. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.23265/0.36638. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.22590/0.32544. Took 0.15 sec\n",
      "Epoch 25, Loss(train/val) 0.23981/0.39175. Took 0.17 sec\n",
      "Epoch 26, Loss(train/val) 0.24477/0.41410. Took 0.18 sec\n",
      "Epoch 27, Loss(train/val) 0.22851/0.38563. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.23029/0.35711. Took 0.16 sec\n",
      "Epoch 29, Loss(train/val) 0.21739/0.40498. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.21701/0.41939. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.21908/0.39305. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.23398/0.39767. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.23792/0.40151. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.21499/0.37592. Took 0.16 sec\n",
      "Epoch 35, Loss(train/val) 0.20333/0.42139. Took 0.15 sec\n",
      "Epoch 36, Loss(train/val) 0.19936/0.40648. Took 0.13 sec\n",
      "Epoch 37, Loss(train/val) 0.20801/0.42018. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.19539/0.41452. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.19693/0.41591. Took 0.15 sec\n",
      "Epoch 40, Loss(train/val) 0.19370/0.40871. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.19227/0.42248. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.19527/0.43199. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.18893/0.41683. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.18676/0.42670. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.17787/0.41063. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.17825/0.41941. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.18276/0.39283. Took 0.15 sec\n",
      "Epoch 48, Loss(train/val) 0.17412/0.40261. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.16223/0.40809. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.16900/0.39592. Took 0.14 sec\n",
      "Epoch 51, Loss(train/val) 0.18451/0.40384. Took 0.15 sec\n",
      "Epoch 52, Loss(train/val) 0.17788/0.36470. Took 0.15 sec\n",
      "Epoch 53, Loss(train/val) 0.16562/0.40756. Took 0.15 sec\n",
      "Epoch 54, Loss(train/val) 0.16736/0.43103. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.16786/0.36628. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.15426/0.36045. Took 0.16 sec\n",
      "Epoch 57, Loss(train/val) 0.16427/0.38518. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.16584/0.39246. Took 0.14 sec\n",
      "Epoch 59, Loss(train/val) 0.15253/0.38782. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.15255/0.40581. Took 0.14 sec\n",
      "Epoch 61, Loss(train/val) 0.15233/0.38775. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.16315/0.39007. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.15482/0.42561. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.14858/0.39921. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.14579/0.38711. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.15258/0.40300. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.15756/0.39281. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.14529/0.40353. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.15485/0.39723. Took 0.15 sec\n",
      "Epoch 70, Loss(train/val) 0.14564/0.42365. Took 0.15 sec\n",
      "Epoch 71, Loss(train/val) 0.14515/0.39861. Took 0.15 sec\n",
      "Epoch 72, Loss(train/val) 0.13534/0.41332. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.13804/0.41276. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.14841/0.40095. Took 0.15 sec\n",
      "Epoch 75, Loss(train/val) 0.15150/0.44704. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.13556/0.42979. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.12807/0.43458. Took 0.15 sec\n",
      "Epoch 78, Loss(train/val) 0.12782/0.43211. Took 0.15 sec\n",
      "Epoch 79, Loss(train/val) 0.12526/0.41750. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.12361/0.41226. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.13308/0.40357. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.14050/0.39675. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.13225/0.39190. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.13530/0.37829. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.12570/0.39521. Took 0.15 sec\n",
      "Epoch 86, Loss(train/val) 0.12631/0.39137. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.12713/0.41269. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.13285/0.40285. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.12292/0.40377. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.12223/0.38068. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.12374/0.36689. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.11113/0.37786. Took 0.17 sec\n",
      "Epoch 93, Loss(train/val) 0.11232/0.37650. Took 0.18 sec\n",
      "Epoch 94, Loss(train/val) 0.12474/0.38250. Took 0.14 sec\n",
      "Epoch 95, Loss(train/val) 0.12484/0.39880. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.12807/0.40663. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.11604/0.40519. Took 0.16 sec\n",
      "Epoch 98, Loss(train/val) 0.11377/0.38674. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.12255/0.40706. Took 0.13 sec\n",
      "ACC: 0.609375, MCC: 0.22604490834610982\n",
      "Epoch 0, Loss(train/val) 0.49735/0.49368. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.48298/0.48085. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.46600/0.46889. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.44204/0.46910. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.42062/0.47769. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.40606/0.48562. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.39222/0.50656. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.37405/0.53662. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.36066/0.53808. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.32999/0.54451. Took 0.17 sec\n",
      "Epoch 10, Loss(train/val) 0.32592/0.54287. Took 0.17 sec\n",
      "Epoch 11, Loss(train/val) 0.31345/0.52018. Took 0.18 sec\n",
      "Epoch 12, Loss(train/val) 0.30629/0.38344. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.30075/0.47641. Took 0.17 sec\n",
      "Epoch 14, Loss(train/val) 0.28579/0.45529. Took 0.17 sec\n",
      "Epoch 15, Loss(train/val) 0.28664/0.43607. Took 0.16 sec\n",
      "Epoch 16, Loss(train/val) 0.27984/0.46807. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.28082/0.40410. Took 0.17 sec\n",
      "Epoch 18, Loss(train/val) 0.25560/0.34849. Took 0.16 sec\n",
      "Epoch 19, Loss(train/val) 0.25595/0.36612. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.25655/0.38096. Took 0.15 sec\n",
      "Epoch 21, Loss(train/val) 0.24620/0.35228. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.24663/0.35855. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.25220/0.35799. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.23816/0.41453. Took 0.15 sec\n",
      "Epoch 25, Loss(train/val) 0.22080/0.41478. Took 0.16 sec\n",
      "Epoch 26, Loss(train/val) 0.23882/0.45932. Took 0.15 sec\n",
      "Epoch 27, Loss(train/val) 0.23934/0.38806. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.22282/0.43345. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.22842/0.42223. Took 0.17 sec\n",
      "Epoch 30, Loss(train/val) 0.20817/0.39749. Took 0.17 sec\n",
      "Epoch 31, Loss(train/val) 0.22608/0.36283. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.21161/0.40200. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.21179/0.38302. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.19690/0.41001. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.20675/0.39601. Took 0.13 sec\n",
      "Epoch 36, Loss(train/val) 0.21232/0.46813. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.20499/0.40440. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.20126/0.44251. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.20272/0.38627. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.21005/0.49367. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.20791/0.40827. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.19610/0.44733. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.18812/0.39035. Took 0.15 sec\n",
      "Epoch 44, Loss(train/val) 0.19294/0.37790. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) 0.19107/0.39964. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.18962/0.38714. Took 0.15 sec\n",
      "Epoch 47, Loss(train/val) 0.17488/0.39679. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.18316/0.40148. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.19383/0.40838. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.18461/0.46573. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.16853/0.43883. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.16951/0.46286. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) 0.17810/0.48549. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.16978/0.42079. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.16783/0.46786. Took 0.15 sec\n",
      "Epoch 56, Loss(train/val) 0.17567/0.45651. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.16988/0.46550. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.16526/0.46933. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.16102/0.42983. Took 0.15 sec\n",
      "Epoch 60, Loss(train/val) 0.17003/0.49370. Took 0.14 sec\n",
      "Epoch 61, Loss(train/val) 0.16795/0.45725. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.16634/0.45384. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.16500/0.38511. Took 0.15 sec\n",
      "Epoch 64, Loss(train/val) 0.15604/0.45994. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.17025/0.43568. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.15929/0.48954. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) 0.16057/0.40814. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.16865/0.48251. Took 0.14 sec\n",
      "Epoch 69, Loss(train/val) 0.15540/0.47892. Took 0.15 sec\n",
      "Epoch 70, Loss(train/val) 0.15326/0.49965. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.14929/0.47648. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.15304/0.42902. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.15022/0.40843. Took 0.15 sec\n",
      "Epoch 74, Loss(train/val) 0.14165/0.48344. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) 0.14460/0.50704. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.16538/0.45294. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.16161/0.46559. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.13831/0.47376. Took 0.14 sec\n",
      "Epoch 79, Loss(train/val) 0.14739/0.46680. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.14058/0.48121. Took 0.15 sec\n",
      "Epoch 81, Loss(train/val) 0.14378/0.48543. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.13181/0.46949. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) 0.13809/0.48591. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.12832/0.45827. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.13153/0.40949. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.12903/0.42200. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.13064/0.44307. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.14165/0.46852. Took 0.14 sec\n",
      "Epoch 89, Loss(train/val) 0.12564/0.41969. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.12893/0.47279. Took 0.14 sec\n",
      "Epoch 91, Loss(train/val) 0.12856/0.42954. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.12437/0.39658. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.13325/0.46066. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.12393/0.47922. Took 0.15 sec\n",
      "Epoch 95, Loss(train/val) 0.11956/0.42167. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.11352/0.46265. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.11745/0.41450. Took 0.15 sec\n",
      "Epoch 98, Loss(train/val) 0.11004/0.43867. Took 0.14 sec\n",
      "Epoch 99, Loss(train/val) 0.11727/0.45101. Took 0.13 sec\n",
      "ACC: 0.671875, MCC: 0.3505757849137574\n",
      "Epoch 0, Loss(train/val) 0.49089/0.48018. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.46737/0.45403. Took 0.15 sec\n",
      "Epoch 2, Loss(train/val) 0.43753/0.43352. Took 0.16 sec\n",
      "Epoch 3, Loss(train/val) 0.40606/0.42372. Took 0.15 sec\n",
      "Epoch 4, Loss(train/val) 0.38573/0.41882. Took 0.16 sec\n",
      "Epoch 5, Loss(train/val) 0.37704/0.41660. Took 0.15 sec\n",
      "Epoch 6, Loss(train/val) 0.36504/0.41194. Took 0.15 sec\n",
      "Epoch 7, Loss(train/val) 0.35429/0.41572. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.34637/0.41799. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.33596/0.41482. Took 0.15 sec\n",
      "Epoch 10, Loss(train/val) 0.32860/0.41979. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.33092/0.39495. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.32225/0.42361. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.31248/0.42489. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.31804/0.42790. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.30761/0.39977. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.30832/0.42269. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.29925/0.40748. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.30104/0.42364. Took 0.15 sec\n",
      "Epoch 19, Loss(train/val) 0.29058/0.43377. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.29226/0.43273. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.28315/0.44226. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.28533/0.46165. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.28170/0.43049. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.27685/0.42928. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.26709/0.43857. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.27667/0.45180. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.26994/0.42712. Took 0.17 sec\n",
      "Epoch 28, Loss(train/val) 0.26015/0.41483. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.25795/0.44898. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.26070/0.44541. Took 0.16 sec\n",
      "Epoch 31, Loss(train/val) 0.25191/0.43025. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.24656/0.43828. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.24992/0.43730. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.24192/0.43585. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.23897/0.43754. Took 0.16 sec\n",
      "Epoch 36, Loss(train/val) 0.23956/0.44480. Took 0.16 sec\n",
      "Epoch 37, Loss(train/val) 0.23638/0.44846. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.23355/0.45139. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.22343/0.45448. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.22738/0.44440. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.21844/0.45815. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.21656/0.44246. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.21985/0.44159. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.21739/0.44392. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.21662/0.45128. Took 0.15 sec\n",
      "Epoch 46, Loss(train/val) 0.21345/0.43069. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.21583/0.44207. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.21780/0.41626. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.21548/0.44601. Took 0.15 sec\n",
      "Epoch 50, Loss(train/val) 0.20083/0.42415. Took 0.14 sec\n",
      "Epoch 51, Loss(train/val) 0.20575/0.42857. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.20414/0.44926. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.19786/0.43933. Took 0.15 sec\n",
      "Epoch 54, Loss(train/val) 0.19166/0.42169. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.19168/0.43291. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.19407/0.42317. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.19142/0.46040. Took 0.15 sec\n",
      "Epoch 58, Loss(train/val) 0.18888/0.45481. Took 0.14 sec\n",
      "Epoch 59, Loss(train/val) 0.18765/0.45875. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.19036/0.45350. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.18856/0.45912. Took 0.15 sec\n",
      "Epoch 62, Loss(train/val) 0.18718/0.46656. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.17924/0.46016. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.17906/0.46108. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.17880/0.45482. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.17232/0.48653. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.18635/0.47430. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.17871/0.45245. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.17839/0.47664. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.16784/0.47617. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.17271/0.47600. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.17725/0.46732. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.16894/0.46325. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.17078/0.41248. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.16700/0.44036. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.15922/0.45204. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.15949/0.42706. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.16155/0.47527. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.15899/0.47115. Took 0.15 sec\n",
      "Epoch 80, Loss(train/val) 0.15239/0.46874. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.16170/0.47005. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.16680/0.47358. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.15941/0.46465. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.15622/0.47651. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.15753/0.46575. Took 0.15 sec\n",
      "Epoch 86, Loss(train/val) 0.15085/0.46303. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.15097/0.46679. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.14720/0.47184. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.15181/0.46844. Took 0.15 sec\n",
      "Epoch 90, Loss(train/val) 0.14783/0.46541. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.15576/0.49143. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.15401/0.48951. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.15375/0.50554. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.14702/0.47570. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.14020/0.47809. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.14563/0.47404. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.14570/0.46980. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.14478/0.47265. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.14498/0.49415. Took 0.13 sec\n",
      "ACC: 0.71875, MCC: 0.3543418922609171\n",
      "Epoch 0, Loss(train/val) 0.49258/0.48015. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.46933/0.42948. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.43181/0.37026. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.40230/0.35771. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.38774/0.34864. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.38065/0.34066. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.36878/0.32699. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.36162/0.31302. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.35789/0.31087. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.35084/0.31887. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.34202/0.31176. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.34149/0.31431. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.33224/0.31593. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.33008/0.30349. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.32646/0.31468. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.31909/0.31760. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.30590/0.31770. Took 0.15 sec\n",
      "Epoch 17, Loss(train/val) 0.30583/0.30820. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.29882/0.30766. Took 0.15 sec\n",
      "Epoch 19, Loss(train/val) 0.30218/0.32738. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.29098/0.30551. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.29788/0.29346. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.29639/0.32994. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.29390/0.29861. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.28689/0.31219. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.28027/0.28989. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.27545/0.30030. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.27664/0.31174. Took 0.13 sec\n",
      "Epoch 28, Loss(train/val) 0.26991/0.29530. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.26823/0.31897. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.26379/0.30733. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.26056/0.33564. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.26114/0.31516. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.25806/0.33261. Took 0.16 sec\n",
      "Epoch 34, Loss(train/val) 0.27844/0.31939. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.26279/0.32422. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.25053/0.29931. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.24729/0.32853. Took 0.15 sec\n",
      "Epoch 38, Loss(train/val) 0.24872/0.33522. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.24673/0.33457. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.24770/0.32770. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.24157/0.31513. Took 0.15 sec\n",
      "Epoch 42, Loss(train/val) 0.23879/0.34109. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.23540/0.33330. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.22737/0.32981. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.22997/0.33498. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.24035/0.33203. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.22844/0.32227. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.22394/0.32995. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.22258/0.33012. Took 0.15 sec\n",
      "Epoch 50, Loss(train/val) 0.22347/0.31500. Took 0.14 sec\n",
      "Epoch 51, Loss(train/val) 0.22521/0.33488. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.23248/0.33004. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.22190/0.32111. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.22052/0.29808. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.21551/0.30890. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.21238/0.32241. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.21797/0.30490. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.21084/0.31232. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.20589/0.31767. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.20989/0.31685. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.20508/0.31389. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.20620/0.30204. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.19745/0.31173. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.20630/0.31541. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.19499/0.31167. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.20183/0.32608. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.20353/0.32097. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.19546/0.31422. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.18903/0.31964. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.19382/0.32379. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.18992/0.32500. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.20758/0.31524. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.18974/0.33062. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.19309/0.32389. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.18623/0.31240. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.18816/0.32816. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.18572/0.29424. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.18715/0.28548. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.19038/0.31974. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.18953/0.31623. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.18805/0.30392. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.18753/0.32715. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.18593/0.30253. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.18209/0.31566. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.17967/0.31943. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.17956/0.30561. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.18110/0.30512. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.17408/0.29851. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.17151/0.30685. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.17288/0.29354. Took 0.14 sec\n",
      "Epoch 91, Loss(train/val) 0.16976/0.30794. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.17951/0.29776. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.16988/0.31261. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.17254/0.31832. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.16971/0.33177. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.16712/0.31152. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.16648/0.31269. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.16444/0.30787. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.16660/0.30312. Took 0.13 sec\n",
      "ACC: 0.609375, MCC: 0.21425126095413888\n",
      "Epoch 0, Loss(train/val) 0.49605/0.48946. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.47921/0.46975. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.44959/0.43831. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.41769/0.42288. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.39850/0.40819. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.38749/0.39871. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.38349/0.39230. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.37293/0.37707. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.36729/0.37679. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.36150/0.35424. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.35031/0.37819. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.35287/0.36021. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.34445/0.36028. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.33051/0.35400. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.32800/0.35840. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.32160/0.35852. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.31616/0.36805. Took 0.15 sec\n",
      "Epoch 17, Loss(train/val) 0.30711/0.35981. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.32152/0.36824. Took 0.15 sec\n",
      "Epoch 19, Loss(train/val) 0.31406/0.37451. Took 0.15 sec\n",
      "Epoch 20, Loss(train/val) 0.30127/0.36290. Took 0.15 sec\n",
      "Epoch 21, Loss(train/val) 0.30627/0.36031. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.29707/0.36476. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.30609/0.36275. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.29656/0.34522. Took 0.17 sec\n",
      "Epoch 25, Loss(train/val) 0.29849/0.38098. Took 0.18 sec\n",
      "Epoch 26, Loss(train/val) 0.29701/0.33871. Took 0.16 sec\n",
      "Epoch 27, Loss(train/val) 0.29501/0.36638. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.29405/0.36701. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.27815/0.38260. Took 0.18 sec\n",
      "Epoch 30, Loss(train/val) 0.27956/0.36275. Took 0.16 sec\n",
      "Epoch 31, Loss(train/val) 0.27183/0.34879. Took 0.17 sec\n",
      "Epoch 32, Loss(train/val) 0.26865/0.39136. Took 0.19 sec\n",
      "Epoch 33, Loss(train/val) 0.27826/0.38116. Took 0.17 sec\n",
      "Epoch 34, Loss(train/val) 0.27870/0.35578. Took 0.19 sec\n",
      "Epoch 35, Loss(train/val) 0.26374/0.36895. Took 0.17 sec\n",
      "Epoch 36, Loss(train/val) 0.26001/0.38747. Took 0.19 sec\n",
      "Epoch 37, Loss(train/val) 0.25487/0.35712. Took 0.18 sec\n",
      "Epoch 38, Loss(train/val) 0.25697/0.36576. Took 0.18 sec\n",
      "Epoch 39, Loss(train/val) 0.26748/0.37394. Took 0.17 sec\n",
      "Epoch 40, Loss(train/val) 0.25462/0.34882. Took 0.16 sec\n",
      "Epoch 41, Loss(train/val) 0.25686/0.37812. Took 0.15 sec\n",
      "Epoch 42, Loss(train/val) 0.25428/0.36596. Took 0.17 sec\n",
      "Epoch 43, Loss(train/val) 0.25701/0.36297. Took 0.16 sec\n",
      "Epoch 44, Loss(train/val) 0.25600/0.38159. Took 0.15 sec\n",
      "Epoch 45, Loss(train/val) 0.24569/0.35578. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.23530/0.38282. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.24256/0.35361. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.23594/0.36426. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.23553/0.34830. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.23653/0.35605. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.23355/0.36328. Took 0.15 sec\n",
      "Epoch 52, Loss(train/val) 0.25011/0.35554. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.23440/0.36632. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.24005/0.35218. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.23149/0.36879. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.23751/0.36625. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.22623/0.36605. Took 0.15 sec\n",
      "Epoch 58, Loss(train/val) 0.22253/0.35996. Took 0.14 sec\n",
      "Epoch 59, Loss(train/val) 0.22017/0.37154. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.22111/0.36694. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.21062/0.36730. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.22164/0.37322. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.21052/0.36432. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.21243/0.36724. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.20676/0.36251. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.21999/0.35480. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) 0.21747/0.35320. Took 0.16 sec\n",
      "Epoch 68, Loss(train/val) 0.20742/0.34631. Took 0.14 sec\n",
      "Epoch 69, Loss(train/val) 0.20692/0.36184. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.21133/0.36620. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.20446/0.35661. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.20347/0.36587. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.20717/0.36926. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.19937/0.37313. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.19686/0.36104. Took 0.15 sec\n",
      "Epoch 76, Loss(train/val) 0.19624/0.36721. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.20560/0.36478. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.19720/0.37875. Took 0.14 sec\n",
      "Epoch 79, Loss(train/val) 0.19227/0.37741. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.17994/0.36984. Took 0.14 sec\n",
      "Epoch 81, Loss(train/val) 0.18543/0.38029. Took 0.15 sec\n",
      "Epoch 82, Loss(train/val) 0.18305/0.38548. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) 0.18099/0.38196. Took 0.15 sec\n",
      "Epoch 84, Loss(train/val) 0.18476/0.38046. Took 0.16 sec\n",
      "Epoch 85, Loss(train/val) 0.20229/0.38435. Took 0.15 sec\n",
      "Epoch 86, Loss(train/val) 0.18061/0.38687. Took 0.15 sec\n",
      "Epoch 87, Loss(train/val) 0.17486/0.38238. Took 0.15 sec\n",
      "Epoch 88, Loss(train/val) 0.18140/0.38259. Took 0.14 sec\n",
      "Epoch 89, Loss(train/val) 0.17796/0.37720. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.18153/0.37412. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.18115/0.38657. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.17539/0.37370. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.17416/0.37334. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.17868/0.37114. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.17143/0.38602. Took 0.15 sec\n",
      "Epoch 96, Loss(train/val) 0.17025/0.38610. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.16829/0.38730. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.16213/0.39748. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.16278/0.40065. Took 0.15 sec\n",
      "ACC: 0.671875, MCC: 0.366057079101847\n",
      "Epoch 0, Loss(train/val) 0.49417/0.49140. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.47773/0.47287. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.44948/0.43791. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.41767/0.41450. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.39932/0.40256. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.38626/0.38756. Took 0.15 sec\n",
      "Epoch 6, Loss(train/val) 0.37473/0.37829. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.36357/0.37324. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.35471/0.37255. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.34261/0.36856. Took 0.15 sec\n",
      "Epoch 10, Loss(train/val) 0.34740/0.36440. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.33465/0.37131. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.32710/0.36447. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.32444/0.35473. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.31991/0.36289. Took 0.16 sec\n",
      "Epoch 15, Loss(train/val) 0.31450/0.36402. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.31601/0.35260. Took 0.15 sec\n",
      "Epoch 17, Loss(train/val) 0.30995/0.35759. Took 0.16 sec\n",
      "Epoch 18, Loss(train/val) 0.31002/0.35415. Took 0.17 sec\n",
      "Epoch 19, Loss(train/val) 0.29666/0.36211. Took 0.15 sec\n",
      "Epoch 20, Loss(train/val) 0.29584/0.35177. Took 0.15 sec\n",
      "Epoch 21, Loss(train/val) 0.28950/0.35269. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.29240/0.34715. Took 0.15 sec\n",
      "Epoch 23, Loss(train/val) 0.28321/0.35244. Took 0.18 sec\n",
      "Epoch 24, Loss(train/val) 0.28470/0.34901. Took 0.18 sec\n",
      "Epoch 25, Loss(train/val) 0.28184/0.34595. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.27392/0.35047. Took 0.15 sec\n",
      "Epoch 27, Loss(train/val) 0.26833/0.34829. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.26353/0.35028. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.26374/0.35135. Took 0.17 sec\n",
      "Epoch 30, Loss(train/val) 0.26962/0.35440. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.25937/0.34641. Took 0.13 sec\n",
      "Epoch 32, Loss(train/val) 0.26548/0.34362. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.26164/0.32420. Took 0.16 sec\n",
      "Epoch 34, Loss(train/val) 0.25700/0.34664. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.25950/0.32781. Took 0.15 sec\n",
      "Epoch 36, Loss(train/val) 0.25507/0.34374. Took 0.17 sec\n",
      "Epoch 37, Loss(train/val) 0.25262/0.34760. Took 0.15 sec\n",
      "Epoch 38, Loss(train/val) 0.24307/0.33871. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.24457/0.34427. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.24149/0.33587. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.24188/0.32855. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.24380/0.34828. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.24468/0.32924. Took 0.16 sec\n",
      "Epoch 44, Loss(train/val) 0.23694/0.34958. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.23169/0.35102. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.22720/0.34875. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.23370/0.32941. Took 0.15 sec\n",
      "Epoch 48, Loss(train/val) 0.22548/0.33910. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.22988/0.34536. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.23082/0.33302. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.23443/0.34530. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.23268/0.31176. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.21571/0.33408. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.21938/0.33287. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.21097/0.32684. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.21502/0.34011. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.21289/0.34441. Took 0.15 sec\n",
      "Epoch 58, Loss(train/val) 0.20904/0.32964. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.21887/0.32877. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.21555/0.31987. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.20909/0.32534. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.19998/0.33256. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.20373/0.34072. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.20472/0.35069. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.19297/0.33822. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.19517/0.33485. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.19575/0.34378. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.19575/0.33533. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.19324/0.32194. Took 0.16 sec\n",
      "Epoch 70, Loss(train/val) 0.19560/0.33946. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.18727/0.34348. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.18799/0.33707. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.18864/0.31703. Took 0.12 sec\n",
      "Epoch 74, Loss(train/val) 0.18657/0.32801. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.18846/0.33950. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.19215/0.32780. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.19018/0.34278. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.17756/0.32655. Took 0.14 sec\n",
      "Epoch 79, Loss(train/val) 0.18090/0.34296. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.18313/0.35742. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.18589/0.34530. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.17880/0.32997. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) 0.17360/0.34678. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.17494/0.31349. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.18107/0.33618. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.17462/0.33382. Took 0.15 sec\n",
      "Epoch 87, Loss(train/val) 0.17434/0.33213. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.18038/0.33159. Took 0.14 sec\n",
      "Epoch 89, Loss(train/val) 0.17481/0.33565. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.17658/0.37874. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.17020/0.36893. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.16265/0.37195. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.17457/0.33730. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.16527/0.35110. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.16854/0.35475. Took 0.15 sec\n",
      "Epoch 96, Loss(train/val) 0.16820/0.34163. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.16756/0.37590. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.16445/0.37083. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.15900/0.34565. Took 0.13 sec\n",
      "ACC: 0.6875, MCC: 0.2868600772746187\n",
      "Epoch 0, Loss(train/val) 0.49548/0.46545. Took 0.17 sec\n",
      "Epoch 1, Loss(train/val) 0.48032/0.42652. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.45636/0.38629. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.42796/0.37115. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.41078/0.35506. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.40074/0.34428. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.39612/0.34249. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.38771/0.33979. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.37989/0.33630. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.37601/0.33022. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.36456/0.33397. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.35989/0.32919. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.35623/0.32834. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.34358/0.32504. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.34629/0.33315. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.32855/0.32897. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.33624/0.30899. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.33609/0.31134. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.32439/0.33555. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.32013/0.31810. Took 0.16 sec\n",
      "Epoch 20, Loss(train/val) 0.30243/0.31801. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.30741/0.29986. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.30986/0.32904. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.29515/0.32985. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.29829/0.31505. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.29644/0.32891. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.29038/0.31024. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.29527/0.32121. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.28103/0.30793. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.28167/0.30642. Took 0.13 sec\n",
      "Epoch 30, Loss(train/val) 0.27137/0.30640. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.26668/0.30604. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.26274/0.31797. Took 0.13 sec\n",
      "Epoch 33, Loss(train/val) 0.27423/0.31564. Took 0.13 sec\n",
      "Epoch 34, Loss(train/val) 0.26634/0.29696. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.25532/0.28289. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.26546/0.31720. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.25121/0.31901. Took 0.16 sec\n",
      "Epoch 38, Loss(train/val) 0.24343/0.31978. Took 0.15 sec\n",
      "Epoch 39, Loss(train/val) 0.24815/0.29406. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.24775/0.32147. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.25053/0.30770. Took 0.17 sec\n",
      "Epoch 42, Loss(train/val) 0.25143/0.34243. Took 0.15 sec\n",
      "Epoch 43, Loss(train/val) 0.24873/0.30250. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.24924/0.32780. Took 0.15 sec\n",
      "Epoch 45, Loss(train/val) 0.23698/0.32788. Took 0.16 sec\n",
      "Epoch 46, Loss(train/val) 0.24315/0.28901. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.23658/0.34023. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.23240/0.31490. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.23256/0.32533. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.23369/0.30972. Took 0.14 sec\n",
      "Epoch 51, Loss(train/val) 0.24047/0.30485. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.24207/0.31736. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.23936/0.29591. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.23908/0.32739. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.22455/0.33890. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.23887/0.31229. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.21892/0.30756. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.22736/0.31624. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.22565/0.35176. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.22326/0.31719. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.22090/0.31797. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.22367/0.31612. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.22234/0.32060. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.21805/0.33254. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.21708/0.35315. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.21319/0.33880. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.21439/0.32176. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.21978/0.36994. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.21119/0.30333. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.21658/0.34763. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.21175/0.35430. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.21554/0.30868. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.21420/0.36782. Took 0.15 sec\n",
      "Epoch 74, Loss(train/val) 0.20827/0.30856. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.20421/0.33348. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.21152/0.35431. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.20215/0.31911. Took 0.15 sec\n",
      "Epoch 78, Loss(train/val) 0.19979/0.30930. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.20274/0.34556. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.20266/0.30078. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.19442/0.33510. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.19501/0.33666. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.19514/0.35597. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.19136/0.33783. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.18945/0.35769. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.18149/0.34907. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.19106/0.34487. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.18194/0.34722. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.18177/0.34108. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.18165/0.34889. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.18395/0.34396. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.17595/0.32222. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.18448/0.34551. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.18393/0.34994. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.16929/0.34768. Took 0.15 sec\n",
      "Epoch 96, Loss(train/val) 0.18285/0.35777. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.17149/0.32218. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.17237/0.34242. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.17048/0.34155. Took 0.14 sec\n",
      "ACC: 0.703125, MCC: 0.42333824586679347\n",
      "Epoch 0, Loss(train/val) 0.49093/0.48528. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.47215/0.46274. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.44495/0.43888. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.41422/0.42638. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.39406/0.41976. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.38243/0.41914. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.37261/0.41193. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.36549/0.40271. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.36404/0.40005. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.35578/0.39363. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.34844/0.39226. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.33958/0.39030. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.33693/0.36934. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.33989/0.38297. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.33756/0.37612. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.33026/0.35125. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.31904/0.35929. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.31455/0.34520. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.31720/0.36347. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.31250/0.35805. Took 0.15 sec\n",
      "Epoch 20, Loss(train/val) 0.31229/0.35306. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.30633/0.35440. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.30346/0.36516. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.29828/0.36116. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.28793/0.37551. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.29094/0.35586. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.29096/0.33173. Took 0.13 sec\n",
      "Epoch 27, Loss(train/val) 0.28731/0.34884. Took 0.13 sec\n",
      "Epoch 28, Loss(train/val) 0.29712/0.35380. Took 0.13 sec\n",
      "Epoch 29, Loss(train/val) 0.28107/0.34839. Took 0.13 sec\n",
      "Epoch 30, Loss(train/val) 0.27220/0.33061. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.28637/0.34282. Took 0.13 sec\n",
      "Epoch 32, Loss(train/val) 0.28325/0.33248. Took 0.13 sec\n",
      "Epoch 33, Loss(train/val) 0.27575/0.32322. Took 0.13 sec\n",
      "Epoch 34, Loss(train/val) 0.28824/0.33678. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.26964/0.31268. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.27165/0.31555. Took 0.16 sec\n",
      "Epoch 37, Loss(train/val) 0.27463/0.33252. Took 0.15 sec\n",
      "Epoch 38, Loss(train/val) 0.26145/0.31172. Took 0.15 sec\n",
      "Epoch 39, Loss(train/val) 0.27123/0.33973. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.25538/0.32655. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.25307/0.33076. Took 0.16 sec\n",
      "Epoch 42, Loss(train/val) 0.25593/0.32543. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.24500/0.33543. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.24250/0.32528. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) 0.24472/0.32567. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.23897/0.32161. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.25385/0.34012. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.25337/0.32517. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.24018/0.34402. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.25124/0.31485. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.24500/0.34002. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.23690/0.32269. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.23972/0.33631. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.24005/0.34334. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.24491/0.33523. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.24674/0.30948. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.24079/0.32253. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.24166/0.30495. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.23963/0.31126. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.22837/0.32050. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.22949/0.32776. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.21796/0.32561. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.22616/0.31693. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.23540/0.31530. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.22492/0.32182. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.24185/0.31147. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.25529/0.30292. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.23524/0.31445. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.23299/0.31165. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.22531/0.31528. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.21511/0.32219. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.21303/0.32031. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.22091/0.32302. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.22684/0.31873. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.21480/0.31138. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.21592/0.31390. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.21049/0.33351. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.21679/0.32071. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.21241/0.32053. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.20966/0.31013. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.21761/0.30403. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.21403/0.31258. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.20836/0.31805. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.21042/0.31247. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.20351/0.31174. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.20948/0.32258. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.21176/0.31835. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.21231/0.31090. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.20251/0.30775. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.19897/0.31269. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.19927/0.31249. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.21929/0.31994. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.20919/0.33157. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.20050/0.32271. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.19970/0.31822. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.19757/0.31801. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.19122/0.30558. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.20100/0.35363. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.21376/0.29640. Took 0.14 sec\n",
      "ACC: 0.671875, MCC: 0.29337146314889534\n",
      "Epoch 0, Loss(train/val) 0.49221/0.47369. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.47305/0.43075. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.44463/0.39517. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.41715/0.37815. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.40165/0.37044. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.38912/0.36733. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.37764/0.36385. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.36486/0.36388. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.35445/0.34939. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.35265/0.35398. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.34682/0.35227. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.34062/0.34443. Took 0.15 sec\n",
      "Epoch 12, Loss(train/val) 0.33500/0.33775. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.32851/0.34031. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.32597/0.32896. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.32550/0.36645. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.33266/0.34440. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.31439/0.35187. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.31415/0.34426. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.31402/0.35454. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.32366/0.35364. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.33185/0.36610. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.30639/0.34821. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.29618/0.38589. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.30706/0.37800. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.30021/0.36109. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.29708/0.38507. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.31294/0.35841. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.29985/0.36313. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.29480/0.36460. Took 0.16 sec\n",
      "Epoch 30, Loss(train/val) 0.29745/0.36257. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.29368/0.36379. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.28487/0.37360. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.30057/0.36013. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.29572/0.37558. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.27577/0.38402. Took 0.16 sec\n",
      "Epoch 36, Loss(train/val) 0.28367/0.37312. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.28237/0.38424. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.27813/0.35772. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.28690/0.37774. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.27956/0.35826. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.27446/0.35639. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.28029/0.37598. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.29122/0.36821. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.28903/0.34532. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.28494/0.34262. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.27327/0.36731. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.26696/0.36003. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.26548/0.35255. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.26450/0.37097. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.26809/0.35326. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.27005/0.37043. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.26635/0.37610. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.26640/0.37674. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.26782/0.36402. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.27219/0.37578. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.26513/0.36909. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.25938/0.38119. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.25580/0.36008. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.25900/0.35037. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.25605/0.36613. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.26141/0.34971. Took 0.15 sec\n",
      "Epoch 62, Loss(train/val) 0.25060/0.35977. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.24341/0.37431. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.25071/0.36940. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.24271/0.35558. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.25446/0.35303. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.24485/0.35484. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.24298/0.37668. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.24304/0.36543. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.25847/0.34015. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.25281/0.35133. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.24581/0.38067. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.24049/0.37001. Took 0.15 sec\n",
      "Epoch 74, Loss(train/val) 0.23628/0.37358. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.23513/0.35742. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.23998/0.33799. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.23491/0.36657. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.23052/0.37014. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.23143/0.37336. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.23392/0.36167. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.22479/0.37268. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.22924/0.35826. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.22613/0.36366. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.21902/0.36329. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.22134/0.37014. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.21140/0.35440. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.21997/0.34867. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.21994/0.35620. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.21547/0.35223. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.20750/0.34870. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.21490/0.37058. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.21497/0.35892. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.20865/0.35518. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.21074/0.36271. Took 0.15 sec\n",
      "Epoch 95, Loss(train/val) 0.20569/0.35552. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.20562/0.37493. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.20152/0.37278. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.20417/0.37949. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.19833/0.39116. Took 0.14 sec\n",
      "ACC: 0.671875, MCC: 0.35176473907474043\n",
      "Epoch 0, Loss(train/val) 0.49489/0.49384. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.48017/0.47996. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.45496/0.45457. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.42553/0.42428. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.40511/0.40217. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.38585/0.39706. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.38167/0.39839. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.37120/0.37823. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.35911/0.36458. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.34326/0.38476. Took 0.15 sec\n",
      "Epoch 10, Loss(train/val) 0.33714/0.38213. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.32724/0.35764. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.32154/0.37138. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.32235/0.36857. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.31579/0.40947. Took 0.15 sec\n",
      "Epoch 15, Loss(train/val) 0.31804/0.38278. Took 0.17 sec\n",
      "Epoch 16, Loss(train/val) 0.30807/0.41192. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.31100/0.33714. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.29909/0.42877. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.30555/0.37057. Took 0.16 sec\n",
      "Epoch 20, Loss(train/val) 0.29538/0.40135. Took 0.15 sec\n",
      "Epoch 21, Loss(train/val) 0.29040/0.34500. Took 0.16 sec\n",
      "Epoch 22, Loss(train/val) 0.29584/0.41385. Took 0.15 sec\n",
      "Epoch 23, Loss(train/val) 0.30837/0.42107. Took 0.19 sec\n",
      "Epoch 24, Loss(train/val) 0.28713/0.37881. Took 0.26 sec\n",
      "Epoch 25, Loss(train/val) 0.29206/0.39486. Took 0.23 sec\n",
      "Epoch 26, Loss(train/val) 0.28661/0.36732. Took 0.25 sec\n",
      "Epoch 27, Loss(train/val) 0.27383/0.37158. Took 0.20 sec\n",
      "Epoch 28, Loss(train/val) 0.26969/0.37722. Took 0.19 sec\n",
      "Epoch 29, Loss(train/val) 0.26129/0.42689. Took 0.16 sec\n",
      "Epoch 30, Loss(train/val) 0.27570/0.37759. Took 0.23 sec\n",
      "Epoch 31, Loss(train/val) 0.25483/0.39611. Took 0.19 sec\n",
      "Epoch 32, Loss(train/val) 0.26334/0.37985. Took 0.20 sec\n",
      "Epoch 33, Loss(train/val) 0.26526/0.39116. Took 0.18 sec\n",
      "Epoch 34, Loss(train/val) 0.26455/0.36690. Took 0.22 sec\n",
      "Epoch 35, Loss(train/val) 0.25523/0.35560. Took 0.17 sec\n",
      "Epoch 36, Loss(train/val) 0.25630/0.35660. Took 0.18 sec\n",
      "Epoch 37, Loss(train/val) 0.24707/0.37303. Took 0.16 sec\n",
      "Epoch 38, Loss(train/val) 0.25094/0.36901. Took 0.18 sec\n",
      "Epoch 39, Loss(train/val) 0.24655/0.36854. Took 0.17 sec\n",
      "Epoch 40, Loss(train/val) 0.24375/0.37340. Took 0.16 sec\n",
      "Epoch 41, Loss(train/val) 0.24038/0.38482. Took 0.16 sec\n",
      "Epoch 42, Loss(train/val) 0.22935/0.39274. Took 0.16 sec\n",
      "Epoch 43, Loss(train/val) 0.23103/0.36106. Took 0.17 sec\n",
      "Epoch 44, Loss(train/val) 0.23620/0.37619. Took 0.17 sec\n",
      "Epoch 45, Loss(train/val) 0.22518/0.39009. Took 0.15 sec\n",
      "Epoch 46, Loss(train/val) 0.22563/0.38071. Took 0.17 sec\n",
      "Epoch 47, Loss(train/val) 0.23874/0.36759. Took 0.15 sec\n",
      "Epoch 48, Loss(train/val) 0.22687/0.38343. Took 0.15 sec\n",
      "Epoch 49, Loss(train/val) 0.22649/0.37632. Took 0.15 sec\n",
      "Epoch 50, Loss(train/val) 0.22733/0.39322. Took 0.15 sec\n",
      "Epoch 51, Loss(train/val) 0.21829/0.37628. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.21175/0.38470. Took 0.15 sec\n",
      "Epoch 53, Loss(train/val) 0.21449/0.38064. Took 0.15 sec\n",
      "Epoch 54, Loss(train/val) 0.22584/0.38741. Took 0.15 sec\n",
      "Epoch 55, Loss(train/val) 0.21901/0.36371. Took 0.15 sec\n",
      "Epoch 56, Loss(train/val) 0.20914/0.40564. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.21968/0.39528. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.20734/0.37541. Took 0.15 sec\n",
      "Epoch 59, Loss(train/val) 0.19678/0.38208. Took 0.16 sec\n",
      "Epoch 60, Loss(train/val) 0.19404/0.38713. Took 0.15 sec\n",
      "Epoch 61, Loss(train/val) 0.20657/0.40736. Took 0.15 sec\n",
      "Epoch 62, Loss(train/val) 0.20281/0.40820. Took 0.17 sec\n",
      "Epoch 63, Loss(train/val) 0.20042/0.39023. Took 0.16 sec\n",
      "Epoch 64, Loss(train/val) 0.20496/0.39517. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.19444/0.41201. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.19562/0.40919. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) 0.19193/0.40649. Took 0.15 sec\n",
      "Epoch 68, Loss(train/val) 0.19424/0.39407. Took 0.15 sec\n",
      "Epoch 69, Loss(train/val) 0.18470/0.40245. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.18621/0.41351. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.19022/0.38914. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.18839/0.39621. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.18466/0.40515. Took 0.15 sec\n",
      "Epoch 74, Loss(train/val) 0.18239/0.39131. Took 0.15 sec\n",
      "Epoch 75, Loss(train/val) 0.18929/0.40160. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.18805/0.41873. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.18059/0.41747. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.16760/0.38487. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.18101/0.40283. Took 0.15 sec\n",
      "Epoch 80, Loss(train/val) 0.17412/0.39278. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.17934/0.38245. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.17381/0.39333. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.17955/0.39035. Took 0.15 sec\n",
      "Epoch 84, Loss(train/val) 0.16904/0.40177. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.16928/0.40420. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.16850/0.40895. Took 0.16 sec\n",
      "Epoch 87, Loss(train/val) 0.16801/0.38882. Took 0.15 sec\n",
      "Epoch 88, Loss(train/val) 0.16497/0.38430. Took 0.16 sec\n",
      "Epoch 89, Loss(train/val) 0.16437/0.41317. Took 0.15 sec\n",
      "Epoch 90, Loss(train/val) 0.16732/0.40569. Took 0.18 sec\n",
      "Epoch 91, Loss(train/val) 0.16497/0.39166. Took 0.16 sec\n",
      "Epoch 92, Loss(train/val) 0.16137/0.39460. Took 0.15 sec\n",
      "Epoch 93, Loss(train/val) 0.16255/0.39247. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.15706/0.39905. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.15917/0.39127. Took 0.15 sec\n",
      "Epoch 96, Loss(train/val) 0.16926/0.39538. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.15468/0.40528. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.16360/0.39681. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.16079/0.40644. Took 0.13 sec\n",
      "ACC: 0.671875, MCC: 0.3505757849137574\n",
      "Epoch 0, Loss(train/val) 0.49452/0.47231. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.47920/0.43681. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.45558/0.39680. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.42897/0.37153. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.41102/0.36654. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.39856/0.36610. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.38528/0.34743. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.37327/0.32608. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.35518/0.31592. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.33635/0.30369. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.33571/0.31645. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.31335/0.35141. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.32751/0.35631. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.32217/0.35125. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.31417/0.35126. Took 0.15 sec\n",
      "Epoch 15, Loss(train/val) 0.31944/0.34279. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.31591/0.33251. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.30403/0.34260. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.31884/0.35228. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.29672/0.33436. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.29660/0.33876. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.29148/0.35106. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.30681/0.31671. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.30303/0.33646. Took 0.16 sec\n",
      "Epoch 24, Loss(train/val) 0.28474/0.35105. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.28218/0.35595. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.27634/0.36110. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.27408/0.36684. Took 0.13 sec\n",
      "Epoch 28, Loss(train/val) 0.28098/0.36640. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.26504/0.37548. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.27288/0.38944. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.26401/0.38452. Took 0.13 sec\n",
      "Epoch 32, Loss(train/val) 0.25393/0.37358. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.24670/0.38212. Took 0.16 sec\n",
      "Epoch 34, Loss(train/val) 0.25325/0.37585. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.25238/0.35862. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.24311/0.39159. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.24045/0.35394. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.23484/0.38064. Took 0.16 sec\n",
      "Epoch 39, Loss(train/val) 0.24101/0.38045. Took 0.16 sec\n",
      "Epoch 40, Loss(train/val) 0.23209/0.38814. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.23246/0.36073. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.23019/0.36987. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.22117/0.36813. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.22502/0.37015. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.21690/0.38258. Took 0.15 sec\n",
      "Epoch 46, Loss(train/val) 0.22002/0.36707. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.21505/0.36478. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.21313/0.36590. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.21153/0.36988. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.21151/0.36765. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.20360/0.37015. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.20814/0.36096. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.19998/0.36527. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.20318/0.35777. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.19458/0.37023. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.19642/0.37852. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.18369/0.37211. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.19183/0.37563. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.18621/0.36914. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.18458/0.37286. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.17534/0.37575. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.17654/0.37251. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.17105/0.36846. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.17639/0.38416. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.17342/0.37034. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.17564/0.37357. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.16967/0.37113. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.16683/0.36680. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.16745/0.37422. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.16858/0.36760. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.16739/0.35609. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.17346/0.37221. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.16803/0.36490. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.16860/0.36981. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.16368/0.36609. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.15290/0.37487. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.16015/0.38273. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.15444/0.37371. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.15574/0.37425. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.15764/0.38849. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.15680/0.37981. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.15714/0.37312. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.15717/0.36897. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.15844/0.38499. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.15380/0.36658. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.15684/0.36492. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.15539/0.36624. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.15196/0.36955. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.14882/0.37613. Took 0.15 sec\n",
      "Epoch 90, Loss(train/val) 0.15246/0.36160. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.15232/0.37809. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.14101/0.36534. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.14924/0.36756. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.14753/0.36901. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.13686/0.36092. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.14117/0.37650. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.14526/0.37430. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.14122/0.37332. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.14213/0.35866. Took 0.15 sec\n",
      "ACC: 0.640625, MCC: 0.28894436110328825\n",
      "Epoch 0, Loss(train/val) 0.49729/0.49279. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.48533/0.47631. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.46584/0.45149. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.43610/0.43305. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.41157/0.41940. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.39615/0.40380. Took 0.15 sec\n",
      "Epoch 6, Loss(train/val) 0.37890/0.40377. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.36723/0.39426. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.35559/0.38408. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.34361/0.35635. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.33811/0.35546. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.32055/0.34691. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.31950/0.33861. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.31477/0.35322. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.31036/0.35046. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.31281/0.37031. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.30340/0.35015. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.30227/0.36076. Took 0.16 sec\n",
      "Epoch 18, Loss(train/val) 0.30574/0.33973. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.28608/0.36304. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.28998/0.35836. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.28542/0.37024. Took 0.16 sec\n",
      "Epoch 22, Loss(train/val) 0.29391/0.34036. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.28752/0.36323. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.27713/0.37497. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.27235/0.37318. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.27405/0.37810. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.26687/0.39827. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.27404/0.37479. Took 0.13 sec\n",
      "Epoch 29, Loss(train/val) 0.25679/0.40006. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.26147/0.38674. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.25422/0.38602. Took 0.13 sec\n",
      "Epoch 32, Loss(train/val) 0.25731/0.39127. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.25102/0.39755. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.24462/0.41230. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.24610/0.42089. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.24705/0.40085. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.24816/0.42141. Took 0.15 sec\n",
      "Epoch 38, Loss(train/val) 0.23788/0.41671. Took 0.16 sec\n",
      "Epoch 39, Loss(train/val) 0.23170/0.42666. Took 0.15 sec\n",
      "Epoch 40, Loss(train/val) 0.23319/0.41236. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.23819/0.42118. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.22907/0.42250. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.22475/0.41909. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.22660/0.42245. Took 0.16 sec\n",
      "Epoch 45, Loss(train/val) 0.22060/0.40604. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.22312/0.42142. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.22478/0.42087. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.22194/0.43397. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.22436/0.45027. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.22502/0.42591. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.21606/0.41443. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.22386/0.42987. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.20966/0.42878. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.21095/0.43242. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.20582/0.41866. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.20917/0.42983. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.20148/0.42062. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.19773/0.43678. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.19833/0.43677. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.18647/0.43505. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.19031/0.44249. Took 0.15 sec\n",
      "Epoch 62, Loss(train/val) 0.19082/0.44126. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.18554/0.44634. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.19352/0.42865. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.18519/0.42388. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.18152/0.43650. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.17753/0.42294. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.18002/0.42254. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.18043/0.42618. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.17394/0.42340. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.17892/0.43879. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.17415/0.43945. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.18307/0.42473. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.17114/0.41611. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.17521/0.41946. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.16598/0.41211. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.16199/0.43308. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.17026/0.43572. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.16970/0.42345. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.16897/0.43325. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.16562/0.42679. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.16259/0.42366. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.16125/0.41197. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.17108/0.44116. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.17544/0.39508. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.16753/0.42776. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.16095/0.41937. Took 0.15 sec\n",
      "Epoch 88, Loss(train/val) 0.15351/0.42241. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.16146/0.40857. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.15363/0.42483. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.15254/0.42213. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.15675/0.44303. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.14791/0.44240. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.14551/0.43611. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.15098/0.43089. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.14834/0.43647. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.14685/0.40642. Took 0.18 sec\n",
      "Epoch 98, Loss(train/val) 0.15091/0.42408. Took 0.16 sec\n",
      "Epoch 99, Loss(train/val) 0.15016/0.44406. Took 0.16 sec\n",
      "ACC: 0.578125, MCC: 0.18905852402019946\n",
      "Epoch 0, Loss(train/val) 0.49880/0.49685. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.48028/0.48011. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.45139/0.44991. Took 0.16 sec\n",
      "Epoch 3, Loss(train/val) 0.41178/0.42517. Took 0.16 sec\n",
      "Epoch 4, Loss(train/val) 0.38614/0.41221. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.37219/0.40815. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.36672/0.40783. Took 0.15 sec\n",
      "Epoch 7, Loss(train/val) 0.36005/0.40903. Took 0.16 sec\n",
      "Epoch 8, Loss(train/val) 0.35793/0.40610. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.35189/0.39950. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.34613/0.39362. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.33627/0.39915. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.33648/0.40180. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.33186/0.38816. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.31987/0.39755. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.31220/0.38820. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.29968/0.40072. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.31048/0.37873. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.29793/0.39482. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.29052/0.38679. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.27772/0.39577. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.27872/0.36956. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.26611/0.39312. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.27188/0.39798. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.26637/0.38596. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.25535/0.40116. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.26674/0.38954. Took 0.13 sec\n",
      "Epoch 27, Loss(train/val) 0.25028/0.39862. Took 0.16 sec\n",
      "Epoch 28, Loss(train/val) 0.25117/0.40946. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.24695/0.41687. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.24484/0.41233. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.24631/0.39561. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.23268/0.41120. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.23199/0.41213. Took 0.16 sec\n",
      "Epoch 34, Loss(train/val) 0.23041/0.40590. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.22609/0.41677. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.23105/0.40385. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.21853/0.40919. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.21389/0.40985. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.21133/0.40743. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.20868/0.40180. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.21020/0.40569. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.20807/0.40133. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.20681/0.40747. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.20207/0.39645. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.19476/0.40474. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.19258/0.41091. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.19721/0.40005. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.20193/0.40466. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.19924/0.41635. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.19093/0.39557. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.19286/0.40799. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.19287/0.38444. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.18284/0.39279. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.17976/0.37569. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.17450/0.36543. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.18004/0.37841. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.17590/0.38311. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.18169/0.40544. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.17988/0.37682. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.18058/0.37809. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.17084/0.40100. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.16476/0.38929. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.17133/0.39345. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.17002/0.37052. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.16481/0.39244. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.16861/0.38267. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.16702/0.37415. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.16873/0.38502. Took 0.14 sec\n",
      "Epoch 69, Loss(train/val) 0.16466/0.37452. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.16433/0.38640. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.16029/0.36757. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.15980/0.39561. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.15722/0.35881. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.16714/0.38528. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) 0.15480/0.35749. Took 0.15 sec\n",
      "Epoch 76, Loss(train/val) 0.15911/0.40341. Took 0.15 sec\n",
      "Epoch 77, Loss(train/val) 0.16065/0.39235. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.15354/0.39223. Took 0.16 sec\n",
      "Epoch 79, Loss(train/val) 0.15668/0.39264. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.15473/0.40288. Took 0.14 sec\n",
      "Epoch 81, Loss(train/val) 0.15050/0.39323. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.15252/0.38604. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) 0.15588/0.37859. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.16774/0.41213. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.15318/0.38668. Took 0.15 sec\n",
      "Epoch 86, Loss(train/val) 0.14795/0.39745. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.14347/0.38293. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.14586/0.39872. Took 0.14 sec\n",
      "Epoch 89, Loss(train/val) 0.14844/0.38484. Took 0.15 sec\n",
      "Epoch 90, Loss(train/val) 0.14514/0.37615. Took 0.14 sec\n",
      "Epoch 91, Loss(train/val) 0.14018/0.38786. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.14244/0.39489. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.14229/0.40087. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.14068/0.37654. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.14126/0.37922. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.13799/0.35067. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.14119/0.39245. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.13788/0.35656. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.13197/0.37372. Took 0.13 sec\n",
      "ACC: 0.609375, MCC: 0.2057101528827944\n",
      "Epoch 0, Loss(train/val) 0.48721/0.48788. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.45680/0.46645. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.42681/0.44898. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.40171/0.43144. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.37968/0.42421. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.36994/0.42061. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.36550/0.41215. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.35642/0.41220. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.35307/0.41001. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.34671/0.39568. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.33945/0.39300. Took 0.15 sec\n",
      "Epoch 11, Loss(train/val) 0.33079/0.37779. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.32399/0.37542. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.31606/0.36987. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.30877/0.36437. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.29773/0.35721. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.28881/0.35350. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.27964/0.34366. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.26886/0.35230. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.27236/0.33995. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.26386/0.33921. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.25898/0.33896. Took 0.16 sec\n",
      "Epoch 22, Loss(train/val) 0.25426/0.33040. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.24749/0.33012. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.24533/0.37676. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.26006/0.34846. Took 0.16 sec\n",
      "Epoch 26, Loss(train/val) 0.25145/0.34001. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.25297/0.33499. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.23749/0.34490. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.22905/0.34700. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.23057/0.34000. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.23120/0.33664. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.23212/0.36748. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.22961/0.33036. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.21949/0.32948. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.21893/0.33121. Took 0.16 sec\n",
      "Epoch 36, Loss(train/val) 0.22212/0.32120. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.21929/0.33229. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.21698/0.32803. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.20497/0.32132. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.20714/0.31171. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.20516/0.33881. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.20979/0.35659. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.19425/0.30605. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.20737/0.35587. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) 0.19755/0.33181. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.19121/0.35728. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.19631/0.34972. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.19381/0.35470. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.18836/0.36513. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.18662/0.34250. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.19546/0.31830. Took 0.15 sec\n",
      "Epoch 52, Loss(train/val) 0.19334/0.36867. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) 0.19185/0.31968. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.18501/0.32923. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.18647/0.31506. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.17057/0.31104. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.18091/0.33408. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.17088/0.32593. Took 0.15 sec\n",
      "Epoch 59, Loss(train/val) 0.17992/0.35104. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.17588/0.35953. Took 0.18 sec\n",
      "Epoch 61, Loss(train/val) 0.17007/0.33971. Took 0.15 sec\n",
      "Epoch 62, Loss(train/val) 0.18120/0.31704. Took 0.15 sec\n",
      "Epoch 63, Loss(train/val) 0.18675/0.32776. Took 0.15 sec\n",
      "Epoch 64, Loss(train/val) 0.17207/0.30007. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.16880/0.29921. Took 0.15 sec\n",
      "Epoch 66, Loss(train/val) 0.16463/0.32489. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) 0.17422/0.34757. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.16204/0.32573. Took 0.14 sec\n",
      "Epoch 69, Loss(train/val) 0.16749/0.30793. Took 0.16 sec\n",
      "Epoch 70, Loss(train/val) 0.16507/0.30500. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.15896/0.31601. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.15846/0.31400. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.17048/0.30213. Took 0.15 sec\n",
      "Epoch 74, Loss(train/val) 0.16636/0.30818. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) 0.15470/0.32351. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.15386/0.32055. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.14484/0.30674. Took 0.15 sec\n",
      "Epoch 78, Loss(train/val) 0.15315/0.35766. Took 0.16 sec\n",
      "Epoch 79, Loss(train/val) 0.15354/0.35628. Took 0.16 sec\n",
      "Epoch 80, Loss(train/val) 0.15091/0.35216. Took 0.17 sec\n",
      "Epoch 81, Loss(train/val) 0.14643/0.35549. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.14736/0.32791. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.14313/0.32583. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.14167/0.35336. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.14790/0.32469. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.14389/0.34176. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.15121/0.32768. Took 0.16 sec\n",
      "Epoch 88, Loss(train/val) 0.14599/0.35987. Took 0.14 sec\n",
      "Epoch 89, Loss(train/val) 0.14360/0.33497. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.15854/0.35332. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.14932/0.38804. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.14651/0.35097. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.13578/0.33506. Took 0.16 sec\n",
      "Epoch 94, Loss(train/val) 0.14577/0.32437. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.14702/0.36562. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.14609/0.35123. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.14955/0.33861. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.13627/0.31947. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.13987/0.32373. Took 0.14 sec\n",
      "ACC: 0.703125, MCC: 0.4117055577420104\n",
      "Epoch 0, Loss(train/val) 0.50009/0.49270. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.47896/0.47379. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.45118/0.44160. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.41830/0.41526. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.39116/0.39396. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.37098/0.37863. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.35980/0.36308. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.35415/0.35088. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.35542/0.34052. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.34008/0.34796. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.33111/0.34425. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.32439/0.36398. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.32017/0.36470. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.32127/0.32397. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.31118/0.33812. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.30551/0.31328. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.30296/0.32154. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.29885/0.30665. Took 0.16 sec\n",
      "Epoch 18, Loss(train/val) 0.29286/0.30069. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.27985/0.30613. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.28275/0.32512. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.27607/0.31467. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.27478/0.28366. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.27200/0.29246. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.26391/0.27730. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.25952/0.30859. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.26336/0.28414. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.25427/0.28396. Took 0.13 sec\n",
      "Epoch 28, Loss(train/val) 0.24961/0.28423. Took 0.13 sec\n",
      "Epoch 29, Loss(train/val) 0.25423/0.29667. Took 0.13 sec\n",
      "Epoch 30, Loss(train/val) 0.24723/0.27668. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.25559/0.27713. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.24242/0.27434. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.23825/0.27981. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.23638/0.28111. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.23317/0.28190. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.23862/0.30066. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.22853/0.27332. Took 0.16 sec\n",
      "Epoch 38, Loss(train/val) 0.22834/0.31539. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.23431/0.29634. Took 0.15 sec\n",
      "Epoch 40, Loss(train/val) 0.21922/0.29964. Took 0.15 sec\n",
      "Epoch 41, Loss(train/val) 0.21239/0.32143. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.22429/0.27620. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.22144/0.29320. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.21075/0.33026. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.20812/0.32672. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.20131/0.31576. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.21022/0.33309. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.19531/0.32103. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.19037/0.33991. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.19012/0.33384. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.19326/0.29314. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.20125/0.33784. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.20604/0.34841. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.20734/0.32333. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.18500/0.31909. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.17919/0.31967. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.18277/0.31519. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.18319/0.30918. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.18887/0.31691. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.18309/0.32523. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.17579/0.31721. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.19055/0.33429. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.18109/0.31508. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.17392/0.31559. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.17209/0.31937. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.17066/0.36946. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.17005/0.33337. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.17121/0.32375. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.16462/0.31755. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.16378/0.31462. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.16940/0.30867. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.16825/0.33323. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.16610/0.38442. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.17069/0.30859. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.16201/0.31395. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.16093/0.32632. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.16607/0.31133. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.16563/0.32185. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.16252/0.32061. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.16121/0.30636. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.16966/0.38047. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.16624/0.30485. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.16453/0.31230. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.16081/0.33843. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.15341/0.31256. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.14484/0.32679. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.15129/0.33031. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.15316/0.35082. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.15863/0.36782. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.15269/0.31002. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.14891/0.36265. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.15171/0.34896. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.14776/0.31483. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.15132/0.33265. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.14238/0.30737. Took 0.15 sec\n",
      "Epoch 96, Loss(train/val) 0.14298/0.32083. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.14580/0.35660. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.14005/0.37666. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.13963/0.37825. Took 0.14 sec\n",
      "ACC: 0.671875, MCC: 0.34712429378247933\n",
      "Epoch 0, Loss(train/val) 0.48236/0.49720. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.45105/0.49042. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.42664/0.46305. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.40343/0.42611. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.38347/0.39908. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.37100/0.38692. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.36232/0.38424. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.35319/0.38173. Took 0.15 sec\n",
      "Epoch 8, Loss(train/val) 0.34523/0.38514. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.33614/0.38633. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.32964/0.38579. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.32290/0.38919. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.31349/0.37970. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.30157/0.40213. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.29828/0.40387. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.27981/0.40426. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.28359/0.40773. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.28290/0.40024. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.27550/0.41614. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.26590/0.38791. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.25565/0.40926. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.27182/0.39427. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.28107/0.37906. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.26270/0.40021. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.24960/0.38335. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.25914/0.43564. Took 0.16 sec\n",
      "Epoch 26, Loss(train/val) 0.25233/0.39124. Took 0.13 sec\n",
      "Epoch 27, Loss(train/val) 0.26833/0.38712. Took 0.13 sec\n",
      "Epoch 28, Loss(train/val) 0.25613/0.43177. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.24394/0.41649. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.23702/0.40088. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.23464/0.43279. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.24786/0.39106. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.23211/0.44133. Took 0.17 sec\n",
      "Epoch 34, Loss(train/val) 0.23273/0.42743. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.22393/0.43386. Took 0.13 sec\n",
      "Epoch 36, Loss(train/val) 0.23385/0.44828. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.22693/0.43296. Took 0.17 sec\n",
      "Epoch 38, Loss(train/val) 0.23105/0.42469. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.22813/0.42811. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.22472/0.41879. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.22128/0.42438. Took 0.15 sec\n",
      "Epoch 42, Loss(train/val) 0.22027/0.40887. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.22595/0.39891. Took 0.15 sec\n",
      "Epoch 44, Loss(train/val) 0.22390/0.39498. Took 0.15 sec\n",
      "Epoch 45, Loss(train/val) 0.21860/0.41135. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.21596/0.42009. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.20770/0.41134. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.20728/0.40221. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.20610/0.42720. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.21976/0.43398. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.23100/0.40422. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.21823/0.38089. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.21298/0.37636. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.19778/0.40165. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.21963/0.44682. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.21943/0.41691. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.20317/0.40446. Took 0.15 sec\n",
      "Epoch 58, Loss(train/val) 0.20087/0.41044. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.19587/0.41069. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.19954/0.39002. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.18686/0.39897. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.19267/0.38974. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.19969/0.37707. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.18870/0.39459. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.20300/0.38949. Took 0.16 sec\n",
      "Epoch 66, Loss(train/val) 0.19777/0.39373. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.19876/0.39867. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.19620/0.38487. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.20120/0.40849. Took 0.15 sec\n",
      "Epoch 70, Loss(train/val) 0.18620/0.41095. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.18513/0.39973. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.18465/0.39689. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.18543/0.39252. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.18372/0.39094. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.18521/0.39606. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.19525/0.42754. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.18753/0.37674. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.17857/0.40105. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.17926/0.41216. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.18106/0.38149. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.18840/0.40296. Took 0.15 sec\n",
      "Epoch 82, Loss(train/val) 0.18104/0.42065. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.16974/0.40256. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.17574/0.40511. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.17252/0.39423. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.17514/0.37156. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.17735/0.37706. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.17329/0.39081. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.16616/0.39484. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.16212/0.41992. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.15717/0.39076. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.16003/0.40871. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.15642/0.38951. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.16076/0.38112. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.16771/0.43131. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.15896/0.40368. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.14872/0.42745. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.16397/0.42679. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.16101/0.39378. Took 0.13 sec\n",
      "ACC: 0.71875, MCC: 0.37662337662337664\n",
      "Epoch 0, Loss(train/val) 0.48652/0.44184. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.45445/0.37225. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.41381/0.34162. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.38276/0.32284. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.36215/0.31462. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.35477/0.30777. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.34590/0.31874. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.34490/0.32311. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.34262/0.31717. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.33253/0.31571. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.32687/0.32016. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.32961/0.32352. Took 0.16 sec\n",
      "Epoch 12, Loss(train/val) 0.32519/0.31210. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.32356/0.32381. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.31540/0.33183. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.31307/0.33418. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.31053/0.32915. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.30564/0.33274. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.30128/0.33220. Took 0.15 sec\n",
      "Epoch 19, Loss(train/val) 0.29478/0.32680. Took 0.16 sec\n",
      "Epoch 20, Loss(train/val) 0.29168/0.31796. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.28958/0.30693. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.27806/0.31619. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.28224/0.32624. Took 0.16 sec\n",
      "Epoch 24, Loss(train/val) 0.27381/0.32018. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.27377/0.31892. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.27790/0.33774. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.27694/0.33576. Took 0.16 sec\n",
      "Epoch 28, Loss(train/val) 0.26998/0.32009. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.27299/0.31412. Took 0.13 sec\n",
      "Epoch 30, Loss(train/val) 0.26874/0.31520. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.25731/0.31509. Took 0.17 sec\n",
      "Epoch 32, Loss(train/val) 0.25168/0.31480. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.25616/0.31725. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.26161/0.32472. Took 0.16 sec\n",
      "Epoch 35, Loss(train/val) 0.25626/0.32307. Took 0.17 sec\n",
      "Epoch 36, Loss(train/val) 0.26056/0.35472. Took 0.16 sec\n",
      "Epoch 37, Loss(train/val) 0.25159/0.30891. Took 0.15 sec\n",
      "Epoch 38, Loss(train/val) 0.25034/0.30421. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.25452/0.31726. Took 0.15 sec\n",
      "Epoch 40, Loss(train/val) 0.24220/0.30955. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.23774/0.29344. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.23881/0.31930. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.24592/0.31497. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.23462/0.30955. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.22805/0.32008. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.22506/0.31824. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.23134/0.33320. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.22670/0.30338. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.22083/0.33735. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.21211/0.31175. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.21522/0.29936. Took 0.15 sec\n",
      "Epoch 52, Loss(train/val) 0.21358/0.32266. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.20777/0.30874. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.21776/0.29160. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.20779/0.30105. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.21027/0.30542. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.21058/0.29657. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.20276/0.29950. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.20382/0.31005. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.20550/0.33321. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.20572/0.32632. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.20178/0.32199. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.20373/0.30133. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.19956/0.29354. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.19650/0.29661. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.19848/0.29939. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.19431/0.29541. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.19579/0.29409. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.20159/0.29644. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.19606/0.31860. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.19331/0.32573. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.19391/0.29707. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.19245/0.29241. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.18799/0.29388. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.18149/0.30107. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.18833/0.30512. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.19105/0.29364. Took 0.15 sec\n",
      "Epoch 78, Loss(train/val) 0.19068/0.30029. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.19482/0.30776. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.18272/0.30866. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.18559/0.30565. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.18313/0.30536. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.18188/0.32453. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.18113/0.33412. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.17992/0.30607. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.18439/0.33765. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.18219/0.32085. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.18653/0.30113. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.18104/0.29138. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.18158/0.31386. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.17506/0.31655. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.17387/0.29276. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.16805/0.29707. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.16979/0.30225. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.16629/0.29238. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.17399/0.31275. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.17168/0.33128. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.17245/0.31867. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.16735/0.31060. Took 0.13 sec\n",
      "ACC: 0.71875, MCC: 0.4364357804719847\n",
      "Epoch 0, Loss(train/val) 0.48908/0.47524. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.45920/0.43306. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.42229/0.38831. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.38764/0.35821. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.36418/0.34688. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.35213/0.34391. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.34831/0.35793. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.33549/0.36692. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.33228/0.35177. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.32564/0.35661. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.31446/0.35117. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.31150/0.35794. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.30461/0.35566. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.30123/0.35167. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.29908/0.35100. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.29858/0.35821. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.29263/0.35081. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.28566/0.34867. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.30025/0.32551. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.29392/0.33695. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.28134/0.34336. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.27723/0.33655. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.27395/0.34358. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.26981/0.34206. Took 0.16 sec\n",
      "Epoch 24, Loss(train/val) 0.26263/0.33171. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.26009/0.34532. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.26304/0.34595. Took 0.15 sec\n",
      "Epoch 27, Loss(train/val) 0.25967/0.35042. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.25256/0.33510. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.25336/0.34809. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.25210/0.36087. Took 0.16 sec\n",
      "Epoch 31, Loss(train/val) 0.24710/0.34603. Took 0.16 sec\n",
      "Epoch 32, Loss(train/val) 0.24782/0.34475. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.25280/0.33404. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.24350/0.33959. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.23542/0.33000. Took 0.17 sec\n",
      "Epoch 36, Loss(train/val) 0.23902/0.33910. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.23126/0.34474. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.22719/0.34344. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.22795/0.33947. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.23251/0.34220. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.22810/0.34782. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.22360/0.33943. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.22108/0.35088. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.22144/0.34227. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.21730/0.34265. Took 0.15 sec\n",
      "Epoch 46, Loss(train/val) 0.21133/0.33557. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.21270/0.33600. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.20403/0.34339. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.20848/0.35154. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.20070/0.34860. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.19587/0.34806. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.19770/0.32991. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.19186/0.34525. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.20058/0.34645. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.19677/0.33488. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.19398/0.35842. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.19351/0.32147. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.18955/0.34855. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.18930/0.33810. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.18546/0.33518. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.18430/0.32994. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.18253/0.33117. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.17704/0.32743. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.17961/0.32123. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.17765/0.33998. Took 0.15 sec\n",
      "Epoch 66, Loss(train/val) 0.17375/0.34162. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.16919/0.33733. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.16640/0.36423. Took 0.14 sec\n",
      "Epoch 69, Loss(train/val) 0.17008/0.34907. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.17521/0.34226. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.16103/0.33119. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.16522/0.37120. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.16585/0.33599. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.16056/0.34126. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.15790/0.36088. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.15250/0.36837. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.16584/0.36490. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.16053/0.34099. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.15071/0.33583. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.15296/0.35982. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.15101/0.36741. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.15019/0.36093. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.15063/0.35953. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.15162/0.36586. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.14270/0.36334. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.15222/0.37282. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.14424/0.35180. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.14453/0.37433. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.14097/0.36532. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.13884/0.36295. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.14336/0.34958. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.14334/0.34937. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.14516/0.34914. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.13737/0.34086. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.14364/0.37783. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.13720/0.34388. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.13159/0.35024. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.13691/0.37846. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.14019/0.34879. Took 0.15 sec\n",
      "ACC: 0.609375, MCC: 0.15231225557722924\n",
      "Epoch 0, Loss(train/val) 0.48838/0.46658. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.45814/0.42410. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.42280/0.39581. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.39393/0.38692. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.37273/0.39216. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.35720/0.39569. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.35008/0.40359. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.34354/0.41031. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.33437/0.38135. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.33342/0.37408. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.33130/0.37080. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.32700/0.37112. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.32186/0.37219. Took 0.15 sec\n",
      "Epoch 13, Loss(train/val) 0.32372/0.37656. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.31520/0.40315. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.31342/0.40595. Took 0.16 sec\n",
      "Epoch 16, Loss(train/val) 0.31022/0.37705. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.30445/0.36358. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.30742/0.34636. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.30120/0.36288. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.29825/0.33322. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.29978/0.31653. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.29931/0.35471. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.28552/0.36624. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.29105/0.33640. Took 0.15 sec\n",
      "Epoch 25, Loss(train/val) 0.28439/0.33675. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.28899/0.38158. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.28165/0.39957. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.28258/0.39050. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.28823/0.40561. Took 0.16 sec\n",
      "Epoch 30, Loss(train/val) 0.29077/0.38667. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.28202/0.39842. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.27652/0.40293. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.28632/0.37610. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.28707/0.38314. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.29163/0.40106. Took 0.13 sec\n",
      "Epoch 36, Loss(train/val) 0.28199/0.37465. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.27338/0.38567. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.26999/0.39353. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.27328/0.39946. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.27448/0.40388. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.26706/0.40280. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.26615/0.40095. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.26311/0.39385. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.26682/0.38895. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.26336/0.36723. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.25866/0.38585. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.25748/0.37459. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.25193/0.38822. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.26162/0.42177. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.28519/0.35895. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.30368/0.34410. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.28136/0.32115. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.29909/0.38884. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.25742/0.37555. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.25115/0.38075. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.25146/0.40141. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.25498/0.39256. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.25334/0.38788. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.25362/0.38711. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.24098/0.39742. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.24702/0.41746. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.24781/0.39994. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.23970/0.40800. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.25005/0.38134. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.24224/0.41425. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.23989/0.38789. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.23612/0.39880. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.23468/0.35705. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.23668/0.38622. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.24290/0.40796. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.23717/0.40223. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.22394/0.40587. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.22748/0.37567. Took 0.16 sec\n",
      "Epoch 74, Loss(train/val) 0.24807/0.39356. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.24417/0.37404. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.23086/0.40658. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.23601/0.39564. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.23059/0.41938. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.23348/0.37042. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.23172/0.38090. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.21935/0.38195. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.22988/0.37386. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.21909/0.39128. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.22261/0.40789. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.22497/0.40816. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.22094/0.39359. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.22216/0.36714. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.21672/0.36540. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.21166/0.37743. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.20930/0.39669. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.21150/0.39428. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.21222/0.37465. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.21320/0.38683. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.19731/0.37948. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.20785/0.37724. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.21803/0.39806. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.22113/0.38409. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.21666/0.40095. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.22647/0.42693. Took 0.13 sec\n",
      "ACC: 0.640625, MCC: 0.27539875076496495\n",
      "Epoch 0, Loss(train/val) 0.48997/0.49642. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.45251/0.48001. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.41675/0.42610. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.38863/0.39410. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.37072/0.39686. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.35896/0.39771. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.35008/0.39364. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.34086/0.38809. Took 0.15 sec\n",
      "Epoch 8, Loss(train/val) 0.34023/0.36616. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.33058/0.37479. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.32971/0.36318. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.32190/0.36850. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.31834/0.36135. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.31664/0.35140. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.30504/0.34972. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.30522/0.33560. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.30455/0.34511. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.30261/0.33179. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.29980/0.34385. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.30246/0.36308. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.29947/0.33322. Took 0.15 sec\n",
      "Epoch 21, Loss(train/val) 0.29112/0.33982. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.28572/0.35996. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.28109/0.33478. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.27909/0.35987. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.27267/0.35431. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.26832/0.37683. Took 0.16 sec\n",
      "Epoch 27, Loss(train/val) 0.27195/0.36517. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.27283/0.34990. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.26384/0.37825. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.25992/0.36141. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.25245/0.36148. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.25373/0.34541. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.25406/0.36108. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.24652/0.35784. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.25209/0.38132. Took 0.16 sec\n",
      "Epoch 36, Loss(train/val) 0.24625/0.37350. Took 0.13 sec\n",
      "Epoch 37, Loss(train/val) 0.24739/0.36891. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.23873/0.37339. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.23679/0.39676. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.24374/0.35990. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.23164/0.35907. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.22731/0.36901. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.22682/0.39090. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.23327/0.41928. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.22825/0.37660. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.22867/0.36040. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.22141/0.40948. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.21643/0.40267. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.21848/0.37715. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.21130/0.37726. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.21044/0.39755. Took 0.15 sec\n",
      "Epoch 52, Loss(train/val) 0.21185/0.37391. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.21243/0.40802. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.20780/0.39215. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.20628/0.40724. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.19701/0.42227. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.19687/0.38213. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.19781/0.41824. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.19569/0.40783. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.19654/0.39696. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.20045/0.41815. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.20160/0.40760. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.18335/0.40411. Took 0.15 sec\n",
      "Epoch 64, Loss(train/val) 0.18469/0.40595. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.18160/0.40216. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.18262/0.38878. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.18847/0.41481. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.19989/0.35670. Took 0.14 sec\n",
      "Epoch 69, Loss(train/val) 0.18784/0.41705. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.17741/0.39246. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.18444/0.42728. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.18338/0.38955. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.17369/0.40415. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.17095/0.41462. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.17044/0.40427. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.16697/0.40038. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.16756/0.40355. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.17193/0.42580. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.17287/0.38674. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.15713/0.40639. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.16588/0.39589. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.15806/0.40530. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.15990/0.37242. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.15341/0.40025. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.15513/0.39669. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.15971/0.40840. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.15648/0.40256. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.15382/0.39635. Took 0.14 sec\n",
      "Epoch 89, Loss(train/val) 0.15556/0.38954. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.16058/0.38144. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.15366/0.41302. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.15550/0.40357. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.14733/0.41042. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.14973/0.40558. Took 0.14 sec\n",
      "Epoch 95, Loss(train/val) 0.14329/0.39034. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.14896/0.40651. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.14936/0.39447. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.14553/0.39629. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.14982/0.38431. Took 0.14 sec\n",
      "ACC: 0.59375, MCC: 0.26005806930980846\n",
      "Epoch 0, Loss(train/val) 0.49280/0.50269. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.46734/0.49026. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.43037/0.44602. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.39487/0.41382. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.37490/0.40466. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.36226/0.41573. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.34922/0.40817. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.34075/0.40119. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.33747/0.40601. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.32996/0.40495. Took 0.15 sec\n",
      "Epoch 10, Loss(train/val) 0.32375/0.40182. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.32035/0.39587. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.31451/0.41816. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.31597/0.39182. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.31496/0.43212. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.31011/0.38075. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.29628/0.36372. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.29195/0.35078. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.30248/0.35487. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.29115/0.34618. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.28730/0.35805. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.29116/0.35766. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.27778/0.35337. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.27434/0.35201. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.27221/0.37358. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.27248/0.34068. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.26487/0.34763. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.26355/0.35793. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.25589/0.36508. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.25196/0.37877. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.24941/0.34264. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.24517/0.36693. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.23831/0.38462. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.24210/0.35893. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.25010/0.34004. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.24822/0.33739. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.24251/0.38596. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.23953/0.38174. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.23649/0.36351. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.23195/0.38097. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.23353/0.43069. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.23353/0.37591. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.22732/0.37955. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.21806/0.39347. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.20928/0.37519. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) 0.21719/0.37294. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.22747/0.37770. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.21782/0.39335. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.20993/0.37567. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.21205/0.37649. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.20432/0.35912. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.21914/0.36047. Took 0.15 sec\n",
      "Epoch 52, Loss(train/val) 0.20220/0.37783. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.20262/0.33866. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.21169/0.37156. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.19937/0.40560. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.18978/0.36994. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.19879/0.36068. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.19605/0.34335. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.20357/0.38361. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.19154/0.36598. Took 0.14 sec\n",
      "Epoch 61, Loss(train/val) 0.18844/0.35693. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.19034/0.36404. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.18832/0.37865. Took 0.15 sec\n",
      "Epoch 64, Loss(train/val) 0.18301/0.38626. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.18092/0.35950. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.17641/0.36783. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.18374/0.34600. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.18786/0.38113. Took 0.14 sec\n",
      "Epoch 69, Loss(train/val) 0.18990/0.33206. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.17523/0.33606. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.17650/0.33840. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.17107/0.36063. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.16787/0.32980. Took 0.15 sec\n",
      "Epoch 74, Loss(train/val) 0.17716/0.37442. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.17318/0.34928. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.17224/0.37193. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.16711/0.35667. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.16055/0.39299. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.16483/0.42086. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.16699/0.33872. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.16393/0.33559. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.17135/0.34606. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) 0.15756/0.36372. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.16248/0.34425. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.16027/0.35555. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.15942/0.38551. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.15614/0.36219. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.15263/0.37210. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.14835/0.35629. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.15050/0.35515. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.15358/0.38974. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.15661/0.34601. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.15195/0.31530. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.15776/0.39180. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.15540/0.34550. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.15295/0.39169. Took 0.14 sec\n",
      "Epoch 97, Loss(train/val) 0.14747/0.35526. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.15052/0.32033. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.15202/0.34998. Took 0.14 sec\n",
      "ACC: 0.71875, MCC: 0.44095855184409843\n",
      "Epoch 0, Loss(train/val) 0.49514/0.47914. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.47287/0.43167. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.43449/0.36397. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.39615/0.32715. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.37600/0.32052. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.36835/0.32662. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.36005/0.33155. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.34983/0.33273. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.34001/0.33269. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.33229/0.33143. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.33985/0.33946. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.32383/0.32812. Took 0.15 sec\n",
      "Epoch 12, Loss(train/val) 0.31494/0.33141. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.32240/0.32577. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.30964/0.33716. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.30881/0.33846. Took 0.16 sec\n",
      "Epoch 16, Loss(train/val) 0.30074/0.34356. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.29491/0.34545. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.29432/0.34628. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.28796/0.33963. Took 0.15 sec\n",
      "Epoch 20, Loss(train/val) 0.28050/0.35120. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.27470/0.32856. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.27412/0.36005. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.27592/0.33850. Took 0.16 sec\n",
      "Epoch 24, Loss(train/val) 0.27247/0.32776. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.26403/0.35397. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.26016/0.34145. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.25952/0.35141. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.25155/0.35003. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.25053/0.34209. Took 0.17 sec\n",
      "Epoch 30, Loss(train/val) 0.25707/0.33177. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.25356/0.33248. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.24662/0.33927. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.24694/0.33579. Took 0.16 sec\n",
      "Epoch 34, Loss(train/val) 0.24003/0.33134. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.23873/0.32900. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.23697/0.32509. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.24815/0.31268. Took 0.16 sec\n",
      "Epoch 38, Loss(train/val) 0.23874/0.33974. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.22884/0.32556. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.22350/0.33459. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.21855/0.34584. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.22142/0.34072. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.22419/0.32481. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.21468/0.35153. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.21052/0.33194. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.20503/0.33815. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.20880/0.34977. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.20990/0.33515. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.20603/0.32915. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.20496/0.33753. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.20749/0.34470. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.19582/0.35863. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.19567/0.35227. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.19281/0.34783. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.19134/0.36388. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.19366/0.34150. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.19180/0.34217. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.19153/0.33157. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.19526/0.33175. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.19328/0.32745. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.18584/0.34476. Took 0.15 sec\n",
      "Epoch 62, Loss(train/val) 0.18658/0.34071. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.18449/0.33051. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.18009/0.33376. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.17968/0.33511. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.17529/0.33526. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.18450/0.33799. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.17930/0.32738. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.17482/0.33139. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.17355/0.33489. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.17011/0.32104. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.16762/0.32208. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.16833/0.32161. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.16645/0.34148. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.16195/0.32677. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.16633/0.32427. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.16178/0.31870. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.15994/0.32272. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.16373/0.32824. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.16520/0.33140. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.16302/0.32546. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.15938/0.33890. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.15714/0.33807. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.15747/0.33200. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.15005/0.32373. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.15242/0.32657. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.15281/0.32736. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.15808/0.32160. Took 0.14 sec\n",
      "Epoch 89, Loss(train/val) 0.16605/0.34343. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.15995/0.32807. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.14465/0.33440. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.15444/0.33037. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.15494/0.33250. Took 0.15 sec\n",
      "Epoch 94, Loss(train/val) 0.14306/0.33747. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.15120/0.33800. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.14486/0.34596. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.14906/0.34908. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.15356/0.32903. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.14381/0.35044. Took 0.13 sec\n",
      "ACC: 0.6875, MCC: 0.3880852527001659\n",
      "Epoch 0, Loss(train/val) 0.49424/0.49648. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.47742/0.49356. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.45687/0.49002. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.43473/0.46645. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.41579/0.44243. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.40229/0.45000. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.38631/0.40355. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.37989/0.38950. Took 0.18 sec\n",
      "Epoch 8, Loss(train/val) 0.37114/0.36631. Took 0.15 sec\n",
      "Epoch 9, Loss(train/val) 0.36475/0.37088. Took 0.15 sec\n",
      "Epoch 10, Loss(train/val) 0.35534/0.30536. Took 0.15 sec\n",
      "Epoch 11, Loss(train/val) 0.34225/0.26724. Took 0.15 sec\n",
      "Epoch 12, Loss(train/val) 0.32845/0.36025. Took 0.15 sec\n",
      "Epoch 13, Loss(train/val) 0.32609/0.25300. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.33486/0.28679. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.33355/0.25652. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.31699/0.34198. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.30118/0.28732. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.30152/0.29182. Took 0.15 sec\n",
      "Epoch 19, Loss(train/val) 0.29871/0.23163. Took 0.15 sec\n",
      "Epoch 20, Loss(train/val) 0.30419/0.38490. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.30077/0.20248. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.29911/0.21370. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.28547/0.24318. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.27743/0.21737. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.27752/0.22048. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.28377/0.30001. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.28803/0.23800. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.27267/0.24157. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.27615/0.23052. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.28353/0.38808. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.27288/0.36229. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.26367/0.36633. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.25791/0.38957. Took 0.16 sec\n",
      "Epoch 34, Loss(train/val) 0.25549/0.32066. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.25602/0.39364. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.25498/0.38775. Took 0.13 sec\n",
      "Epoch 37, Loss(train/val) 0.25442/0.38935. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.25663/0.38687. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.25061/0.37811. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.24011/0.40233. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.26004/0.37531. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.24340/0.33851. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.23617/0.34743. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.24628/0.37297. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) 0.24716/0.32017. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.23959/0.24035. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.23393/0.33607. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.23504/0.30442. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.23207/0.29675. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.23324/0.33449. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.22345/0.31992. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.22004/0.34500. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.22809/0.31739. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.21408/0.33254. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.23031/0.25093. Took 0.16 sec\n",
      "Epoch 56, Loss(train/val) 0.23582/0.26543. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.21647/0.25683. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.21321/0.30538. Took 0.14 sec\n",
      "Epoch 59, Loss(train/val) 0.21207/0.28551. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.21397/0.28202. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.21251/0.29042. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.20011/0.30434. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.19657/0.28913. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.19848/0.30559. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.21023/0.29643. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.19533/0.28504. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.19995/0.30416. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.20197/0.31344. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.20484/0.30428. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.19777/0.31070. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.19511/0.28709. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.20363/0.32464. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.19669/0.27079. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.19314/0.31928. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.19784/0.30009. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.18561/0.29979. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.18692/0.25617. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.18587/0.31419. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.18993/0.27281. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.17260/0.27071. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.17780/0.32336. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.17766/0.28887. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.17812/0.33898. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.18986/0.28926. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.18037/0.28700. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.17753/0.28381. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.17018/0.31619. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.18227/0.30279. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.17250/0.28912. Took 0.15 sec\n",
      "Epoch 90, Loss(train/val) 0.16822/0.29564. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.17077/0.30504. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.17172/0.30822. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.17021/0.33615. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.16220/0.32286. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.15940/0.32613. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.16212/0.32199. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.16067/0.32386. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.16302/0.31892. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.16664/0.32160. Took 0.13 sec\n",
      "ACC: 0.65625, MCC: 0.36084391824351614\n",
      "Epoch 0, Loss(train/val) 0.49426/0.48582. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.47353/0.46723. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.44517/0.43627. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.41785/0.39020. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.39342/0.38872. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.37301/0.37906. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.35741/0.38477. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.34616/0.38535. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.33412/0.37560. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.33790/0.38984. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.32985/0.37041. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.33101/0.38342. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.31329/0.38571. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.32364/0.40444. Took 0.16 sec\n",
      "Epoch 14, Loss(train/val) 0.31268/0.36227. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.29819/0.35525. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.29157/0.37710. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.29860/0.36072. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.29379/0.35952. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.28767/0.38247. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.28415/0.36494. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.27672/0.37831. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.28038/0.36538. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.27776/0.38114. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.27038/0.35557. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.26090/0.35946. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.26070/0.35740. Took 0.13 sec\n",
      "Epoch 27, Loss(train/val) 0.24642/0.35956. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.25269/0.35690. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.24373/0.37440. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.25285/0.36506. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.25406/0.36269. Took 0.17 sec\n",
      "Epoch 32, Loss(train/val) 0.24728/0.37627. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.24083/0.37027. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.23755/0.36180. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.24208/0.35698. Took 0.16 sec\n",
      "Epoch 36, Loss(train/val) 0.22654/0.35350. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.22708/0.35231. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.23193/0.35205. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.22538/0.33661. Took 0.15 sec\n",
      "Epoch 40, Loss(train/val) 0.23187/0.35834. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.22741/0.32845. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.21856/0.33868. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.21515/0.33415. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.21627/0.33595. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.20823/0.34350. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.20153/0.34339. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.20608/0.34160. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.21311/0.36679. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.21242/0.33637. Took 0.15 sec\n",
      "Epoch 50, Loss(train/val) 0.20648/0.34807. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.20735/0.32740. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.19763/0.34493. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.20915/0.32530. Took 0.16 sec\n",
      "Epoch 54, Loss(train/val) 0.19926/0.33047. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.19768/0.33012. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.19879/0.33657. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.19338/0.34703. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.19974/0.32869. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.19570/0.33732. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.19270/0.34676. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.18304/0.34504. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.19090/0.33513. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.18755/0.31535. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.18715/0.31396. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.18214/0.31433. Took 0.15 sec\n",
      "Epoch 66, Loss(train/val) 0.18382/0.31253. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.18116/0.31479. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.17370/0.30827. Took 0.14 sec\n",
      "Epoch 69, Loss(train/val) 0.17603/0.32131. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.17074/0.31794. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.17837/0.33794. Took 0.15 sec\n",
      "Epoch 72, Loss(train/val) 0.17790/0.32443. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.18401/0.34384. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.18152/0.33271. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.17340/0.32434. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.18054/0.33475. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.17343/0.34190. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.16950/0.33239. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.16198/0.34635. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.16137/0.32828. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.16364/0.33100. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.16026/0.33640. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.17298/0.33292. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.17940/0.34184. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.15927/0.36068. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.15973/0.33018. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.15624/0.35109. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.15682/0.33594. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.16230/0.33762. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.16004/0.34384. Took 0.14 sec\n",
      "Epoch 91, Loss(train/val) 0.16513/0.33812. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.15172/0.35283. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.15877/0.33257. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.15436/0.33742. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.14297/0.32787. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.14811/0.34247. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.13988/0.33823. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.14695/0.34547. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.13716/0.33946. Took 0.13 sec\n",
      "ACC: 0.6875, MCC: 0.3694581280788177\n",
      "Epoch 0, Loss(train/val) 0.49512/0.48531. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.47978/0.46092. Took 0.15 sec\n",
      "Epoch 2, Loss(train/val) 0.45294/0.40592. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.42550/0.36971. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.40361/0.35277. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.38187/0.34760. Took 0.15 sec\n",
      "Epoch 6, Loss(train/val) 0.36760/0.31644. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.35160/0.31143. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.33681/0.28268. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.33460/0.26300. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.31062/0.25491. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.30934/0.29667. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.32271/0.32546. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.32207/0.26377. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.30022/0.26994. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.29554/0.28554. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.28892/0.31134. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.28296/0.29977. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.28609/0.28895. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.28105/0.29257. Took 0.16 sec\n",
      "Epoch 20, Loss(train/val) 0.27023/0.28605. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.27443/0.30040. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.26982/0.29706. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.26145/0.31702. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.27048/0.32922. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.26729/0.32933. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.25700/0.31975. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.26915/0.34008. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.26030/0.32390. Took 0.13 sec\n",
      "Epoch 29, Loss(train/val) 0.25345/0.32830. Took 0.13 sec\n",
      "Epoch 30, Loss(train/val) 0.24180/0.32636. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.24103/0.33553. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.23931/0.32573. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.24580/0.30408. Took 0.16 sec\n",
      "Epoch 34, Loss(train/val) 0.24818/0.31452. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.25066/0.32313. Took 0.15 sec\n",
      "Epoch 36, Loss(train/val) 0.24014/0.31913. Took 0.16 sec\n",
      "Epoch 37, Loss(train/val) 0.23405/0.32312. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.23068/0.34351. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.23748/0.32017. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.22873/0.32391. Took 0.16 sec\n",
      "Epoch 41, Loss(train/val) 0.23199/0.30767. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.21609/0.31421. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.21626/0.31005. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.21180/0.30603. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.22150/0.32098. Took 0.15 sec\n",
      "Epoch 46, Loss(train/val) 0.21776/0.31000. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.21589/0.34133. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.23062/0.31099. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.21657/0.31228. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.19668/0.34168. Took 0.14 sec\n",
      "Epoch 51, Loss(train/val) 0.21537/0.30230. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.20161/0.31305. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.20589/0.30827. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.19787/0.28681. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.19954/0.28967. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.20772/0.31142. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.19473/0.28989. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.19477/0.28013. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.19424/0.28061. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.19363/0.28410. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.19358/0.28907. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.18708/0.29495. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.18515/0.28644. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.19231/0.30308. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.18381/0.30019. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.18544/0.29314. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.18216/0.28190. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.17962/0.27942. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.17997/0.27403. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.18812/0.27115. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.17508/0.27573. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.18267/0.26219. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.18010/0.28616. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.17385/0.27180. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.17370/0.26843. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.16956/0.26568. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.16722/0.29960. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.17044/0.28014. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.16983/0.28806. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.16563/0.27498. Took 0.14 sec\n",
      "Epoch 81, Loss(train/val) 0.16619/0.29620. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.16790/0.29156. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.18066/0.27538. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.17588/0.25854. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.15709/0.26833. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.16287/0.28048. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.15664/0.27371. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.15445/0.26915. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.15043/0.29773. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.15959/0.26597. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.15708/0.29828. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.15753/0.25899. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.14919/0.26867. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.15537/0.26713. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.14954/0.25618. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.15753/0.24207. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.15462/0.27863. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.14527/0.26897. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.14248/0.27243. Took 0.13 sec\n",
      "ACC: 0.640625, MCC: 0.3522521434341141\n",
      "Epoch 0, Loss(train/val) 0.49179/0.48523. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.47448/0.46803. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.45400/0.44938. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.42850/0.42622. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.41141/0.42530. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.39248/0.41329. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.37050/0.40637. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.35539/0.41912. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.34304/0.37586. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.32107/0.37329. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.33305/0.37778. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.32309/0.37290. Took 0.16 sec\n",
      "Epoch 12, Loss(train/val) 0.31228/0.40910. Took 0.16 sec\n",
      "Epoch 13, Loss(train/val) 0.31382/0.39023. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.30743/0.41633. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.29953/0.37486. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.30291/0.35437. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.29547/0.35306. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.29093/0.37736. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.28626/0.37553. Took 0.15 sec\n",
      "Epoch 20, Loss(train/val) 0.27796/0.37852. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.27208/0.39664. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.26668/0.38265. Took 0.15 sec\n",
      "Epoch 23, Loss(train/val) 0.25647/0.37599. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.25737/0.38994. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.26088/0.39873. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.25562/0.38709. Took 0.15 sec\n",
      "Epoch 27, Loss(train/val) 0.24300/0.39886. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.24748/0.40145. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.24699/0.40657. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.23288/0.41840. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.23501/0.39520. Took 0.16 sec\n",
      "Epoch 32, Loss(train/val) 0.23993/0.42281. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.24094/0.40274. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.22898/0.41614. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.22374/0.42766. Took 0.16 sec\n",
      "Epoch 36, Loss(train/val) 0.22750/0.42440. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.22080/0.41437. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.21690/0.41629. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.21291/0.42377. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.22502/0.40380. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.20820/0.41677. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.21937/0.42543. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.20214/0.43140. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.19402/0.40644. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.19842/0.39918. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.19980/0.41037. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.20162/0.42349. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.19158/0.41356. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.19938/0.41191. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.18952/0.41066. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.18757/0.41929. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.19811/0.40103. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.18986/0.40844. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.18750/0.39460. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.19523/0.41391. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.17989/0.41490. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.17924/0.40461. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.18108/0.40697. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.17651/0.43758. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.18374/0.42415. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.18471/0.38337. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.18147/0.40398. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.17323/0.40045. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.17019/0.39588. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.17973/0.42294. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.17347/0.42726. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) 0.16514/0.42725. Took 0.15 sec\n",
      "Epoch 68, Loss(train/val) 0.16554/0.39600. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.17477/0.40186. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.16691/0.38724. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.17118/0.41370. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.16050/0.41158. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.15850/0.41105. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.16194/0.41867. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.16422/0.42200. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.15640/0.38737. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.14950/0.42500. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.15470/0.38946. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.15770/0.39163. Took 0.15 sec\n",
      "Epoch 80, Loss(train/val) 0.15346/0.41831. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.14969/0.40666. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.15976/0.38659. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.15388/0.38647. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.14723/0.40665. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.13813/0.41777. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.14383/0.38614. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.14100/0.38992. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.14703/0.40222. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.14639/0.38005. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.13952/0.38663. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.14163/0.39142. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.14095/0.40194. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.14212/0.39139. Took 0.15 sec\n",
      "Epoch 94, Loss(train/val) 0.13965/0.39156. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.14195/0.39120. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.13813/0.40699. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.13177/0.38805. Took 0.15 sec\n",
      "Epoch 98, Loss(train/val) 0.15149/0.37838. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.13529/0.40592. Took 0.13 sec\n",
      "ACC: 0.59375, MCC: 0.33149187026157156\n",
      "Epoch 0, Loss(train/val) 0.49253/0.47037. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.47002/0.43141. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.44248/0.39190. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.42122/0.37235. Took 0.16 sec\n",
      "Epoch 4, Loss(train/val) 0.40807/0.36975. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.39755/0.36109. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.38225/0.32821. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.35632/0.32480. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.34085/0.32110. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.33131/0.29501. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.31619/0.30402. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.30263/0.31141. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.30091/0.30364. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.29112/0.29039. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.28774/0.28062. Took 0.15 sec\n",
      "Epoch 15, Loss(train/val) 0.28125/0.29337. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.27018/0.28731. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.26515/0.29428. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.27077/0.30538. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.27536/0.28645. Took 0.16 sec\n",
      "Epoch 20, Loss(train/val) 0.25178/0.26550. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.25304/0.27659. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.25251/0.28812. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.25113/0.28976. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.23870/0.28539. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.23465/0.29281. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.21964/0.27461. Took 0.13 sec\n",
      "Epoch 27, Loss(train/val) 0.22489/0.28266. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.22247/0.28577. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.21974/0.28938. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.22173/0.28665. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.21057/0.28939. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.21373/0.29312. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.20470/0.29380. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.20484/0.28889. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.21177/0.29884. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.20320/0.29023. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.20033/0.28396. Took 0.15 sec\n",
      "Epoch 38, Loss(train/val) 0.18263/0.29024. Took 0.15 sec\n",
      "Epoch 39, Loss(train/val) 0.20205/0.30396. Took 0.16 sec\n",
      "Epoch 40, Loss(train/val) 0.20865/0.31005. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.18686/0.30011. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.18106/0.31101. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.18622/0.30820. Took 0.15 sec\n",
      "Epoch 44, Loss(train/val) 0.18046/0.31719. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.16843/0.30648. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.16628/0.30966. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.17709/0.28776. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.17969/0.31077. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.16885/0.30123. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.16910/0.31594. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.16257/0.30432. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.15547/0.29865. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.15958/0.32095. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.15777/0.30842. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.15737/0.33116. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.15698/0.30767. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.16172/0.34027. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.15776/0.32282. Took 0.14 sec\n",
      "Epoch 59, Loss(train/val) 0.16137/0.31208. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.15455/0.33989. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.14551/0.32846. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.15066/0.34551. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.14497/0.31521. Took 0.18 sec\n",
      "Epoch 64, Loss(train/val) 0.14893/0.30901. Took 0.15 sec\n",
      "Epoch 65, Loss(train/val) 0.14010/0.32293. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.15125/0.32221. Took 0.15 sec\n",
      "Epoch 67, Loss(train/val) 0.15350/0.32522. Took 0.15 sec\n",
      "Epoch 68, Loss(train/val) 0.14772/0.30580. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.13949/0.32631. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.13991/0.32554. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.14759/0.32621. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.13817/0.34563. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.13182/0.31471. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.13686/0.32479. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.12807/0.32992. Took 0.15 sec\n",
      "Epoch 76, Loss(train/val) 0.13332/0.32000. Took 0.15 sec\n",
      "Epoch 77, Loss(train/val) 0.13152/0.33519. Took 0.15 sec\n",
      "Epoch 78, Loss(train/val) 0.12456/0.33914. Took 0.15 sec\n",
      "Epoch 79, Loss(train/val) 0.12728/0.30827. Took 0.15 sec\n",
      "Epoch 80, Loss(train/val) 0.13159/0.33276. Took 0.15 sec\n",
      "Epoch 81, Loss(train/val) 0.12432/0.31141. Took 0.17 sec\n",
      "Epoch 82, Loss(train/val) 0.12458/0.33815. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) 0.11671/0.34701. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.11497/0.31708. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.11504/0.31851. Took 0.16 sec\n",
      "Epoch 86, Loss(train/val) 0.12410/0.31661. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.12980/0.37179. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.11153/0.34912. Took 0.15 sec\n",
      "Epoch 89, Loss(train/val) 0.12962/0.34261. Took 0.16 sec\n",
      "Epoch 90, Loss(train/val) 0.11262/0.34460. Took 0.16 sec\n",
      "Epoch 91, Loss(train/val) 0.12135/0.32179. Took 0.15 sec\n",
      "Epoch 92, Loss(train/val) 0.11521/0.34990. Took 0.18 sec\n",
      "Epoch 93, Loss(train/val) 0.11599/0.32870. Took 0.16 sec\n",
      "Epoch 94, Loss(train/val) 0.10979/0.35489. Took 0.14 sec\n",
      "Epoch 95, Loss(train/val) 0.11439/0.34320. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.10544/0.34092. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.11641/0.34986. Took 0.16 sec\n",
      "Epoch 98, Loss(train/val) 0.11017/0.36926. Took 0.15 sec\n",
      "Epoch 99, Loss(train/val) 0.11006/0.34076. Took 0.15 sec\n",
      "ACC: 0.625, MCC: 0.2856530694872366\n",
      "Epoch 0, Loss(train/val) 0.49161/0.47552. Took 0.17 sec\n",
      "Epoch 1, Loss(train/val) 0.46734/0.43295. Took 0.15 sec\n",
      "Epoch 2, Loss(train/val) 0.43261/0.38950. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.40020/0.35824. Took 0.16 sec\n",
      "Epoch 4, Loss(train/val) 0.38048/0.34681. Took 0.15 sec\n",
      "Epoch 5, Loss(train/val) 0.36297/0.33433. Took 0.15 sec\n",
      "Epoch 6, Loss(train/val) 0.35389/0.33935. Took 0.15 sec\n",
      "Epoch 7, Loss(train/val) 0.33840/0.31520. Took 0.17 sec\n",
      "Epoch 8, Loss(train/val) 0.32940/0.29645. Took 0.18 sec\n",
      "Epoch 9, Loss(train/val) 0.32263/0.30785. Took 0.15 sec\n",
      "Epoch 10, Loss(train/val) 0.31424/0.28087. Took 0.18 sec\n",
      "Epoch 11, Loss(train/val) 0.30952/0.27301. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.29301/0.25501. Took 0.16 sec\n",
      "Epoch 13, Loss(train/val) 0.29129/0.23074. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.27939/0.24032. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.29042/0.23841. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.28986/0.27260. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.28044/0.24342. Took 0.16 sec\n",
      "Epoch 18, Loss(train/val) 0.28152/0.22482. Took 0.15 sec\n",
      "Epoch 19, Loss(train/val) 0.30972/0.20697. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.29039/0.20539. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.28153/0.21394. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.27219/0.25059. Took 0.19 sec\n",
      "Epoch 23, Loss(train/val) 0.27314/0.25358. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.26331/0.21479. Took 0.15 sec\n",
      "Epoch 25, Loss(train/val) 0.27435/0.20086. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.26796/0.22239. Took 0.15 sec\n",
      "Epoch 27, Loss(train/val) 0.26544/0.24666. Took 0.16 sec\n",
      "Epoch 28, Loss(train/val) 0.25076/0.21651. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.26232/0.24929. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.25435/0.23523. Took 0.16 sec\n",
      "Epoch 31, Loss(train/val) 0.25392/0.21620. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.24741/0.21284. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.25629/0.29568. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.26141/0.19692. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.24527/0.25342. Took 0.16 sec\n",
      "Epoch 36, Loss(train/val) 0.25893/0.22623. Took 0.19 sec\n",
      "Epoch 37, Loss(train/val) 0.25603/0.20646. Took 0.16 sec\n",
      "Epoch 38, Loss(train/val) 0.25708/0.22208. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.25009/0.31240. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.25771/0.29291. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.25329/0.27662. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.25007/0.28716. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.23641/0.25870. Took 0.15 sec\n",
      "Epoch 44, Loss(train/val) 0.23718/0.28454. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) 0.22297/0.24131. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.22621/0.31456. Took 0.15 sec\n",
      "Epoch 47, Loss(train/val) 0.22341/0.29412. Took 0.16 sec\n",
      "Epoch 48, Loss(train/val) 0.22724/0.23838. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.21489/0.25711. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.22661/0.22099. Took 0.17 sec\n",
      "Epoch 51, Loss(train/val) 0.21793/0.20067. Took 0.15 sec\n",
      "Epoch 52, Loss(train/val) 0.22188/0.24293. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.21974/0.19658. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.21980/0.26143. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.22411/0.26109. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.21433/0.25235. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.21330/0.27718. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.21062/0.24552. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.21625/0.29580. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.20444/0.20597. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.19933/0.22337. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.20360/0.28188. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.19791/0.23739. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.21364/0.25911. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.19572/0.24183. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.20225/0.24024. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.18976/0.24817. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.19610/0.26706. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.19262/0.23441. Took 0.15 sec\n",
      "Epoch 70, Loss(train/val) 0.19218/0.28640. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.18359/0.27549. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.18946/0.27496. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.19725/0.26582. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.18749/0.27443. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.17952/0.26422. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.18749/0.27125. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.18405/0.28641. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.17991/0.19377. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.19001/0.26377. Took 0.15 sec\n",
      "Epoch 80, Loss(train/val) 0.17827/0.23922. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.17863/0.18023. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.16650/0.27569. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.17524/0.23770. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.17711/0.23857. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.16545/0.25914. Took 0.15 sec\n",
      "Epoch 86, Loss(train/val) 0.16689/0.23817. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.17576/0.32451. Took 0.15 sec\n",
      "Epoch 88, Loss(train/val) 0.16426/0.22602. Took 0.14 sec\n",
      "Epoch 89, Loss(train/val) 0.16379/0.29192. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.16997/0.26298. Took 0.16 sec\n",
      "Epoch 91, Loss(train/val) 0.17304/0.29017. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.16270/0.28875. Took 0.15 sec\n",
      "Epoch 93, Loss(train/val) 0.17214/0.20569. Took 0.15 sec\n",
      "Epoch 94, Loss(train/val) 0.16471/0.31706. Took 0.16 sec\n",
      "Epoch 95, Loss(train/val) 0.16227/0.22245. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.16015/0.23310. Took 0.14 sec\n",
      "Epoch 97, Loss(train/val) 0.15812/0.31115. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.16155/0.25803. Took 0.17 sec\n",
      "Epoch 99, Loss(train/val) 0.15515/0.25817. Took 0.14 sec\n",
      "ACC: 0.671875, MCC: 0.3387999020202087\n",
      "Epoch 0, Loss(train/val) 0.49209/0.48863. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.46715/0.46486. Took 0.15 sec\n",
      "Epoch 2, Loss(train/val) 0.43118/0.42998. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.40318/0.40673. Took 0.15 sec\n",
      "Epoch 4, Loss(train/val) 0.39169/0.39395. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.38316/0.38715. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.37295/0.38072. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.36455/0.37604. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.36047/0.40799. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.35828/0.42668. Took 0.15 sec\n",
      "Epoch 10, Loss(train/val) 0.34736/0.36325. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.34268/0.39276. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.32563/0.40409. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.31210/0.38527. Took 0.16 sec\n",
      "Epoch 14, Loss(train/val) 0.30569/0.37793. Took 0.15 sec\n",
      "Epoch 15, Loss(train/val) 0.32028/0.37211. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.29704/0.36344. Took 0.17 sec\n",
      "Epoch 17, Loss(train/val) 0.29185/0.36680. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.29309/0.34306. Took 0.17 sec\n",
      "Epoch 19, Loss(train/val) 0.28267/0.36206. Took 0.17 sec\n",
      "Epoch 20, Loss(train/val) 0.27468/0.33869. Took 0.17 sec\n",
      "Epoch 21, Loss(train/val) 0.27401/0.36769. Took 0.17 sec\n",
      "Epoch 22, Loss(train/val) 0.26147/0.36306. Took 0.16 sec\n",
      "Epoch 23, Loss(train/val) 0.26526/0.36314. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.26287/0.36114. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.26132/0.36553. Took 0.17 sec\n",
      "Epoch 26, Loss(train/val) 0.25639/0.35967. Took 0.13 sec\n",
      "Epoch 27, Loss(train/val) 0.24310/0.32712. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.26021/0.35331. Took 0.17 sec\n",
      "Epoch 29, Loss(train/val) 0.25265/0.35456. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.23770/0.34521. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.24809/0.36138. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.24689/0.31972. Took 0.16 sec\n",
      "Epoch 33, Loss(train/val) 0.24146/0.36286. Took 0.17 sec\n",
      "Epoch 34, Loss(train/val) 0.23851/0.34993. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.22667/0.33137. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.24068/0.36239. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.21997/0.36142. Took 0.15 sec\n",
      "Epoch 38, Loss(train/val) 0.22218/0.32682. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.22923/0.38072. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.22786/0.33139. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.22680/0.34728. Took 0.15 sec\n",
      "Epoch 42, Loss(train/val) 0.22186/0.35577. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.22545/0.34007. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.21996/0.33355. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.21501/0.32851. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.20745/0.37728. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.20855/0.36797. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.20507/0.34734. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.21132/0.35179. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.20603/0.32593. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.20037/0.34090. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.20741/0.35396. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.19570/0.34321. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.20619/0.35431. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.19364/0.33928. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.19194/0.34623. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.19511/0.33468. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.19209/0.34398. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.19648/0.33429. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.19520/0.33574. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.20051/0.34039. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.18925/0.33859. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.19290/0.32893. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.20161/0.33005. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.18838/0.34905. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.17746/0.35311. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.18825/0.35218. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.18497/0.34533. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.17025/0.36045. Took 0.15 sec\n",
      "Epoch 70, Loss(train/val) 0.18141/0.35298. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.17117/0.34341. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.17600/0.33686. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.17608/0.34277. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.17689/0.34010. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.17480/0.33420. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.18089/0.36372. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.17582/0.33930. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.18353/0.33503. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.17443/0.33526. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.17068/0.34809. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.16721/0.33414. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.16124/0.33922. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.16659/0.33552. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.16779/0.34700. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.17629/0.35000. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.15938/0.33065. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.16054/0.35358. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.16190/0.33557. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.15660/0.33743. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.15989/0.33085. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.15871/0.33899. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.15907/0.33187. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.15595/0.32766. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.15371/0.33455. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.15761/0.33936. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.14650/0.33441. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.15687/0.34788. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.15721/0.33860. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.14960/0.33174. Took 0.13 sec\n",
      "ACC: 0.640625, MCC: 0.2882306768491569\n",
      "Epoch 0, Loss(train/val) 0.49262/0.48783. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.46760/0.46757. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.42626/0.44688. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.39519/0.43061. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.38239/0.44843. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.36726/0.41412. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.35172/0.37325. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.34385/0.35798. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.33991/0.37586. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.32299/0.37242. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.31563/0.35472. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.31550/0.36129. Took 0.15 sec\n",
      "Epoch 12, Loss(train/val) 0.29830/0.34819. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.28999/0.36307. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.28405/0.35951. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.28018/0.35745. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.28720/0.37354. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.28475/0.36280. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.28783/0.35374. Took 0.16 sec\n",
      "Epoch 19, Loss(train/val) 0.27417/0.36876. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.27769/0.36991. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.26971/0.38197. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.26883/0.37457. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.25740/0.38238. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.25479/0.38393. Took 0.15 sec\n",
      "Epoch 25, Loss(train/val) 0.25010/0.39051. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.24991/0.41101. Took 0.13 sec\n",
      "Epoch 27, Loss(train/val) 0.24748/0.40861. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.23975/0.40439. Took 0.13 sec\n",
      "Epoch 29, Loss(train/val) 0.23103/0.38907. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.24233/0.39510. Took 0.16 sec\n",
      "Epoch 31, Loss(train/val) 0.25117/0.40876. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.23482/0.41178. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.23465/0.41362. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.22622/0.41077. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.23167/0.39920. Took 0.16 sec\n",
      "Epoch 36, Loss(train/val) 0.23162/0.41438. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.22980/0.40416. Took 0.15 sec\n",
      "Epoch 38, Loss(train/val) 0.22614/0.40870. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.21228/0.38446. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.22122/0.39457. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.22041/0.40844. Took 0.15 sec\n",
      "Epoch 42, Loss(train/val) 0.21663/0.41472. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.20685/0.40588. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.20246/0.42736. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.20658/0.41522. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.20344/0.35915. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.20579/0.38503. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.20147/0.39583. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.20140/0.38761. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.19804/0.39867. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.19068/0.39496. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.19575/0.40354. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) 0.19024/0.38493. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.20342/0.41036. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.18767/0.38420. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.19779/0.35738. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.19315/0.38443. Took 0.15 sec\n",
      "Epoch 58, Loss(train/val) 0.18809/0.35787. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.19042/0.38762. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.18646/0.35308. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.18843/0.36174. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.18453/0.35510. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.18170/0.37625. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.18776/0.37852. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.17656/0.38278. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.18185/0.39084. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.19397/0.37518. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.18382/0.37093. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.17911/0.38186. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.17761/0.36649. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.18092/0.37067. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.17799/0.35177. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.17167/0.36494. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.17493/0.36313. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.16248/0.35709. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.17104/0.36781. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.17397/0.36676. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.18499/0.37078. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.17791/0.36558. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.16817/0.37602. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.16782/0.35307. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.17139/0.35148. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.17006/0.35067. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.17265/0.35503. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.16903/0.36030. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.17000/0.35591. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.16280/0.34360. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.16488/0.35404. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.17287/0.35988. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.16868/0.34589. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.16275/0.35707. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.17118/0.36525. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.15599/0.37060. Took 0.15 sec\n",
      "Epoch 94, Loss(train/val) 0.16020/0.37187. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.16442/0.37744. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.16355/0.37162. Took 0.14 sec\n",
      "Epoch 97, Loss(train/val) 0.15562/0.37674. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.15691/0.36681. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.16361/0.38298. Took 0.13 sec\n",
      "ACC: 0.5625, MCC: 0.13517414889732077\n",
      "Epoch 0, Loss(train/val) 0.49190/0.49024. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.46619/0.46962. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.41805/0.44868. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.38464/0.44895. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.36374/0.44381. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.34971/0.43507. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.34090/0.43176. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.32950/0.39747. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.31663/0.38484. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.30640/0.37141. Took 0.16 sec\n",
      "Epoch 10, Loss(train/val) 0.30940/0.36249. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.28380/0.37015. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.28722/0.37559. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.28348/0.38758. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.29321/0.36403. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.28248/0.36059. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.28455/0.38785. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.28504/0.40522. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.27216/0.36911. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.27472/0.38565. Took 0.15 sec\n",
      "Epoch 20, Loss(train/val) 0.26201/0.37594. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.26264/0.37917. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.26923/0.36302. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.25578/0.36781. Took 0.16 sec\n",
      "Epoch 24, Loss(train/val) 0.24974/0.35677. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.25420/0.37278. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.25370/0.37754. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.25977/0.38240. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.25796/0.36591. Took 0.17 sec\n",
      "Epoch 29, Loss(train/val) 0.23710/0.35323. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.24124/0.37012. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.24693/0.36779. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.24097/0.38120. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.23744/0.36283. Took 0.13 sec\n",
      "Epoch 34, Loss(train/val) 0.23889/0.37289. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.23568/0.35542. Took 0.13 sec\n",
      "Epoch 36, Loss(train/val) 0.23791/0.40331. Took 0.13 sec\n",
      "Epoch 37, Loss(train/val) 0.24564/0.38083. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.23247/0.38420. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.22638/0.36957. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.23651/0.38996. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.23752/0.36669. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.22038/0.36818. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.22384/0.35726. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.22254/0.40407. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.23723/0.34449. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.21901/0.34615. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.21890/0.38332. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.23011/0.40697. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.22121/0.42858. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.22922/0.39345. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.21322/0.37074. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.22193/0.37265. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.21682/0.39470. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.20973/0.38028. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.21667/0.34264. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.20940/0.35524. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.21021/0.36037. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.21352/0.39560. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.20869/0.38084. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.20200/0.37725. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.20881/0.34837. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.21496/0.35498. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.22114/0.41654. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.22893/0.41825. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.20897/0.39928. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.21114/0.37241. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.21588/0.41902. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.23480/0.39734. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.22272/0.40986. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.22313/0.39295. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.20238/0.37732. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.19325/0.38760. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.20967/0.39641. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.21037/0.39808. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.20473/0.40826. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.20319/0.42231. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.18943/0.38999. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.19093/0.39879. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.18734/0.41255. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.19507/0.43373. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.19479/0.39022. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.19178/0.41033. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.18561/0.41624. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.19444/0.41964. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.19698/0.40931. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.18780/0.37396. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.19752/0.39025. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.18410/0.35030. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.18442/0.38012. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.18028/0.39661. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.18982/0.37902. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.19069/0.38073. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.17582/0.39333. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.18105/0.41660. Took 0.14 sec\n",
      "Epoch 95, Loss(train/val) 0.17777/0.41464. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.18216/0.41537. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.18028/0.41317. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.17626/0.41824. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.16365/0.40796. Took 0.13 sec\n",
      "ACC: 0.625, MCC: 0.25417271391119695\n",
      "Epoch 0, Loss(train/val) 0.49284/0.49703. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.46670/0.49309. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.42810/0.48399. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.39671/0.47966. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.37919/0.47787. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.36822/0.48503. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.36269/0.47711. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.35461/0.47061. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.34823/0.45979. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.33698/0.45629. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.33118/0.44419. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.32001/0.43219. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.32620/0.43207. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.31771/0.41267. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.30208/0.40148. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.29605/0.39010. Took 0.16 sec\n",
      "Epoch 16, Loss(train/val) 0.29346/0.41570. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.28303/0.39604. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.27652/0.39919. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.26519/0.39837. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.26787/0.41085. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.26722/0.39574. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.25598/0.41352. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.24528/0.39104. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.25073/0.40471. Took 0.15 sec\n",
      "Epoch 25, Loss(train/val) 0.23630/0.39340. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.23758/0.40802. Took 0.16 sec\n",
      "Epoch 27, Loss(train/val) 0.23676/0.40608. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.23493/0.41532. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.24313/0.42789. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.23629/0.41147. Took 0.17 sec\n",
      "Epoch 31, Loss(train/val) 0.22761/0.41802. Took 0.17 sec\n",
      "Epoch 32, Loss(train/val) 0.22256/0.39444. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.22299/0.40918. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.21735/0.39495. Took 0.16 sec\n",
      "Epoch 35, Loss(train/val) 0.21535/0.41322. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.21886/0.41035. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.21598/0.40917. Took 0.15 sec\n",
      "Epoch 38, Loss(train/val) 0.20547/0.41880. Took 0.15 sec\n",
      "Epoch 39, Loss(train/val) 0.21164/0.40630. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.20510/0.41531. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.20634/0.41967. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.19850/0.41019. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.20020/0.42130. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.19376/0.43930. Took 0.17 sec\n",
      "Epoch 45, Loss(train/val) 0.18655/0.42290. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.19317/0.43079. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.19965/0.43163. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.20305/0.44596. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.19869/0.43117. Took 0.15 sec\n",
      "Epoch 50, Loss(train/val) 0.20074/0.43508. Took 0.14 sec\n",
      "Epoch 51, Loss(train/val) 0.19678/0.42695. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.17988/0.42455. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) 0.18853/0.43405. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.18177/0.44941. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.18123/0.41606. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.18241/0.43389. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.17875/0.43620. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.17271/0.44324. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.17251/0.43389. Took 0.15 sec\n",
      "Epoch 60, Loss(train/val) 0.17543/0.41761. Took 0.14 sec\n",
      "Epoch 61, Loss(train/val) 0.17545/0.43118. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.17104/0.45314. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.16707/0.46724. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.16881/0.46551. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.16082/0.46231. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.16498/0.45528. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) 0.15722/0.46188. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.16506/0.43621. Took 0.14 sec\n",
      "Epoch 69, Loss(train/val) 0.16535/0.47791. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.15780/0.44929. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.15987/0.45649. Took 0.15 sec\n",
      "Epoch 72, Loss(train/val) 0.15462/0.45377. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.15009/0.46024. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.14894/0.45505. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) 0.16279/0.43644. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.15226/0.41811. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.15247/0.44468. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.14238/0.47350. Took 0.14 sec\n",
      "Epoch 79, Loss(train/val) 0.14616/0.45595. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.14805/0.46185. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.15383/0.44497. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.14474/0.44748. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.14556/0.44096. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.13715/0.43449. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.14405/0.43189. Took 0.15 sec\n",
      "Epoch 86, Loss(train/val) 0.14571/0.42703. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.14519/0.41671. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.13657/0.40131. Took 0.14 sec\n",
      "Epoch 89, Loss(train/val) 0.13659/0.42766. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.14323/0.43187. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.13042/0.42407. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.13773/0.41422. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.14196/0.44261. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.13489/0.42359. Took 0.14 sec\n",
      "Epoch 95, Loss(train/val) 0.12910/0.43489. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.13253/0.44519. Took 0.14 sec\n",
      "Epoch 97, Loss(train/val) 0.12788/0.46788. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.12895/0.44291. Took 0.15 sec\n",
      "Epoch 99, Loss(train/val) 0.13896/0.43515. Took 0.13 sec\n",
      "ACC: 0.703125, MCC: 0.4052867805690852\n",
      "Epoch 0, Loss(train/val) 0.48651/0.50045. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.46015/0.49649. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.42465/0.48675. Took 0.15 sec\n",
      "Epoch 3, Loss(train/val) 0.39469/0.48174. Took 0.15 sec\n",
      "Epoch 4, Loss(train/val) 0.37576/0.46926. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.37007/0.45333. Took 0.15 sec\n",
      "Epoch 6, Loss(train/val) 0.36328/0.43947. Took 0.16 sec\n",
      "Epoch 7, Loss(train/val) 0.35411/0.43633. Took 0.15 sec\n",
      "Epoch 8, Loss(train/val) 0.34857/0.44553. Took 0.18 sec\n",
      "Epoch 9, Loss(train/val) 0.33891/0.43638. Took 0.15 sec\n",
      "Epoch 10, Loss(train/val) 0.32984/0.44183. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.32586/0.44425. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.31754/0.43566. Took 0.16 sec\n",
      "Epoch 13, Loss(train/val) 0.30955/0.44906. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.29477/0.45402. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.29227/0.44815. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.28121/0.47764. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.27257/0.45390. Took 0.16 sec\n",
      "Epoch 18, Loss(train/val) 0.26858/0.45770. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.27098/0.50169. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.26973/0.47174. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.25534/0.50688. Took 0.16 sec\n",
      "Epoch 22, Loss(train/val) 0.25346/0.49311. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.25096/0.50249. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.24542/0.49741. Took 0.16 sec\n",
      "Epoch 25, Loss(train/val) 0.24273/0.48363. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.23986/0.49326. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.22904/0.48948. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.24157/0.47828. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.22715/0.49184. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.23156/0.49697. Took 0.16 sec\n",
      "Epoch 31, Loss(train/val) 0.22801/0.50491. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.22003/0.50504. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.22499/0.51798. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.21120/0.50407. Took 0.17 sec\n",
      "Epoch 35, Loss(train/val) 0.21365/0.51221. Took 0.15 sec\n",
      "Epoch 36, Loss(train/val) 0.22807/0.47570. Took 0.16 sec\n",
      "Epoch 37, Loss(train/val) 0.21503/0.49898. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.21216/0.47969. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.22164/0.48825. Took 0.15 sec\n",
      "Epoch 40, Loss(train/val) 0.20338/0.47867. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.20816/0.48506. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.19785/0.48262. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.20251/0.49061. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.19753/0.49171. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) 0.18688/0.48739. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.19871/0.47937. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.19184/0.50086. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.18950/0.48057. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.18398/0.49289. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.17759/0.49772. Took 0.14 sec\n",
      "Epoch 51, Loss(train/val) 0.18087/0.49971. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.18478/0.47993. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.19045/0.49296. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.19322/0.49683. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.17903/0.48660. Took 0.15 sec\n",
      "Epoch 56, Loss(train/val) 0.16892/0.49028. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.17054/0.49917. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.16879/0.49573. Took 0.15 sec\n",
      "Epoch 59, Loss(train/val) 0.16896/0.49617. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.16772/0.49812. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.17928/0.50724. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.17129/0.49680. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.17064/0.49207. Took 0.15 sec\n",
      "Epoch 64, Loss(train/val) 0.16976/0.48335. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.16695/0.48685. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.16490/0.48788. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) 0.16694/0.49157. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.16535/0.47922. Took 0.14 sec\n",
      "Epoch 69, Loss(train/val) 0.15554/0.48035. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.16246/0.47739. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.15828/0.50039. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.15555/0.49063. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.15329/0.47600. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.15458/0.48009. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) 0.15388/0.48645. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.14643/0.48163. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.15822/0.48180. Took 0.15 sec\n",
      "Epoch 78, Loss(train/val) 0.15636/0.49290. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.15362/0.47522. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.14873/0.46921. Took 0.15 sec\n",
      "Epoch 81, Loss(train/val) 0.15409/0.48657. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.14182/0.49362. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) 0.14481/0.47387. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.14461/0.46204. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.13516/0.49275. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.14040/0.48827. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.14239/0.47829. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.14087/0.47296. Took 0.14 sec\n",
      "Epoch 89, Loss(train/val) 0.15228/0.46824. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.14173/0.46285. Took 0.14 sec\n",
      "Epoch 91, Loss(train/val) 0.14162/0.47370. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.13850/0.47892. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.13707/0.46498. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.13270/0.47569. Took 0.15 sec\n",
      "Epoch 95, Loss(train/val) 0.13030/0.47056. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.13848/0.45909. Took 0.14 sec\n",
      "Epoch 97, Loss(train/val) 0.12739/0.46379. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.13365/0.46636. Took 0.14 sec\n",
      "Epoch 99, Loss(train/val) 0.13379/0.46667. Took 0.14 sec\n",
      "ACC: 0.6875, MCC: 0.4172897660939783\n",
      "Epoch 0, Loss(train/val) 0.49396/0.47891. Took 0.74 sec\n",
      "Epoch 1, Loss(train/val) 0.47419/0.43524. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.43809/0.36566. Took 0.15 sec\n",
      "Epoch 3, Loss(train/val) 0.40205/0.33741. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.38200/0.30623. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.36596/0.29681. Took 0.16 sec\n",
      "Epoch 6, Loss(train/val) 0.35857/0.28722. Took 0.15 sec\n",
      "Epoch 7, Loss(train/val) 0.35272/0.27128. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.34448/0.26141. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.33723/0.25236. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.33799/0.24353. Took 0.15 sec\n",
      "Epoch 11, Loss(train/val) 0.33152/0.22892. Took 0.15 sec\n",
      "Epoch 12, Loss(train/val) 0.32309/0.22809. Took 0.15 sec\n",
      "Epoch 13, Loss(train/val) 0.32618/0.21261. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.31504/0.20467. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.31600/0.19390. Took 0.16 sec\n",
      "Epoch 16, Loss(train/val) 0.31283/0.19648. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.29562/0.34853. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.31240/0.21606. Took 0.15 sec\n",
      "Epoch 19, Loss(train/val) 0.30632/0.18323. Took 0.15 sec\n",
      "Epoch 20, Loss(train/val) 0.29494/0.20070. Took 0.15 sec\n",
      "Epoch 21, Loss(train/val) 0.29199/0.23975. Took 0.16 sec\n",
      "Epoch 22, Loss(train/val) 0.27775/0.18641. Took 0.15 sec\n",
      "Epoch 23, Loss(train/val) 0.28578/0.24029. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.27063/0.19223. Took 0.15 sec\n",
      "Epoch 25, Loss(train/val) 0.27226/0.20079. Took 0.16 sec\n",
      "Epoch 26, Loss(train/val) 0.26457/0.36318. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.27370/0.36496. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.26669/0.24796. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.25935/0.24641. Took 0.13 sec\n",
      "Epoch 30, Loss(train/val) 0.25901/0.26653. Took 0.13 sec\n",
      "Epoch 31, Loss(train/val) 0.26128/0.25706. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.27842/0.21039. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.26690/0.26081. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.25293/0.31240. Took 0.13 sec\n",
      "Epoch 35, Loss(train/val) 0.25410/0.20875. Took 0.13 sec\n",
      "Epoch 36, Loss(train/val) 0.24998/0.29221. Took 0.13 sec\n",
      "Epoch 37, Loss(train/val) 0.24904/0.31139. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.23824/0.38005. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.24562/0.29734. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.23768/0.26827. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.23873/0.37962. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.22868/0.30258. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.23223/0.28657. Took 0.15 sec\n",
      "Epoch 44, Loss(train/val) 0.24092/0.31397. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.23732/0.26812. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.23348/0.36313. Took 0.15 sec\n",
      "Epoch 47, Loss(train/val) 0.24129/0.36903. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.24146/0.36448. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.22825/0.37647. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.23802/0.38527. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.23226/0.32243. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.22155/0.35759. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) 0.22231/0.38301. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.22707/0.28232. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.23068/0.20218. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.21674/0.19667. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.21394/0.21938. Took 0.15 sec\n",
      "Epoch 58, Loss(train/val) 0.21630/0.22985. Took 0.14 sec\n",
      "Epoch 59, Loss(train/val) 0.21634/0.21868. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.21461/0.21962. Took 0.14 sec\n",
      "Epoch 61, Loss(train/val) 0.20936/0.22295. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.21195/0.21131. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.20394/0.22724. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.20405/0.29276. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.21041/0.23070. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.19847/0.21971. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.20674/0.20883. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.19986/0.26319. Took 0.14 sec\n",
      "Epoch 69, Loss(train/val) 0.20948/0.28503. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.19583/0.23358. Took 0.15 sec\n",
      "Epoch 71, Loss(train/val) 0.19547/0.20462. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.19642/0.21690. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.19476/0.22023. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.18893/0.30493. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) 0.19106/0.32273. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.18080/0.29255. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.18505/0.28970. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.18907/0.29045. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.18892/0.26354. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.18161/0.23813. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.18235/0.23471. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.17730/0.22191. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) 0.17974/0.24775. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.17373/0.23644. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.16874/0.22976. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.17363/0.23925. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.17012/0.24539. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.16620/0.29242. Took 0.14 sec\n",
      "Epoch 89, Loss(train/val) 0.16988/0.28496. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.16580/0.26287. Took 0.14 sec\n",
      "Epoch 91, Loss(train/val) 0.16183/0.24636. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.16531/0.32184. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.16370/0.28274. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.16469/0.29395. Took 0.14 sec\n",
      "Epoch 95, Loss(train/val) 0.15310/0.28715. Took 0.15 sec\n",
      "Epoch 96, Loss(train/val) 0.15854/0.27737. Took 0.14 sec\n",
      "Epoch 97, Loss(train/val) 0.16133/0.28973. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.16022/0.26675. Took 0.14 sec\n",
      "Epoch 99, Loss(train/val) 0.15308/0.30014. Took 0.15 sec\n",
      "ACC: 0.75, MCC: 0.4890025047479465\n",
      "Epoch 0, Loss(train/val) 0.49251/0.49301. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.46733/0.46977. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.42642/0.39837. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.38810/0.35430. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.37033/0.33129. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.35410/0.31405. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.34758/0.29985. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.33915/0.30297. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.33511/0.32721. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.32669/0.30824. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.32111/0.32599. Took 0.16 sec\n",
      "Epoch 11, Loss(train/val) 0.31756/0.30945. Took 0.15 sec\n",
      "Epoch 12, Loss(train/val) 0.30746/0.35805. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.29699/0.38985. Took 0.16 sec\n",
      "Epoch 14, Loss(train/val) 0.28932/0.33152. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.28630/0.30455. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.28536/0.35059. Took 0.16 sec\n",
      "Epoch 17, Loss(train/val) 0.28167/0.30083. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.27447/0.27842. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.27332/0.33014. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.26166/0.31090. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.26108/0.27544. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.26441/0.27411. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.25107/0.34400. Took 0.16 sec\n",
      "Epoch 24, Loss(train/val) 0.24893/0.30299. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.24281/0.28515. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.24150/0.29512. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.24921/0.38412. Took 0.16 sec\n",
      "Epoch 28, Loss(train/val) 0.25751/0.30034. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.23103/0.31640. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.24291/0.32325. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.23405/0.27757. Took 0.16 sec\n",
      "Epoch 32, Loss(train/val) 0.23128/0.34475. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.23318/0.30960. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.22410/0.35953. Took 0.16 sec\n",
      "Epoch 35, Loss(train/val) 0.21960/0.33462. Took 0.15 sec\n",
      "Epoch 36, Loss(train/val) 0.21914/0.36326. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.21338/0.34562. Took 0.15 sec\n",
      "Epoch 38, Loss(train/val) 0.21639/0.33835. Took 0.15 sec\n",
      "Epoch 39, Loss(train/val) 0.21249/0.33810. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.21216/0.28528. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.21684/0.37340. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.21418/0.33915. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.21147/0.32105. Took 0.15 sec\n",
      "Epoch 44, Loss(train/val) 0.20168/0.32991. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.20880/0.33554. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.20752/0.33466. Took 0.15 sec\n",
      "Epoch 47, Loss(train/val) 0.21713/0.38500. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.20558/0.28940. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.19956/0.36744. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.19545/0.29655. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.20011/0.29502. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.20043/0.30258. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) 0.19355/0.29304. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.19220/0.33708. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.19020/0.34618. Took 0.15 sec\n",
      "Epoch 56, Loss(train/val) 0.18571/0.30193. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.18930/0.30010. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.18350/0.29496. Took 0.14 sec\n",
      "Epoch 59, Loss(train/val) 0.18474/0.29476. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.19265/0.36095. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.18216/0.31999. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.18388/0.34069. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.18146/0.33884. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.17623/0.32847. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.17338/0.30983. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.17479/0.33404. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.17469/0.31211. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.17203/0.32726. Took 0.14 sec\n",
      "Epoch 69, Loss(train/val) 0.18366/0.34093. Took 0.15 sec\n",
      "Epoch 70, Loss(train/val) 0.17384/0.33277. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.17220/0.33635. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.17131/0.35439. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.16985/0.33437. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.17054/0.32648. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) 0.17227/0.34675. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.16672/0.34643. Took 0.15 sec\n",
      "Epoch 77, Loss(train/val) 0.16316/0.34601. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.15845/0.36326. Took 0.14 sec\n",
      "Epoch 79, Loss(train/val) 0.15803/0.35325. Took 0.15 sec\n",
      "Epoch 80, Loss(train/val) 0.16248/0.36850. Took 0.14 sec\n",
      "Epoch 81, Loss(train/val) 0.16348/0.34555. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.16460/0.33750. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.15751/0.36568. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.17071/0.35097. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.17189/0.36052. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.16245/0.35970. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.15459/0.34844. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.15752/0.35493. Took 0.14 sec\n",
      "Epoch 89, Loss(train/val) 0.14562/0.36052. Took 0.15 sec\n",
      "Epoch 90, Loss(train/val) 0.15909/0.37063. Took 0.14 sec\n",
      "Epoch 91, Loss(train/val) 0.15551/0.36255. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.15088/0.37500. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.15157/0.35883. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.15262/0.38712. Took 0.14 sec\n",
      "Epoch 95, Loss(train/val) 0.14381/0.36551. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.14493/0.36614. Took 0.14 sec\n",
      "Epoch 97, Loss(train/val) 0.14440/0.39257. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.14295/0.35122. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.14860/0.39460. Took 0.13 sec\n",
      "ACC: 0.6875, MCC: 0.4109749995082186\n",
      "Epoch 0, Loss(train/val) 0.49348/0.48779. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.47132/0.45938. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.43570/0.41295. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.40343/0.37681. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.38419/0.35858. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.37167/0.35828. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.36189/0.35187. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.35348/0.34710. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.33580/0.35203. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.32611/0.34603. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.31657/0.35385. Took 0.15 sec\n",
      "Epoch 11, Loss(train/val) 0.30766/0.35093. Took 0.16 sec\n",
      "Epoch 12, Loss(train/val) 0.31829/0.37222. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.31450/0.34247. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.31634/0.35252. Took 0.16 sec\n",
      "Epoch 15, Loss(train/val) 0.29631/0.37546. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.29412/0.37757. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.28894/0.35610. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.27917/0.33421. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.28596/0.34034. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.28888/0.34379. Took 0.16 sec\n",
      "Epoch 21, Loss(train/val) 0.27972/0.36858. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.27641/0.37001. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.27713/0.34619. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.27153/0.35795. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.26670/0.34495. Took 0.16 sec\n",
      "Epoch 26, Loss(train/val) 0.25642/0.35594. Took 0.15 sec\n",
      "Epoch 27, Loss(train/val) 0.25619/0.34929. Took 0.13 sec\n",
      "Epoch 28, Loss(train/val) 0.26055/0.36795. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.27300/0.35221. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.25628/0.37958. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.25885/0.38328. Took 0.16 sec\n",
      "Epoch 32, Loss(train/val) 0.25418/0.37388. Took 0.17 sec\n",
      "Epoch 33, Loss(train/val) 0.24198/0.35293. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.25494/0.35791. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.24686/0.35972. Took 0.15 sec\n",
      "Epoch 36, Loss(train/val) 0.24344/0.34662. Took 0.18 sec\n",
      "Epoch 37, Loss(train/val) 0.23374/0.37472. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.22169/0.37182. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.24117/0.37107. Took 0.15 sec\n",
      "Epoch 40, Loss(train/val) 0.25046/0.37797. Took 0.16 sec\n",
      "Epoch 41, Loss(train/val) 0.23655/0.37145. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.22526/0.37267. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.22506/0.38122. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.21955/0.37465. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) 0.22102/0.37087. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.21930/0.35691. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.21379/0.36200. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.21837/0.36650. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.22203/0.38076. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.22707/0.36157. Took 0.14 sec\n",
      "Epoch 51, Loss(train/val) 0.22169/0.37272. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.20635/0.37274. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) 0.20972/0.35868. Took 0.15 sec\n",
      "Epoch 54, Loss(train/val) 0.21572/0.37693. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.19948/0.35636. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.20409/0.35009. Took 0.15 sec\n",
      "Epoch 57, Loss(train/val) 0.19884/0.36964. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.19696/0.35221. Took 0.14 sec\n",
      "Epoch 59, Loss(train/val) 0.20108/0.35493. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.19076/0.34210. Took 0.14 sec\n",
      "Epoch 61, Loss(train/val) 0.19509/0.36081. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.19709/0.36675. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.20061/0.37106. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.18758/0.32414. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.19623/0.34608. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.19199/0.36839. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) 0.18433/0.36209. Took 0.16 sec\n",
      "Epoch 68, Loss(train/val) 0.18942/0.36753. Took 0.14 sec\n",
      "Epoch 69, Loss(train/val) 0.18521/0.34094. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.18867/0.36747. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.17241/0.36675. Took 0.15 sec\n",
      "Epoch 72, Loss(train/val) 0.17791/0.35704. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.18401/0.37458. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.16712/0.35965. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) 0.18170/0.36049. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.17329/0.37805. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.17791/0.38635. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.18092/0.38781. Took 0.14 sec\n",
      "Epoch 79, Loss(train/val) 0.17974/0.37249. Took 0.15 sec\n",
      "Epoch 80, Loss(train/val) 0.16659/0.33895. Took 0.14 sec\n",
      "Epoch 81, Loss(train/val) 0.15993/0.36957. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.15857/0.35528. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) 0.16223/0.36494. Took 0.15 sec\n",
      "Epoch 84, Loss(train/val) 0.16745/0.36473. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.16133/0.37642. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.16721/0.35796. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.16486/0.36821. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.17384/0.36446. Took 0.14 sec\n",
      "Epoch 89, Loss(train/val) 0.16944/0.37121. Took 0.15 sec\n",
      "Epoch 90, Loss(train/val) 0.16561/0.36966. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.15761/0.35735. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.15883/0.35434. Took 0.15 sec\n",
      "Epoch 93, Loss(train/val) 0.15445/0.36196. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.15274/0.37344. Took 0.14 sec\n",
      "Epoch 95, Loss(train/val) 0.15643/0.37652. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.14462/0.35778. Took 0.14 sec\n",
      "Epoch 97, Loss(train/val) 0.15247/0.39416. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.14583/0.38830. Took 0.14 sec\n",
      "Epoch 99, Loss(train/val) 0.16288/0.36606. Took 0.13 sec\n",
      "ACC: 0.703125, MCC: 0.40572253759682037\n",
      "Epoch 0, Loss(train/val) 0.49189/0.47883. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.46390/0.44204. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.42296/0.40358. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.38899/0.36832. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.37134/0.34671. Took 0.15 sec\n",
      "Epoch 5, Loss(train/val) 0.35874/0.34088. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.35529/0.34352. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.34357/0.33576. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.33669/0.33584. Took 0.15 sec\n",
      "Epoch 9, Loss(train/val) 0.32770/0.33554. Took 0.15 sec\n",
      "Epoch 10, Loss(train/val) 0.31363/0.35648. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.31072/0.34839. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.30911/0.34596. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.29440/0.31649. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.28845/0.32207. Took 0.17 sec\n",
      "Epoch 15, Loss(train/val) 0.26966/0.32598. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.27817/0.31134. Took 0.15 sec\n",
      "Epoch 17, Loss(train/val) 0.27743/0.31042. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.26772/0.31925. Took 0.15 sec\n",
      "Epoch 19, Loss(train/val) 0.25186/0.32246. Took 0.15 sec\n",
      "Epoch 20, Loss(train/val) 0.25007/0.31061. Took 0.15 sec\n",
      "Epoch 21, Loss(train/val) 0.26079/0.31612. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.25118/0.31133. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.24842/0.30920. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.24278/0.32115. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.23650/0.32791. Took 0.16 sec\n",
      "Epoch 26, Loss(train/val) 0.22379/0.31207. Took 0.15 sec\n",
      "Epoch 27, Loss(train/val) 0.23924/0.32737. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.23167/0.32789. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.23233/0.31769. Took 0.16 sec\n",
      "Epoch 30, Loss(train/val) 0.23014/0.32336. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.22444/0.32507. Took 0.16 sec\n",
      "Epoch 32, Loss(train/val) 0.21514/0.32360. Took 0.18 sec\n",
      "Epoch 33, Loss(train/val) 0.21397/0.31935. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.21838/0.32100. Took 0.16 sec\n",
      "Epoch 35, Loss(train/val) 0.21578/0.32720. Took 0.15 sec\n",
      "Epoch 36, Loss(train/val) 0.21716/0.31960. Took 0.17 sec\n",
      "Epoch 37, Loss(train/val) 0.21344/0.31260. Took 0.15 sec\n",
      "Epoch 38, Loss(train/val) 0.20253/0.31442. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.19437/0.31149. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.19541/0.30918. Took 0.15 sec\n",
      "Epoch 41, Loss(train/val) 0.20385/0.30428. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.21298/0.31104. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.20533/0.31878. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.20274/0.32041. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) 0.19467/0.32248. Took 0.15 sec\n",
      "Epoch 46, Loss(train/val) 0.19093/0.32262. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.19208/0.31214. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.19126/0.32723. Took 0.15 sec\n",
      "Epoch 49, Loss(train/val) 0.19381/0.31203. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.18474/0.32947. Took 0.14 sec\n",
      "Epoch 51, Loss(train/val) 0.18932/0.31426. Took 0.15 sec\n",
      "Epoch 52, Loss(train/val) 0.17836/0.32069. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) 0.17737/0.31119. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.17955/0.31874. Took 0.16 sec\n",
      "Epoch 55, Loss(train/val) 0.17687/0.30979. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.17473/0.30459. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.18900/0.31485. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.19018/0.32110. Took 0.14 sec\n",
      "Epoch 59, Loss(train/val) 0.17903/0.32366. Took 0.15 sec\n",
      "Epoch 60, Loss(train/val) 0.17002/0.31074. Took 0.14 sec\n",
      "Epoch 61, Loss(train/val) 0.16808/0.31001. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.16885/0.32380. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.16294/0.31541. Took 0.15 sec\n",
      "Epoch 64, Loss(train/val) 0.16134/0.30369. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.16254/0.30752. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.16348/0.30603. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) 0.15657/0.30588. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.16050/0.31367. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.15658/0.32123. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.15760/0.31012. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.16429/0.32373. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.15718/0.31243. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.14995/0.32405. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.15494/0.32647. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) 0.14998/0.32190. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.14906/0.31899. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.15524/0.32363. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.16112/0.34450. Took 0.14 sec\n",
      "Epoch 79, Loss(train/val) 0.14660/0.33650. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.15227/0.32798. Took 0.14 sec\n",
      "Epoch 81, Loss(train/val) 0.14845/0.32795. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.14107/0.32430. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.14444/0.33879. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.14356/0.32957. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.13711/0.31861. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.14302/0.31252. Took 0.15 sec\n",
      "Epoch 87, Loss(train/val) 0.14430/0.32189. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.15501/0.33611. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.14037/0.32265. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.14390/0.32860. Took 0.14 sec\n",
      "Epoch 91, Loss(train/val) 0.13105/0.33508. Took 0.15 sec\n",
      "Epoch 92, Loss(train/val) 0.13465/0.34600. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.14477/0.32809. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.13793/0.33120. Took 0.14 sec\n",
      "Epoch 95, Loss(train/val) 0.13901/0.32424. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.13211/0.31256. Took 0.14 sec\n",
      "Epoch 97, Loss(train/val) 0.13045/0.32647. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.13707/0.32111. Took 0.14 sec\n",
      "Epoch 99, Loss(train/val) 0.13136/0.33510. Took 0.15 sec\n",
      "ACC: 0.765625, MCC: 0.49660854465066007\n",
      "Epoch 0, Loss(train/val) 0.49529/0.46825. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.47350/0.40586. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.43538/0.35339. Took 0.15 sec\n",
      "Epoch 3, Loss(train/val) 0.39984/0.32837. Took 0.15 sec\n",
      "Epoch 4, Loss(train/val) 0.37937/0.31197. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.36987/0.30627. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.36218/0.29654. Took 0.15 sec\n",
      "Epoch 7, Loss(train/val) 0.35096/0.28764. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.33945/0.29220. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.33148/0.26683. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.31867/0.27184. Took 0.15 sec\n",
      "Epoch 11, Loss(train/val) 0.31521/0.26882. Took 0.15 sec\n",
      "Epoch 12, Loss(train/val) 0.31142/0.27191. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.30280/0.25199. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.30376/0.24606. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.29022/0.26873. Took 0.17 sec\n",
      "Epoch 16, Loss(train/val) 0.30152/0.28141. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.30738/0.27279. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.29293/0.25283. Took 0.17 sec\n",
      "Epoch 19, Loss(train/val) 0.28794/0.24334. Took 0.15 sec\n",
      "Epoch 20, Loss(train/val) 0.27733/0.24166. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.27484/0.23807. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.27884/0.24460. Took 0.16 sec\n",
      "Epoch 23, Loss(train/val) 0.27674/0.22108. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.27027/0.22469. Took 0.15 sec\n",
      "Epoch 25, Loss(train/val) 0.27024/0.21631. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.26217/0.22888. Took 0.15 sec\n",
      "Epoch 27, Loss(train/val) 0.25748/0.22572. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.25927/0.23849. Took 0.17 sec\n",
      "Epoch 29, Loss(train/val) 0.26253/0.20475. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.25832/0.23505. Took 0.17 sec\n",
      "Epoch 31, Loss(train/val) 0.26180/0.22960. Took 0.16 sec\n",
      "Epoch 32, Loss(train/val) 0.25351/0.21012. Took 0.17 sec\n",
      "Epoch 33, Loss(train/val) 0.25353/0.21047. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.24538/0.22898. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.25047/0.25366. Took 0.17 sec\n",
      "Epoch 36, Loss(train/val) 0.25449/0.21966. Took 0.16 sec\n",
      "Epoch 37, Loss(train/val) 0.24190/0.21652. Took 0.15 sec\n",
      "Epoch 38, Loss(train/val) 0.24731/0.23115. Took 0.18 sec\n",
      "Epoch 39, Loss(train/val) 0.24772/0.24776. Took 0.19 sec\n",
      "Epoch 40, Loss(train/val) 0.23727/0.22005. Took 0.15 sec\n",
      "Epoch 41, Loss(train/val) 0.24249/0.22475. Took 0.16 sec\n",
      "Epoch 42, Loss(train/val) 0.22530/0.21389. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.23328/0.21120. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.23367/0.20764. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.22789/0.21680. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.23080/0.22439. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.24143/0.25492. Took 0.15 sec\n",
      "Epoch 48, Loss(train/val) 0.22603/0.28729. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.25602/0.27289. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.23713/0.27544. Took 0.14 sec\n",
      "Epoch 51, Loss(train/val) 0.23807/0.28355. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.23476/0.30332. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) 0.22752/0.28064. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.22147/0.28336. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.21656/0.27579. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.22593/0.26596. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.21181/0.29009. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.22085/0.28723. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.22360/0.27833. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.21817/0.29716. Took 0.14 sec\n",
      "Epoch 61, Loss(train/val) 0.21692/0.27008. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.21393/0.28104. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.21416/0.30510. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.20930/0.28184. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.21644/0.30000. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.21442/0.29447. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) 0.20353/0.27883. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.21300/0.27928. Took 0.14 sec\n",
      "Epoch 69, Loss(train/val) 0.21942/0.27985. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.20581/0.28680. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.20606/0.29803. Took 0.15 sec\n",
      "Epoch 72, Loss(train/val) 0.20856/0.25048. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.21188/0.23964. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.20869/0.28736. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) 0.20802/0.28671. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.21580/0.25945. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.20474/0.29967. Took 0.15 sec\n",
      "Epoch 78, Loss(train/val) 0.20525/0.30411. Took 0.14 sec\n",
      "Epoch 79, Loss(train/val) 0.19562/0.29116. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.19834/0.29151. Took 0.14 sec\n",
      "Epoch 81, Loss(train/val) 0.20056/0.30733. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.19557/0.30538. Took 0.15 sec\n",
      "Epoch 83, Loss(train/val) 0.19483/0.30068. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.19834/0.29153. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.20156/0.30323. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.18674/0.29704. Took 0.15 sec\n",
      "Epoch 87, Loss(train/val) 0.19088/0.29914. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.19740/0.30592. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.19609/0.30557. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.18795/0.31262. Took 0.14 sec\n",
      "Epoch 91, Loss(train/val) 0.19019/0.30309. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.18742/0.31048. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.19832/0.30351. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.18506/0.31160. Took 0.15 sec\n",
      "Epoch 95, Loss(train/val) 0.18579/0.28463. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.19210/0.27313. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.19026/0.30191. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.18491/0.27244. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.21459/0.30423. Took 0.13 sec\n",
      "ACC: 0.734375, MCC: 0.46584907198285247\n",
      "Epoch 0, Loss(train/val) 0.48958/0.48553. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.46096/0.46335. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.42004/0.42904. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.38878/0.39991. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.37631/0.39640. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.36908/0.36865. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.35876/0.31403. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.35564/0.32029. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.34770/0.27899. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.34135/0.26355. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.33515/0.26910. Took 0.15 sec\n",
      "Epoch 11, Loss(train/val) 0.33075/0.22914. Took 0.15 sec\n",
      "Epoch 12, Loss(train/val) 0.32225/0.25462. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.32149/0.23148. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.31489/0.25773. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.30740/0.25149. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.29454/0.24342. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.28726/0.26221. Took 0.16 sec\n",
      "Epoch 18, Loss(train/val) 0.28217/0.25896. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.27553/0.26904. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.27030/0.24688. Took 0.15 sec\n",
      "Epoch 21, Loss(train/val) 0.26748/0.25894. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.26456/0.25216. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.26077/0.26874. Took 0.16 sec\n",
      "Epoch 24, Loss(train/val) 0.25134/0.27595. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.24472/0.27882. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.24341/0.24816. Took 0.15 sec\n",
      "Epoch 27, Loss(train/val) 0.25692/0.27975. Took 0.16 sec\n",
      "Epoch 28, Loss(train/val) 0.24577/0.27371. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.23512/0.26995. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.24600/0.26317. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.24253/0.28214. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.23699/0.29059. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.22909/0.27192. Took 0.17 sec\n",
      "Epoch 34, Loss(train/val) 0.23173/0.27176. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.22761/0.29033. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.23214/0.29400. Took 0.17 sec\n",
      "Epoch 37, Loss(train/val) 0.22336/0.25502. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.22387/0.24115. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.22355/0.26830. Took 0.15 sec\n",
      "Epoch 40, Loss(train/val) 0.21433/0.28246. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.22134/0.29021. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.21847/0.28567. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.20955/0.29736. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.20608/0.31649. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.20390/0.26981. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.20512/0.30368. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.21291/0.28222. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.20456/0.30851. Took 0.15 sec\n",
      "Epoch 49, Loss(train/val) 0.20137/0.31061. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.19877/0.30911. Took 0.14 sec\n",
      "Epoch 51, Loss(train/val) 0.20016/0.30493. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.19409/0.31242. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) 0.19684/0.31935. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.19361/0.31164. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.19353/0.31293. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.19120/0.29920. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.19224/0.30009. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.18738/0.31082. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.20103/0.31127. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.18987/0.33155. Took 0.15 sec\n",
      "Epoch 61, Loss(train/val) 0.19823/0.30966. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.18011/0.31905. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.18861/0.30620. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.18973/0.30432. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.17928/0.28609. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.18393/0.29825. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) 0.17932/0.30790. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.17648/0.28786. Took 0.14 sec\n",
      "Epoch 69, Loss(train/val) 0.18020/0.28859. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.17348/0.28028. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.17329/0.30433. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.17757/0.27884. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.17061/0.27753. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.16997/0.28965. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.17079/0.28359. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.16777/0.26154. Took 0.15 sec\n",
      "Epoch 77, Loss(train/val) 0.16623/0.26795. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.16550/0.31421. Took 0.14 sec\n",
      "Epoch 79, Loss(train/val) 0.17148/0.30858. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.17211/0.28787. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.16917/0.31728. Took 0.15 sec\n",
      "Epoch 82, Loss(train/val) 0.16312/0.27650. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) 0.16826/0.29653. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.16625/0.28623. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.16666/0.31892. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.15905/0.32821. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.16377/0.35361. Took 0.15 sec\n",
      "Epoch 88, Loss(train/val) 0.15489/0.34381. Took 0.14 sec\n",
      "Epoch 89, Loss(train/val) 0.16703/0.33005. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.16471/0.29561. Took 0.15 sec\n",
      "Epoch 91, Loss(train/val) 0.16492/0.31985. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.15569/0.32291. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.15278/0.30638. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.14961/0.32900. Took 0.14 sec\n",
      "Epoch 95, Loss(train/val) 0.15561/0.34624. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.16153/0.30940. Took 0.14 sec\n",
      "Epoch 97, Loss(train/val) 0.15587/0.32215. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.15301/0.35898. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.15324/0.37406. Took 0.14 sec\n",
      "ACC: 0.65625, MCC: 0.3227486121839514\n",
      "Epoch 0, Loss(train/val) 0.49214/0.48767. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.46796/0.46104. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.43158/0.42549. Took 0.15 sec\n",
      "Epoch 3, Loss(train/val) 0.39225/0.39914. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.37185/0.37646. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.35482/0.34782. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.34166/0.35730. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.32711/0.36192. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.32382/0.32718. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.31556/0.34321. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.31252/0.33673. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.31097/0.32659. Took 0.16 sec\n",
      "Epoch 12, Loss(train/val) 0.29570/0.33179. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.28516/0.33644. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.27776/0.34693. Took 0.15 sec\n",
      "Epoch 15, Loss(train/val) 0.28753/0.33647. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.28231/0.35825. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.27799/0.34500. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.26829/0.32453. Took 0.15 sec\n",
      "Epoch 19, Loss(train/val) 0.26862/0.34381. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.26742/0.36992. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.27482/0.33710. Took 0.16 sec\n",
      "Epoch 22, Loss(train/val) 0.25796/0.35312. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.25764/0.35545. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.25144/0.36010. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.24573/0.36081. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.24609/0.36593. Took 0.15 sec\n",
      "Epoch 27, Loss(train/val) 0.24909/0.37096. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.24969/0.34033. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.23785/0.35618. Took 0.16 sec\n",
      "Epoch 30, Loss(train/val) 0.24782/0.35199. Took 0.16 sec\n",
      "Epoch 31, Loss(train/val) 0.24313/0.34595. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.23554/0.34816. Took 0.17 sec\n",
      "Epoch 33, Loss(train/val) 0.24257/0.37015. Took 0.16 sec\n",
      "Epoch 34, Loss(train/val) 0.25502/0.37271. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.24482/0.36192. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.22907/0.34941. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.23462/0.36994. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.22567/0.36706. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.22304/0.37227. Took 0.15 sec\n",
      "Epoch 40, Loss(train/val) 0.21852/0.35014. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.23014/0.35919. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.23127/0.34908. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.22673/0.33510. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.21692/0.34892. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) 0.21885/0.34008. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.20896/0.34473. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.21333/0.36697. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.22102/0.36292. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.21521/0.35246. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.21349/0.36539. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.22306/0.35646. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.21949/0.34611. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) 0.21192/0.35821. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.21013/0.33894. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.20355/0.33971. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.21119/0.36342. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.20383/0.34688. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.20559/0.35939. Took 0.15 sec\n",
      "Epoch 59, Loss(train/val) 0.20410/0.36275. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.19969/0.32102. Took 0.14 sec\n",
      "Epoch 61, Loss(train/val) 0.19440/0.33638. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.19661/0.33639. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.19524/0.33154. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.20526/0.33866. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.20120/0.33021. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.19542/0.34002. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) 0.19442/0.34345. Took 0.15 sec\n",
      "Epoch 68, Loss(train/val) 0.18970/0.34291. Took 0.14 sec\n",
      "Epoch 69, Loss(train/val) 0.18877/0.34115. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.19112/0.33299. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.18731/0.32446. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.19015/0.32726. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.18702/0.34240. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.18920/0.33500. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) 0.18414/0.31510. Took 0.15 sec\n",
      "Epoch 76, Loss(train/val) 0.18753/0.32403. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.18703/0.33810. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.17799/0.33856. Took 0.14 sec\n",
      "Epoch 79, Loss(train/val) 0.17521/0.33145. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.17966/0.30363. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.17495/0.31773. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.17531/0.32443. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) 0.18085/0.32658. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.17739/0.33327. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.17075/0.33382. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.17467/0.34856. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.17407/0.34494. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.17595/0.34189. Took 0.14 sec\n",
      "Epoch 89, Loss(train/val) 0.16724/0.32928. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.16729/0.33177. Took 0.14 sec\n",
      "Epoch 91, Loss(train/val) 0.16856/0.30983. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.16970/0.32457. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.16521/0.31336. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.16657/0.30221. Took 0.15 sec\n",
      "Epoch 95, Loss(train/val) 0.16450/0.30842. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.15581/0.31173. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.16391/0.32579. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.16543/0.31855. Took 0.14 sec\n",
      "Epoch 99, Loss(train/val) 0.15907/0.29613. Took 0.14 sec\n",
      "ACC: 0.578125, MCC: 0.2073870882883376\n",
      "Epoch 0, Loss(train/val) 0.49258/0.48322. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.47004/0.45820. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.43111/0.42003. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.39613/0.39994. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.38022/0.39947. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.36677/0.39531. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.35900/0.39615. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.35144/0.41148. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.34043/0.40355. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.33349/0.39804. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.32529/0.41540. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.30632/0.39769. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.30775/0.40515. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.30251/0.40749. Took 0.16 sec\n",
      "Epoch 14, Loss(train/val) 0.30149/0.38903. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.30088/0.40530. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.28860/0.40915. Took 0.15 sec\n",
      "Epoch 17, Loss(train/val) 0.28034/0.39045. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.27393/0.37711. Took 0.15 sec\n",
      "Epoch 19, Loss(train/val) 0.27930/0.39196. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.27360/0.38343. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.27833/0.39910. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.27060/0.41148. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.24772/0.38344. Took 0.16 sec\n",
      "Epoch 24, Loss(train/val) 0.26544/0.40811. Took 0.15 sec\n",
      "Epoch 25, Loss(train/val) 0.25942/0.40801. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.26036/0.37423. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.26123/0.41533. Took 0.16 sec\n",
      "Epoch 28, Loss(train/val) 0.25314/0.40927. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.24841/0.41157. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.24435/0.41280. Took 0.17 sec\n",
      "Epoch 31, Loss(train/val) 0.23903/0.40138. Took 0.17 sec\n",
      "Epoch 32, Loss(train/val) 0.24999/0.40066. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.24873/0.38626. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.24770/0.40572. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.24070/0.39421. Took 0.16 sec\n",
      "Epoch 36, Loss(train/val) 0.23942/0.40041. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.23146/0.39971. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.23160/0.39945. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.22596/0.41630. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.22506/0.39655. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.21899/0.40871. Took 0.15 sec\n",
      "Epoch 42, Loss(train/val) 0.22885/0.39067. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.21997/0.39769. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.22500/0.41576. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) 0.22458/0.39718. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.21758/0.42119. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.21295/0.42274. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.21117/0.42737. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.20208/0.39330. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.20788/0.38791. Took 0.14 sec\n",
      "Epoch 51, Loss(train/val) 0.21700/0.43746. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.20101/0.42635. Took 0.15 sec\n",
      "Epoch 53, Loss(train/val) 0.19735/0.46533. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.20587/0.45400. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.20380/0.42621. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.19234/0.45927. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.19567/0.44448. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.19113/0.45665. Took 0.14 sec\n",
      "Epoch 59, Loss(train/val) 0.18935/0.45019. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.18202/0.46075. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.18585/0.46280. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.18260/0.46277. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.18021/0.46349. Took 0.15 sec\n",
      "Epoch 64, Loss(train/val) 0.17840/0.45811. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.18291/0.48877. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.17886/0.47381. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) 0.19328/0.46686. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.18227/0.46736. Took 0.14 sec\n",
      "Epoch 69, Loss(train/val) 0.17850/0.49600. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.16662/0.47303. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.16086/0.46511. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.17167/0.48795. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.15913/0.47605. Took 0.15 sec\n",
      "Epoch 74, Loss(train/val) 0.17092/0.48243. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.16764/0.48278. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.16356/0.46893. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.17526/0.45790. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.17363/0.47710. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.16323/0.47458. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.15623/0.48359. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.15848/0.48583. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.16062/0.48515. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) 0.15616/0.48376. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.15261/0.46613. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.14744/0.48459. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.14912/0.47139. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.14460/0.48063. Took 0.15 sec\n",
      "Epoch 88, Loss(train/val) 0.15736/0.47986. Took 0.14 sec\n",
      "Epoch 89, Loss(train/val) 0.14585/0.46954. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.14292/0.47060. Took 0.14 sec\n",
      "Epoch 91, Loss(train/val) 0.14607/0.45924. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.14324/0.46936. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.14657/0.47664. Took 0.15 sec\n",
      "Epoch 94, Loss(train/val) 0.13982/0.48214. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.13806/0.47723. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.14728/0.44971. Took 0.14 sec\n",
      "Epoch 97, Loss(train/val) 0.14086/0.47108. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.13799/0.46460. Took 0.14 sec\n",
      "Epoch 99, Loss(train/val) 0.14184/0.46985. Took 0.13 sec\n",
      "ACC: 0.671875, MCC: 0.35861276178747237\n",
      "Epoch 0, Loss(train/val) 0.49638/0.48847. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.47725/0.46123. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.43920/0.42252. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.39644/0.39913. Took 0.15 sec\n",
      "Epoch 4, Loss(train/val) 0.37109/0.38411. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.35583/0.37690. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.34321/0.36315. Took 0.15 sec\n",
      "Epoch 7, Loss(train/val) 0.33176/0.35230. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.33396/0.35164. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.31640/0.32488. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.32715/0.38132. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.32215/0.37031. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.31353/0.37391. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.30276/0.36113. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.30205/0.37816. Took 0.15 sec\n",
      "Epoch 15, Loss(train/val) 0.29108/0.38079. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.29601/0.37437. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.28251/0.34681. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.28999/0.36575. Took 0.16 sec\n",
      "Epoch 19, Loss(train/val) 0.28750/0.34893. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.29483/0.39960. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.28659/0.34951. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.27933/0.38887. Took 0.15 sec\n",
      "Epoch 23, Loss(train/val) 0.27100/0.35661. Took 0.16 sec\n",
      "Epoch 24, Loss(train/val) 0.28675/0.38841. Took 0.15 sec\n",
      "Epoch 25, Loss(train/val) 0.27813/0.40856. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.27787/0.36972. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.27252/0.39497. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.26330/0.41080. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.25595/0.40122. Took 0.16 sec\n",
      "Epoch 30, Loss(train/val) 0.26282/0.39066. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.26239/0.40778. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.26337/0.38631. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.25151/0.39747. Took 0.16 sec\n",
      "Epoch 34, Loss(train/val) 0.24462/0.37777. Took 0.17 sec\n",
      "Epoch 35, Loss(train/val) 0.24743/0.37277. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.24011/0.37683. Took 0.17 sec\n",
      "Epoch 37, Loss(train/val) 0.23715/0.38899. Took 0.15 sec\n",
      "Epoch 38, Loss(train/val) 0.24236/0.38499. Took 0.15 sec\n",
      "Epoch 39, Loss(train/val) 0.23039/0.34373. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.23684/0.38637. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.23908/0.40010. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.23090/0.36351. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.23779/0.35276. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.23331/0.34391. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) 0.24931/0.38244. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.22054/0.36645. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.22905/0.35759. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.22008/0.35020. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.21439/0.37651. Took 0.15 sec\n",
      "Epoch 50, Loss(train/val) 0.21888/0.36894. Took 0.14 sec\n",
      "Epoch 51, Loss(train/val) 0.21284/0.37209. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.21642/0.37390. Took 0.15 sec\n",
      "Epoch 53, Loss(train/val) 0.21446/0.38214. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.20635/0.42175. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.21741/0.37339. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.20687/0.39611. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.20011/0.37557. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.20603/0.37377. Took 0.14 sec\n",
      "Epoch 59, Loss(train/val) 0.20356/0.39290. Took 0.15 sec\n",
      "Epoch 60, Loss(train/val) 0.20260/0.38605. Took 0.14 sec\n",
      "Epoch 61, Loss(train/val) 0.19846/0.41005. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.20460/0.39391. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.19793/0.39036. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.19885/0.37661. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.19679/0.40848. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.18814/0.40116. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) 0.18922/0.39974. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.19764/0.36847. Took 0.14 sec\n",
      "Epoch 69, Loss(train/val) 0.19072/0.40461. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.18905/0.40342. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.18987/0.41765. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.19694/0.38928. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.20232/0.41159. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.19216/0.38908. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) 0.17631/0.39431. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.18722/0.39840. Took 0.15 sec\n",
      "Epoch 77, Loss(train/val) 0.19367/0.38974. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.18710/0.39134. Took 0.14 sec\n",
      "Epoch 79, Loss(train/val) 0.18304/0.37897. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.18356/0.38871. Took 0.14 sec\n",
      "Epoch 81, Loss(train/val) 0.18694/0.37983. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.18724/0.38179. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) 0.18636/0.38541. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.19083/0.39047. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.18106/0.40607. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.17885/0.38666. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.18392/0.38963. Took 0.15 sec\n",
      "Epoch 88, Loss(train/val) 0.17441/0.39993. Took 0.14 sec\n",
      "Epoch 89, Loss(train/val) 0.17824/0.37573. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.17643/0.39365. Took 0.14 sec\n",
      "Epoch 91, Loss(train/val) 0.18330/0.38204. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.17692/0.40059. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.17782/0.39281. Took 0.15 sec\n",
      "Epoch 94, Loss(train/val) 0.17239/0.40081. Took 0.14 sec\n",
      "Epoch 95, Loss(train/val) 0.17034/0.36312. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.18389/0.40027. Took 0.14 sec\n",
      "Epoch 97, Loss(train/val) 0.18436/0.36844. Took 0.15 sec\n",
      "Epoch 98, Loss(train/val) 0.17039/0.39920. Took 0.14 sec\n",
      "Epoch 99, Loss(train/val) 0.16788/0.37343. Took 0.13 sec\n",
      "ACC: 0.625, MCC: 0.24305875451990117\n",
      "Epoch 0, Loss(train/val) 0.49480/0.49449. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.47681/0.48085. Took 0.15 sec\n",
      "Epoch 2, Loss(train/val) 0.44589/0.46494. Took 0.16 sec\n",
      "Epoch 3, Loss(train/val) 0.41219/0.46192. Took 0.16 sec\n",
      "Epoch 4, Loss(train/val) 0.39276/0.46179. Took 0.15 sec\n",
      "Epoch 5, Loss(train/val) 0.38254/0.45711. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.37156/0.45324. Took 0.17 sec\n",
      "Epoch 7, Loss(train/val) 0.36104/0.40503. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.36445/0.42773. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.35453/0.42634. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.34697/0.38104. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.33550/0.40652. Took 0.15 sec\n",
      "Epoch 12, Loss(train/val) 0.32421/0.41172. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.31759/0.38307. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.31411/0.38835. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.30815/0.36566. Took 0.16 sec\n",
      "Epoch 16, Loss(train/val) 0.30132/0.35452. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.29880/0.35180. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.28564/0.34779. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.29123/0.37333. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.28098/0.40729. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.28479/0.37918. Took 0.16 sec\n",
      "Epoch 22, Loss(train/val) 0.28246/0.35003. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.27392/0.39391. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.27342/0.44732. Took 0.16 sec\n",
      "Epoch 25, Loss(train/val) 0.27990/0.40550. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.26011/0.37803. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.26615/0.37029. Took 0.16 sec\n",
      "Epoch 28, Loss(train/val) 0.26346/0.38619. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.24976/0.37645. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.25715/0.41078. Took 0.17 sec\n",
      "Epoch 31, Loss(train/val) 0.24197/0.40372. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.25406/0.37857. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.24173/0.39828. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.24272/0.38334. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.24377/0.39510. Took 0.15 sec\n",
      "Epoch 36, Loss(train/val) 0.24491/0.38405. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.22727/0.38342. Took 0.15 sec\n",
      "Epoch 38, Loss(train/val) 0.23038/0.34268. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.22009/0.40637. Took 0.16 sec\n",
      "Epoch 40, Loss(train/val) 0.22705/0.42421. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.22232/0.40509. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.22198/0.39620. Took 0.15 sec\n",
      "Epoch 43, Loss(train/val) 0.22289/0.38153. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.22185/0.42281. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.21184/0.42180. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.20426/0.43701. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.21866/0.45036. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.21357/0.47620. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.19552/0.43631. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.20721/0.46355. Took 0.14 sec\n",
      "Epoch 51, Loss(train/val) 0.19673/0.48265. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.19652/0.48115. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) 0.19593/0.45408. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.19027/0.43178. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.19830/0.48573. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.19196/0.45057. Took 0.15 sec\n",
      "Epoch 57, Loss(train/val) 0.18317/0.45564. Took 0.15 sec\n",
      "Epoch 58, Loss(train/val) 0.18773/0.48738. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.18422/0.47083. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.19320/0.49287. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.17973/0.45933. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.18015/0.46353. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.17223/0.42329. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.17762/0.45197. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.16756/0.42205. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.17818/0.44793. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) 0.15719/0.45014. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.17140/0.43390. Took 0.14 sec\n",
      "Epoch 69, Loss(train/val) 0.17733/0.43498. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.16801/0.41631. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.17389/0.45214. Took 0.15 sec\n",
      "Epoch 72, Loss(train/val) 0.16985/0.45871. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.15878/0.45790. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.16750/0.44689. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.15370/0.45312. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.16151/0.43413. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.15664/0.48317. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.15132/0.44914. Took 0.14 sec\n",
      "Epoch 79, Loss(train/val) 0.15375/0.46973. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.14931/0.45361. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.15263/0.44315. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.15829/0.44005. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) 0.16025/0.50010. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.14736/0.46873. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.15267/0.44555. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.15507/0.43198. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.14241/0.46646. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.15154/0.48044. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.14783/0.46152. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.14815/0.48842. Took 0.14 sec\n",
      "Epoch 91, Loss(train/val) 0.14447/0.51052. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.14733/0.46318. Took 0.15 sec\n",
      "Epoch 93, Loss(train/val) 0.14008/0.48821. Took 0.15 sec\n",
      "Epoch 94, Loss(train/val) 0.15014/0.44970. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.14067/0.51322. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.14070/0.51490. Took 0.14 sec\n",
      "Epoch 97, Loss(train/val) 0.13978/0.48709. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.13281/0.50758. Took 0.14 sec\n",
      "Epoch 99, Loss(train/val) 0.13614/0.46069. Took 0.14 sec\n",
      "ACC: 0.609375, MCC: 0.21796176586341726\n",
      "Epoch 0, Loss(train/val) 0.49412/0.49292. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.47122/0.47733. Took 0.15 sec\n",
      "Epoch 2, Loss(train/val) 0.43479/0.45128. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.40235/0.44688. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.38414/0.43360. Took 0.15 sec\n",
      "Epoch 5, Loss(train/val) 0.37145/0.42068. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.36080/0.41933. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.34749/0.40929. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.33742/0.42242. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.32850/0.40633. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.32883/0.41151. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.31742/0.40232. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.31340/0.40361. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.30329/0.39930. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.30356/0.39680. Took 0.16 sec\n",
      "Epoch 15, Loss(train/val) 0.30288/0.39071. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.28917/0.38253. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.29624/0.42144. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.30718/0.42058. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.29928/0.41207. Took 0.16 sec\n",
      "Epoch 20, Loss(train/val) 0.29343/0.39740. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.28224/0.38800. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.27922/0.39572. Took 0.15 sec\n",
      "Epoch 23, Loss(train/val) 0.27679/0.38086. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.27779/0.38749. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.26541/0.38912. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.26438/0.41868. Took 0.15 sec\n",
      "Epoch 27, Loss(train/val) 0.26363/0.42814. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.25803/0.39222. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.25779/0.39195. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.25843/0.41708. Took 0.16 sec\n",
      "Epoch 31, Loss(train/val) 0.25102/0.42277. Took 0.16 sec\n",
      "Epoch 32, Loss(train/val) 0.24537/0.40785. Took 0.16 sec\n",
      "Epoch 33, Loss(train/val) 0.24460/0.42921. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.24296/0.42980. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.24640/0.44956. Took 0.16 sec\n",
      "Epoch 36, Loss(train/val) 0.23951/0.45741. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.23320/0.43060. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.22270/0.43696. Took 0.16 sec\n",
      "Epoch 39, Loss(train/val) 0.22355/0.44478. Took 0.15 sec\n",
      "Epoch 40, Loss(train/val) 0.23089/0.44239. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.21876/0.42923. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.21773/0.42169. Took 0.15 sec\n",
      "Epoch 43, Loss(train/val) 0.21478/0.41596. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.22399/0.42518. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) 0.22065/0.43465. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.20566/0.43681. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.21323/0.44053. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.21684/0.44403. Took 0.15 sec\n",
      "Epoch 49, Loss(train/val) 0.20735/0.45047. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.20322/0.45193. Took 0.14 sec\n",
      "Epoch 51, Loss(train/val) 0.20216/0.44079. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.20224/0.44446. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) 0.20458/0.44237. Took 0.15 sec\n",
      "Epoch 54, Loss(train/val) 0.19998/0.42709. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.20000/0.45808. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.19782/0.45513. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.20380/0.44307. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.19445/0.45017. Took 0.14 sec\n",
      "Epoch 59, Loss(train/val) 0.19384/0.46160. Took 0.15 sec\n",
      "Epoch 60, Loss(train/val) 0.18493/0.44491. Took 0.14 sec\n",
      "Epoch 61, Loss(train/val) 0.18831/0.42895. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.18332/0.43791. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.18912/0.44725. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.18335/0.44342. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.18255/0.45005. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.18408/0.44559. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) 0.17643/0.45025. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.17514/0.44855. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.17600/0.44443. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.17881/0.42880. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.17942/0.45440. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.16954/0.45831. Took 0.15 sec\n",
      "Epoch 73, Loss(train/val) 0.16371/0.44592. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.18092/0.43961. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.16652/0.45389. Took 0.15 sec\n",
      "Epoch 76, Loss(train/val) 0.16412/0.47911. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.16555/0.47003. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.17655/0.44668. Took 0.14 sec\n",
      "Epoch 79, Loss(train/val) 0.16294/0.47443. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.16115/0.47977. Took 0.14 sec\n",
      "Epoch 81, Loss(train/val) 0.15364/0.48013. Took 0.15 sec\n",
      "Epoch 82, Loss(train/val) 0.15800/0.46902. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) 0.15192/0.46212. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.15388/0.44819. Took 0.15 sec\n",
      "Epoch 85, Loss(train/val) 0.15299/0.47261. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.14804/0.45413. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.14277/0.44115. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.14760/0.43953. Took 0.14 sec\n",
      "Epoch 89, Loss(train/val) 0.15125/0.44637. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.14354/0.46132. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.15184/0.44831. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.14391/0.43926. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.13629/0.44919. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.14822/0.45021. Took 0.14 sec\n",
      "Epoch 95, Loss(train/val) 0.14212/0.45534. Took 0.15 sec\n",
      "Epoch 96, Loss(train/val) 0.13583/0.46407. Took 0.14 sec\n",
      "Epoch 97, Loss(train/val) 0.13974/0.47737. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.14655/0.44740. Took 0.14 sec\n",
      "Epoch 99, Loss(train/val) 0.14149/0.46382. Took 0.14 sec\n",
      "ACC: 0.734375, MCC: 0.5309883381788612\n",
      "Epoch 0, Loss(train/val) 0.49135/0.47406. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.46498/0.43419. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.42605/0.39053. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.39660/0.37484. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.38483/0.36236. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.37403/0.34414. Took 0.15 sec\n",
      "Epoch 6, Loss(train/val) 0.36704/0.33356. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.36117/0.32948. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.34701/0.33710. Took 0.15 sec\n",
      "Epoch 9, Loss(train/val) 0.33981/0.35464. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.32690/0.34929. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.31598/0.33008. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.30731/0.35895. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.30704/0.34625. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.30847/0.35134. Took 0.15 sec\n",
      "Epoch 15, Loss(train/val) 0.29041/0.34237. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.29461/0.34488. Took 0.15 sec\n",
      "Epoch 17, Loss(train/val) 0.28658/0.35273. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.27903/0.33776. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.27675/0.35494. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.27124/0.34180. Took 0.16 sec\n",
      "Epoch 21, Loss(train/val) 0.27078/0.33719. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.26568/0.33805. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.26064/0.34766. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.25402/0.33583. Took 0.15 sec\n",
      "Epoch 25, Loss(train/val) 0.25734/0.36373. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.25094/0.36645. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.24658/0.35575. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.25074/0.36674. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.25495/0.35324. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.24835/0.36064. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.23485/0.34598. Took 0.17 sec\n",
      "Epoch 32, Loss(train/val) 0.23326/0.35507. Took 0.16 sec\n",
      "Epoch 33, Loss(train/val) 0.23486/0.35370. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.22784/0.35987. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.22585/0.37125. Took 0.16 sec\n",
      "Epoch 36, Loss(train/val) 0.22956/0.36490. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.21993/0.34996. Took 0.15 sec\n",
      "Epoch 38, Loss(train/val) 0.21864/0.35811. Took 0.15 sec\n",
      "Epoch 39, Loss(train/val) 0.22152/0.36182. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.21101/0.34741. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.21309/0.35656. Took 0.15 sec\n",
      "Epoch 42, Loss(train/val) 0.21330/0.35482. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.21258/0.34113. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.20294/0.34726. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.20723/0.34663. Took 0.15 sec\n",
      "Epoch 46, Loss(train/val) 0.20627/0.34441. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.20163/0.36709. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.20502/0.41629. Took 0.15 sec\n",
      "Epoch 49, Loss(train/val) 0.20639/0.36387. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.20071/0.36774. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.19603/0.34085. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.20283/0.33296. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) 0.19986/0.35814. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.19028/0.34912. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.19109/0.38082. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.18871/0.36343. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.18863/0.35765. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.19126/0.37191. Took 0.14 sec\n",
      "Epoch 59, Loss(train/val) 0.18325/0.36667. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.18967/0.36154. Took 0.14 sec\n",
      "Epoch 61, Loss(train/val) 0.18340/0.34050. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.18370/0.34005. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.17947/0.35769. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.18258/0.35498. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.17720/0.36037. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.17892/0.36220. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) 0.18111/0.40969. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.17459/0.36281. Took 0.14 sec\n",
      "Epoch 69, Loss(train/val) 0.17329/0.36173. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.18813/0.35899. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.18113/0.36184. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.17804/0.36795. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.17574/0.35200. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.16033/0.35217. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) 0.16868/0.35557. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.17204/0.35780. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.16859/0.34662. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.16261/0.34946. Took 0.14 sec\n",
      "Epoch 79, Loss(train/val) 0.16658/0.34354. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.16930/0.36835. Took 0.14 sec\n",
      "Epoch 81, Loss(train/val) 0.16152/0.33263. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.15490/0.36077. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) 0.15347/0.33739. Took 0.15 sec\n",
      "Epoch 84, Loss(train/val) 0.15697/0.33672. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.16038/0.37589. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.15535/0.34512. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.15973/0.36241. Took 0.15 sec\n",
      "Epoch 88, Loss(train/val) 0.15766/0.37850. Took 0.14 sec\n",
      "Epoch 89, Loss(train/val) 0.15476/0.37611. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.15118/0.37113. Took 0.14 sec\n",
      "Epoch 91, Loss(train/val) 0.15058/0.35048. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.15686/0.37371. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.14600/0.37347. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.15629/0.37389. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.15164/0.38033. Took 0.15 sec\n",
      "Epoch 96, Loss(train/val) 0.15414/0.35461. Took 0.14 sec\n",
      "Epoch 97, Loss(train/val) 0.14798/0.36036. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.13608/0.35032. Took 0.14 sec\n",
      "Epoch 99, Loss(train/val) 0.14382/0.32484. Took 0.15 sec\n",
      "ACC: 0.609375, MCC: 0.21341610326458507\n",
      "Epoch 0, Loss(train/val) 0.49147/0.48773. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.46800/0.47006. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.42865/0.45476. Took 0.15 sec\n",
      "Epoch 3, Loss(train/val) 0.39626/0.44579. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.37762/0.44044. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.37325/0.43060. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.36631/0.42785. Took 0.15 sec\n",
      "Epoch 7, Loss(train/val) 0.35570/0.43094. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.34543/0.43065. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.33586/0.43423. Took 0.15 sec\n",
      "Epoch 10, Loss(train/val) 0.32972/0.44706. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.31956/0.44851. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.31332/0.45890. Took 0.16 sec\n",
      "Epoch 13, Loss(train/val) 0.30790/0.45843. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.29572/0.43893. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.29724/0.44419. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.30060/0.45612. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.29282/0.44595. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.28095/0.42121. Took 0.15 sec\n",
      "Epoch 19, Loss(train/val) 0.28554/0.42131. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.27729/0.42789. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.27430/0.43006. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.27066/0.42019. Took 0.15 sec\n",
      "Epoch 23, Loss(train/val) 0.27532/0.37920. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.27595/0.40387. Took 0.15 sec\n",
      "Epoch 25, Loss(train/val) 0.27318/0.37157. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.26306/0.38479. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.26028/0.38916. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.26080/0.39157. Took 0.16 sec\n",
      "Epoch 29, Loss(train/val) 0.25668/0.37902. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.24325/0.39484. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.23603/0.37884. Took 0.17 sec\n",
      "Epoch 32, Loss(train/val) 0.24076/0.36652. Took 0.16 sec\n",
      "Epoch 33, Loss(train/val) 0.24911/0.37017. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.23353/0.39218. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.23696/0.39098. Took 0.16 sec\n",
      "Epoch 36, Loss(train/val) 0.23818/0.40316. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.24097/0.39361. Took 0.16 sec\n",
      "Epoch 38, Loss(train/val) 0.23482/0.38340. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.22464/0.38436. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.23493/0.38592. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.23165/0.37736. Took 0.15 sec\n",
      "Epoch 42, Loss(train/val) 0.22104/0.36881. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.21983/0.37773. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.22501/0.35524. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.22405/0.37376. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.22308/0.37378. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.21060/0.38551. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.20869/0.39205. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.21046/0.37731. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.20870/0.37637. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.20465/0.39401. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.20879/0.40749. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) 0.20110/0.38132. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.20623/0.37151. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.19520/0.37249. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.20018/0.35846. Took 0.15 sec\n",
      "Epoch 57, Loss(train/val) 0.21138/0.38366. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.19872/0.38434. Took 0.15 sec\n",
      "Epoch 59, Loss(train/val) 0.21316/0.39516. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.19675/0.37020. Took 0.14 sec\n",
      "Epoch 61, Loss(train/val) 0.20359/0.34489. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.20219/0.37976. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.19925/0.34348. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.18478/0.38037. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.19548/0.38492. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.19566/0.36144. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) 0.18592/0.36845. Took 0.15 sec\n",
      "Epoch 68, Loss(train/val) 0.18990/0.38648. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.18256/0.38323. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.17772/0.40018. Took 0.15 sec\n",
      "Epoch 71, Loss(train/val) 0.17640/0.39660. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.17290/0.37125. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.17769/0.38752. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.17092/0.40175. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) 0.17814/0.36836. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.17585/0.39069. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.17617/0.39404. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.17733/0.37810. Took 0.14 sec\n",
      "Epoch 79, Loss(train/val) 0.16712/0.39220. Took 0.15 sec\n",
      "Epoch 80, Loss(train/val) 0.16320/0.36867. Took 0.14 sec\n",
      "Epoch 81, Loss(train/val) 0.17313/0.38746. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.17484/0.36607. Took 0.15 sec\n",
      "Epoch 83, Loss(train/val) 0.16888/0.38760. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.16797/0.38507. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.17192/0.38962. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.15907/0.39160. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.15694/0.40142. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.16638/0.39841. Took 0.15 sec\n",
      "Epoch 89, Loss(train/val) 0.15974/0.40814. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.15530/0.40560. Took 0.14 sec\n",
      "Epoch 91, Loss(train/val) 0.16762/0.41424. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.16037/0.37518. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.16053/0.36995. Took 0.15 sec\n",
      "Epoch 94, Loss(train/val) 0.16383/0.39768. Took 0.14 sec\n",
      "Epoch 95, Loss(train/val) 0.15430/0.40658. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.15140/0.37964. Took 0.15 sec\n",
      "Epoch 97, Loss(train/val) 0.15855/0.39440. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.15500/0.38369. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.14958/0.37339. Took 0.14 sec\n",
      "ACC: 0.59375, MCC: 0.18497841147451874\n",
      "Epoch 0, Loss(train/val) 0.49311/0.47995. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.46964/0.43778. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.43224/0.37705. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.40343/0.34207. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.39036/0.32523. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.38327/0.32558. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.37868/0.30355. Took 0.15 sec\n",
      "Epoch 7, Loss(train/val) 0.37301/0.29315. Took 0.15 sec\n",
      "Epoch 8, Loss(train/val) 0.36489/0.30065. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.36398/0.30219. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.35548/0.29934. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.35132/0.29854. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.35211/0.30385. Took 0.16 sec\n",
      "Epoch 13, Loss(train/val) 0.34517/0.31091. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.33275/0.31714. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.32498/0.31501. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.32789/0.34636. Took 0.15 sec\n",
      "Epoch 17, Loss(train/val) 0.31381/0.30236. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.32279/0.29412. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.31391/0.34554. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.31012/0.38534. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.30142/0.34198. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.28645/0.36714. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.28120/0.34178. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.28020/0.33310. Took 0.16 sec\n",
      "Epoch 25, Loss(train/val) 0.26126/0.32686. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.26387/0.31266. Took 0.15 sec\n",
      "Epoch 27, Loss(train/val) 0.26282/0.32667. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.27131/0.30083. Took 0.17 sec\n",
      "Epoch 29, Loss(train/val) 0.25446/0.35818. Took 0.16 sec\n",
      "Epoch 30, Loss(train/val) 0.24946/0.33440. Took 0.17 sec\n",
      "Epoch 31, Loss(train/val) 0.26285/0.34453. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.24496/0.33866. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.23430/0.36461. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.23407/0.39212. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.23244/0.37189. Took 0.16 sec\n",
      "Epoch 36, Loss(train/val) 0.23749/0.37960. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.22776/0.35193. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.22321/0.41924. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.21881/0.41540. Took 0.15 sec\n",
      "Epoch 40, Loss(train/val) 0.23712/0.41876. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.21985/0.37102. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.20868/0.41449. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.21012/0.41927. Took 0.15 sec\n",
      "Epoch 44, Loss(train/val) 0.21169/0.41871. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) 0.20565/0.42445. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.20838/0.39195. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.19781/0.42972. Took 0.15 sec\n",
      "Epoch 48, Loss(train/val) 0.20058/0.42069. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.19904/0.42820. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.19602/0.41731. Took 0.14 sec\n",
      "Epoch 51, Loss(train/val) 0.18936/0.39487. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.19249/0.38498. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) 0.18862/0.41560. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.18995/0.40958. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.18302/0.40462. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.18233/0.42135. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.18088/0.40389. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.18578/0.42099. Took 0.14 sec\n",
      "Epoch 59, Loss(train/val) 0.18372/0.41121. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.18863/0.41287. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.17664/0.40801. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.18556/0.39148. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.16626/0.39443. Took 0.15 sec\n",
      "Epoch 64, Loss(train/val) 0.17026/0.41225. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.17462/0.41357. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.16875/0.40109. Took 0.15 sec\n",
      "Epoch 67, Loss(train/val) 0.16904/0.42851. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.17089/0.39238. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.15926/0.42144. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.15131/0.39421. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.15675/0.36141. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.15998/0.41704. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.15400/0.39390. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.14002/0.40975. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.14587/0.41853. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.15321/0.40048. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.14779/0.42501. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.14665/0.43213. Took 0.14 sec\n",
      "Epoch 79, Loss(train/val) 0.14391/0.41724. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.14030/0.43398. Took 0.14 sec\n",
      "Epoch 81, Loss(train/val) 0.14495/0.45666. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.14366/0.44077. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) 0.12920/0.43331. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.13954/0.46038. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.13911/0.46679. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.14023/0.44512. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.14541/0.44899. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.13585/0.46555. Took 0.14 sec\n",
      "Epoch 89, Loss(train/val) 0.13068/0.49549. Took 0.15 sec\n",
      "Epoch 90, Loss(train/val) 0.12779/0.47565. Took 0.14 sec\n",
      "Epoch 91, Loss(train/val) 0.12968/0.46250. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.12745/0.46013. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.12555/0.45276. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.13151/0.49418. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.13119/0.47400. Took 0.15 sec\n",
      "Epoch 96, Loss(train/val) 0.14233/0.46349. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.13836/0.48117. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.12417/0.48848. Took 0.14 sec\n",
      "Epoch 99, Loss(train/val) 0.12925/0.48957. Took 0.15 sec\n",
      "ACC: 0.59375, MCC: 0.1686533906277161\n",
      "Epoch 0, Loss(train/val) 0.49303/0.49343. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.46924/0.46764. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.43451/0.42734. Took 0.15 sec\n",
      "Epoch 3, Loss(train/val) 0.40599/0.41361. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.39393/0.40924. Took 0.15 sec\n",
      "Epoch 5, Loss(train/val) 0.38360/0.41079. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.37898/0.40789. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.36852/0.40458. Took 0.15 sec\n",
      "Epoch 8, Loss(train/val) 0.36785/0.40323. Took 0.15 sec\n",
      "Epoch 9, Loss(train/val) 0.36051/0.38935. Took 0.15 sec\n",
      "Epoch 10, Loss(train/val) 0.35655/0.37728. Took 0.15 sec\n",
      "Epoch 11, Loss(train/val) 0.34878/0.37764. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.35149/0.37771. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.33768/0.38715. Took 0.16 sec\n",
      "Epoch 14, Loss(train/val) 0.33001/0.40256. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.32905/0.38569. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.33118/0.36435. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.32692/0.38166. Took 0.16 sec\n",
      "Epoch 18, Loss(train/val) 0.30871/0.37341. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.30750/0.43772. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.30064/0.46814. Took 0.16 sec\n",
      "Epoch 21, Loss(train/val) 0.30445/0.37021. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.30562/0.40170. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.29420/0.43607. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.29527/0.47279. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.28263/0.45282. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.27784/0.45278. Took 0.15 sec\n",
      "Epoch 27, Loss(train/val) 0.27867/0.46358. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.28166/0.46720. Took 0.16 sec\n",
      "Epoch 29, Loss(train/val) 0.28405/0.44581. Took 0.16 sec\n",
      "Epoch 30, Loss(train/val) 0.27707/0.44513. Took 0.16 sec\n",
      "Epoch 31, Loss(train/val) 0.27219/0.42160. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.26720/0.43699. Took 0.18 sec\n",
      "Epoch 33, Loss(train/val) 0.26643/0.46914. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.26434/0.43275. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.26174/0.49599. Took 0.15 sec\n",
      "Epoch 36, Loss(train/val) 0.25310/0.45142. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.26296/0.44573. Took 0.15 sec\n",
      "Epoch 38, Loss(train/val) 0.26451/0.41677. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.25101/0.45851. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.24527/0.45447. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.25238/0.46143. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.25686/0.48136. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.24514/0.47768. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.26216/0.46330. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.25485/0.42396. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.24785/0.46017. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.25069/0.45679. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.23115/0.45433. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.23749/0.44821. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.23102/0.43946. Took 0.14 sec\n",
      "Epoch 51, Loss(train/val) 0.23918/0.46288. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.21975/0.45240. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) 0.24604/0.42282. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.23912/0.40156. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.23541/0.40122. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.22111/0.44452. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.22500/0.44208. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.21969/0.45293. Took 0.14 sec\n",
      "Epoch 59, Loss(train/val) 0.22875/0.43190. Took 0.15 sec\n",
      "Epoch 60, Loss(train/val) 0.22461/0.46568. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.21364/0.45568. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.21955/0.45268. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.22936/0.43807. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.21130/0.45216. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.22982/0.45708. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.22217/0.45502. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) 0.22731/0.46715. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.21093/0.46452. Took 0.15 sec\n",
      "Epoch 69, Loss(train/val) 0.23300/0.46357. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.21415/0.47568. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.21072/0.44083. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.21316/0.46140. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.20797/0.45651. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.20546/0.45534. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.20381/0.44373. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.21114/0.44887. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.19343/0.45392. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.20419/0.44723. Took 0.14 sec\n",
      "Epoch 79, Loss(train/val) 0.20626/0.43356. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.20314/0.48193. Took 0.14 sec\n",
      "Epoch 81, Loss(train/val) 0.21822/0.42653. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.20183/0.45652. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.21493/0.38568. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.20734/0.45382. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.21278/0.46931. Took 0.17 sec\n",
      "Epoch 86, Loss(train/val) 0.22741/0.44233. Took 0.15 sec\n",
      "Epoch 87, Loss(train/val) 0.21231/0.46866. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.20884/0.45979. Took 0.15 sec\n",
      "Epoch 89, Loss(train/val) 0.20602/0.44367. Took 0.15 sec\n",
      "Epoch 90, Loss(train/val) 0.20439/0.42842. Took 0.14 sec\n",
      "Epoch 91, Loss(train/val) 0.20858/0.43860. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.20083/0.44133. Took 0.15 sec\n",
      "Epoch 93, Loss(train/val) 0.19791/0.43807. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.20326/0.44655. Took 0.14 sec\n",
      "Epoch 95, Loss(train/val) 0.19838/0.43313. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.20294/0.44713. Took 0.14 sec\n",
      "Epoch 97, Loss(train/val) 0.19561/0.45476. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.19403/0.44925. Took 0.15 sec\n",
      "Epoch 99, Loss(train/val) 0.18972/0.45618. Took 0.14 sec\n",
      "ACC: 0.703125, MCC: 0.4078191053434671\n",
      "Epoch 0, Loss(train/val) 0.49242/0.47797. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.47259/0.44446. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.44352/0.38747. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.41030/0.35973. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.38994/0.35389. Took 0.15 sec\n",
      "Epoch 5, Loss(train/val) 0.37733/0.34460. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.36425/0.33317. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.35582/0.33007. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.35290/0.33605. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.34012/0.32149. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.33582/0.32123. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.32468/0.31741. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.32346/0.30043. Took 0.15 sec\n",
      "Epoch 13, Loss(train/val) 0.30090/0.29700. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.30659/0.31687. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.30352/0.29145. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.29375/0.32001. Took 0.15 sec\n",
      "Epoch 17, Loss(train/val) 0.29824/0.29930. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.29136/0.31136. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.29886/0.30375. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.29004/0.29681. Took 0.15 sec\n",
      "Epoch 21, Loss(train/val) 0.26727/0.30000. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.28412/0.31245. Took 0.15 sec\n",
      "Epoch 23, Loss(train/val) 0.27701/0.28843. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.26085/0.30101. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.24765/0.29533. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.27411/0.29996. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.25321/0.29692. Took 0.16 sec\n",
      "Epoch 28, Loss(train/val) 0.25807/0.31467. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.25866/0.27055. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.26313/0.29961. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.24268/0.30232. Took 0.17 sec\n",
      "Epoch 32, Loss(train/val) 0.24414/0.28048. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.25253/0.33458. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.25070/0.28557. Took 0.17 sec\n",
      "Epoch 35, Loss(train/val) 0.24360/0.29785. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.24010/0.28357. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.25107/0.30009. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.24260/0.27973. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.23271/0.28860. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.23557/0.29816. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.23455/0.30408. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.22861/0.28680. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.23763/0.31633. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.23171/0.28216. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) 0.22173/0.28740. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.22360/0.26305. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.21892/0.29397. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.22079/0.28274. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.21787/0.28680. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.21614/0.33178. Took 0.14 sec\n",
      "Epoch 51, Loss(train/val) 0.20799/0.30158. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.20611/0.33974. Took 0.15 sec\n",
      "Epoch 53, Loss(train/val) 0.21375/0.29236. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.20991/0.30735. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.22131/0.31990. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.24058/0.30948. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.21768/0.29572. Took 0.16 sec\n",
      "Epoch 58, Loss(train/val) 0.21870/0.30682. Took 0.14 sec\n",
      "Epoch 59, Loss(train/val) 0.22001/0.32189. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.21129/0.29538. Took 0.14 sec\n",
      "Epoch 61, Loss(train/val) 0.21938/0.32828. Took 0.15 sec\n",
      "Epoch 62, Loss(train/val) 0.20693/0.31912. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.20356/0.31948. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.20876/0.32909. Took 0.16 sec\n",
      "Epoch 65, Loss(train/val) 0.19650/0.30021. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.19620/0.30920. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) 0.20785/0.32457. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.19467/0.31078. Took 0.14 sec\n",
      "Epoch 69, Loss(train/val) 0.19538/0.31522. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.20063/0.32016. Took 0.15 sec\n",
      "Epoch 71, Loss(train/val) 0.20465/0.33044. Took 0.15 sec\n",
      "Epoch 72, Loss(train/val) 0.20278/0.32452. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.19094/0.33257. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.20304/0.35289. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) 0.20697/0.30226. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.19475/0.31484. Took 0.15 sec\n",
      "Epoch 77, Loss(train/val) 0.19311/0.29027. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.19492/0.31915. Took 0.14 sec\n",
      "Epoch 79, Loss(train/val) 0.20283/0.31711. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.18945/0.31315. Took 0.14 sec\n",
      "Epoch 81, Loss(train/val) 0.19261/0.32282. Took 0.15 sec\n",
      "Epoch 82, Loss(train/val) 0.19379/0.29941. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) 0.18854/0.31749. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.18113/0.29717. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.18944/0.31320. Took 0.15 sec\n",
      "Epoch 86, Loss(train/val) 0.19175/0.30743. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.19981/0.28510. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.18531/0.30122. Took 0.16 sec\n",
      "Epoch 89, Loss(train/val) 0.18880/0.35825. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.18650/0.32513. Took 0.14 sec\n",
      "Epoch 91, Loss(train/val) 0.16810/0.31336. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.16810/0.31025. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.17315/0.31259. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.17620/0.29286. Took 0.15 sec\n",
      "Epoch 95, Loss(train/val) 0.16994/0.30546. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.17959/0.33005. Took 0.14 sec\n",
      "Epoch 97, Loss(train/val) 0.17219/0.35109. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.18813/0.31124. Took 0.14 sec\n",
      "Epoch 99, Loss(train/val) 0.17958/0.30575. Took 0.15 sec\n",
      "ACC: 0.453125, MCC: -0.018266554145039696\n",
      "Epoch 0, Loss(train/val) 0.49388/0.49668. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.47413/0.47872. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.44254/0.43382. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.40805/0.41076. Took 0.15 sec\n",
      "Epoch 4, Loss(train/val) 0.38772/0.40721. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.36914/0.40179. Took 0.15 sec\n",
      "Epoch 6, Loss(train/val) 0.35087/0.39692. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.34135/0.40217. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.32766/0.41125. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.32691/0.39616. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.31126/0.41464. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.30946/0.44823. Took 0.15 sec\n",
      "Epoch 12, Loss(train/val) 0.29717/0.45453. Took 0.15 sec\n",
      "Epoch 13, Loss(train/val) 0.29831/0.46460. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.29112/0.44866. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.28109/0.41117. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.30027/0.49048. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.27740/0.44580. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.28364/0.42637. Took 0.15 sec\n",
      "Epoch 19, Loss(train/val) 0.26725/0.44429. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.27551/0.42060. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.27039/0.40695. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.25344/0.42617. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.24980/0.39817. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.24820/0.42034. Took 0.15 sec\n",
      "Epoch 25, Loss(train/val) 0.24288/0.40355. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.23175/0.38928. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.23318/0.37896. Took 0.16 sec\n",
      "Epoch 28, Loss(train/val) 0.23221/0.41627. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.23631/0.41347. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.23499/0.42487. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.22787/0.43622. Took 0.18 sec\n",
      "Epoch 32, Loss(train/val) 0.22132/0.41014. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.22847/0.36390. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.22285/0.41017. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.21859/0.45029. Took 0.15 sec\n",
      "Epoch 36, Loss(train/val) 0.21336/0.33193. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.21725/0.34475. Took 0.16 sec\n",
      "Epoch 38, Loss(train/val) 0.20914/0.45894. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.22115/0.39815. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.21234/0.43735. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.20201/0.45857. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.20323/0.42870. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.20848/0.37123. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.19715/0.43593. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) 0.18724/0.37721. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.19904/0.37833. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.18752/0.39301. Took 0.15 sec\n",
      "Epoch 48, Loss(train/val) 0.19146/0.40537. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.18555/0.43031. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.18306/0.36384. Took 0.14 sec\n",
      "Epoch 51, Loss(train/val) 0.18618/0.40456. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.17867/0.36743. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) 0.18810/0.40903. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.18090/0.39189. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.18077/0.39134. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.17200/0.37708. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.17284/0.38669. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.17873/0.38156. Took 0.14 sec\n",
      "Epoch 59, Loss(train/val) 0.17077/0.43262. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.16735/0.33677. Took 0.14 sec\n",
      "Epoch 61, Loss(train/val) 0.17671/0.38852. Took 0.15 sec\n",
      "Epoch 62, Loss(train/val) 0.16899/0.38451. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.15969/0.36324. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.16796/0.38388. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.16129/0.34917. Took 0.15 sec\n",
      "Epoch 66, Loss(train/val) 0.16645/0.33040. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.16170/0.36624. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.15777/0.34971. Took 0.16 sec\n",
      "Epoch 69, Loss(train/val) 0.16270/0.37479. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.15407/0.35650. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.15481/0.30871. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.15745/0.33286. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.16227/0.35013. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.15538/0.37755. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.15014/0.34320. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.15947/0.34426. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.15037/0.38569. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.14814/0.33541. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.15376/0.35704. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.14992/0.36813. Took 0.14 sec\n",
      "Epoch 81, Loss(train/val) 0.14197/0.38983. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.14072/0.35432. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) 0.13864/0.36716. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.14373/0.36633. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.13159/0.36029. Took 0.15 sec\n",
      "Epoch 86, Loss(train/val) 0.14608/0.32692. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.14132/0.34146. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.13377/0.37856. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.14796/0.33087. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.13181/0.33604. Took 0.14 sec\n",
      "Epoch 91, Loss(train/val) 0.13284/0.34960. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.12848/0.35458. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.12769/0.30982. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.13406/0.32526. Took 0.14 sec\n",
      "Epoch 95, Loss(train/val) 0.12514/0.33599. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.12132/0.35619. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.12759/0.31644. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.12548/0.33830. Took 0.14 sec\n",
      "Epoch 99, Loss(train/val) 0.12444/0.33263. Took 0.14 sec\n",
      "ACC: 0.609375, MCC: 0.21971768720102058\n",
      "Epoch 0, Loss(train/val) 0.49651/0.49005. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.48015/0.46451. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.45174/0.43228. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.41743/0.41588. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.39528/0.40930. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.37446/0.40165. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.35767/0.39987. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.34327/0.38941. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.33770/0.36439. Took 0.15 sec\n",
      "Epoch 9, Loss(train/val) 0.34250/0.37339. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.31752/0.34249. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.30864/0.35220. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.30491/0.34038. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.29158/0.35271. Took 0.16 sec\n",
      "Epoch 14, Loss(train/val) 0.28579/0.35165. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.28258/0.36098. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.28074/0.36434. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.27782/0.38018. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.28212/0.37325. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.27056/0.34695. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.26844/0.34534. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.25354/0.34667. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.25715/0.34036. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.25841/0.38171. Took 0.16 sec\n",
      "Epoch 24, Loss(train/val) 0.26597/0.35951. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.25740/0.32486. Took 0.16 sec\n",
      "Epoch 26, Loss(train/val) 0.24916/0.34372. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.24104/0.31619. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.24623/0.34151. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.24853/0.35880. Took 0.16 sec\n",
      "Epoch 30, Loss(train/val) 0.23201/0.32910. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.25095/0.36087. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.22676/0.34615. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.22419/0.34267. Took 0.17 sec\n",
      "Epoch 34, Loss(train/val) 0.22578/0.33174. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.23060/0.31850. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.21508/0.33549. Took 0.17 sec\n",
      "Epoch 37, Loss(train/val) 0.22402/0.33469. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.23088/0.32399. Took 0.16 sec\n",
      "Epoch 39, Loss(train/val) 0.21817/0.30104. Took 0.15 sec\n",
      "Epoch 40, Loss(train/val) 0.21983/0.30737. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.21775/0.31085. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.20530/0.31418. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.20796/0.31001. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.20246/0.30550. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) 0.20363/0.32340. Took 0.15 sec\n",
      "Epoch 46, Loss(train/val) 0.20410/0.31600. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.20649/0.31044. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.21020/0.33642. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.20055/0.31895. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.19403/0.32725. Took 0.14 sec\n",
      "Epoch 51, Loss(train/val) 0.19607/0.31616. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.20394/0.31873. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) 0.18796/0.31869. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.19375/0.31101. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.18931/0.31209. Took 0.15 sec\n",
      "Epoch 56, Loss(train/val) 0.18299/0.33561. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.18507/0.34766. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.17736/0.33494. Took 0.14 sec\n",
      "Epoch 59, Loss(train/val) 0.18290/0.33247. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.18382/0.35396. Took 0.14 sec\n",
      "Epoch 61, Loss(train/val) 0.17846/0.34026. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.18207/0.33534. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.16700/0.34605. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.17478/0.34632. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.16129/0.33046. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.16237/0.32966. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) 0.16563/0.32491. Took 0.15 sec\n",
      "Epoch 68, Loss(train/val) 0.16688/0.33763. Took 0.14 sec\n",
      "Epoch 69, Loss(train/val) 0.15811/0.34788. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.15806/0.35696. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.16018/0.35287. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.15336/0.35186. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.16600/0.33585. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.15611/0.35254. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.15371/0.33164. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.15321/0.35215. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.15322/0.34979. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.15727/0.33650. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.14655/0.34597. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.15853/0.32997. Took 0.14 sec\n",
      "Epoch 81, Loss(train/val) 0.13847/0.33317. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.15358/0.34321. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.14850/0.32587. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.15187/0.33797. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.14937/0.33524. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.15494/0.36442. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.14543/0.36196. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.13371/0.35912. Took 0.15 sec\n",
      "Epoch 89, Loss(train/val) 0.13963/0.35718. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.13916/0.36379. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.13343/0.37296. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.13511/0.38299. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.13435/0.36527. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.13641/0.38705. Took 0.14 sec\n",
      "Epoch 95, Loss(train/val) 0.13018/0.38513. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.12349/0.35912. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.12757/0.38894. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.13914/0.35515. Took 0.14 sec\n",
      "Epoch 99, Loss(train/val) 0.12380/0.33970. Took 0.13 sec\n",
      "ACC: 0.6875, MCC: 0.38177085778546666\n",
      "Epoch 0, Loss(train/val) 0.49554/0.48831. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.48115/0.46378. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.45275/0.41615. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.41797/0.38176. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.39666/0.37646. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.38466/0.37915. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.36731/0.37395. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.35687/0.39303. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.34936/0.37213. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.33516/0.38020. Took 0.16 sec\n",
      "Epoch 10, Loss(train/val) 0.32317/0.38430. Took 0.15 sec\n",
      "Epoch 11, Loss(train/val) 0.31404/0.39570. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.31378/0.40677. Took 0.16 sec\n",
      "Epoch 13, Loss(train/val) 0.29794/0.39403. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.29253/0.33448. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.29382/0.41497. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.28898/0.35940. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.26959/0.33217. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.26960/0.39099. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.28691/0.34501. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.27771/0.33890. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.26516/0.34849. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.25585/0.32790. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.26939/0.33539. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.25258/0.31692. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.24646/0.31540. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.24433/0.33399. Took 0.16 sec\n",
      "Epoch 27, Loss(train/val) 0.25750/0.32766. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.24649/0.32064. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.23843/0.30993. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.24291/0.30240. Took 0.17 sec\n",
      "Epoch 31, Loss(train/val) 0.23220/0.31408. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.23372/0.31383. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.23602/0.29945. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.22123/0.30400. Took 0.17 sec\n",
      "Epoch 35, Loss(train/val) 0.22959/0.29957. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.22620/0.29496. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.22279/0.29536. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.21779/0.30096. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.22347/0.29504. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.20966/0.31104. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.21491/0.31178. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.22165/0.31513. Took 0.15 sec\n",
      "Epoch 43, Loss(train/val) 0.21309/0.30850. Took 0.15 sec\n",
      "Epoch 44, Loss(train/val) 0.20185/0.29886. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) 0.21422/0.30384. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.19539/0.29582. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.20720/0.28498. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.20612/0.29578. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.20451/0.30275. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.20768/0.29868. Took 0.14 sec\n",
      "Epoch 51, Loss(train/val) 0.19553/0.30540. Took 0.15 sec\n",
      "Epoch 52, Loss(train/val) 0.19428/0.29789. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) 0.19772/0.29960. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.19743/0.28939. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.19569/0.30805. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.20279/0.29190. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.18861/0.29105. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.18888/0.28172. Took 0.14 sec\n",
      "Epoch 59, Loss(train/val) 0.18955/0.28921. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.18025/0.29301. Took 0.14 sec\n",
      "Epoch 61, Loss(train/val) 0.17792/0.29226. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.18573/0.28183. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.18045/0.29317. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.17773/0.28949. Took 0.15 sec\n",
      "Epoch 65, Loss(train/val) 0.18012/0.28975. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.17403/0.28582. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) 0.17532/0.28720. Took 0.15 sec\n",
      "Epoch 68, Loss(train/val) 0.17201/0.29449. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.17026/0.28035. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.16802/0.28754. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.17659/0.31070. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.16741/0.28049. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.16474/0.28520. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.16921/0.28624. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.15425/0.28231. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.17678/0.30905. Took 0.16 sec\n",
      "Epoch 77, Loss(train/val) 0.15939/0.28590. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.16161/0.28806. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.15828/0.29089. Took 0.15 sec\n",
      "Epoch 80, Loss(train/val) 0.16617/0.27605. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.15515/0.27376. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.16494/0.31641. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) 0.15374/0.27276. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.16245/0.28885. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.15352/0.28800. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.15496/0.27784. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.15837/0.30118. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.16423/0.29164. Took 0.14 sec\n",
      "Epoch 89, Loss(train/val) 0.15032/0.29121. Took 0.15 sec\n",
      "Epoch 90, Loss(train/val) 0.14915/0.29947. Took 0.14 sec\n",
      "Epoch 91, Loss(train/val) 0.15215/0.29046. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.15616/0.26888. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.15031/0.27415. Took 0.15 sec\n",
      "Epoch 94, Loss(train/val) 0.14002/0.28893. Took 0.14 sec\n",
      "Epoch 95, Loss(train/val) 0.15070/0.29485. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.15426/0.27856. Took 0.14 sec\n",
      "Epoch 97, Loss(train/val) 0.14065/0.28986. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.14676/0.30600. Took 0.14 sec\n",
      "Epoch 99, Loss(train/val) 0.14708/0.30082. Took 0.13 sec\n",
      "ACC: 0.625, MCC: 0.24305875451990117\n",
      "Epoch 0, Loss(train/val) 0.49463/0.48898. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.47821/0.47266. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.44705/0.44294. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.41741/0.41779. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.39591/0.41526. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.38214/0.41699. Took 0.17 sec\n",
      "Epoch 6, Loss(train/val) 0.37114/0.39995. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.35602/0.38861. Took 0.16 sec\n",
      "Epoch 8, Loss(train/val) 0.34345/0.37404. Took 0.18 sec\n",
      "Epoch 9, Loss(train/val) 0.32829/0.36610. Took 0.16 sec\n",
      "Epoch 10, Loss(train/val) 0.32380/0.36177. Took 0.15 sec\n",
      "Epoch 11, Loss(train/val) 0.31891/0.35755. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.31475/0.34665. Took 0.15 sec\n",
      "Epoch 13, Loss(train/val) 0.30714/0.34100. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.32927/0.35309. Took 0.15 sec\n",
      "Epoch 15, Loss(train/val) 0.31012/0.32796. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.29949/0.33270. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.31296/0.33156. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.28948/0.30877. Took 0.16 sec\n",
      "Epoch 19, Loss(train/val) 0.29038/0.31144. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.29089/0.32721. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.28127/0.30982. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.28614/0.31269. Took 0.15 sec\n",
      "Epoch 23, Loss(train/val) 0.27797/0.32958. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.28190/0.31019. Took 0.15 sec\n",
      "Epoch 25, Loss(train/val) 0.27581/0.33758. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.27667/0.31371. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.27631/0.32618. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.27718/0.29059. Took 0.16 sec\n",
      "Epoch 29, Loss(train/val) 0.26096/0.30550. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.25742/0.29400. Took 0.16 sec\n",
      "Epoch 31, Loss(train/val) 0.25511/0.30784. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.25847/0.32368. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.26215/0.31738. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.25159/0.28688. Took 0.17 sec\n",
      "Epoch 35, Loss(train/val) 0.25904/0.30997. Took 0.13 sec\n",
      "Epoch 36, Loss(train/val) 0.26115/0.31368. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.26561/0.32696. Took 0.15 sec\n",
      "Epoch 38, Loss(train/val) 0.24064/0.31970. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.24273/0.28837. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.24729/0.31095. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.23745/0.30513. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.25217/0.31432. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.23821/0.33253. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.24325/0.32474. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) 0.23143/0.28052. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.22874/0.29000. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.23144/0.34002. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.25033/0.28735. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.23460/0.29988. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.23146/0.30271. Took 0.14 sec\n",
      "Epoch 51, Loss(train/val) 0.22294/0.27565. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.21518/0.28985. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) 0.22723/0.31500. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.22432/0.29961. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.22280/0.28905. Took 0.15 sec\n",
      "Epoch 56, Loss(train/val) 0.21344/0.27648. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.20644/0.27467. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.21384/0.27266. Took 0.14 sec\n",
      "Epoch 59, Loss(train/val) 0.20597/0.30054. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.22224/0.27526. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.21186/0.27887. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.20424/0.29587. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.21244/0.28640. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.20239/0.30089. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.20967/0.27084. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.19366/0.28721. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) 0.19582/0.29264. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.20356/0.28338. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.20308/0.27557. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.19331/0.31747. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.19908/0.31070. Took 0.15 sec\n",
      "Epoch 72, Loss(train/val) 0.19236/0.29751. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.18818/0.28731. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.19709/0.29599. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) 0.19102/0.29170. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.20257/0.31528. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.19070/0.30889. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.18459/0.31354. Took 0.15 sec\n",
      "Epoch 79, Loss(train/val) 0.18714/0.31386. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.18617/0.30132. Took 0.14 sec\n",
      "Epoch 81, Loss(train/val) 0.19004/0.31219. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.17923/0.31253. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.18573/0.28834. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.18226/0.32140. Took 0.15 sec\n",
      "Epoch 85, Loss(train/val) 0.18187/0.29594. Took 0.15 sec\n",
      "Epoch 86, Loss(train/val) 0.19269/0.32550. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.18583/0.32662. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.17685/0.32718. Took 0.14 sec\n",
      "Epoch 89, Loss(train/val) 0.18711/0.31796. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.17246/0.31869. Took 0.15 sec\n",
      "Epoch 91, Loss(train/val) 0.17566/0.30574. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.16776/0.29544. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.16653/0.30264. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.17192/0.31199. Took 0.14 sec\n",
      "Epoch 95, Loss(train/val) 0.16816/0.31732. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.16116/0.33452. Took 0.15 sec\n",
      "Epoch 97, Loss(train/val) 0.15967/0.32448. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.16300/0.33284. Took 0.14 sec\n",
      "Epoch 99, Loss(train/val) 0.16954/0.33450. Took 0.13 sec\n",
      "ACC: 0.625, MCC: 0.21821789023599236\n",
      "Epoch 0, Loss(train/val) 0.49676/0.49074. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.48283/0.47794. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.45802/0.45945. Took 0.16 sec\n",
      "Epoch 3, Loss(train/val) 0.41998/0.44880. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.38929/0.44233. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.36930/0.43895. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.35887/0.45033. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.34694/0.45425. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.33586/0.37326. Took 0.16 sec\n",
      "Epoch 9, Loss(train/val) 0.33207/0.42671. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.31549/0.39108. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.31107/0.35535. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.31682/0.39569. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.31059/0.36415. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.31730/0.39317. Took 0.17 sec\n",
      "Epoch 15, Loss(train/val) 0.34293/0.38581. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.31259/0.34742. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.30415/0.34579. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.29541/0.34358. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.28699/0.34742. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.29396/0.31891. Took 0.16 sec\n",
      "Epoch 21, Loss(train/val) 0.29323/0.33261. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.28178/0.33764. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.28703/0.33237. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.28227/0.32442. Took 0.15 sec\n",
      "Epoch 25, Loss(train/val) 0.28124/0.31452. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.26688/0.32507. Took 0.17 sec\n",
      "Epoch 27, Loss(train/val) 0.26735/0.31662. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.26311/0.31898. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.25935/0.32565. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.26744/0.36487. Took 0.18 sec\n",
      "Epoch 31, Loss(train/val) 0.26087/0.34962. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.25384/0.31547. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.25771/0.32725. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.25562/0.34884. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.24556/0.33220. Took 0.16 sec\n",
      "Epoch 36, Loss(train/val) 0.24577/0.34148. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.24489/0.32202. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.24497/0.32511. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.23062/0.34002. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.22990/0.33474. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.22773/0.33567. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.22539/0.33627. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.22785/0.32882. Took 0.15 sec\n",
      "Epoch 44, Loss(train/val) 0.21933/0.32659. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) 0.22363/0.33389. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.21508/0.31621. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.20771/0.32744. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.22278/0.34130. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.20696/0.31101. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.20899/0.31919. Took 0.14 sec\n",
      "Epoch 51, Loss(train/val) 0.20338/0.33700. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.19157/0.35070. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.19693/0.34733. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.18005/0.32448. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.18895/0.34236. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.18445/0.33696. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.18899/0.32855. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.20949/0.33788. Took 0.14 sec\n",
      "Epoch 59, Loss(train/val) 0.18138/0.33758. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.17940/0.33467. Took 0.14 sec\n",
      "Epoch 61, Loss(train/val) 0.18446/0.33359. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.17843/0.34815. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.16749/0.34621. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.16721/0.36186. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.15956/0.33988. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.16570/0.32766. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.15951/0.34461. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.16616/0.35224. Took 0.14 sec\n",
      "Epoch 69, Loss(train/val) 0.15908/0.35137. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.15311/0.34104. Took 0.15 sec\n",
      "Epoch 71, Loss(train/val) 0.14870/0.36751. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.15228/0.34473. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.15570/0.37105. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.14675/0.35193. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) 0.13956/0.35841. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.14601/0.37069. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.14001/0.37763. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.13866/0.37104. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.14005/0.35150. Took 0.15 sec\n",
      "Epoch 80, Loss(train/val) 0.12997/0.37807. Took 0.14 sec\n",
      "Epoch 81, Loss(train/val) 0.12949/0.36328. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.13163/0.35892. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) 0.13281/0.35848. Took 0.15 sec\n",
      "Epoch 84, Loss(train/val) 0.13198/0.35346. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.13740/0.35026. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.13354/0.37709. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.12319/0.32234. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.12353/0.32748. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.13232/0.37065. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.12718/0.38060. Took 0.15 sec\n",
      "Epoch 91, Loss(train/val) 0.11885/0.37461. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.11967/0.36426. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.11381/0.34333. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.11219/0.33824. Took 0.14 sec\n",
      "Epoch 95, Loss(train/val) 0.11272/0.35199. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.11335/0.30778. Took 0.15 sec\n",
      "Epoch 97, Loss(train/val) 0.11475/0.37822. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.10001/0.33747. Took 0.14 sec\n",
      "Epoch 99, Loss(train/val) 0.10946/0.34112. Took 0.14 sec\n",
      "ACC: 0.671875, MCC: 0.348024598442583\n",
      "Epoch 0, Loss(train/val) 0.49462/0.48632. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.47526/0.45856. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.44315/0.41750. Took 0.15 sec\n",
      "Epoch 3, Loss(train/val) 0.40935/0.41414. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.39210/0.39010. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.37708/0.37710. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.36606/0.36780. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.34968/0.37986. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.33540/0.35106. Took 0.15 sec\n",
      "Epoch 9, Loss(train/val) 0.31654/0.36639. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.31376/0.37833. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.29480/0.37751. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.29713/0.36886. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.29430/0.37526. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.30061/0.36866. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.30413/0.42106. Took 0.16 sec\n",
      "Epoch 16, Loss(train/val) 0.29122/0.36602. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.30268/0.39850. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.28566/0.41212. Took 0.15 sec\n",
      "Epoch 19, Loss(train/val) 0.27705/0.38172. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.27358/0.38252. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.27545/0.39336. Took 0.16 sec\n",
      "Epoch 22, Loss(train/val) 0.25845/0.39695. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.26421/0.35126. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.26837/0.37665. Took 0.15 sec\n",
      "Epoch 25, Loss(train/val) 0.27510/0.42447. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.27983/0.43434. Took 0.15 sec\n",
      "Epoch 27, Loss(train/val) 0.26807/0.37726. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.27077/0.36609. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.25551/0.37856. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.26361/0.40515. Took 0.17 sec\n",
      "Epoch 31, Loss(train/val) 0.24463/0.45839. Took 0.16 sec\n",
      "Epoch 32, Loss(train/val) 0.24831/0.42022. Took 0.16 sec\n",
      "Epoch 33, Loss(train/val) 0.24501/0.42254. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.24828/0.43372. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.23765/0.43237. Took 0.16 sec\n",
      "Epoch 36, Loss(train/val) 0.24631/0.42136. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.24164/0.44497. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.24813/0.42391. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.23131/0.43463. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.24448/0.42008. Took 0.15 sec\n",
      "Epoch 41, Loss(train/val) 0.25342/0.43362. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.23554/0.42257. Took 0.15 sec\n",
      "Epoch 43, Loss(train/val) 0.22970/0.44057. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.23081/0.44390. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) 0.22293/0.41638. Took 0.15 sec\n",
      "Epoch 46, Loss(train/val) 0.22541/0.42829. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.21837/0.44590. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.21840/0.45149. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.22100/0.44453. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.22218/0.42507. Took 0.14 sec\n",
      "Epoch 51, Loss(train/val) 0.20802/0.44995. Took 0.15 sec\n",
      "Epoch 52, Loss(train/val) 0.22794/0.43061. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) 0.21303/0.44813. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.21309/0.42754. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.20451/0.42983. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.20960/0.43081. Took 0.15 sec\n",
      "Epoch 57, Loss(train/val) 0.20290/0.41980. Took 0.15 sec\n",
      "Epoch 58, Loss(train/val) 0.20828/0.43146. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.19497/0.43982. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.20407/0.42527. Took 0.14 sec\n",
      "Epoch 61, Loss(train/val) 0.19633/0.43674. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.19705/0.43444. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.20031/0.42266. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.21006/0.38394. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.20149/0.40910. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.19127/0.39336. Took 0.15 sec\n",
      "Epoch 67, Loss(train/val) 0.20466/0.39506. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.18436/0.43154. Took 0.14 sec\n",
      "Epoch 69, Loss(train/val) 0.18189/0.42225. Took 0.15 sec\n",
      "Epoch 70, Loss(train/val) 0.18433/0.43472. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.18615/0.37689. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.19190/0.39094. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.18979/0.42570. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.18960/0.39997. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) 0.18238/0.41249. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.19816/0.37651. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.18040/0.40548. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.17064/0.38038. Took 0.14 sec\n",
      "Epoch 79, Loss(train/val) 0.19271/0.42689. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.18314/0.40534. Took 0.14 sec\n",
      "Epoch 81, Loss(train/val) 0.16986/0.42113. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.18364/0.40879. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) 0.16912/0.40140. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.16672/0.38809. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.16912/0.41497. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.17329/0.40807. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.16241/0.41141. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.16014/0.39957. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.16676/0.40105. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.16489/0.37827. Took 0.14 sec\n",
      "Epoch 91, Loss(train/val) 0.16081/0.38171. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.16474/0.39916. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.17810/0.33780. Took 0.15 sec\n",
      "Epoch 94, Loss(train/val) 0.17631/0.40860. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.16895/0.39416. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.16442/0.37303. Took 0.14 sec\n",
      "Epoch 97, Loss(train/val) 0.16576/0.38914. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.16219/0.39362. Took 0.15 sec\n",
      "Epoch 99, Loss(train/val) 0.15390/0.40889. Took 0.13 sec\n",
      "ACC: 0.59375, MCC: 0.17785945835997752\n",
      "Epoch 0, Loss(train/val) 0.49034/0.48727. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.46455/0.46572. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.42811/0.44135. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.40001/0.43890. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.38682/0.40413. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.37442/0.38887. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.36827/0.37648. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.36049/0.34926. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.34592/0.34661. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.33738/0.34940. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.33217/0.32675. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.33070/0.33623. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.32546/0.35599. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.31043/0.33702. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.31131/0.31817. Took 0.15 sec\n",
      "Epoch 15, Loss(train/val) 0.32014/0.32252. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.30145/0.31498. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.30479/0.33069. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.31131/0.35916. Took 0.15 sec\n",
      "Epoch 19, Loss(train/val) 0.32055/0.34838. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.30147/0.31676. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.29166/0.31874. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.29722/0.31524. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.28659/0.30139. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.28794/0.29896. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.27565/0.29353. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.28507/0.30056. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.26559/0.31331. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.27355/0.30728. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.26224/0.30901. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.27220/0.30984. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.26639/0.31777. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.25005/0.30099. Took 0.16 sec\n",
      "Epoch 33, Loss(train/val) 0.25357/0.32015. Took 0.16 sec\n",
      "Epoch 34, Loss(train/val) 0.24705/0.30989. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.23999/0.30030. Took 0.15 sec\n",
      "Epoch 36, Loss(train/val) 0.24046/0.30376. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.24631/0.30806. Took 0.17 sec\n",
      "Epoch 38, Loss(train/val) 0.23345/0.31068. Took 0.15 sec\n",
      "Epoch 39, Loss(train/val) 0.24014/0.32518. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.23251/0.30103. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.21776/0.29502. Took 0.15 sec\n",
      "Epoch 42, Loss(train/val) 0.22781/0.32030. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.22339/0.32980. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.20902/0.31406. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.22139/0.29917. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.21631/0.28054. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.21378/0.29112. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.21584/0.29450. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.20244/0.30485. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.21295/0.31634. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.20416/0.31943. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.20287/0.31570. Took 0.15 sec\n",
      "Epoch 53, Loss(train/val) 0.19388/0.29073. Took 0.15 sec\n",
      "Epoch 54, Loss(train/val) 0.19687/0.29621. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.19844/0.27323. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.19605/0.30431. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.19107/0.28319. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.19613/0.27406. Took 0.14 sec\n",
      "Epoch 59, Loss(train/val) 0.18605/0.28835. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.17796/0.28204. Took 0.14 sec\n",
      "Epoch 61, Loss(train/val) 0.17813/0.29217. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.17999/0.29094. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.17298/0.27934. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.17227/0.29909. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.17691/0.26769. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.17444/0.26533. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) 0.17245/0.28647. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.16606/0.31115. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.17675/0.33681. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.17823/0.29700. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.16577/0.29846. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.16433/0.28721. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.16476/0.33259. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.17027/0.28784. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) 0.16426/0.28987. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.16587/0.30143. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.16004/0.29626. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.15800/0.27766. Took 0.14 sec\n",
      "Epoch 79, Loss(train/val) 0.16126/0.29326. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.16359/0.27034. Took 0.14 sec\n",
      "Epoch 81, Loss(train/val) 0.15137/0.32599. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.16156/0.30496. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) 0.14713/0.30642. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.15300/0.29164. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.14753/0.31665. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.15092/0.30448. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.15031/0.28871. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.14863/0.32634. Took 0.14 sec\n",
      "Epoch 89, Loss(train/val) 0.14654/0.31605. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.14549/0.31873. Took 0.15 sec\n",
      "Epoch 91, Loss(train/val) 0.15183/0.31361. Took 0.15 sec\n",
      "Epoch 92, Loss(train/val) 0.13567/0.31913. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.13894/0.31343. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.14014/0.31213. Took 0.14 sec\n",
      "Epoch 95, Loss(train/val) 0.14252/0.30096. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.15117/0.30675. Took 0.14 sec\n",
      "Epoch 97, Loss(train/val) 0.14134/0.31067. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.14221/0.31391. Took 0.14 sec\n",
      "Epoch 99, Loss(train/val) 0.13291/0.31001. Took 0.14 sec\n",
      "ACC: 0.75, MCC: 0.5335783750799326\n",
      "Epoch 0, Loss(train/val) 0.49001/0.48117. Took 0.16 sec\n",
      "Epoch 1, Loss(train/val) 0.45959/0.44016. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.41789/0.40874. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.39469/0.38727. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.37915/0.36873. Took 0.15 sec\n",
      "Epoch 5, Loss(train/val) 0.36591/0.36394. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.35158/0.35070. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.34352/0.34897. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.33175/0.34278. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.32374/0.33166. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.31545/0.33547. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.30113/0.33494. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.31212/0.35113. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.29831/0.33397. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.31287/0.32148. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.29891/0.32992. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.30365/0.34460. Took 0.15 sec\n",
      "Epoch 17, Loss(train/val) 0.28539/0.34190. Took 0.16 sec\n",
      "Epoch 18, Loss(train/val) 0.28157/0.33234. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.28784/0.32670. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.28547/0.32181. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.29927/0.33631. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.29964/0.33761. Took 0.16 sec\n",
      "Epoch 23, Loss(train/val) 0.28969/0.29698. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.29458/0.27275. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.28982/0.31034. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.27511/0.32995. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.27579/0.32990. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.27291/0.32753. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.26765/0.34074. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.28565/0.32796. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.27547/0.32425. Took 0.16 sec\n",
      "Epoch 32, Loss(train/val) 0.28573/0.27664. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.27120/0.28007. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.26965/0.30330. Took 0.18 sec\n",
      "Epoch 35, Loss(train/val) 0.25477/0.29006. Took 0.15 sec\n",
      "Epoch 36, Loss(train/val) 0.26451/0.30636. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.24897/0.30335. Took 0.17 sec\n",
      "Epoch 38, Loss(train/val) 0.25956/0.32581. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.29125/0.38414. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.28723/0.31938. Took 0.17 sec\n",
      "Epoch 41, Loss(train/val) 0.25177/0.29704. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.26441/0.25682. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.26391/0.29666. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.25818/0.30319. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) 0.25061/0.31415. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.24902/0.31510. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.24092/0.31379. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.24924/0.30349. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.24351/0.30532. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.24865/0.31022. Took 0.14 sec\n",
      "Epoch 51, Loss(train/val) 0.24025/0.30483. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.23128/0.32026. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) 0.24452/0.31843. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.23878/0.31020. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.23153/0.26428. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.24136/0.32336. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.22733/0.28643. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.22913/0.30663. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.21831/0.28171. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.22701/0.30432. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.22404/0.33371. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.22117/0.30684. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.21800/0.28497. Took 0.15 sec\n",
      "Epoch 64, Loss(train/val) 0.21727/0.28735. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.21991/0.26104. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.21842/0.30382. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.22588/0.29112. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.21475/0.25719. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.21043/0.25616. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.21028/0.30049. Took 0.15 sec\n",
      "Epoch 71, Loss(train/val) 0.20972/0.27355. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.20406/0.27569. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.21743/0.28049. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.20957/0.25680. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.20320/0.24071. Took 0.15 sec\n",
      "Epoch 76, Loss(train/val) 0.20038/0.25376. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.19843/0.24838. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.18799/0.25521. Took 0.14 sec\n",
      "Epoch 79, Loss(train/val) 0.18379/0.23503. Took 0.15 sec\n",
      "Epoch 80, Loss(train/val) 0.19874/0.25482. Took 0.14 sec\n",
      "Epoch 81, Loss(train/val) 0.20242/0.24431. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.18512/0.25508. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) 0.19542/0.22655. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.19054/0.28733. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.18382/0.27929. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.19107/0.26105. Took 0.15 sec\n",
      "Epoch 87, Loss(train/val) 0.18383/0.25289. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.18743/0.26166. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.17349/0.24950. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.17021/0.25994. Took 0.14 sec\n",
      "Epoch 91, Loss(train/val) 0.18001/0.26952. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.17768/0.25937. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.18056/0.27172. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.17425/0.26132. Took 0.15 sec\n",
      "Epoch 95, Loss(train/val) 0.17186/0.24714. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.17358/0.27471. Took 0.14 sec\n",
      "Epoch 97, Loss(train/val) 0.16488/0.25577. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.17076/0.27081. Took 0.14 sec\n",
      "Epoch 99, Loss(train/val) 0.17297/0.24278. Took 0.14 sec\n",
      "ACC: 0.671875, MCC: 0.33613646607466174\n",
      "Epoch 0, Loss(train/val) 0.48846/0.48152. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.46566/0.46161. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.43740/0.45115. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.41078/0.43857. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.38759/0.42514. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.36798/0.43575. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.35429/0.40780. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.33463/0.37837. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.32741/0.36483. Took 0.16 sec\n",
      "Epoch 9, Loss(train/val) 0.33084/0.37037. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.33007/0.35178. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.30882/0.34758. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.30300/0.34634. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.29893/0.34872. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.30594/0.35642. Took 0.16 sec\n",
      "Epoch 15, Loss(train/val) 0.30974/0.31928. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.30642/0.35145. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.29468/0.32631. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.29262/0.34123. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.28725/0.32722. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.29445/0.35558. Took 0.16 sec\n",
      "Epoch 21, Loss(train/val) 0.28521/0.31843. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.28634/0.32354. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.28445/0.37781. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.30656/0.38541. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.28506/0.34411. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.28674/0.34621. Took 0.17 sec\n",
      "Epoch 27, Loss(train/val) 0.27785/0.33982. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.27331/0.34809. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.27323/0.38394. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.25789/0.36257. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.26700/0.36111. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.26995/0.33891. Took 0.16 sec\n",
      "Epoch 33, Loss(train/val) 0.26782/0.36441. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.26451/0.34550. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.26133/0.33654. Took 0.15 sec\n",
      "Epoch 36, Loss(train/val) 0.25954/0.33835. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.25607/0.33076. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.25142/0.34263. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.25496/0.33589. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.24951/0.34528. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.25388/0.35422. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.24814/0.35051. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.23374/0.34168. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.25083/0.33486. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) 0.23483/0.33924. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.22798/0.34070. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.23233/0.34842. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.22379/0.34689. Took 0.15 sec\n",
      "Epoch 49, Loss(train/val) 0.22700/0.33246. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.22350/0.33697. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.21314/0.33350. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.22033/0.33714. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.22527/0.34621. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.21484/0.34086. Took 0.15 sec\n",
      "Epoch 55, Loss(train/val) 0.21267/0.36357. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.22460/0.35891. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.20770/0.35373. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.20984/0.33708. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.20807/0.35377. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.20650/0.34713. Took 0.14 sec\n",
      "Epoch 61, Loss(train/val) 0.20170/0.35993. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.19167/0.35710. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.19482/0.35952. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.18851/0.36945. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.19866/0.37794. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.18691/0.38155. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) 0.18056/0.38298. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.19234/0.36955. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.18731/0.37766. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.19050/0.36668. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.17721/0.38115. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.18210/0.38172. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.17598/0.36284. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.18385/0.37567. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.17372/0.38792. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.17003/0.36127. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.17467/0.37489. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.17367/0.39629. Took 0.14 sec\n",
      "Epoch 79, Loss(train/val) 0.17084/0.39431. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.17572/0.39550. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.17633/0.39318. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.16075/0.36415. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) 0.17471/0.38494. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.15959/0.38454. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.15699/0.40100. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.15783/0.39936. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.16360/0.39078. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.15216/0.39754. Took 0.14 sec\n",
      "Epoch 89, Loss(train/val) 0.15367/0.38791. Took 0.15 sec\n",
      "Epoch 90, Loss(train/val) 0.15109/0.38431. Took 0.14 sec\n",
      "Epoch 91, Loss(train/val) 0.14999/0.39327. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.15493/0.37495. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.15603/0.38109. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.15541/0.36757. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.15221/0.37283. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.15481/0.37413. Took 0.15 sec\n",
      "Epoch 97, Loss(train/val) 0.15233/0.38629. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.14927/0.38415. Took 0.14 sec\n",
      "Epoch 99, Loss(train/val) 0.13990/0.37274. Took 0.13 sec\n",
      "ACC: 0.625, MCC: 0.34426518632954817\n",
      "Epoch 0, Loss(train/val) 0.49221/0.48804. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.46631/0.46675. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.43818/0.42976. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.41436/0.39955. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.39736/0.39687. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.38196/0.38402. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.36472/0.39871. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.34834/0.36233. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.33794/0.38250. Took 0.16 sec\n",
      "Epoch 9, Loss(train/val) 0.33110/0.38731. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.31899/0.36863. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.31287/0.35897. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.31430/0.37196. Took 0.15 sec\n",
      "Epoch 13, Loss(train/val) 0.30985/0.34943. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.29773/0.34871. Took 0.15 sec\n",
      "Epoch 15, Loss(train/val) 0.29084/0.35366. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.29182/0.35816. Took 0.15 sec\n",
      "Epoch 17, Loss(train/val) 0.30810/0.36213. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.29424/0.35262. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.29070/0.34768. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.28988/0.32129. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.27369/0.34661. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.29918/0.35243. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.29422/0.35309. Took 0.16 sec\n",
      "Epoch 24, Loss(train/val) 0.28673/0.34947. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.28700/0.34702. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.28431/0.33372. Took 0.15 sec\n",
      "Epoch 27, Loss(train/val) 0.28125/0.32823. Took 0.17 sec\n",
      "Epoch 28, Loss(train/val) 0.27566/0.35667. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.27715/0.34489. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.28134/0.34797. Took 0.16 sec\n",
      "Epoch 31, Loss(train/val) 0.27104/0.33892. Took 0.16 sec\n",
      "Epoch 32, Loss(train/val) 0.26959/0.34888. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.26918/0.34867. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.27102/0.34105. Took 0.16 sec\n",
      "Epoch 35, Loss(train/val) 0.26353/0.32142. Took 0.15 sec\n",
      "Epoch 36, Loss(train/val) 0.26717/0.35168. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.26368/0.34964. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.27017/0.33766. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.25997/0.32901. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.24594/0.34796. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.24813/0.34014. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.25104/0.35451. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.24173/0.34975. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.24858/0.33941. Took 0.15 sec\n",
      "Epoch 45, Loss(train/val) 0.24324/0.34339. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.24814/0.40490. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.24345/0.38254. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.23943/0.34583. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.24349/0.31271. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.23623/0.32642. Took 0.14 sec\n",
      "Epoch 51, Loss(train/val) 0.23525/0.31225. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.22891/0.34100. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) 0.23053/0.35598. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.22660/0.34244. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.22471/0.31958. Took 0.15 sec\n",
      "Epoch 56, Loss(train/val) 0.23164/0.34578. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.24172/0.33055. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.21026/0.31916. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.22073/0.35954. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.21430/0.28986. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.23164/0.31589. Took 0.15 sec\n",
      "Epoch 62, Loss(train/val) 0.21432/0.29976. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.21244/0.29059. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.22464/0.32325. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.22051/0.31165. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.21764/0.32576. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.20287/0.29693. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.20297/0.28245. Took 0.14 sec\n",
      "Epoch 69, Loss(train/val) 0.21263/0.30245. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.20660/0.29636. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.19946/0.27573. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.19238/0.28781. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.19598/0.31952. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.20165/0.28650. Took 0.15 sec\n",
      "Epoch 75, Loss(train/val) 0.20002/0.34093. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.21258/0.32016. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.20864/0.28738. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.21213/0.33763. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.20176/0.33507. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.19587/0.33384. Took 0.15 sec\n",
      "Epoch 81, Loss(train/val) 0.21001/0.33669. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.19333/0.33050. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) 0.20025/0.28661. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.19530/0.30609. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.19656/0.30297. Took 0.15 sec\n",
      "Epoch 86, Loss(train/val) 0.19813/0.31741. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.17957/0.28833. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.19393/0.29283. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.18048/0.30796. Took 0.15 sec\n",
      "Epoch 90, Loss(train/val) 0.19156/0.33772. Took 0.14 sec\n",
      "Epoch 91, Loss(train/val) 0.18830/0.32972. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.18557/0.34424. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.18771/0.33621. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.18319/0.33294. Took 0.14 sec\n",
      "Epoch 95, Loss(train/val) 0.18647/0.30067. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.17835/0.36072. Took 0.14 sec\n",
      "Epoch 97, Loss(train/val) 0.18400/0.32831. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.17664/0.32556. Took 0.14 sec\n",
      "Epoch 99, Loss(train/val) 0.17938/0.33961. Took 0.14 sec\n",
      "ACC: 0.59375, MCC: 0.3142857142857143\n",
      "Epoch 0, Loss(train/val) 0.49258/0.49696. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.46674/0.48862. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.44102/0.46133. Took 0.15 sec\n",
      "Epoch 3, Loss(train/val) 0.41876/0.43410. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.40262/0.42106. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.38721/0.40779. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.37192/0.41921. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.36303/0.41083. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.35607/0.41013. Took 0.15 sec\n",
      "Epoch 9, Loss(train/val) 0.33826/0.40576. Took 0.15 sec\n",
      "Epoch 10, Loss(train/val) 0.32838/0.38978. Took 0.15 sec\n",
      "Epoch 11, Loss(train/val) 0.33957/0.38683. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.33303/0.39196. Took 0.15 sec\n",
      "Epoch 13, Loss(train/val) 0.32490/0.38541. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.32403/0.37207. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.32368/0.39871. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.32347/0.37832. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.31511/0.40483. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.32357/0.36531. Took 0.15 sec\n",
      "Epoch 19, Loss(train/val) 0.30981/0.40831. Took 0.15 sec\n",
      "Epoch 20, Loss(train/val) 0.32686/0.40270. Took 0.15 sec\n",
      "Epoch 21, Loss(train/val) 0.31589/0.39672. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.30852/0.40078. Took 0.15 sec\n",
      "Epoch 23, Loss(train/val) 0.29694/0.40212. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.30467/0.39435. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.30323/0.40528. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.29486/0.41622. Took 0.15 sec\n",
      "Epoch 27, Loss(train/val) 0.29066/0.39553. Took 0.16 sec\n",
      "Epoch 28, Loss(train/val) 0.30051/0.39335. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.30065/0.41364. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.29528/0.43270. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.29902/0.42401. Took 0.17 sec\n",
      "Epoch 32, Loss(train/val) 0.29474/0.40936. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.28796/0.41918. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.29105/0.44058. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.27893/0.43278. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.27826/0.41558. Took 0.16 sec\n",
      "Epoch 37, Loss(train/val) 0.27931/0.42578. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.26941/0.44566. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.28199/0.41773. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.27676/0.41769. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.26391/0.43202. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.25456/0.44438. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.24682/0.43870. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.25894/0.43342. Took 0.15 sec\n",
      "Epoch 45, Loss(train/val) 0.24864/0.42874. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.25873/0.40428. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.25431/0.41196. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.24615/0.43998. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.24181/0.43356. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.23577/0.44116. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.23449/0.43433. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.23302/0.42625. Took 0.15 sec\n",
      "Epoch 53, Loss(train/val) 0.23445/0.42410. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.22026/0.42005. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.22462/0.42945. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.22254/0.42438. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.22344/0.43972. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.22885/0.43130. Took 0.14 sec\n",
      "Epoch 59, Loss(train/val) 0.21676/0.42853. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.21145/0.42123. Took 0.14 sec\n",
      "Epoch 61, Loss(train/val) 0.20988/0.42816. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.20534/0.42441. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.20759/0.42361. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.20156/0.42776. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.19898/0.43227. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.20325/0.42850. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) 0.19307/0.42819. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.19101/0.43489. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.19164/0.42916. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.19019/0.42639. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.19387/0.42655. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.18340/0.42890. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.18271/0.43377. Took 0.15 sec\n",
      "Epoch 74, Loss(train/val) 0.17715/0.42455. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) 0.18584/0.42475. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.17307/0.42500. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.17251/0.42443. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.16914/0.42192. Took 0.14 sec\n",
      "Epoch 79, Loss(train/val) 0.17250/0.42084. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.17595/0.40641. Took 0.15 sec\n",
      "Epoch 81, Loss(train/val) 0.17023/0.42419. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.16770/0.42416. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) 0.16883/0.42470. Took 0.15 sec\n",
      "Epoch 84, Loss(train/val) 0.16320/0.43199. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.17056/0.43176. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.17134/0.42496. Took 0.15 sec\n",
      "Epoch 87, Loss(train/val) 0.16472/0.42307. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.16557/0.43269. Took 0.14 sec\n",
      "Epoch 89, Loss(train/val) 0.16052/0.42616. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.15708/0.42102. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.15474/0.42145. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.15580/0.43298. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.15399/0.43104. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.15262/0.41927. Took 0.14 sec\n",
      "Epoch 95, Loss(train/val) 0.14563/0.43106. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.13841/0.41449. Took 0.14 sec\n",
      "Epoch 97, Loss(train/val) 0.14610/0.42048. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.14601/0.41178. Took 0.14 sec\n",
      "Epoch 99, Loss(train/val) 0.14595/0.41375. Took 0.14 sec\n",
      "ACC: 0.625, MCC: 0.30903173899329384\n",
      "Epoch 0, Loss(train/val) 0.49262/0.49231. Took 0.81 sec\n",
      "Epoch 1, Loss(train/val) 0.47389/0.47260. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.44653/0.43404. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.41780/0.41251. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.39456/0.40559. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.38174/0.40199. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.37489/0.40751. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.36125/0.38909. Took 0.16 sec\n",
      "Epoch 8, Loss(train/val) 0.35946/0.38187. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.34958/0.36524. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.34262/0.36869. Took 0.16 sec\n",
      "Epoch 11, Loss(train/val) 0.33627/0.37211. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.33521/0.34484. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.34001/0.35377. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.31964/0.39024. Took 0.17 sec\n",
      "Epoch 15, Loss(train/val) 0.31849/0.39167. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.32095/0.38993. Took 0.16 sec\n",
      "Epoch 17, Loss(train/val) 0.30709/0.38512. Took 0.16 sec\n",
      "Epoch 18, Loss(train/val) 0.30762/0.36204. Took 0.15 sec\n",
      "Epoch 19, Loss(train/val) 0.30336/0.35590. Took 0.15 sec\n",
      "Epoch 20, Loss(train/val) 0.30871/0.35974. Took 0.17 sec\n",
      "Epoch 21, Loss(train/val) 0.29264/0.36977. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.30535/0.37652. Took 0.15 sec\n",
      "Epoch 23, Loss(train/val) 0.32631/0.35767. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.28962/0.36994. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.29797/0.35698. Took 0.17 sec\n",
      "Epoch 26, Loss(train/val) 0.28424/0.37643. Took 0.15 sec\n",
      "Epoch 27, Loss(train/val) 0.27967/0.37242. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.27954/0.39695. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.28344/0.37730. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.27416/0.37868. Took 0.16 sec\n",
      "Epoch 31, Loss(train/val) 0.27009/0.37938. Took 0.13 sec\n",
      "Epoch 32, Loss(train/val) 0.25557/0.35661. Took 0.13 sec\n",
      "Epoch 33, Loss(train/val) 0.25502/0.36036. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.25380/0.37766. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.24427/0.35363. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.25219/0.35416. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.24458/0.37566. Took 0.15 sec\n",
      "Epoch 38, Loss(train/val) 0.25039/0.35544. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.24026/0.36934. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.23457/0.36560. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.24014/0.36710. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.24145/0.37409. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.22441/0.37957. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.22454/0.38753. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.22017/0.38454. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.21765/0.36712. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.20537/0.37146. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.20444/0.39371. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.20137/0.37296. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.20741/0.36252. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.20576/0.37099. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.20266/0.36996. Took 0.15 sec\n",
      "Epoch 53, Loss(train/val) 0.20448/0.40509. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.19613/0.36182. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.20251/0.36375. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.19853/0.38822. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.19929/0.37308. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.19637/0.38500. Took 0.14 sec\n",
      "Epoch 59, Loss(train/val) 0.19328/0.37061. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.19065/0.37663. Took 0.14 sec\n",
      "Epoch 61, Loss(train/val) 0.19141/0.35569. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.18847/0.36463. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.18641/0.39997. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.17951/0.39424. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.18190/0.35992. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.18246/0.39353. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.17837/0.40584. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.17629/0.43033. Took 0.14 sec\n",
      "Epoch 69, Loss(train/val) 0.17516/0.40745. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.17713/0.40174. Took 0.15 sec\n",
      "Epoch 71, Loss(train/val) 0.18256/0.38035. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.16698/0.39164. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.16656/0.41014. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.16934/0.38820. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) 0.17530/0.40058. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.17578/0.38239. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.16560/0.41548. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.19033/0.36786. Took 0.14 sec\n",
      "Epoch 79, Loss(train/val) 0.17751/0.37704. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.17409/0.41629. Took 0.14 sec\n",
      "Epoch 81, Loss(train/val) 0.17246/0.40702. Took 0.15 sec\n",
      "Epoch 82, Loss(train/val) 0.18026/0.37980. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) 0.16592/0.35822. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.17313/0.38809. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.16933/0.41629. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.16462/0.37813. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.16019/0.38047. Took 0.15 sec\n",
      "Epoch 88, Loss(train/val) 0.15788/0.39810. Took 0.14 sec\n",
      "Epoch 89, Loss(train/val) 0.15943/0.40141. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.15557/0.39656. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.15846/0.38322. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.15956/0.37514. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.16802/0.39398. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.15307/0.42266. Took 0.14 sec\n",
      "Epoch 95, Loss(train/val) 0.15498/0.36984. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.14848/0.39221. Took 0.14 sec\n",
      "Epoch 97, Loss(train/val) 0.14461/0.41644. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.15438/0.40814. Took 0.14 sec\n",
      "Epoch 99, Loss(train/val) 0.14920/0.41496. Took 0.13 sec\n",
      "ACC: 0.609375, MCC: 0.29542903223069444\n",
      "Epoch 0, Loss(train/val) 0.49310/0.48956. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.47663/0.46630. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.45407/0.42955. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.43039/0.39706. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.40882/0.36845. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.39218/0.35397. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.37855/0.34143. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.36871/0.35440. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.35492/0.35213. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.34640/0.37562. Took 0.15 sec\n",
      "Epoch 10, Loss(train/val) 0.32979/0.37525. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.32888/0.35367. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.31361/0.35927. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.32686/0.31565. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.30468/0.34129. Took 0.15 sec\n",
      "Epoch 15, Loss(train/val) 0.30605/0.37934. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.30924/0.35826. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.30580/0.32479. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.29224/0.32870. Took 0.16 sec\n",
      "Epoch 19, Loss(train/val) 0.28181/0.33971. Took 0.15 sec\n",
      "Epoch 20, Loss(train/val) 0.28376/0.34165. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.28006/0.35282. Took 0.16 sec\n",
      "Epoch 22, Loss(train/val) 0.27551/0.34026. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.26776/0.33440. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.26512/0.32141. Took 0.16 sec\n",
      "Epoch 25, Loss(train/val) 0.26633/0.32820. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.25565/0.33027. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.24688/0.32702. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.25161/0.33008. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.24911/0.35637. Took 0.17 sec\n",
      "Epoch 30, Loss(train/val) 0.25722/0.35563. Took 0.16 sec\n",
      "Epoch 31, Loss(train/val) 0.24188/0.33898. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.23744/0.33841. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.23080/0.32033. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.22476/0.34380. Took 0.17 sec\n",
      "Epoch 35, Loss(train/val) 0.22710/0.36015. Took 0.17 sec\n",
      "Epoch 36, Loss(train/val) 0.22817/0.33812. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.22517/0.35487. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.21252/0.32732. Took 0.15 sec\n",
      "Epoch 39, Loss(train/val) 0.20706/0.33799. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.21098/0.33884. Took 0.15 sec\n",
      "Epoch 41, Loss(train/val) 0.20631/0.33175. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.19127/0.33385. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.20484/0.34974. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.20726/0.34032. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.19954/0.33880. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.19877/0.34261. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.19289/0.33626. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.19345/0.34223. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.19223/0.33791. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.18093/0.33927. Took 0.14 sec\n",
      "Epoch 51, Loss(train/val) 0.18274/0.33424. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.18301/0.32345. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) 0.18019/0.32324. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.16963/0.35211. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.18740/0.32719. Took 0.16 sec\n",
      "Epoch 56, Loss(train/val) 0.17445/0.35325. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.16737/0.35025. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.16604/0.32274. Took 0.14 sec\n",
      "Epoch 59, Loss(train/val) 0.16160/0.34508. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.17309/0.34070. Took 0.14 sec\n",
      "Epoch 61, Loss(train/val) 0.16076/0.35258. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.16570/0.36269. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.15698/0.35151. Took 0.15 sec\n",
      "Epoch 64, Loss(train/val) 0.15542/0.36607. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.15810/0.36265. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.15924/0.33518. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) 0.15050/0.34580. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.15122/0.35698. Took 0.14 sec\n",
      "Epoch 69, Loss(train/val) 0.14851/0.36129. Took 0.15 sec\n",
      "Epoch 70, Loss(train/val) 0.14741/0.33844. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.15844/0.36020. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.14018/0.34137. Took 0.15 sec\n",
      "Epoch 73, Loss(train/val) 0.14640/0.34500. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.14095/0.41513. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) 0.13953/0.35994. Took 0.15 sec\n",
      "Epoch 76, Loss(train/val) 0.14281/0.35577. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.13580/0.34163. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.12620/0.36890. Took 0.14 sec\n",
      "Epoch 79, Loss(train/val) 0.12700/0.36330. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.13185/0.35203. Took 0.14 sec\n",
      "Epoch 81, Loss(train/val) 0.13910/0.35005. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.13819/0.33845. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.13567/0.39315. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.12412/0.34395. Took 0.15 sec\n",
      "Epoch 85, Loss(train/val) 0.13317/0.40300. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.12515/0.39777. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.12934/0.36015. Took 0.15 sec\n",
      "Epoch 88, Loss(train/val) 0.12535/0.38593. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.13137/0.36297. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.12997/0.35096. Took 0.15 sec\n",
      "Epoch 91, Loss(train/val) 0.12081/0.36945. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.12375/0.36136. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.12156/0.39052. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.12371/0.41234. Took 0.14 sec\n",
      "Epoch 95, Loss(train/val) 0.11413/0.38152. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.11787/0.38715. Took 0.15 sec\n",
      "Epoch 97, Loss(train/val) 0.11787/0.39456. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.11267/0.39251. Took 0.14 sec\n",
      "Epoch 99, Loss(train/val) 0.11255/0.39188. Took 0.15 sec\n",
      "ACC: 0.625, MCC: 0.2691246795032895\n",
      "Epoch 0, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) nan/nan. Took 0.16 sec\n",
      "Epoch 5, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 6, Loss(train/val) nan/nan. Took 0.16 sec\n",
      "Epoch 7, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 12, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 17, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) nan/nan. Took 0.17 sec\n",
      "Epoch 25, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 27, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) nan/nan. Took 0.17 sec\n",
      "Epoch 29, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) nan/nan. Took 0.16 sec\n",
      "Epoch 32, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) nan/nan. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 41, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 42, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) nan/nan. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) nan/nan. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) nan/nan. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 51, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 52, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) nan/nan. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 58, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 59, Loss(train/val) nan/nan. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) nan/nan. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 62, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 65, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 67, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 69, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) nan/nan. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) nan/nan. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) nan/nan. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 79, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 81, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) nan/nan. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 89, Loss(train/val) nan/nan. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 91, Loss(train/val) nan/nan. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 95, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) nan/nan. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 98, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 99, Loss(train/val) nan/nan. Took 0.13 sec\n",
      "ACC: 0.5, MCC: 0.0\n",
      "Epoch 0, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) nan/nan. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) nan/nan. Took 0.16 sec\n",
      "Epoch 7, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 12, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 13, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 15, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) nan/nan. Took 0.16 sec\n",
      "Epoch 19, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) nan/nan. Took 0.16 sec\n",
      "Epoch 23, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) nan/nan. Took 0.17 sec\n",
      "Epoch 25, Loss(train/val) nan/nan. Took 0.16 sec\n",
      "Epoch 26, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 27, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) nan/nan. Took 0.16 sec\n",
      "Epoch 30, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) nan/nan. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) nan/nan. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 44, Loss(train/val) nan/nan. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) nan/nan. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) nan/nan. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 50, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 51, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 53, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) nan/nan. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) nan/nan. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) nan/nan. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 61, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 69, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 73, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) nan/nan. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 79, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 81, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 82, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) nan/nan. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) nan/nan. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) nan/nan. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 89, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) nan/nan. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 95, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 97, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 99, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "ACC: 0.546875, MCC: 0.0\n",
      "Epoch 0, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) nan/nan. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) nan/nan. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 5, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 6, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 7, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) nan/nan. Took 0.16 sec\n",
      "Epoch 10, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) nan/nan. Took 0.16 sec\n",
      "Epoch 13, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 17, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) nan/nan. Took 0.16 sec\n",
      "Epoch 19, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) nan/nan. Took 0.16 sec\n",
      "Epoch 22, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) nan/nan. Took 0.16 sec\n",
      "Epoch 25, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) nan/nan. Took 0.16 sec\n",
      "Epoch 27, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) nan/nan. Took 0.16 sec\n",
      "Epoch 32, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) nan/nan. Took 0.16 sec\n",
      "Epoch 35, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 41, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) nan/nan. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) nan/nan. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) nan/nan. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 51, Loss(train/val) nan/nan. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) nan/nan. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) nan/nan. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 59, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) nan/nan. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) nan/nan. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) nan/nan. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 69, Loss(train/val) nan/nan. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) nan/nan. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 76, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 79, Loss(train/val) nan/nan. Took 0.16 sec\n",
      "Epoch 80, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 81, Loss(train/val) nan/nan. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 89, Loss(train/val) nan/nan. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 91, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) nan/nan. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 95, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 97, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 99, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "ACC: 0.46875, MCC: 0.0\n",
      "Epoch 0, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) nan/nan. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 3, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) nan/nan. Took 0.17 sec\n",
      "Epoch 7, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) nan/nan. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 11, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 12, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 13, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) nan/nan. Took 0.16 sec\n",
      "Epoch 19, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 23, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 25, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) nan/nan. Took 0.16 sec\n",
      "Epoch 27, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) nan/nan. Took 0.16 sec\n",
      "Epoch 33, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) nan/nan. Took 0.13 sec\n",
      "Epoch 35, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) nan/nan. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) nan/nan. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) nan/nan. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 48, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) nan/nan. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 51, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 53, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) nan/nan. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 59, Loss(train/val) nan/nan. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 61, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 66, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 69, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 70, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) nan/nan. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) nan/nan. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) nan/nan. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) nan/nan. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 81, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) nan/nan. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) nan/nan. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) nan/nan. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 88, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 89, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 91, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 95, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) nan/nan. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) nan/nan. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 99, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "ACC: 0.546875, MCC: 0.0\n",
      "Epoch 0, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 3, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 4, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 7, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 8, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 12, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) nan/nan. Took 0.16 sec\n",
      "Epoch 15, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 19, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 20, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 21, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) nan/nan. Took 0.16 sec\n",
      "Epoch 24, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 25, Loss(train/val) nan/nan. Took 0.16 sec\n",
      "Epoch 26, Loss(train/val) nan/nan. Took 0.16 sec\n",
      "Epoch 27, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) nan/nan. Took 0.16 sec\n",
      "Epoch 29, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) nan/nan. Took 0.17 sec\n",
      "Epoch 32, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) nan/nan. Took 0.13 sec\n",
      "Epoch 36, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 38, Loss(train/val) nan/nan. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) nan/nan. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 49, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) nan/nan. Took 0.16 sec\n",
      "Epoch 51, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 56, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 59, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 61, Loss(train/val) nan/nan. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) nan/nan. Took 0.16 sec\n",
      "Epoch 63, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 66, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 69, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) nan/nan. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) nan/nan. Took 0.16 sec\n",
      "Epoch 73, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 75, Loss(train/val) nan/nan. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) nan/nan. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 79, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 81, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) nan/nan. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 89, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 91, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) nan/nan. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 95, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 97, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 99, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "ACC: 0.546875, MCC: 0.0\n",
      "Epoch 0, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 3, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) nan/nan. Took 0.16 sec\n",
      "Epoch 8, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 9, Loss(train/val) nan/nan. Took 0.16 sec\n",
      "Epoch 10, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 13, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) nan/nan. Took 0.16 sec\n",
      "Epoch 19, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) nan/nan. Took 0.16 sec\n",
      "Epoch 23, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 25, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 27, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) nan/nan. Took 0.16 sec\n",
      "Epoch 29, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) nan/nan. Took 0.16 sec\n",
      "Epoch 33, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) nan/nan. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) nan/nan. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 51, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 53, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 59, Loss(train/val) nan/nan. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 61, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 65, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 69, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 78, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 79, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 81, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) nan/nan. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 89, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 91, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 94, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 95, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 97, Loss(train/val) nan/nan. Took 0.16 sec\n",
      "Epoch 98, Loss(train/val) nan/nan. Took 0.16 sec\n",
      "Epoch 99, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "ACC: 0.5, MCC: 0.0\n",
      "Epoch 0, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 4, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) nan/nan. Took 0.16 sec\n",
      "Epoch 9, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) nan/nan. Took 0.16 sec\n",
      "Epoch 15, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) nan/nan. Took 0.16 sec\n",
      "Epoch 20, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 21, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) nan/nan. Took 0.16 sec\n",
      "Epoch 25, Loss(train/val) nan/nan. Took 0.16 sec\n",
      "Epoch 26, Loss(train/val) nan/nan. Took 0.16 sec\n",
      "Epoch 27, Loss(train/val) nan/nan. Took 0.17 sec\n",
      "Epoch 28, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 40, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 43, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 48, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 51, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) nan/nan. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) nan/nan. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 58, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 59, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 61, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 62, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 69, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 72, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) nan/nan. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) nan/nan. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) nan/nan. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) nan/nan. Took 0.16 sec\n",
      "Epoch 83, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 89, Loss(train/val) nan/nan. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 91, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 95, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) nan/nan. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) nan/nan. Took 0.15 sec\n",
      "Epoch 98, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "Epoch 99, Loss(train/val) nan/nan. Took 0.14 sec\n",
      "ACC: 0.546875, MCC: 0.0\n",
      "Epoch 0, Loss(train/val) 0.49384/0.48371. Took 0.81 sec\n",
      "Epoch 1, Loss(train/val) 0.47383/0.45106. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.43703/0.39209. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.40196/0.35691. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.38551/0.34875. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.37369/0.32643. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.36501/0.30782. Took 0.15 sec\n",
      "Epoch 7, Loss(train/val) 0.35799/0.30876. Took 0.15 sec\n",
      "Epoch 8, Loss(train/val) 0.34894/0.30821. Took 0.15 sec\n",
      "Epoch 9, Loss(train/val) 0.34243/0.31312. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.33265/0.29915. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.32113/0.32073. Took 0.15 sec\n",
      "Epoch 12, Loss(train/val) 0.31468/0.38182. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.31155/0.29812. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.30501/0.39014. Took 0.16 sec\n",
      "Epoch 15, Loss(train/val) 0.30684/0.41238. Took 0.16 sec\n",
      "Epoch 16, Loss(train/val) 0.31212/0.42986. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.30396/0.30776. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.30146/0.31157. Took 0.16 sec\n",
      "Epoch 19, Loss(train/val) 0.28935/0.34821. Took 0.17 sec\n",
      "Epoch 20, Loss(train/val) 0.27957/0.42570. Took 0.15 sec\n",
      "Epoch 21, Loss(train/val) 0.28242/0.41133. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.27796/0.48842. Took 0.16 sec\n",
      "Epoch 23, Loss(train/val) 0.27898/0.46030. Took 0.16 sec\n",
      "Epoch 24, Loss(train/val) 0.26993/0.44654. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.26527/0.44756. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.27875/0.44209. Took 0.15 sec\n",
      "Epoch 27, Loss(train/val) 0.26540/0.48436. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.27120/0.50761. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.26324/0.51249. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.26623/0.49428. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.24862/0.48737. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.25505/0.45182. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.25004/0.48269. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.25388/0.48133. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.24165/0.45015. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.24162/0.45344. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.24834/0.41839. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.23792/0.42162. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.24025/0.44423. Took 0.15 sec\n",
      "Epoch 40, Loss(train/val) 0.23365/0.42807. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.22868/0.43846. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.23630/0.44473. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.22443/0.35609. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.23098/0.43789. Took 0.15 sec\n",
      "Epoch 45, Loss(train/val) 0.22673/0.47978. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.22022/0.45276. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.22058/0.46849. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.21717/0.43781. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.21328/0.44628. Took 0.15 sec\n",
      "Epoch 50, Loss(train/val) 0.21505/0.48553. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.21593/0.39939. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.21408/0.48032. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.20473/0.48358. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.20730/0.47369. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.20449/0.48765. Took 0.15 sec\n",
      "Epoch 56, Loss(train/val) 0.20935/0.47631. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.20273/0.45855. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.20137/0.47242. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.20109/0.49836. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.18852/0.50994. Took 0.14 sec\n",
      "Epoch 61, Loss(train/val) 0.19068/0.47923. Took 0.15 sec\n",
      "Epoch 62, Loss(train/val) 0.20250/0.47995. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.19034/0.43766. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.18621/0.45799. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.19433/0.42706. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.19263/0.49871. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) 0.19065/0.45770. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.18570/0.49067. Took 0.14 sec\n",
      "Epoch 69, Loss(train/val) 0.18505/0.48566. Took 0.15 sec\n",
      "Epoch 70, Loss(train/val) 0.17714/0.44883. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.17303/0.47746. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.18325/0.46383. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.18148/0.40927. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.19037/0.46224. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.16784/0.48713. Took 0.15 sec\n",
      "Epoch 76, Loss(train/val) 0.17602/0.49310. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.17349/0.48713. Took 0.16 sec\n",
      "Epoch 78, Loss(train/val) 0.18153/0.42044. Took 0.14 sec\n",
      "Epoch 79, Loss(train/val) 0.18632/0.48431. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.16535/0.49645. Took 0.14 sec\n",
      "Epoch 81, Loss(train/val) 0.17054/0.43492. Took 0.15 sec\n",
      "Epoch 82, Loss(train/val) 0.16969/0.49504. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) 0.17295/0.51918. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.16361/0.50730. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.15720/0.50555. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.16242/0.49790. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.16626/0.51627. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.16139/0.46577. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.16679/0.51169. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.17518/0.41876. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.15939/0.35994. Took 0.15 sec\n",
      "Epoch 92, Loss(train/val) 0.15854/0.45892. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.16123/0.41486. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.16145/0.33966. Took 0.14 sec\n",
      "Epoch 95, Loss(train/val) 0.15567/0.38288. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.14928/0.37612. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.16384/0.36886. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.15698/0.36890. Took 0.14 sec\n",
      "Epoch 99, Loss(train/val) 0.15087/0.33819. Took 0.13 sec\n",
      "ACC: 0.546875, MCC: 0.2734514088116147\n",
      "Epoch 0, Loss(train/val) 0.49336/0.48907. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.46989/0.46897. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.43174/0.43758. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.39690/0.42402. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.38090/0.42466. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.36785/0.43897. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.35441/0.39632. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.34166/0.39908. Took 0.15 sec\n",
      "Epoch 8, Loss(train/val) 0.32267/0.34500. Took 0.16 sec\n",
      "Epoch 9, Loss(train/val) 0.31925/0.39099. Took 0.15 sec\n",
      "Epoch 10, Loss(train/val) 0.30842/0.36219. Took 0.16 sec\n",
      "Epoch 11, Loss(train/val) 0.29955/0.28462. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.30747/0.28315. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.29818/0.31719. Took 0.16 sec\n",
      "Epoch 14, Loss(train/val) 0.28977/0.37431. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.28962/0.31936. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.28756/0.38562. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.28034/0.40344. Took 0.16 sec\n",
      "Epoch 18, Loss(train/val) 0.28359/0.39106. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.26912/0.37936. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.29136/0.27363. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.28368/0.37279. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.28732/0.29513. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.27006/0.33004. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.26617/0.34709. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.25655/0.34981. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.26446/0.28396. Took 0.17 sec\n",
      "Epoch 27, Loss(train/val) 0.27065/0.28002. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.25872/0.34013. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.25336/0.34449. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.25124/0.36457. Took 0.16 sec\n",
      "Epoch 31, Loss(train/val) 0.24607/0.31246. Took 0.16 sec\n",
      "Epoch 32, Loss(train/val) 0.25210/0.34293. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.24805/0.26733. Took 0.16 sec\n",
      "Epoch 34, Loss(train/val) 0.25130/0.36013. Took 0.16 sec\n",
      "Epoch 35, Loss(train/val) 0.23669/0.30576. Took 0.15 sec\n",
      "Epoch 36, Loss(train/val) 0.24431/0.35404. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.23442/0.35078. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.24252/0.33290. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.23840/0.33298. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.23082/0.32270. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.23786/0.33979. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.22553/0.30409. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.22965/0.29474. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.23072/0.33150. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) 0.22821/0.31814. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.23495/0.36037. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.22645/0.34383. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.23022/0.32857. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.22764/0.30169. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.21840/0.30570. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.21609/0.30678. Took 0.15 sec\n",
      "Epoch 52, Loss(train/val) 0.22357/0.29391. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) 0.22712/0.29899. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.21898/0.33993. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.21669/0.34502. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.22207/0.30443. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.20982/0.32290. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.20833/0.26497. Took 0.14 sec\n",
      "Epoch 59, Loss(train/val) 0.22169/0.32279. Took 0.15 sec\n",
      "Epoch 60, Loss(train/val) 0.20925/0.31015. Took 0.14 sec\n",
      "Epoch 61, Loss(train/val) 0.20984/0.32728. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.21165/0.35058. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.20285/0.29921. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.20471/0.31943. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.19733/0.28922. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.20085/0.29700. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) 0.19766/0.29251. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.20368/0.30734. Took 0.14 sec\n",
      "Epoch 69, Loss(train/val) 0.19406/0.31262. Took 0.15 sec\n",
      "Epoch 70, Loss(train/val) 0.19442/0.26956. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.19320/0.29863. Took 0.15 sec\n",
      "Epoch 72, Loss(train/val) 0.18897/0.28198. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.18785/0.31282. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.18327/0.31485. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) 0.18964/0.31683. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.20303/0.34562. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.18073/0.29157. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.19257/0.28961. Took 0.14 sec\n",
      "Epoch 79, Loss(train/val) 0.18942/0.32496. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.17909/0.31469. Took 0.14 sec\n",
      "Epoch 81, Loss(train/val) 0.18434/0.29010. Took 0.15 sec\n",
      "Epoch 82, Loss(train/val) 0.17848/0.31476. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.17783/0.31742. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.18690/0.31837. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.17328/0.31147. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.18714/0.32053. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.17201/0.26278. Took 0.15 sec\n",
      "Epoch 88, Loss(train/val) 0.18007/0.33928. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.18281/0.31146. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.18299/0.25408. Took 0.14 sec\n",
      "Epoch 91, Loss(train/val) 0.17180/0.29839. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.16997/0.28025. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.17728/0.28307. Took 0.15 sec\n",
      "Epoch 94, Loss(train/val) 0.17714/0.29970. Took 0.14 sec\n",
      "Epoch 95, Loss(train/val) 0.16883/0.29701. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.16964/0.29195. Took 0.15 sec\n",
      "Epoch 97, Loss(train/val) 0.16707/0.29496. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.16773/0.27665. Took 0.14 sec\n",
      "Epoch 99, Loss(train/val) 0.16908/0.30462. Took 0.14 sec\n",
      "ACC: 0.625, MCC: 0.19786087521634682\n",
      "Epoch 0, Loss(train/val) 0.49197/0.49116. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.46797/0.46542. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.43059/0.43718. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.40237/0.41927. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.38422/0.41133. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.37205/0.40596. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.35778/0.41600. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.34698/0.42788. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.33378/0.41202. Took 0.15 sec\n",
      "Epoch 9, Loss(train/val) 0.33074/0.40838. Took 0.15 sec\n",
      "Epoch 10, Loss(train/val) 0.32517/0.38797. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.32319/0.35424. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.31332/0.34463. Took 0.16 sec\n",
      "Epoch 13, Loss(train/val) 0.31176/0.36328. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.30755/0.37177. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.30534/0.37579. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.29826/0.35222. Took 0.15 sec\n",
      "Epoch 17, Loss(train/val) 0.29702/0.36272. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.29638/0.38862. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.28706/0.38395. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.28186/0.39079. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.28346/0.37244. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.28477/0.44042. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.27726/0.40228. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.27735/0.38868. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.27463/0.41010. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.27750/0.40114. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.25987/0.39873. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.26842/0.41953. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.25669/0.37679. Took 0.16 sec\n",
      "Epoch 30, Loss(train/val) 0.26026/0.40533. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.25482/0.38550. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.26347/0.38278. Took 0.16 sec\n",
      "Epoch 33, Loss(train/val) 0.25824/0.41996. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.26019/0.39376. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.26033/0.46523. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.24554/0.40150. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.25108/0.45933. Took 0.16 sec\n",
      "Epoch 38, Loss(train/val) 0.25151/0.44453. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.24855/0.45328. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.23879/0.47880. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.23381/0.48601. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.22718/0.42053. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.23166/0.44706. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.22196/0.42249. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.22679/0.43924. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.22118/0.43332. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.23096/0.41718. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.21629/0.45640. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.21305/0.44300. Took 0.15 sec\n",
      "Epoch 50, Loss(train/val) 0.21169/0.46041. Took 0.14 sec\n",
      "Epoch 51, Loss(train/val) 0.20866/0.44848. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.20593/0.43399. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) 0.20068/0.41084. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.20771/0.42099. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.20323/0.46489. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.20379/0.41807. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.20859/0.44105. Took 0.15 sec\n",
      "Epoch 58, Loss(train/val) 0.20485/0.40759. Took 0.14 sec\n",
      "Epoch 59, Loss(train/val) 0.19246/0.39741. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.18756/0.41192. Took 0.14 sec\n",
      "Epoch 61, Loss(train/val) 0.19585/0.42634. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.19157/0.40565. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.17625/0.43303. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.18235/0.46560. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.18395/0.44867. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.18462/0.45650. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.18374/0.46229. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.17894/0.45299. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.18224/0.46005. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.17222/0.45326. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.17592/0.44162. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.16372/0.45790. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.16352/0.42492. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.16864/0.43855. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.16986/0.41089. Took 0.15 sec\n",
      "Epoch 76, Loss(train/val) 0.16259/0.42444. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.16704/0.41174. Took 0.15 sec\n",
      "Epoch 78, Loss(train/val) 0.16126/0.43751. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.16613/0.43382. Took 0.15 sec\n",
      "Epoch 80, Loss(train/val) 0.16722/0.43296. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.15304/0.43344. Took 0.15 sec\n",
      "Epoch 82, Loss(train/val) 0.15268/0.42061. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) 0.16784/0.43269. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.15654/0.42953. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.15467/0.45458. Took 0.15 sec\n",
      "Epoch 86, Loss(train/val) 0.16017/0.41827. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.17064/0.43298. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.16102/0.42805. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.15460/0.43255. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.16196/0.42972. Took 0.14 sec\n",
      "Epoch 91, Loss(train/val) 0.14930/0.44073. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.15096/0.41002. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.14586/0.42957. Took 0.15 sec\n",
      "Epoch 94, Loss(train/val) 0.15437/0.44693. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.14517/0.44719. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.14294/0.45764. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.14680/0.46024. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.14748/0.45926. Took 0.14 sec\n",
      "Epoch 99, Loss(train/val) 0.15925/0.47344. Took 0.13 sec\n",
      "ACC: 0.6875, MCC: 0.38177085778546666\n",
      "Epoch 0, Loss(train/val) 0.49052/0.48720. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.46633/0.46230. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.43672/0.42538. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.40919/0.38785. Took 0.16 sec\n",
      "Epoch 4, Loss(train/val) 0.39399/0.37038. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.37874/0.35784. Took 0.16 sec\n",
      "Epoch 6, Loss(train/val) 0.36954/0.34984. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.35909/0.35000. Took 0.15 sec\n",
      "Epoch 8, Loss(train/val) 0.34504/0.34531. Took 0.15 sec\n",
      "Epoch 9, Loss(train/val) 0.34648/0.33651. Took 0.18 sec\n",
      "Epoch 10, Loss(train/val) 0.34263/0.34463. Took 0.16 sec\n",
      "Epoch 11, Loss(train/val) 0.33678/0.34111. Took 0.15 sec\n",
      "Epoch 12, Loss(train/val) 0.32971/0.34387. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.31802/0.34746. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.32732/0.33827. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.32042/0.33348. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.31701/0.33209. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.31385/0.33390. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.31720/0.34890. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.30306/0.33137. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.31101/0.37091. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.31052/0.33576. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.28907/0.33548. Took 0.15 sec\n",
      "Epoch 23, Loss(train/val) 0.29783/0.33310. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.29479/0.35063. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.28093/0.33779. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.30467/0.33268. Took 0.16 sec\n",
      "Epoch 27, Loss(train/val) 0.28699/0.33334. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.28073/0.34253. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.26706/0.33410. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.27563/0.33854. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.28073/0.32282. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.27484/0.33681. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.25898/0.32184. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.28000/0.35810. Took 0.16 sec\n",
      "Epoch 35, Loss(train/val) 0.26515/0.32309. Took 0.15 sec\n",
      "Epoch 36, Loss(train/val) 0.25952/0.31949. Took 0.17 sec\n",
      "Epoch 37, Loss(train/val) 0.26021/0.33784. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.25457/0.31994. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.25160/0.36702. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.26306/0.34063. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.25386/0.33878. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.24261/0.33986. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.24821/0.36447. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.24630/0.32470. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) 0.24529/0.34442. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.24281/0.33673. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.24837/0.33096. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.23018/0.32955. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.24011/0.32274. Took 0.15 sec\n",
      "Epoch 50, Loss(train/val) 0.22842/0.32416. Took 0.14 sec\n",
      "Epoch 51, Loss(train/val) 0.22903/0.33584. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.22453/0.34032. Took 0.15 sec\n",
      "Epoch 53, Loss(train/val) 0.22574/0.33787. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.22039/0.34031. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.22722/0.33093. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.21608/0.34358. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.21668/0.35116. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.21241/0.33694. Took 0.14 sec\n",
      "Epoch 59, Loss(train/val) 0.20922/0.33959. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.20744/0.33296. Took 0.14 sec\n",
      "Epoch 61, Loss(train/val) 0.21763/0.34056. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.20692/0.34066. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.20466/0.33056. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.21355/0.33506. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.22385/0.33541. Took 0.15 sec\n",
      "Epoch 66, Loss(train/val) 0.21331/0.33221. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.21094/0.35530. Took 0.15 sec\n",
      "Epoch 68, Loss(train/val) 0.19791/0.35116. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.20600/0.35612. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.19966/0.34440. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.19255/0.36441. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.20044/0.34446. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.20531/0.36051. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.19871/0.36471. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) 0.19263/0.34330. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.20038/0.34949. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.19456/0.36400. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.18266/0.35233. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.18741/0.36598. Took 0.15 sec\n",
      "Epoch 80, Loss(train/val) 0.18035/0.32732. Took 0.14 sec\n",
      "Epoch 81, Loss(train/val) 0.18510/0.35889. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.18837/0.33587. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.18194/0.36788. Took 0.15 sec\n",
      "Epoch 84, Loss(train/val) 0.18761/0.34922. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.18888/0.36084. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.17873/0.36364. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.18506/0.37416. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.17451/0.34917. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.17533/0.35373. Took 0.15 sec\n",
      "Epoch 90, Loss(train/val) 0.18130/0.36998. Took 0.14 sec\n",
      "Epoch 91, Loss(train/val) 0.17091/0.35527. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.17229/0.33777. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.16514/0.34134. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.16858/0.34412. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.16996/0.35152. Took 0.15 sec\n",
      "Epoch 96, Loss(train/val) 0.17072/0.35256. Took 0.14 sec\n",
      "Epoch 97, Loss(train/val) 0.17390/0.34345. Took 0.15 sec\n",
      "Epoch 98, Loss(train/val) 0.16345/0.34165. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.16661/0.34073. Took 0.14 sec\n",
      "ACC: 0.640625, MCC: 0.28894436110328825\n",
      "Epoch 0, Loss(train/val) 0.49187/0.49527. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.46787/0.47843. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.43389/0.44214. Took 0.15 sec\n",
      "Epoch 3, Loss(train/val) 0.40104/0.43375. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.38388/0.43890. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.37340/0.43593. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.35903/0.43951. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.35486/0.42208. Took 0.16 sec\n",
      "Epoch 8, Loss(train/val) 0.34598/0.42810. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.34243/0.42773. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.33009/0.41940. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.33955/0.41093. Took 0.16 sec\n",
      "Epoch 12, Loss(train/val) 0.33004/0.40085. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.31815/0.42436. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.32520/0.42322. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.31145/0.42542. Took 0.16 sec\n",
      "Epoch 16, Loss(train/val) 0.30507/0.43379. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.29638/0.41133. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.29622/0.40329. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.29976/0.40372. Took 0.16 sec\n",
      "Epoch 20, Loss(train/val) 0.28781/0.41595. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.28769/0.40803. Took 0.16 sec\n",
      "Epoch 22, Loss(train/val) 0.28884/0.40755. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.28654/0.41960. Took 0.16 sec\n",
      "Epoch 24, Loss(train/val) 0.28600/0.42114. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.28178/0.38626. Took 0.16 sec\n",
      "Epoch 26, Loss(train/val) 0.28212/0.42434. Took 0.15 sec\n",
      "Epoch 27, Loss(train/val) 0.27923/0.41327. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.27092/0.42076. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.26878/0.40510. Took 0.17 sec\n",
      "Epoch 30, Loss(train/val) 0.26861/0.40239. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.27425/0.40134. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.25830/0.42220. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.25543/0.40192. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.27002/0.39219. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.26198/0.40366. Took 0.15 sec\n",
      "Epoch 36, Loss(train/val) 0.25671/0.38583. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.25477/0.39761. Took 0.16 sec\n",
      "Epoch 38, Loss(train/val) 0.24890/0.44185. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.24465/0.40189. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.24226/0.39309. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.24569/0.39951. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.24158/0.37420. Took 0.15 sec\n",
      "Epoch 43, Loss(train/val) 0.23546/0.40769. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.24325/0.38703. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) 0.23603/0.38103. Took 0.15 sec\n",
      "Epoch 46, Loss(train/val) 0.23172/0.38459. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.23418/0.38898. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.22199/0.40097. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.22327/0.37916. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.21753/0.40968. Took 0.14 sec\n",
      "Epoch 51, Loss(train/val) 0.23127/0.39278. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.22027/0.37063. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) 0.22577/0.37288. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.21688/0.37514. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.21189/0.41822. Took 0.15 sec\n",
      "Epoch 56, Loss(train/val) 0.21969/0.36079. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.20441/0.38445. Took 0.16 sec\n",
      "Epoch 58, Loss(train/val) 0.19942/0.38066. Took 0.14 sec\n",
      "Epoch 59, Loss(train/val) 0.21112/0.37996. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.20485/0.37182. Took 0.14 sec\n",
      "Epoch 61, Loss(train/val) 0.19930/0.38325. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.20441/0.36227. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.20129/0.37338. Took 0.15 sec\n",
      "Epoch 64, Loss(train/val) 0.20139/0.36811. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.19829/0.38263. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.19086/0.37720. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) 0.19566/0.38582. Took 0.15 sec\n",
      "Epoch 68, Loss(train/val) 0.18734/0.38928. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.18951/0.39638. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.19222/0.40214. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.19060/0.39322. Took 0.15 sec\n",
      "Epoch 72, Loss(train/val) 0.18412/0.39373. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.17905/0.38901. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.17918/0.39986. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) 0.17715/0.41074. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.18339/0.42155. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.17664/0.40794. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.17743/0.39427. Took 0.14 sec\n",
      "Epoch 79, Loss(train/val) 0.17659/0.40438. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.17703/0.39571. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.17356/0.41122. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.17657/0.40073. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.16320/0.39894. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.16442/0.38019. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.16533/0.37914. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.16804/0.38675. Took 0.15 sec\n",
      "Epoch 87, Loss(train/val) 0.15948/0.37905. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.16836/0.37746. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.15860/0.37624. Took 0.15 sec\n",
      "Epoch 90, Loss(train/val) 0.15550/0.39719. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.16475/0.38670. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.16469/0.38288. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.16102/0.39431. Took 0.15 sec\n",
      "Epoch 94, Loss(train/val) 0.16428/0.39272. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.15726/0.39237. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.15620/0.39331. Took 0.14 sec\n",
      "Epoch 97, Loss(train/val) 0.15706/0.37601. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.14827/0.38887. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.15590/0.39804. Took 0.15 sec\n",
      "ACC: 0.671875, MCC: 0.3505757849137574\n",
      "Epoch 0, Loss(train/val) 0.49303/0.48397. Took 0.16 sec\n",
      "Epoch 1, Loss(train/val) 0.46987/0.45239. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.43362/0.41949. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.40211/0.39110. Took 0.16 sec\n",
      "Epoch 4, Loss(train/val) 0.38666/0.37003. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.37680/0.35592. Took 0.15 sec\n",
      "Epoch 6, Loss(train/val) 0.36910/0.34570. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.35968/0.34547. Took 0.15 sec\n",
      "Epoch 8, Loss(train/val) 0.35374/0.33249. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.35077/0.35112. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.33904/0.33407. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.33137/0.33291. Took 0.15 sec\n",
      "Epoch 12, Loss(train/val) 0.32456/0.34561. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.31893/0.35428. Took 0.16 sec\n",
      "Epoch 14, Loss(train/val) 0.31041/0.32814. Took 0.16 sec\n",
      "Epoch 15, Loss(train/val) 0.30738/0.34755. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.29903/0.34480. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.29542/0.36580. Took 0.16 sec\n",
      "Epoch 18, Loss(train/val) 0.30141/0.35688. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.29688/0.34011. Took 0.16 sec\n",
      "Epoch 20, Loss(train/val) 0.29147/0.31339. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.28194/0.35350. Took 0.18 sec\n",
      "Epoch 22, Loss(train/val) 0.28431/0.37214. Took 0.16 sec\n",
      "Epoch 23, Loss(train/val) 0.27485/0.35492. Took 0.16 sec\n",
      "Epoch 24, Loss(train/val) 0.27235/0.35835. Took 0.15 sec\n",
      "Epoch 25, Loss(train/val) 0.26883/0.38433. Took 0.16 sec\n",
      "Epoch 26, Loss(train/val) 0.26685/0.37084. Took 0.15 sec\n",
      "Epoch 27, Loss(train/val) 0.26462/0.38215. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.25686/0.34664. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.26416/0.37845. Took 0.16 sec\n",
      "Epoch 30, Loss(train/val) 0.25304/0.38221. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.24495/0.37477. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.23950/0.39437. Took 0.17 sec\n",
      "Epoch 33, Loss(train/val) 0.23800/0.38905. Took 0.17 sec\n",
      "Epoch 34, Loss(train/val) 0.24221/0.39530. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.23964/0.38192. Took 0.15 sec\n",
      "Epoch 36, Loss(train/val) 0.22922/0.35618. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.22864/0.37139. Took 0.15 sec\n",
      "Epoch 38, Loss(train/val) 0.22391/0.36960. Took 0.16 sec\n",
      "Epoch 39, Loss(train/val) 0.22511/0.36511. Took 0.15 sec\n",
      "Epoch 40, Loss(train/val) 0.22314/0.39089. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.20841/0.37063. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.21426/0.34941. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.22379/0.38350. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.21534/0.37936. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) 0.20722/0.35298. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.21477/0.35504. Took 0.15 sec\n",
      "Epoch 47, Loss(train/val) 0.20570/0.36687. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.20522/0.37717. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.20527/0.37266. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.19887/0.34765. Took 0.14 sec\n",
      "Epoch 51, Loss(train/val) 0.19440/0.34250. Took 0.15 sec\n",
      "Epoch 52, Loss(train/val) 0.19058/0.34345. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) 0.18450/0.34445. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.19619/0.36876. Took 0.15 sec\n",
      "Epoch 55, Loss(train/val) 0.19013/0.35748. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.18821/0.35253. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.18682/0.36285. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.18404/0.32727. Took 0.14 sec\n",
      "Epoch 59, Loss(train/val) 0.19214/0.33700. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.18257/0.35544. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.19303/0.34012. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.17487/0.33171. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.17674/0.33493. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.17353/0.31529. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.16971/0.34070. Took 0.15 sec\n",
      "Epoch 66, Loss(train/val) 0.18041/0.32751. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.16916/0.34416. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.18221/0.34775. Took 0.14 sec\n",
      "Epoch 69, Loss(train/val) 0.17335/0.33606. Took 0.15 sec\n",
      "Epoch 70, Loss(train/val) 0.15909/0.37037. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.18439/0.37059. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.16475/0.34422. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.17177/0.35936. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.15807/0.35858. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.16598/0.34641. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.15377/0.34954. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.15485/0.33950. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.14779/0.34680. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.15963/0.35328. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.14540/0.35132. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.14616/0.35280. Took 0.15 sec\n",
      "Epoch 82, Loss(train/val) 0.14843/0.35514. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) 0.14883/0.36263. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.14628/0.36266. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.15015/0.34935. Took 0.16 sec\n",
      "Epoch 86, Loss(train/val) 0.14693/0.36455. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.14695/0.36653. Took 0.15 sec\n",
      "Epoch 88, Loss(train/val) 0.14454/0.37235. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.13312/0.36955. Took 0.16 sec\n",
      "Epoch 90, Loss(train/val) 0.13771/0.35045. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.13870/0.36439. Took 0.15 sec\n",
      "Epoch 92, Loss(train/val) 0.14649/0.36842. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.14076/0.35433. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.14084/0.35926. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.13919/0.37189. Took 0.15 sec\n",
      "Epoch 96, Loss(train/val) 0.14650/0.36729. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.13749/0.37170. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.14884/0.35469. Took 0.14 sec\n",
      "Epoch 99, Loss(train/val) 0.14199/0.36754. Took 0.15 sec\n",
      "ACC: 0.765625, MCC: 0.5146502354656655\n",
      "Epoch 0, Loss(train/val) 0.49001/0.46236. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.46260/0.40865. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.43177/0.37206. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.40521/0.34456. Took 0.15 sec\n",
      "Epoch 4, Loss(train/val) 0.39302/0.33697. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.38292/0.33335. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.37313/0.32785. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.36464/0.32259. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.35319/0.30342. Took 0.15 sec\n",
      "Epoch 9, Loss(train/val) 0.34781/0.32547. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.33597/0.33194. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.33030/0.30657. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.31899/0.29375. Took 0.15 sec\n",
      "Epoch 13, Loss(train/val) 0.31512/0.31805. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.31612/0.25550. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.30940/0.31600. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.30070/0.27089. Took 0.16 sec\n",
      "Epoch 17, Loss(train/val) 0.29885/0.27932. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.29557/0.27174. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.29421/0.30778. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.29374/0.30458. Took 0.15 sec\n",
      "Epoch 21, Loss(train/val) 0.29623/0.28202. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.28563/0.28658. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.28290/0.26903. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.27776/0.29180. Took 0.16 sec\n",
      "Epoch 25, Loss(train/val) 0.27390/0.28726. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.27689/0.28871. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.27274/0.28579. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.27716/0.31111. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.27873/0.27005. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.27141/0.27808. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.26766/0.29610. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.26617/0.32287. Took 0.16 sec\n",
      "Epoch 33, Loss(train/val) 0.27613/0.30332. Took 0.16 sec\n",
      "Epoch 34, Loss(train/val) 0.28043/0.35631. Took 0.16 sec\n",
      "Epoch 35, Loss(train/val) 0.27074/0.27845. Took 0.15 sec\n",
      "Epoch 36, Loss(train/val) 0.26421/0.30854. Took 0.17 sec\n",
      "Epoch 37, Loss(train/val) 0.26400/0.28391. Took 0.16 sec\n",
      "Epoch 38, Loss(train/val) 0.26449/0.32985. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.25390/0.30082. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.25401/0.34037. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.25458/0.34953. Took 0.16 sec\n",
      "Epoch 42, Loss(train/val) 0.25326/0.31852. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.24782/0.28577. Took 0.15 sec\n",
      "Epoch 44, Loss(train/val) 0.26613/0.35400. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) 0.26191/0.31170. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.24975/0.34972. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.24696/0.28332. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.23690/0.32998. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.24008/0.34409. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.24360/0.33561. Took 0.14 sec\n",
      "Epoch 51, Loss(train/val) 0.23558/0.33596. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.23914/0.32109. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) 0.22719/0.32697. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.23505/0.34821. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.22596/0.33811. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.23738/0.34935. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.22665/0.33331. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.22463/0.35546. Took 0.14 sec\n",
      "Epoch 59, Loss(train/val) 0.22900/0.34703. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.22649/0.32163. Took 0.14 sec\n",
      "Epoch 61, Loss(train/val) 0.21998/0.34436. Took 0.15 sec\n",
      "Epoch 62, Loss(train/val) 0.22306/0.36365. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.21460/0.32383. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.22321/0.37096. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.21745/0.35034. Took 0.15 sec\n",
      "Epoch 66, Loss(train/val) 0.21262/0.35256. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.20607/0.35566. Took 0.15 sec\n",
      "Epoch 68, Loss(train/val) 0.21239/0.36627. Took 0.14 sec\n",
      "Epoch 69, Loss(train/val) 0.20769/0.37133. Took 0.15 sec\n",
      "Epoch 70, Loss(train/val) 0.20752/0.37656. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.19968/0.35791. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.21557/0.35217. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.21005/0.35516. Took 0.16 sec\n",
      "Epoch 74, Loss(train/val) 0.20405/0.34114. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) 0.20331/0.34562. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.19531/0.35972. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.18974/0.35022. Took 0.15 sec\n",
      "Epoch 78, Loss(train/val) 0.18789/0.35661. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.19020/0.36377. Took 0.15 sec\n",
      "Epoch 80, Loss(train/val) 0.19644/0.33904. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.18878/0.35796. Took 0.16 sec\n",
      "Epoch 82, Loss(train/val) 0.18938/0.37296. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) 0.18227/0.35741. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.17761/0.35272. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.16817/0.33599. Took 0.15 sec\n",
      "Epoch 86, Loss(train/val) 0.17946/0.31393. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.17583/0.34401. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.17495/0.35374. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.17232/0.34230. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.17061/0.32229. Took 0.14 sec\n",
      "Epoch 91, Loss(train/val) 0.16270/0.35267. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.18101/0.37457. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.16437/0.34690. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.18095/0.31723. Took 0.14 sec\n",
      "Epoch 95, Loss(train/val) 0.16752/0.34838. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.16825/0.35859. Took 0.14 sec\n",
      "Epoch 97, Loss(train/val) 0.16076/0.35181. Took 0.15 sec\n",
      "Epoch 98, Loss(train/val) 0.16021/0.32003. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.16599/0.32926. Took 0.14 sec\n",
      "ACC: 0.703125, MCC: 0.4220139130427161\n",
      "Epoch 0, Loss(train/val) 0.49314/0.48186. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.46422/0.44111. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.42663/0.38905. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.39266/0.35857. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.37193/0.34511. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.35706/0.34790. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.34482/0.37918. Took 0.15 sec\n",
      "Epoch 7, Loss(train/val) 0.33712/0.36058. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.32391/0.47864. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.30748/0.48115. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.31240/0.45474. Took 0.15 sec\n",
      "Epoch 11, Loss(train/val) 0.29774/0.44051. Took 0.15 sec\n",
      "Epoch 12, Loss(train/val) 0.29027/0.33916. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.29405/0.33348. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.28236/0.34043. Took 0.15 sec\n",
      "Epoch 15, Loss(train/val) 0.29435/0.32448. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.28679/0.35739. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.27882/0.36177. Took 0.17 sec\n",
      "Epoch 18, Loss(train/val) 0.27856/0.31880. Took 0.15 sec\n",
      "Epoch 19, Loss(train/val) 0.28715/0.47337. Took 0.15 sec\n",
      "Epoch 20, Loss(train/val) 0.28248/0.32562. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.28184/0.32816. Took 0.16 sec\n",
      "Epoch 22, Loss(train/val) 0.27106/0.30384. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.26949/0.31140. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.27593/0.33545. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.26153/0.39520. Took 0.16 sec\n",
      "Epoch 26, Loss(train/val) 0.27488/0.32259. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.26712/0.42219. Took 0.16 sec\n",
      "Epoch 28, Loss(train/val) 0.25520/0.37551. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.25106/0.40448. Took 0.16 sec\n",
      "Epoch 30, Loss(train/val) 0.25717/0.35145. Took 0.16 sec\n",
      "Epoch 31, Loss(train/val) 0.24417/0.39988. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.24801/0.36529. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.24946/0.35480. Took 0.17 sec\n",
      "Epoch 34, Loss(train/val) 0.24032/0.32172. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.24429/0.31365. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.24406/0.31905. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.24090/0.30570. Took 0.15 sec\n",
      "Epoch 38, Loss(train/val) 0.25961/0.30021. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.24053/0.33477. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.24338/0.30471. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.24569/0.30464. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.23412/0.33288. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.23946/0.29515. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.23309/0.31932. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.22715/0.34435. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.22775/0.31412. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.22537/0.30882. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.22477/0.36568. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.22333/0.38272. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.21811/0.37699. Took 0.14 sec\n",
      "Epoch 51, Loss(train/val) 0.22237/0.37145. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.21638/0.36260. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) 0.22012/0.35169. Took 0.15 sec\n",
      "Epoch 54, Loss(train/val) 0.21392/0.35910. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.21397/0.35437. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.21402/0.34039. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.21671/0.35682. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.21955/0.34873. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.21829/0.36486. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.21804/0.36094. Took 0.14 sec\n",
      "Epoch 61, Loss(train/val) 0.21472/0.33971. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.20982/0.35011. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.21200/0.35608. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.20872/0.36130. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.20854/0.37474. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.20266/0.39484. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) 0.20472/0.41046. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.20685/0.39831. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.20173/0.38746. Took 0.15 sec\n",
      "Epoch 70, Loss(train/val) 0.20090/0.34959. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.20321/0.39001. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.19684/0.38290. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.19724/0.37941. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.19342/0.38587. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) 0.20086/0.38598. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.19292/0.39120. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.19542/0.40419. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.19564/0.40090. Took 0.14 sec\n",
      "Epoch 79, Loss(train/val) 0.19351/0.38450. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.18984/0.40398. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.19368/0.39867. Took 0.15 sec\n",
      "Epoch 82, Loss(train/val) 0.19071/0.41270. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) 0.19344/0.41987. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.18940/0.40500. Took 0.15 sec\n",
      "Epoch 85, Loss(train/val) 0.19044/0.39557. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.18491/0.37817. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.18844/0.39328. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.20272/0.38463. Took 0.14 sec\n",
      "Epoch 89, Loss(train/val) 0.18892/0.40578. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.19048/0.39051. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.18795/0.39534. Took 0.15 sec\n",
      "Epoch 92, Loss(train/val) 0.18568/0.40810. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.18758/0.39007. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.18631/0.38838. Took 0.14 sec\n",
      "Epoch 95, Loss(train/val) 0.18621/0.40095. Took 0.15 sec\n",
      "Epoch 96, Loss(train/val) 0.18650/0.40477. Took 0.14 sec\n",
      "Epoch 97, Loss(train/val) 0.19402/0.41041. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.18204/0.39784. Took 0.14 sec\n",
      "Epoch 99, Loss(train/val) 0.18562/0.38856. Took 0.16 sec\n",
      "ACC: 0.6875, MCC: 0.40012794823942693\n",
      "Epoch 0, Loss(train/val) 0.48865/0.49295. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.45580/0.47629. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.41692/0.42699. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.38534/0.37537. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.36520/0.34931. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.34956/0.34018. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.33995/0.35220. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.33676/0.33824. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.33532/0.35419. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.32899/0.35120. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.32007/0.35690. Took 0.16 sec\n",
      "Epoch 11, Loss(train/val) 0.31301/0.36043. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.31709/0.37055. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.31389/0.37321. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.31360/0.36540. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.29709/0.35813. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.30190/0.36348. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.29510/0.34067. Took 0.16 sec\n",
      "Epoch 18, Loss(train/val) 0.28351/0.32892. Took 0.15 sec\n",
      "Epoch 19, Loss(train/val) 0.29050/0.34373. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.29419/0.35313. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.28750/0.33919. Took 0.16 sec\n",
      "Epoch 22, Loss(train/val) 0.27798/0.33892. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.27416/0.33012. Took 0.16 sec\n",
      "Epoch 24, Loss(train/val) 0.27674/0.34608. Took 0.15 sec\n",
      "Epoch 25, Loss(train/val) 0.26775/0.33423. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.25703/0.35911. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.26114/0.34832. Took 0.16 sec\n",
      "Epoch 28, Loss(train/val) 0.25763/0.35889. Took 0.16 sec\n",
      "Epoch 29, Loss(train/val) 0.24995/0.41745. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.24707/0.40248. Took 0.16 sec\n",
      "Epoch 31, Loss(train/val) 0.24433/0.40716. Took 0.17 sec\n",
      "Epoch 32, Loss(train/val) 0.24267/0.39652. Took 0.16 sec\n",
      "Epoch 33, Loss(train/val) 0.24104/0.43539. Took 0.16 sec\n",
      "Epoch 34, Loss(train/val) 0.24273/0.41880. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.23528/0.42061. Took 0.16 sec\n",
      "Epoch 36, Loss(train/val) 0.22975/0.43036. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.23701/0.45008. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.23239/0.43986. Took 0.15 sec\n",
      "Epoch 39, Loss(train/val) 0.22316/0.44241. Took 0.15 sec\n",
      "Epoch 40, Loss(train/val) 0.22462/0.40406. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.22823/0.42051. Took 0.15 sec\n",
      "Epoch 42, Loss(train/val) 0.22366/0.38790. Took 0.15 sec\n",
      "Epoch 43, Loss(train/val) 0.22553/0.39226. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.21759/0.36206. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) 0.21916/0.36902. Took 0.16 sec\n",
      "Epoch 46, Loss(train/val) 0.21472/0.39037. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.21556/0.40742. Took 0.15 sec\n",
      "Epoch 48, Loss(train/val) 0.21237/0.38491. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.21649/0.39688. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.19953/0.37229. Took 0.14 sec\n",
      "Epoch 51, Loss(train/val) 0.20017/0.38815. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.20451/0.35595. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) 0.20889/0.36988. Took 0.15 sec\n",
      "Epoch 54, Loss(train/val) 0.20357/0.39718. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.19962/0.41608. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.20463/0.39877. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.20346/0.36722. Took 0.15 sec\n",
      "Epoch 58, Loss(train/val) 0.20160/0.36395. Took 0.16 sec\n",
      "Epoch 59, Loss(train/val) 0.19989/0.38608. Took 0.17 sec\n",
      "Epoch 60, Loss(train/val) 0.19383/0.35454. Took 0.16 sec\n",
      "Epoch 61, Loss(train/val) 0.19468/0.36325. Took 0.15 sec\n",
      "Epoch 62, Loss(train/val) 0.18841/0.36914. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.18571/0.38165. Took 0.15 sec\n",
      "Epoch 64, Loss(train/val) 0.18099/0.36563. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.18265/0.37080. Took 0.15 sec\n",
      "Epoch 66, Loss(train/val) 0.18540/0.35985. Took 0.15 sec\n",
      "Epoch 67, Loss(train/val) 0.18795/0.34762. Took 0.15 sec\n",
      "Epoch 68, Loss(train/val) 0.18754/0.36570. Took 0.14 sec\n",
      "Epoch 69, Loss(train/val) 0.18322/0.33425. Took 0.16 sec\n",
      "Epoch 70, Loss(train/val) 0.17996/0.34635. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.17480/0.37583. Took 0.15 sec\n",
      "Epoch 72, Loss(train/val) 0.17815/0.39364. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.17057/0.34632. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.16985/0.37963. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.17715/0.39652. Took 0.15 sec\n",
      "Epoch 76, Loss(train/val) 0.16889/0.41510. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.17552/0.39134. Took 0.15 sec\n",
      "Epoch 78, Loss(train/val) 0.18471/0.37324. Took 0.14 sec\n",
      "Epoch 79, Loss(train/val) 0.16405/0.37005. Took 0.15 sec\n",
      "Epoch 80, Loss(train/val) 0.16816/0.34768. Took 0.14 sec\n",
      "Epoch 81, Loss(train/val) 0.16528/0.34054. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.16409/0.34913. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) 0.17801/0.35749. Took 0.15 sec\n",
      "Epoch 84, Loss(train/val) 0.16357/0.36794. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.16115/0.37290. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.15473/0.37486. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.15968/0.38508. Took 0.15 sec\n",
      "Epoch 88, Loss(train/val) 0.15628/0.40890. Took 0.14 sec\n",
      "Epoch 89, Loss(train/val) 0.16173/0.38723. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.15785/0.37471. Took 0.14 sec\n",
      "Epoch 91, Loss(train/val) 0.16067/0.39209. Took 0.15 sec\n",
      "Epoch 92, Loss(train/val) 0.15195/0.39267. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.15663/0.37921. Took 0.15 sec\n",
      "Epoch 94, Loss(train/val) 0.15173/0.40166. Took 0.14 sec\n",
      "Epoch 95, Loss(train/val) 0.14866/0.38884. Took 0.15 sec\n",
      "Epoch 96, Loss(train/val) 0.14977/0.41754. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.14391/0.41677. Took 0.15 sec\n",
      "Epoch 98, Loss(train/val) 0.14951/0.35980. Took 0.14 sec\n",
      "Epoch 99, Loss(train/val) 0.14799/0.42383. Took 0.15 sec\n",
      "ACC: 0.609375, MCC: 0.25819888974716115\n",
      "Epoch 0, Loss(train/val) 0.48475/0.48653. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.45244/0.46281. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.41549/0.43336. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.38806/0.42674. Took 0.15 sec\n",
      "Epoch 4, Loss(train/val) 0.37233/0.41128. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.35823/0.40526. Took 0.15 sec\n",
      "Epoch 6, Loss(train/val) 0.35563/0.38702. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.34961/0.39221. Took 0.15 sec\n",
      "Epoch 8, Loss(train/val) 0.33541/0.37580. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.33594/0.37250. Took 0.16 sec\n",
      "Epoch 10, Loss(train/val) 0.33867/0.37400. Took 0.16 sec\n",
      "Epoch 11, Loss(train/val) 0.31551/0.34078. Took 0.15 sec\n",
      "Epoch 12, Loss(train/val) 0.31060/0.38610. Took 0.15 sec\n",
      "Epoch 13, Loss(train/val) 0.30342/0.31798. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.29313/0.32974. Took 0.15 sec\n",
      "Epoch 15, Loss(train/val) 0.29803/0.35241. Took 0.16 sec\n",
      "Epoch 16, Loss(train/val) 0.29387/0.33970. Took 0.15 sec\n",
      "Epoch 17, Loss(train/val) 0.28509/0.32745. Took 0.17 sec\n",
      "Epoch 18, Loss(train/val) 0.27580/0.36524. Took 0.15 sec\n",
      "Epoch 19, Loss(train/val) 0.26558/0.40815. Took 0.16 sec\n",
      "Epoch 20, Loss(train/val) 0.27352/0.33381. Took 0.15 sec\n",
      "Epoch 21, Loss(train/val) 0.26660/0.33359. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.25284/0.30242. Took 0.15 sec\n",
      "Epoch 23, Loss(train/val) 0.25737/0.35610. Took 0.16 sec\n",
      "Epoch 24, Loss(train/val) 0.26012/0.30766. Took 0.15 sec\n",
      "Epoch 25, Loss(train/val) 0.25202/0.31286. Took 0.16 sec\n",
      "Epoch 26, Loss(train/val) 0.24749/0.28758. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.24256/0.29739. Took 0.16 sec\n",
      "Epoch 28, Loss(train/val) 0.24111/0.31183. Took 0.16 sec\n",
      "Epoch 29, Loss(train/val) 0.24138/0.30495. Took 0.17 sec\n",
      "Epoch 30, Loss(train/val) 0.23985/0.30333. Took 0.17 sec\n",
      "Epoch 31, Loss(train/val) 0.23039/0.30318. Took 0.17 sec\n",
      "Epoch 32, Loss(train/val) 0.23312/0.32996. Took 0.17 sec\n",
      "Epoch 33, Loss(train/val) 0.21868/0.37228. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.22108/0.33573. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.22081/0.31387. Took 0.17 sec\n",
      "Epoch 36, Loss(train/val) 0.21591/0.34048. Took 0.16 sec\n",
      "Epoch 37, Loss(train/val) 0.21433/0.34690. Took 0.15 sec\n",
      "Epoch 38, Loss(train/val) 0.20304/0.30914. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.21007/0.30455. Took 0.16 sec\n",
      "Epoch 40, Loss(train/val) 0.20362/0.32396. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.20234/0.32272. Took 0.15 sec\n",
      "Epoch 42, Loss(train/val) 0.21261/0.28628. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.20330/0.31567. Took 0.16 sec\n",
      "Epoch 44, Loss(train/val) 0.19933/0.31847. Took 0.15 sec\n",
      "Epoch 45, Loss(train/val) 0.19483/0.29908. Took 0.15 sec\n",
      "Epoch 46, Loss(train/val) 0.19753/0.32383. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.19167/0.29645. Took 0.16 sec\n",
      "Epoch 48, Loss(train/val) 0.19715/0.30444. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.18850/0.33675. Took 0.15 sec\n",
      "Epoch 50, Loss(train/val) 0.18607/0.31090. Took 0.14 sec\n",
      "Epoch 51, Loss(train/val) 0.18855/0.33086. Took 0.15 sec\n",
      "Epoch 52, Loss(train/val) 0.19029/0.32921. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.18319/0.32714. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.17497/0.33310. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.18271/0.31313. Took 0.15 sec\n",
      "Epoch 56, Loss(train/val) 0.18378/0.32516. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.18439/0.33929. Took 0.15 sec\n",
      "Epoch 58, Loss(train/val) 0.17340/0.34216. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.17645/0.35497. Took 0.15 sec\n",
      "Epoch 60, Loss(train/val) 0.18438/0.33188. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.16458/0.32823. Took 0.15 sec\n",
      "Epoch 62, Loss(train/val) 0.16940/0.34494. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.17195/0.33037. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.17555/0.37860. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.15627/0.33088. Took 0.15 sec\n",
      "Epoch 66, Loss(train/val) 0.15926/0.34420. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.16405/0.36838. Took 0.15 sec\n",
      "Epoch 68, Loss(train/val) 0.15796/0.37419. Took 0.14 sec\n",
      "Epoch 69, Loss(train/val) 0.15882/0.34477. Took 0.15 sec\n",
      "Epoch 70, Loss(train/val) 0.16007/0.38007. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.15352/0.39558. Took 0.15 sec\n",
      "Epoch 72, Loss(train/val) 0.16194/0.37900. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.15873/0.34529. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.15802/0.36525. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) 0.16086/0.33194. Took 0.15 sec\n",
      "Epoch 76, Loss(train/val) 0.16011/0.37649. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.14758/0.32898. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.14761/0.32232. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.16037/0.32203. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.14802/0.37635. Took 0.14 sec\n",
      "Epoch 81, Loss(train/val) 0.15354/0.37503. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.13653/0.35616. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) 0.14705/0.35563. Took 0.15 sec\n",
      "Epoch 84, Loss(train/val) 0.14564/0.38039. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.14884/0.36869. Took 0.15 sec\n",
      "Epoch 86, Loss(train/val) 0.15080/0.38319. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.14679/0.34844. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.14754/0.33609. Took 0.14 sec\n",
      "Epoch 89, Loss(train/val) 0.14408/0.37560. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.14516/0.34343. Took 0.14 sec\n",
      "Epoch 91, Loss(train/val) 0.14670/0.34021. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.13839/0.39097. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.13986/0.36429. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.14265/0.37493. Took 0.14 sec\n",
      "Epoch 95, Loss(train/val) 0.14025/0.37370. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.13524/0.34753. Took 0.14 sec\n",
      "Epoch 97, Loss(train/val) 0.13815/0.35662. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.12985/0.37811. Took 0.14 sec\n",
      "Epoch 99, Loss(train/val) 0.13858/0.33832. Took 0.14 sec\n",
      "ACC: 0.671875, MCC: 0.44580357744773585\n",
      "Epoch 0, Loss(train/val) 0.48582/0.47564. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.45328/0.43166. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.41414/0.37420. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.38197/0.34814. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.36488/0.30995. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.34806/0.27519. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.34761/0.26558. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.32855/0.24195. Took 0.15 sec\n",
      "Epoch 8, Loss(train/val) 0.32510/0.26261. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.32323/0.25468. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.31704/0.26629. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.30537/0.26759. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.29849/0.26126. Took 0.15 sec\n",
      "Epoch 13, Loss(train/val) 0.30245/0.26555. Took 0.16 sec\n",
      "Epoch 14, Loss(train/val) 0.30153/0.37895. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.31703/0.34139. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.29544/0.28734. Took 0.16 sec\n",
      "Epoch 17, Loss(train/val) 0.28700/0.33329. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.28996/0.30877. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.27436/0.30234. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.27503/0.31303. Took 0.15 sec\n",
      "Epoch 21, Loss(train/val) 0.27449/0.33157. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.26822/0.32673. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.25237/0.34007. Took 0.16 sec\n",
      "Epoch 24, Loss(train/val) 0.25645/0.34276. Took 0.15 sec\n",
      "Epoch 25, Loss(train/val) 0.25483/0.36219. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.25149/0.34939. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.24007/0.32821. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.24046/0.36422. Took 0.16 sec\n",
      "Epoch 29, Loss(train/val) 0.23536/0.35735. Took 0.16 sec\n",
      "Epoch 30, Loss(train/val) 0.23408/0.38034. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.23173/0.37393. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.22934/0.37313. Took 0.17 sec\n",
      "Epoch 33, Loss(train/val) 0.22185/0.40134. Took 0.17 sec\n",
      "Epoch 34, Loss(train/val) 0.21594/0.38720. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.21902/0.38842. Took 0.15 sec\n",
      "Epoch 36, Loss(train/val) 0.21110/0.39947. Took 0.16 sec\n",
      "Epoch 37, Loss(train/val) 0.20615/0.39920. Took 0.15 sec\n",
      "Epoch 38, Loss(train/val) 0.21204/0.40386. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.21172/0.37806. Took 0.16 sec\n",
      "Epoch 40, Loss(train/val) 0.20438/0.39685. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.20073/0.38593. Took 0.15 sec\n",
      "Epoch 42, Loss(train/val) 0.19659/0.40611. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.20278/0.37409. Took 0.15 sec\n",
      "Epoch 44, Loss(train/val) 0.18840/0.40942. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.19219/0.38828. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.18908/0.41172. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.18482/0.41070. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.17847/0.40074. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.17983/0.38622. Took 0.15 sec\n",
      "Epoch 50, Loss(train/val) 0.18399/0.41548. Took 0.14 sec\n",
      "Epoch 51, Loss(train/val) 0.17733/0.40476. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.17781/0.38747. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.17361/0.39826. Took 0.15 sec\n",
      "Epoch 54, Loss(train/val) 0.16541/0.40993. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.17064/0.39440. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.17430/0.38798. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.16254/0.37568. Took 0.15 sec\n",
      "Epoch 58, Loss(train/val) 0.16806/0.40619. Took 0.14 sec\n",
      "Epoch 59, Loss(train/val) 0.15503/0.40427. Took 0.15 sec\n",
      "Epoch 60, Loss(train/val) 0.15826/0.38751. Took 0.14 sec\n",
      "Epoch 61, Loss(train/val) 0.15353/0.40205. Took 0.15 sec\n",
      "Epoch 62, Loss(train/val) 0.17045/0.41111. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.16181/0.40122. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.15421/0.38866. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.16715/0.40767. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.15951/0.38757. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) 0.15754/0.38607. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.14895/0.38806. Took 0.14 sec\n",
      "Epoch 69, Loss(train/val) 0.14743/0.41461. Took 0.15 sec\n",
      "Epoch 70, Loss(train/val) 0.15661/0.38835. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.14792/0.39507. Took 0.15 sec\n",
      "Epoch 72, Loss(train/val) 0.14432/0.42005. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.14122/0.42371. Took 0.15 sec\n",
      "Epoch 74, Loss(train/val) 0.14150/0.40965. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) 0.13163/0.39139. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.12869/0.39989. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.13176/0.37334. Took 0.15 sec\n",
      "Epoch 78, Loss(train/val) 0.13651/0.39422. Took 0.14 sec\n",
      "Epoch 79, Loss(train/val) 0.13692/0.38346. Took 0.15 sec\n",
      "Epoch 80, Loss(train/val) 0.12526/0.38577. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.12689/0.39500. Took 0.15 sec\n",
      "Epoch 82, Loss(train/val) 0.13404/0.41096. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) 0.12785/0.37425. Took 0.15 sec\n",
      "Epoch 84, Loss(train/val) 0.12405/0.38290. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.11672/0.37799. Took 0.15 sec\n",
      "Epoch 86, Loss(train/val) 0.12418/0.38468. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.11325/0.39454. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.11958/0.39709. Took 0.14 sec\n",
      "Epoch 89, Loss(train/val) 0.11845/0.41241. Took 0.16 sec\n",
      "Epoch 90, Loss(train/val) 0.12450/0.37520. Took 0.14 sec\n",
      "Epoch 91, Loss(train/val) 0.11690/0.41809. Took 0.15 sec\n",
      "Epoch 92, Loss(train/val) 0.12256/0.42359. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.11800/0.41426. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.12321/0.39663. Took 0.14 sec\n",
      "Epoch 95, Loss(train/val) 0.11660/0.42374. Took 0.15 sec\n",
      "Epoch 96, Loss(train/val) 0.11960/0.42049. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.12439/0.41268. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.11023/0.40166. Took 0.14 sec\n",
      "Epoch 99, Loss(train/val) 0.11595/0.39791. Took 0.14 sec\n",
      "ACC: 0.625, MCC: 0.2581784245713871\n",
      "Epoch 0, Loss(train/val) 0.49089/0.49434. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.45926/0.48438. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.41680/0.44783. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.38396/0.41483. Took 0.15 sec\n",
      "Epoch 4, Loss(train/val) 0.36784/0.41088. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.36041/0.40429. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.34491/0.40146. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.33553/0.39860. Took 0.15 sec\n",
      "Epoch 8, Loss(train/val) 0.32578/0.39554. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.32154/0.37990. Took 0.15 sec\n",
      "Epoch 10, Loss(train/val) 0.32359/0.42646. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.31987/0.39144. Took 0.15 sec\n",
      "Epoch 12, Loss(train/val) 0.31557/0.38554. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.30006/0.47658. Took 0.16 sec\n",
      "Epoch 14, Loss(train/val) 0.29682/0.48295. Took 0.15 sec\n",
      "Epoch 15, Loss(train/val) 0.29125/0.47453. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.28106/0.44263. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.27879/0.51810. Took 0.16 sec\n",
      "Epoch 18, Loss(train/val) 0.26562/0.51716. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.26911/0.46569. Took 0.16 sec\n",
      "Epoch 20, Loss(train/val) 0.27633/0.51933. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.26310/0.53073. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.25672/0.49587. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.25131/0.52883. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.25248/0.50906. Took 0.15 sec\n",
      "Epoch 25, Loss(train/val) 0.24833/0.52604. Took 0.16 sec\n",
      "Epoch 26, Loss(train/val) 0.24634/0.56567. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.24217/0.57150. Took 0.16 sec\n",
      "Epoch 28, Loss(train/val) 0.24049/0.53080. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.24072/0.56108. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.24322/0.53078. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.22487/0.55715. Took 0.16 sec\n",
      "Epoch 32, Loss(train/val) 0.22842/0.53026. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.22405/0.55906. Took 0.16 sec\n",
      "Epoch 34, Loss(train/val) 0.22711/0.54128. Took 0.18 sec\n",
      "Epoch 35, Loss(train/val) 0.22111/0.54596. Took 0.18 sec\n",
      "Epoch 36, Loss(train/val) 0.21741/0.55344. Took 0.17 sec\n",
      "Epoch 37, Loss(train/val) 0.21459/0.54335. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.20878/0.55242. Took 0.15 sec\n",
      "Epoch 39, Loss(train/val) 0.20792/0.53184. Took 0.16 sec\n",
      "Epoch 40, Loss(train/val) 0.21459/0.55024. Took 0.15 sec\n",
      "Epoch 41, Loss(train/val) 0.20604/0.55829. Took 0.15 sec\n",
      "Epoch 42, Loss(train/val) 0.20952/0.55917. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.19925/0.52819. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.20054/0.55027. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) 0.19811/0.53237. Took 0.16 sec\n",
      "Epoch 46, Loss(train/val) 0.21134/0.51358. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.20250/0.50056. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.19221/0.46106. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.19742/0.47425. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.19703/0.52062. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.19533/0.48634. Took 0.15 sec\n",
      "Epoch 52, Loss(train/val) 0.19015/0.53361. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.18766/0.53833. Took 0.15 sec\n",
      "Epoch 54, Loss(train/val) 0.19085/0.53690. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.19896/0.51855. Took 0.15 sec\n",
      "Epoch 56, Loss(train/val) 0.18361/0.52118. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.19389/0.56493. Took 0.15 sec\n",
      "Epoch 58, Loss(train/val) 0.18750/0.55771. Took 0.14 sec\n",
      "Epoch 59, Loss(train/val) 0.18385/0.54163. Took 0.15 sec\n",
      "Epoch 60, Loss(train/val) 0.18140/0.42083. Took 0.14 sec\n",
      "Epoch 61, Loss(train/val) 0.18067/0.39999. Took 0.15 sec\n",
      "Epoch 62, Loss(train/val) 0.17719/0.48873. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.17424/0.52971. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.16709/0.55234. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.18339/0.52425. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.17914/0.54291. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) 0.19727/0.48153. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.18215/0.54162. Took 0.14 sec\n",
      "Epoch 69, Loss(train/val) 0.16729/0.51225. Took 0.15 sec\n",
      "Epoch 70, Loss(train/val) 0.16998/0.49695. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.16197/0.51921. Took 0.15 sec\n",
      "Epoch 72, Loss(train/val) 0.16654/0.53924. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.16558/0.50496. Took 0.15 sec\n",
      "Epoch 74, Loss(train/val) 0.16476/0.48881. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.16185/0.51499. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.16087/0.53386. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.17020/0.52022. Took 0.15 sec\n",
      "Epoch 78, Loss(train/val) 0.16257/0.54886. Took 0.14 sec\n",
      "Epoch 79, Loss(train/val) 0.16426/0.57460. Took 0.15 sec\n",
      "Epoch 80, Loss(train/val) 0.15527/0.53508. Took 0.14 sec\n",
      "Epoch 81, Loss(train/val) 0.16585/0.52550. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.15547/0.50203. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.15081/0.44833. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.15863/0.56718. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.15141/0.50749. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.15405/0.52819. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.15691/0.47115. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.15463/0.47864. Took 0.14 sec\n",
      "Epoch 89, Loss(train/val) 0.15122/0.37163. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.15887/0.51776. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.15099/0.44945. Took 0.15 sec\n",
      "Epoch 92, Loss(train/val) 0.14983/0.52975. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.15544/0.49249. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.14829/0.52415. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.14340/0.51781. Took 0.15 sec\n",
      "Epoch 96, Loss(train/val) 0.14908/0.53807. Took 0.14 sec\n",
      "Epoch 97, Loss(train/val) 0.14111/0.48933. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.13968/0.46812. Took 0.14 sec\n",
      "Epoch 99, Loss(train/val) 0.13949/0.46513. Took 0.14 sec\n",
      "ACC: 0.59375, MCC: 0.19487030513625772\n",
      "Epoch 0, Loss(train/val) 0.49464/0.49027. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.47259/0.46833. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.43449/0.42864. Took 0.15 sec\n",
      "Epoch 3, Loss(train/val) 0.39480/0.39735. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.37292/0.38341. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.36183/0.37447. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.34780/0.37975. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.33830/0.39168. Took 0.15 sec\n",
      "Epoch 8, Loss(train/val) 0.32934/0.39143. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.32576/0.37718. Took 0.15 sec\n",
      "Epoch 10, Loss(train/val) 0.31467/0.39191. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.30978/0.42152. Took 0.15 sec\n",
      "Epoch 12, Loss(train/val) 0.31748/0.45701. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.29922/0.44766. Took 0.16 sec\n",
      "Epoch 14, Loss(train/val) 0.30137/0.47559. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.29284/0.38355. Took 0.16 sec\n",
      "Epoch 16, Loss(train/val) 0.30369/0.46212. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.28871/0.38722. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.27857/0.48536. Took 0.15 sec\n",
      "Epoch 19, Loss(train/val) 0.28059/0.48904. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.27674/0.45997. Took 0.15 sec\n",
      "Epoch 21, Loss(train/val) 0.27028/0.49874. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.27247/0.48848. Took 0.15 sec\n",
      "Epoch 23, Loss(train/val) 0.26458/0.49615. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.26601/0.49655. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.24924/0.49030. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.24951/0.49039. Took 0.15 sec\n",
      "Epoch 27, Loss(train/val) 0.25219/0.47961. Took 0.16 sec\n",
      "Epoch 28, Loss(train/val) 0.24775/0.47455. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.23598/0.47626. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.23311/0.46321. Took 0.16 sec\n",
      "Epoch 31, Loss(train/val) 0.23357/0.46363. Took 0.16 sec\n",
      "Epoch 32, Loss(train/val) 0.23320/0.46047. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.23250/0.44109. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.23204/0.47113. Took 0.16 sec\n",
      "Epoch 35, Loss(train/val) 0.21730/0.45965. Took 0.15 sec\n",
      "Epoch 36, Loss(train/val) 0.22348/0.43691. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.22091/0.43429. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.21656/0.46706. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.21566/0.42277. Took 0.15 sec\n",
      "Epoch 40, Loss(train/val) 0.20873/0.43517. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.20585/0.45232. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.21473/0.42552. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.20384/0.40832. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.20098/0.43407. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.21165/0.40395. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.19563/0.44159. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.18899/0.43090. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.19489/0.42102. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.20798/0.45705. Took 0.15 sec\n",
      "Epoch 50, Loss(train/val) 0.18951/0.42857. Took 0.14 sec\n",
      "Epoch 51, Loss(train/val) 0.18881/0.42627. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.18096/0.43182. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) 0.18723/0.41129. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.18517/0.40298. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.17536/0.41290. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.17824/0.40966. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.17864/0.43549. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.18585/0.42765. Took 0.14 sec\n",
      "Epoch 59, Loss(train/val) 0.17102/0.42238. Took 0.15 sec\n",
      "Epoch 60, Loss(train/val) 0.17416/0.43124. Took 0.14 sec\n",
      "Epoch 61, Loss(train/val) 0.17956/0.43674. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.17171/0.41285. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.16502/0.43030. Took 0.15 sec\n",
      "Epoch 64, Loss(train/val) 0.16742/0.43473. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.16491/0.40443. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.16340/0.38487. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) 0.17297/0.41998. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.16128/0.40695. Took 0.14 sec\n",
      "Epoch 69, Loss(train/val) 0.16273/0.41259. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.15825/0.37331. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.16054/0.41134. Took 0.15 sec\n",
      "Epoch 72, Loss(train/val) 0.15082/0.38774. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.15064/0.38742. Took 0.15 sec\n",
      "Epoch 74, Loss(train/val) 0.15714/0.38909. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) 0.14889/0.37304. Took 0.15 sec\n",
      "Epoch 76, Loss(train/val) 0.15041/0.37137. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.14981/0.39212. Took 0.15 sec\n",
      "Epoch 78, Loss(train/val) 0.14643/0.36503. Took 0.14 sec\n",
      "Epoch 79, Loss(train/val) 0.13563/0.37008. Took 0.16 sec\n",
      "Epoch 80, Loss(train/val) 0.14283/0.38269. Took 0.14 sec\n",
      "Epoch 81, Loss(train/val) 0.13309/0.35867. Took 0.15 sec\n",
      "Epoch 82, Loss(train/val) 0.14438/0.35686. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) 0.12971/0.38557. Took 0.15 sec\n",
      "Epoch 84, Loss(train/val) 0.14164/0.37452. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.13724/0.36529. Took 0.15 sec\n",
      "Epoch 86, Loss(train/val) 0.12990/0.37054. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.13610/0.37074. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.12749/0.36950. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.13525/0.36948. Took 0.15 sec\n",
      "Epoch 90, Loss(train/val) 0.14024/0.38942. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.12841/0.39922. Took 0.15 sec\n",
      "Epoch 92, Loss(train/val) 0.13800/0.39141. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.12867/0.37838. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.13045/0.36833. Took 0.14 sec\n",
      "Epoch 95, Loss(train/val) 0.12557/0.36489. Took 0.15 sec\n",
      "Epoch 96, Loss(train/val) 0.12921/0.39963. Took 0.14 sec\n",
      "Epoch 97, Loss(train/val) 0.11816/0.39657. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.11920/0.38412. Took 0.14 sec\n",
      "Epoch 99, Loss(train/val) 0.12525/0.38233. Took 0.15 sec\n",
      "ACC: 0.609375, MCC: 0.18262637225482492\n",
      "Epoch 0, Loss(train/val) 0.49525/0.47177. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.47442/0.40582. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.44077/0.32136. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.40756/0.27728. Took 0.16 sec\n",
      "Epoch 4, Loss(train/val) 0.38664/0.26797. Took 0.15 sec\n",
      "Epoch 5, Loss(train/val) 0.37675/0.26321. Took 0.15 sec\n",
      "Epoch 6, Loss(train/val) 0.35867/0.25161. Took 0.16 sec\n",
      "Epoch 7, Loss(train/val) 0.34899/0.25182. Took 0.16 sec\n",
      "Epoch 8, Loss(train/val) 0.33863/0.23192. Took 0.16 sec\n",
      "Epoch 9, Loss(train/val) 0.34089/0.22476. Took 0.18 sec\n",
      "Epoch 10, Loss(train/val) 0.32416/0.20637. Took 0.17 sec\n",
      "Epoch 11, Loss(train/val) 0.31840/0.22596. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.31030/0.21202. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.30532/0.20118. Took 0.17 sec\n",
      "Epoch 14, Loss(train/val) 0.29793/0.20448. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.29388/0.23114. Took 0.16 sec\n",
      "Epoch 16, Loss(train/val) 0.28984/0.19683. Took 0.15 sec\n",
      "Epoch 17, Loss(train/val) 0.28085/0.20832. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.29065/0.19548. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.28458/0.23031. Took 0.16 sec\n",
      "Epoch 20, Loss(train/val) 0.29874/0.25193. Took 0.16 sec\n",
      "Epoch 21, Loss(train/val) 0.29487/0.25283. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.30108/0.25519. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.29271/0.23591. Took 0.16 sec\n",
      "Epoch 24, Loss(train/val) 0.28303/0.20448. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.27957/0.19379. Took 0.16 sec\n",
      "Epoch 26, Loss(train/val) 0.27003/0.20684. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.27554/0.19090. Took 0.16 sec\n",
      "Epoch 28, Loss(train/val) 0.26448/0.19912. Took 0.16 sec\n",
      "Epoch 29, Loss(train/val) 0.25978/0.19889. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.26155/0.20221. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.26213/0.21213. Took 0.17 sec\n",
      "Epoch 32, Loss(train/val) 0.26186/0.20491. Took 0.16 sec\n",
      "Epoch 33, Loss(train/val) 0.25899/0.24429. Took 0.17 sec\n",
      "Epoch 34, Loss(train/val) 0.25153/0.21826. Took 0.16 sec\n",
      "Epoch 35, Loss(train/val) 0.25254/0.20883. Took 0.17 sec\n",
      "Epoch 36, Loss(train/val) 0.26363/0.25754. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.27049/0.24155. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.25906/0.24017. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.25139/0.24056. Took 0.15 sec\n",
      "Epoch 40, Loss(train/val) 0.24084/0.21802. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.25145/0.19671. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.26964/0.20150. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.24303/0.24522. Took 0.15 sec\n",
      "Epoch 44, Loss(train/val) 0.24167/0.19262. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.25937/0.19750. Took 0.15 sec\n",
      "Epoch 46, Loss(train/val) 0.25323/0.23113. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.24294/0.19344. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.24887/0.25245. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.23743/0.24455. Took 0.15 sec\n",
      "Epoch 50, Loss(train/val) 0.23026/0.22618. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.23354/0.21070. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.22503/0.23222. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) 0.24024/0.24321. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.24232/0.20755. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.22525/0.21832. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.22584/0.21220. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.21864/0.19614. Took 0.16 sec\n",
      "Epoch 58, Loss(train/val) 0.22777/0.18794. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.23367/0.21702. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.22095/0.21114. Took 0.14 sec\n",
      "Epoch 61, Loss(train/val) 0.22389/0.21639. Took 0.15 sec\n",
      "Epoch 62, Loss(train/val) 0.21699/0.21722. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.22505/0.26882. Took 0.15 sec\n",
      "Epoch 64, Loss(train/val) 0.21548/0.22720. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.21278/0.21455. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.20882/0.21111. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) 0.20884/0.23451. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.21960/0.19533. Took 0.14 sec\n",
      "Epoch 69, Loss(train/val) 0.21431/0.20007. Took 0.15 sec\n",
      "Epoch 70, Loss(train/val) 0.20410/0.22178. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.20473/0.21961. Took 0.15 sec\n",
      "Epoch 72, Loss(train/val) 0.20322/0.22361. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.19476/0.21981. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.19591/0.28993. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) 0.20730/0.22873. Took 0.15 sec\n",
      "Epoch 76, Loss(train/val) 0.19879/0.25420. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.19883/0.25276. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.19043/0.22733. Took 0.14 sec\n",
      "Epoch 79, Loss(train/val) 0.20079/0.25358. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.19537/0.23647. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.19399/0.25426. Took 0.15 sec\n",
      "Epoch 82, Loss(train/val) 0.18981/0.24772. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.19744/0.26659. Took 0.15 sec\n",
      "Epoch 84, Loss(train/val) 0.20047/0.19117. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.22400/0.17908. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.20630/0.24355. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.19047/0.22036. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.18661/0.25167. Took 0.14 sec\n",
      "Epoch 89, Loss(train/val) 0.17961/0.22235. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.18784/0.23779. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.19070/0.22686. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.18268/0.20821. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.18388/0.27250. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.17829/0.25878. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.18091/0.23125. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.18088/0.27924. Took 0.14 sec\n",
      "Epoch 97, Loss(train/val) 0.18284/0.25251. Took 0.15 sec\n",
      "Epoch 98, Loss(train/val) 0.18395/0.22675. Took 0.14 sec\n",
      "Epoch 99, Loss(train/val) 0.17770/0.27845. Took 0.14 sec\n",
      "ACC: 0.671875, MCC: 0.3400501664684957\n",
      "Epoch 0, Loss(train/val) 0.48951/0.49119. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.46019/0.47553. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.41912/0.45617. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.39172/0.44561. Took 0.15 sec\n",
      "Epoch 4, Loss(train/val) 0.37559/0.43392. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.36929/0.42787. Took 0.15 sec\n",
      "Epoch 6, Loss(train/val) 0.36094/0.42945. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.35575/0.42469. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.34827/0.42406. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.33647/0.41466. Took 0.15 sec\n",
      "Epoch 10, Loss(train/val) 0.32609/0.41014. Took 0.15 sec\n",
      "Epoch 11, Loss(train/val) 0.31625/0.40856. Took 0.15 sec\n",
      "Epoch 12, Loss(train/val) 0.31319/0.41666. Took 0.15 sec\n",
      "Epoch 13, Loss(train/val) 0.30350/0.41224. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.30203/0.41200. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.29013/0.41311. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.28670/0.41309. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.27233/0.41517. Took 0.16 sec\n",
      "Epoch 18, Loss(train/val) 0.28068/0.39517. Took 0.15 sec\n",
      "Epoch 19, Loss(train/val) 0.28337/0.39675. Took 0.16 sec\n",
      "Epoch 20, Loss(train/val) 0.26872/0.39455. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.26703/0.41757. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.26374/0.41574. Took 0.15 sec\n",
      "Epoch 23, Loss(train/val) 0.25958/0.40782. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.25711/0.41522. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.25452/0.41409. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.24369/0.41035. Took 0.15 sec\n",
      "Epoch 27, Loss(train/val) 0.25064/0.39297. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.24348/0.39941. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.23182/0.41342. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.23854/0.40866. Took 0.17 sec\n",
      "Epoch 31, Loss(train/val) 0.23738/0.40902. Took 0.16 sec\n",
      "Epoch 32, Loss(train/val) 0.22742/0.40278. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.22480/0.40180. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.23373/0.40637. Took 0.16 sec\n",
      "Epoch 35, Loss(train/val) 0.22468/0.40722. Took 0.15 sec\n",
      "Epoch 36, Loss(train/val) 0.22285/0.40343. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.21254/0.40514. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.21740/0.40423. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.21979/0.41145. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.21586/0.40696. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.21432/0.39973. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.21430/0.39615. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.20438/0.39723. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.20249/0.39453. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) 0.19720/0.40296. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.20115/0.39888. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.20589/0.39607. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.20991/0.39941. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.20398/0.40797. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.19506/0.39335. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.19213/0.38335. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.19083/0.39836. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) 0.18728/0.39035. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.19348/0.39119. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.19324/0.38376. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.19148/0.39188. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.18536/0.38063. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.19229/0.41080. Took 0.14 sec\n",
      "Epoch 59, Loss(train/val) 0.18227/0.38558. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.20009/0.41820. Took 0.14 sec\n",
      "Epoch 61, Loss(train/val) 0.18520/0.40958. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.19200/0.39166. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.19618/0.38969. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.18130/0.41092. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.17756/0.39512. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.17156/0.39796. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) 0.18441/0.40856. Took 0.15 sec\n",
      "Epoch 68, Loss(train/val) 0.17893/0.40827. Took 0.14 sec\n",
      "Epoch 69, Loss(train/val) 0.17972/0.42102. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.17671/0.39979. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.16786/0.40900. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.16976/0.38729. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.17363/0.38868. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.17187/0.37091. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) 0.18095/0.38843. Took 0.15 sec\n",
      "Epoch 76, Loss(train/val) 0.16538/0.38802. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.17415/0.41558. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.16157/0.40196. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.16809/0.38948. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.16615/0.39263. Took 0.14 sec\n",
      "Epoch 81, Loss(train/val) 0.16664/0.41423. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.16476/0.37693. Took 0.15 sec\n",
      "Epoch 83, Loss(train/val) 0.16414/0.40654. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.15883/0.37273. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.16049/0.41104. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.16149/0.40814. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.15947/0.38832. Took 0.15 sec\n",
      "Epoch 88, Loss(train/val) 0.16690/0.41473. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.16543/0.40164. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.15810/0.42029. Took 0.14 sec\n",
      "Epoch 91, Loss(train/val) 0.15316/0.40912. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.15105/0.38712. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.14990/0.41981. Took 0.15 sec\n",
      "Epoch 94, Loss(train/val) 0.15251/0.38690. Took 0.14 sec\n",
      "Epoch 95, Loss(train/val) 0.15862/0.39524. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.14947/0.37210. Took 0.14 sec\n",
      "Epoch 97, Loss(train/val) 0.15350/0.38103. Took 0.15 sec\n",
      "Epoch 98, Loss(train/val) 0.14876/0.40948. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.14598/0.38415. Took 0.14 sec\n",
      "ACC: 0.78125, MCC: 0.5555555555555556\n",
      "Epoch 0, Loss(train/val) 0.48932/0.47713. Took 0.16 sec\n",
      "Epoch 1, Loss(train/val) 0.46150/0.44492. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.42140/0.42072. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.39112/0.38264. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.36978/0.36011. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.36036/0.34460. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.35531/0.34030. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.35011/0.32464. Took 0.15 sec\n",
      "Epoch 8, Loss(train/val) 0.34686/0.34115. Took 0.15 sec\n",
      "Epoch 9, Loss(train/val) 0.34039/0.31065. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.32976/0.31029. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.33007/0.31744. Took 0.16 sec\n",
      "Epoch 12, Loss(train/val) 0.32338/0.29897. Took 0.16 sec\n",
      "Epoch 13, Loss(train/val) 0.31739/0.32111. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.31294/0.29805. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.30910/0.29827. Took 0.16 sec\n",
      "Epoch 16, Loss(train/val) 0.30967/0.30299. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.30723/0.29905. Took 0.16 sec\n",
      "Epoch 18, Loss(train/val) 0.29415/0.30141. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.29363/0.30304. Took 0.16 sec\n",
      "Epoch 20, Loss(train/val) 0.29522/0.28403. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.29310/0.26999. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.28543/0.28918. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.27983/0.28446. Took 0.16 sec\n",
      "Epoch 24, Loss(train/val) 0.27981/0.36639. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.28215/0.28954. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.27854/0.28968. Took 0.15 sec\n",
      "Epoch 27, Loss(train/val) 0.26350/0.31224. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.27936/0.27514. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.26886/0.34486. Took 0.16 sec\n",
      "Epoch 30, Loss(train/val) 0.29379/0.30693. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.27167/0.27881. Took 0.16 sec\n",
      "Epoch 32, Loss(train/val) 0.25439/0.29846. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.26117/0.34048. Took 0.17 sec\n",
      "Epoch 34, Loss(train/val) 0.26118/0.27911. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.25836/0.26774. Took 0.16 sec\n",
      "Epoch 36, Loss(train/val) 0.25325/0.27985. Took 0.16 sec\n",
      "Epoch 37, Loss(train/val) 0.24866/0.28668. Took 0.15 sec\n",
      "Epoch 38, Loss(train/val) 0.27072/0.30149. Took 0.15 sec\n",
      "Epoch 39, Loss(train/val) 0.27458/0.29924. Took 0.15 sec\n",
      "Epoch 40, Loss(train/val) 0.25433/0.29439. Took 0.15 sec\n",
      "Epoch 41, Loss(train/val) 0.26892/0.33337. Took 0.15 sec\n",
      "Epoch 42, Loss(train/val) 0.25655/0.29034. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.24373/0.28952. Took 0.15 sec\n",
      "Epoch 44, Loss(train/val) 0.26227/0.32625. Took 0.15 sec\n",
      "Epoch 45, Loss(train/val) 0.24769/0.29084. Took 0.15 sec\n",
      "Epoch 46, Loss(train/val) 0.24168/0.32801. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.23958/0.31531. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.23927/0.31453. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.22971/0.29004. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.23399/0.30864. Took 0.14 sec\n",
      "Epoch 51, Loss(train/val) 0.22735/0.29675. Took 0.15 sec\n",
      "Epoch 52, Loss(train/val) 0.22544/0.32779. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.22946/0.34446. Took 0.15 sec\n",
      "Epoch 54, Loss(train/val) 0.22542/0.30473. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.21946/0.30725. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.21817/0.31267. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.21278/0.30203. Took 0.15 sec\n",
      "Epoch 58, Loss(train/val) 0.21923/0.30123. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.20520/0.27586. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.21395/0.30340. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.20943/0.31182. Took 0.15 sec\n",
      "Epoch 62, Loss(train/val) 0.21574/0.30847. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.20464/0.29345. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.20901/0.31014. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.20535/0.29027. Took 0.15 sec\n",
      "Epoch 66, Loss(train/val) 0.19424/0.30990. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) 0.20047/0.31432. Took 0.15 sec\n",
      "Epoch 68, Loss(train/val) 0.21479/0.33666. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.21328/0.33764. Took 0.15 sec\n",
      "Epoch 70, Loss(train/val) 0.20447/0.31165. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.20614/0.32762. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.22726/0.30815. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.21629/0.29943. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.20511/0.30509. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) 0.23090/0.30959. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.21962/0.28950. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.20965/0.29075. Took 0.15 sec\n",
      "Epoch 78, Loss(train/val) 0.22237/0.31652. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.21060/0.30011. Took 0.15 sec\n",
      "Epoch 80, Loss(train/val) 0.20017/0.26419. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.21255/0.28431. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.19771/0.28892. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) 0.19943/0.29764. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.20087/0.31144. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.20982/0.31919. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.22317/0.31478. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.20845/0.29958. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.20946/0.30542. Took 0.14 sec\n",
      "Epoch 89, Loss(train/val) 0.21136/0.27992. Took 0.15 sec\n",
      "Epoch 90, Loss(train/val) 0.19586/0.30294. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.19351/0.29865. Took 0.15 sec\n",
      "Epoch 92, Loss(train/val) 0.19537/0.27598. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.19780/0.27309. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.20243/0.28838. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.19162/0.29381. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.18307/0.28823. Took 0.14 sec\n",
      "Epoch 97, Loss(train/val) 0.18431/0.29666. Took 0.15 sec\n",
      "Epoch 98, Loss(train/val) 0.18654/0.29491. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.19987/0.30537. Took 0.14 sec\n",
      "ACC: 0.703125, MCC: 0.414743266617645\n",
      "Epoch 0, Loss(train/val) 0.49149/0.48503. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.46580/0.45693. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.42371/0.43385. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.39046/0.42315. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.37605/0.41440. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.36518/0.39669. Took 0.15 sec\n",
      "Epoch 6, Loss(train/val) 0.35111/0.37739. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.34465/0.36605. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.33694/0.34260. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.33249/0.33728. Took 0.15 sec\n",
      "Epoch 10, Loss(train/val) 0.32990/0.35775. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.31684/0.34540. Took 0.15 sec\n",
      "Epoch 12, Loss(train/val) 0.30942/0.33008. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.30811/0.34507. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.30356/0.33440. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.29406/0.36482. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.28547/0.37528. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.27801/0.34189. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.27386/0.34020. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.27865/0.35762. Took 0.17 sec\n",
      "Epoch 20, Loss(train/val) 0.26471/0.36603. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.25973/0.31342. Took 0.16 sec\n",
      "Epoch 22, Loss(train/val) 0.27139/0.41474. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.26316/0.32870. Took 0.16 sec\n",
      "Epoch 24, Loss(train/val) 0.26821/0.37879. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.24967/0.31130. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.24666/0.31501. Took 0.15 sec\n",
      "Epoch 27, Loss(train/val) 0.25527/0.32186. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.24798/0.30918. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.25491/0.31337. Took 0.16 sec\n",
      "Epoch 30, Loss(train/val) 0.25328/0.34939. Took 0.16 sec\n",
      "Epoch 31, Loss(train/val) 0.24955/0.31238. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.23222/0.30734. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.23592/0.32293. Took 0.17 sec\n",
      "Epoch 34, Loss(train/val) 0.23145/0.34923. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.23245/0.32808. Took 0.15 sec\n",
      "Epoch 36, Loss(train/val) 0.23087/0.31232. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.23581/0.31905. Took 0.16 sec\n",
      "Epoch 38, Loss(train/val) 0.21095/0.30536. Took 0.15 sec\n",
      "Epoch 39, Loss(train/val) 0.23195/0.31246. Took 0.16 sec\n",
      "Epoch 40, Loss(train/val) 0.23892/0.32532. Took 0.15 sec\n",
      "Epoch 41, Loss(train/val) 0.21866/0.31614. Took 0.15 sec\n",
      "Epoch 42, Loss(train/val) 0.22473/0.31568. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.22655/0.30531. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.22143/0.32320. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.21188/0.34264. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.22343/0.33518. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.22138/0.30989. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.22957/0.30069. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.20784/0.31322. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.21026/0.32447. Took 0.14 sec\n",
      "Epoch 51, Loss(train/val) 0.22535/0.31407. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.21187/0.29465. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) 0.20488/0.30751. Took 0.15 sec\n",
      "Epoch 54, Loss(train/val) 0.22123/0.31430. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.20616/0.32444. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.20898/0.30482. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.20037/0.27744. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.20711/0.31759. Took 0.14 sec\n",
      "Epoch 59, Loss(train/val) 0.20492/0.31883. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.20745/0.31971. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.19289/0.33015. Took 0.15 sec\n",
      "Epoch 62, Loss(train/val) 0.19581/0.30493. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.20394/0.31980. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.19635/0.31380. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.19417/0.30605. Took 0.15 sec\n",
      "Epoch 66, Loss(train/val) 0.19101/0.33250. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) 0.18430/0.30926. Took 0.15 sec\n",
      "Epoch 68, Loss(train/val) 0.18462/0.30800. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.18676/0.32155. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.18891/0.30866. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.19090/0.32690. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.18276/0.31349. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.18337/0.31425. Took 0.15 sec\n",
      "Epoch 74, Loss(train/val) 0.18078/0.33044. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) 0.17726/0.31216. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.17567/0.31519. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.17215/0.31676. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.17966/0.31389. Took 0.14 sec\n",
      "Epoch 79, Loss(train/val) 0.17480/0.31546. Took 0.15 sec\n",
      "Epoch 80, Loss(train/val) 0.17310/0.31278. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.17780/0.31499. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.17412/0.30991. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) 0.18472/0.31026. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.16793/0.30771. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.17899/0.31921. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.17266/0.32612. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.16489/0.30985. Took 0.15 sec\n",
      "Epoch 88, Loss(train/val) 0.16466/0.31072. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.16588/0.31684. Took 0.15 sec\n",
      "Epoch 90, Loss(train/val) 0.17144/0.30042. Took 0.14 sec\n",
      "Epoch 91, Loss(train/val) 0.16481/0.30746. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.16524/0.30366. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.15426/0.31242. Took 0.15 sec\n",
      "Epoch 94, Loss(train/val) 0.15764/0.31387. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.16151/0.28954. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.16834/0.28581. Took 0.14 sec\n",
      "Epoch 97, Loss(train/val) 0.16463/0.31588. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.16796/0.32403. Took 0.14 sec\n",
      "Epoch 99, Loss(train/val) 0.17094/0.32215. Took 0.13 sec\n",
      "ACC: 0.703125, MCC: 0.3994092126298922\n",
      "Epoch 0, Loss(train/val) 0.49007/0.47770. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.46323/0.43266. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.42089/0.39203. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.38427/0.39931. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.36308/0.39933. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.35087/0.39678. Took 0.15 sec\n",
      "Epoch 6, Loss(train/val) 0.33615/0.38980. Took 0.15 sec\n",
      "Epoch 7, Loss(train/val) 0.32806/0.37383. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.32037/0.37112. Took 0.15 sec\n",
      "Epoch 9, Loss(train/val) 0.31668/0.37741. Took 0.15 sec\n",
      "Epoch 10, Loss(train/val) 0.30614/0.34759. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.30441/0.36222. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.29229/0.36095. Took 0.15 sec\n",
      "Epoch 13, Loss(train/val) 0.29314/0.35416. Took 0.16 sec\n",
      "Epoch 14, Loss(train/val) 0.29089/0.34853. Took 0.15 sec\n",
      "Epoch 15, Loss(train/val) 0.29108/0.36011. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.28479/0.35172. Took 0.16 sec\n",
      "Epoch 17, Loss(train/val) 0.27991/0.34265. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.27836/0.35675. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.27521/0.35481. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.26778/0.34694. Took 0.15 sec\n",
      "Epoch 21, Loss(train/val) 0.26621/0.35681. Took 0.16 sec\n",
      "Epoch 22, Loss(train/val) 0.27062/0.35340. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.26161/0.33957. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.26242/0.35114. Took 0.15 sec\n",
      "Epoch 25, Loss(train/val) 0.25742/0.33920. Took 0.16 sec\n",
      "Epoch 26, Loss(train/val) 0.25332/0.34920. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.25011/0.33795. Took 0.16 sec\n",
      "Epoch 28, Loss(train/val) 0.25175/0.33638. Took 0.17 sec\n",
      "Epoch 29, Loss(train/val) 0.24732/0.34479. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.25007/0.32090. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.24378/0.31809. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.24476/0.32326. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.24368/0.33792. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.23669/0.32251. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.23043/0.34812. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.23620/0.33541. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.23222/0.30518. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.22942/0.35408. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.23093/0.32817. Took 0.15 sec\n",
      "Epoch 40, Loss(train/val) 0.22558/0.33377. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.22102/0.34566. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.22060/0.37031. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.23049/0.35333. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.22170/0.33087. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.21606/0.34350. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.20879/0.34458. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.21139/0.34086. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.21237/0.33629. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.21920/0.34451. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.20098/0.33876. Took 0.14 sec\n",
      "Epoch 51, Loss(train/val) 0.20261/0.32680. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.20632/0.34816. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) 0.19605/0.35435. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.20523/0.33803. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.19927/0.34901. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.19852/0.33662. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.19772/0.35115. Took 0.15 sec\n",
      "Epoch 58, Loss(train/val) 0.19124/0.34994. Took 0.14 sec\n",
      "Epoch 59, Loss(train/val) 0.19722/0.34387. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.19622/0.34409. Took 0.14 sec\n",
      "Epoch 61, Loss(train/val) 0.19714/0.33704. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.19465/0.31702. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.18285/0.33477. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.19218/0.35065. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.19594/0.33140. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.19247/0.35597. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) 0.18215/0.33643. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.17704/0.34520. Took 0.14 sec\n",
      "Epoch 69, Loss(train/val) 0.18025/0.34232. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.18324/0.33450. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.18471/0.31668. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.18959/0.35019. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.17514/0.34936. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.17801/0.33382. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) 0.16993/0.33398. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.17411/0.34099. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.18667/0.33569. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.17594/0.33419. Took 0.14 sec\n",
      "Epoch 79, Loss(train/val) 0.17643/0.32387. Took 0.15 sec\n",
      "Epoch 80, Loss(train/val) 0.17297/0.31988. Took 0.14 sec\n",
      "Epoch 81, Loss(train/val) 0.17262/0.33254. Took 0.15 sec\n",
      "Epoch 82, Loss(train/val) 0.17586/0.33153. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) 0.17256/0.33268. Took 0.16 sec\n",
      "Epoch 84, Loss(train/val) 0.16572/0.32910. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.17204/0.34141. Took 0.15 sec\n",
      "Epoch 86, Loss(train/val) 0.17592/0.32168. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.17384/0.31758. Took 0.15 sec\n",
      "Epoch 88, Loss(train/val) 0.17200/0.31695. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.16832/0.31208. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.16268/0.30940. Took 0.14 sec\n",
      "Epoch 91, Loss(train/val) 0.16349/0.31016. Took 0.15 sec\n",
      "Epoch 92, Loss(train/val) 0.16996/0.33473. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.16959/0.31684. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.16854/0.33802. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.16574/0.32195. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.16139/0.33120. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.17335/0.34291. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.15929/0.31193. Took 0.14 sec\n",
      "Epoch 99, Loss(train/val) 0.16041/0.33493. Took 0.15 sec\n",
      "ACC: 0.703125, MCC: 0.4294637672436267\n",
      "Epoch 0, Loss(train/val) 0.49238/0.48044. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.46583/0.43997. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.42252/0.40405. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.38927/0.38798. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.36932/0.38237. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.35653/0.37743. Took 0.15 sec\n",
      "Epoch 6, Loss(train/val) 0.35056/0.35886. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.34372/0.36216. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.34181/0.36454. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.32960/0.36657. Took 0.15 sec\n",
      "Epoch 10, Loss(train/val) 0.32066/0.36835. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.31510/0.36433. Took 0.16 sec\n",
      "Epoch 12, Loss(train/val) 0.31157/0.36689. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.31156/0.37312. Took 0.16 sec\n",
      "Epoch 14, Loss(train/val) 0.30539/0.36805. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.29906/0.37103. Took 0.16 sec\n",
      "Epoch 16, Loss(train/val) 0.29656/0.36183. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.29116/0.36914. Took 0.16 sec\n",
      "Epoch 18, Loss(train/val) 0.29125/0.37437. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.28460/0.35960. Took 0.15 sec\n",
      "Epoch 20, Loss(train/val) 0.28328/0.36921. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.27984/0.35212. Took 0.16 sec\n",
      "Epoch 22, Loss(train/val) 0.27857/0.34431. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.28438/0.37645. Took 0.17 sec\n",
      "Epoch 24, Loss(train/val) 0.27427/0.36153. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.27052/0.37502. Took 0.16 sec\n",
      "Epoch 26, Loss(train/val) 0.27019/0.35560. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.26520/0.35409. Took 0.16 sec\n",
      "Epoch 28, Loss(train/val) 0.26928/0.35556. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.26622/0.36896. Took 0.16 sec\n",
      "Epoch 30, Loss(train/val) 0.26038/0.36085. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.26008/0.34786. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.26134/0.36479. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.25836/0.36313. Took 0.17 sec\n",
      "Epoch 34, Loss(train/val) 0.26239/0.35349. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.25409/0.37220. Took 0.15 sec\n",
      "Epoch 36, Loss(train/val) 0.25809/0.35876. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.25072/0.36282. Took 0.16 sec\n",
      "Epoch 38, Loss(train/val) 0.25088/0.37378. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.24638/0.36237. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.24949/0.34816. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.24623/0.37301. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.24247/0.37022. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.24724/0.36546. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.24198/0.38475. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) 0.23908/0.36006. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.24653/0.37342. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.24361/0.36287. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.23966/0.37749. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.23459/0.37746. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.23546/0.36143. Took 0.14 sec\n",
      "Epoch 51, Loss(train/val) 0.23882/0.37156. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.24045/0.36944. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) 0.23707/0.38271. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.24086/0.35916. Took 0.15 sec\n",
      "Epoch 55, Loss(train/val) 0.23715/0.36759. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.23268/0.35597. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.22984/0.36027. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.23563/0.34277. Took 0.14 sec\n",
      "Epoch 59, Loss(train/val) 0.23197/0.35449. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.23010/0.36138. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.23397/0.36244. Took 0.15 sec\n",
      "Epoch 62, Loss(train/val) 0.23104/0.35987. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.23107/0.35807. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.22917/0.35957. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.22730/0.36866. Took 0.15 sec\n",
      "Epoch 66, Loss(train/val) 0.22844/0.36114. Took 0.15 sec\n",
      "Epoch 67, Loss(train/val) 0.22729/0.35897. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.22532/0.36723. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.22540/0.35568. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.22673/0.36870. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.22951/0.36235. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.22281/0.37443. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.22917/0.35326. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.22652/0.34925. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) 0.22787/0.35276. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.22494/0.37000. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.21848/0.36830. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.22369/0.36917. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.22326/0.37623. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.21959/0.35903. Took 0.14 sec\n",
      "Epoch 81, Loss(train/val) 0.22207/0.35321. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.22011/0.36202. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) 0.21849/0.36191. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.22261/0.34260. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.22333/0.35169. Took 0.15 sec\n",
      "Epoch 86, Loss(train/val) 0.22012/0.36148. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.22096/0.38236. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.22067/0.35438. Took 0.15 sec\n",
      "Epoch 89, Loss(train/val) 0.22288/0.36797. Took 0.15 sec\n",
      "Epoch 90, Loss(train/val) 0.21933/0.36299. Took 0.14 sec\n",
      "Epoch 91, Loss(train/val) 0.22129/0.34225. Took 0.15 sec\n",
      "Epoch 92, Loss(train/val) 0.21501/0.36394. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.22583/0.34430. Took 0.15 sec\n",
      "Epoch 94, Loss(train/val) 0.22640/0.35987. Took 0.14 sec\n",
      "Epoch 95, Loss(train/val) 0.22296/0.34976. Took 0.15 sec\n",
      "Epoch 96, Loss(train/val) 0.22515/0.35901. Took 0.14 sec\n",
      "Epoch 97, Loss(train/val) 0.21712/0.35269. Took 0.15 sec\n",
      "Epoch 98, Loss(train/val) 0.21220/0.36090. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.21413/0.35764. Took 0.14 sec\n",
      "ACC: 0.640625, MCC: 0.28894436110328825\n",
      "Epoch 0, Loss(train/val) 0.49029/0.48225. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.46078/0.44496. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.42091/0.41119. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.39092/0.40192. Took 0.15 sec\n",
      "Epoch 4, Loss(train/val) 0.37407/0.39529. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.36299/0.38256. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.35789/0.39244. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.35452/0.38342. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.35179/0.37408. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.34725/0.36511. Took 0.16 sec\n",
      "Epoch 10, Loss(train/val) 0.34331/0.35852. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.33868/0.35651. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.33264/0.35871. Took 0.15 sec\n",
      "Epoch 13, Loss(train/val) 0.32659/0.36973. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.32157/0.37635. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.32232/0.39397. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.31583/0.40500. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.31565/0.37626. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.30665/0.39181. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.30927/0.37788. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.30300/0.37774. Took 0.15 sec\n",
      "Epoch 21, Loss(train/val) 0.29638/0.39879. Took 0.16 sec\n",
      "Epoch 22, Loss(train/val) 0.29661/0.40111. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.29926/0.39880. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.29607/0.40357. Took 0.15 sec\n",
      "Epoch 25, Loss(train/val) 0.28442/0.39378. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.27863/0.39363. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.28677/0.41606. Took 0.16 sec\n",
      "Epoch 28, Loss(train/val) 0.27632/0.40345. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.27548/0.39389. Took 0.16 sec\n",
      "Epoch 30, Loss(train/val) 0.27584/0.40477. Took 0.17 sec\n",
      "Epoch 31, Loss(train/val) 0.27016/0.39642. Took 0.16 sec\n",
      "Epoch 32, Loss(train/val) 0.26920/0.40459. Took 0.16 sec\n",
      "Epoch 33, Loss(train/val) 0.26591/0.39099. Took 0.16 sec\n",
      "Epoch 34, Loss(train/val) 0.26536/0.39850. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.26368/0.39493. Took 0.17 sec\n",
      "Epoch 36, Loss(train/val) 0.25746/0.39090. Took 0.16 sec\n",
      "Epoch 37, Loss(train/val) 0.26263/0.42484. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.25883/0.39899. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.25087/0.40719. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.25048/0.40278. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.24525/0.41299. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.24666/0.40488. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.24014/0.39200. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.23903/0.41663. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) 0.24626/0.40114. Took 0.15 sec\n",
      "Epoch 46, Loss(train/val) 0.23399/0.39019. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.23557/0.40934. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.22605/0.40242. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.23814/0.41459. Took 0.15 sec\n",
      "Epoch 50, Loss(train/val) 0.23911/0.40748. Took 0.14 sec\n",
      "Epoch 51, Loss(train/val) 0.24537/0.41246. Took 0.15 sec\n",
      "Epoch 52, Loss(train/val) 0.23213/0.35751. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) 0.22227/0.38242. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.22628/0.39454. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.23788/0.35239. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.23096/0.34218. Took 0.15 sec\n",
      "Epoch 57, Loss(train/val) 0.22895/0.38258. Took 0.15 sec\n",
      "Epoch 58, Loss(train/val) 0.23552/0.37660. Took 0.14 sec\n",
      "Epoch 59, Loss(train/val) 0.23121/0.39586. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.22590/0.37399. Took 0.14 sec\n",
      "Epoch 61, Loss(train/val) 0.22354/0.34891. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.22035/0.35773. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.21643/0.34960. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.21532/0.39530. Took 0.15 sec\n",
      "Epoch 65, Loss(train/val) 0.21306/0.36516. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.21545/0.36365. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) 0.20998/0.37110. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.20787/0.36351. Took 0.14 sec\n",
      "Epoch 69, Loss(train/val) 0.20466/0.36387. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.21021/0.36085. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.21111/0.38086. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.20925/0.39482. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.20413/0.36325. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.20940/0.37267. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) 0.20494/0.36851. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.20163/0.38206. Took 0.15 sec\n",
      "Epoch 77, Loss(train/val) 0.19837/0.37550. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.20321/0.36385. Took 0.15 sec\n",
      "Epoch 79, Loss(train/val) 0.19674/0.37133. Took 0.15 sec\n",
      "Epoch 80, Loss(train/val) 0.21087/0.36820. Took 0.15 sec\n",
      "Epoch 81, Loss(train/val) 0.19175/0.37423. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.20032/0.37817. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) 0.20252/0.37383. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.19500/0.36250. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.19855/0.37752. Took 0.15 sec\n",
      "Epoch 86, Loss(train/val) 0.19488/0.37951. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.19757/0.39018. Took 0.15 sec\n",
      "Epoch 88, Loss(train/val) 0.19440/0.38151. Took 0.14 sec\n",
      "Epoch 89, Loss(train/val) 0.19543/0.38832. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.18625/0.38651. Took 0.14 sec\n",
      "Epoch 91, Loss(train/val) 0.18817/0.38474. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.19227/0.37057. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.19512/0.40059. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.19155/0.37744. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.19104/0.40538. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.19203/0.39399. Took 0.14 sec\n",
      "Epoch 97, Loss(train/val) 0.18913/0.38065. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.19343/0.40960. Took 0.14 sec\n",
      "Epoch 99, Loss(train/val) 0.19018/0.35868. Took 0.14 sec\n",
      "ACC: 0.734375, MCC: 0.476625505332187\n",
      "Epoch 0, Loss(train/val) 0.49468/0.49168. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.47054/0.47129. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.42999/0.43861. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.39534/0.45730. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.37341/0.47096. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.36536/0.47262. Took 0.15 sec\n",
      "Epoch 6, Loss(train/val) 0.35105/0.46991. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.34485/0.46197. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.34637/0.45213. Took 0.16 sec\n",
      "Epoch 9, Loss(train/val) 0.33369/0.46085. Took 0.16 sec\n",
      "Epoch 10, Loss(train/val) 0.32586/0.43237. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.31247/0.43473. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.31220/0.39529. Took 0.15 sec\n",
      "Epoch 13, Loss(train/val) 0.30185/0.39931. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.30197/0.40829. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.29318/0.40054. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.27696/0.42088. Took 0.15 sec\n",
      "Epoch 17, Loss(train/val) 0.27760/0.39763. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.27054/0.40078. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.26162/0.39964. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.26145/0.41441. Took 0.16 sec\n",
      "Epoch 21, Loss(train/val) 0.25534/0.40416. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.24782/0.40267. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.24615/0.41170. Took 0.16 sec\n",
      "Epoch 24, Loss(train/val) 0.24681/0.40133. Took 0.16 sec\n",
      "Epoch 25, Loss(train/val) 0.25135/0.38919. Took 0.16 sec\n",
      "Epoch 26, Loss(train/val) 0.24037/0.37626. Took 0.16 sec\n",
      "Epoch 27, Loss(train/val) 0.23462/0.40550. Took 0.17 sec\n",
      "Epoch 28, Loss(train/val) 0.23625/0.41140. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.23324/0.39085. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.22416/0.40330. Took 0.16 sec\n",
      "Epoch 31, Loss(train/val) 0.22593/0.40193. Took 0.17 sec\n",
      "Epoch 32, Loss(train/val) 0.21861/0.38293. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.21829/0.41290. Took 0.16 sec\n",
      "Epoch 34, Loss(train/val) 0.22354/0.40895. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.21601/0.36642. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.21393/0.42673. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.21276/0.39345. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.21661/0.38435. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.20375/0.36976. Took 0.15 sec\n",
      "Epoch 40, Loss(train/val) 0.19860/0.38440. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.20188/0.42373. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.21440/0.38612. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.20075/0.42042. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.20145/0.43004. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) 0.18847/0.44880. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.19323/0.42215. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.18810/0.48150. Took 0.15 sec\n",
      "Epoch 48, Loss(train/val) 0.18897/0.43129. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.19225/0.43035. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.17780/0.40274. Took 0.14 sec\n",
      "Epoch 51, Loss(train/val) 0.18045/0.41192. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.18678/0.44331. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.17981/0.39235. Took 0.15 sec\n",
      "Epoch 54, Loss(train/val) 0.17760/0.44574. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.18064/0.49229. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.18087/0.50939. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.18182/0.41669. Took 0.16 sec\n",
      "Epoch 58, Loss(train/val) 0.18653/0.45517. Took 0.14 sec\n",
      "Epoch 59, Loss(train/val) 0.18044/0.45823. Took 0.15 sec\n",
      "Epoch 60, Loss(train/val) 0.17348/0.50652. Took 0.14 sec\n",
      "Epoch 61, Loss(train/val) 0.17089/0.46152. Took 0.16 sec\n",
      "Epoch 62, Loss(train/val) 0.17406/0.43713. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.16397/0.43822. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.16578/0.42439. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.16228/0.45870. Took 0.15 sec\n",
      "Epoch 66, Loss(train/val) 0.16557/0.42630. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.15841/0.46026. Took 0.16 sec\n",
      "Epoch 68, Loss(train/val) 0.16246/0.40412. Took 0.14 sec\n",
      "Epoch 69, Loss(train/val) 0.16458/0.43844. Took 0.15 sec\n",
      "Epoch 70, Loss(train/val) 0.15529/0.45403. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.15646/0.43594. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.16967/0.38672. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.15930/0.44026. Took 0.15 sec\n",
      "Epoch 74, Loss(train/val) 0.16021/0.43956. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.15065/0.49298. Took 0.15 sec\n",
      "Epoch 76, Loss(train/val) 0.16530/0.43334. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.15419/0.50981. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.17248/0.48278. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.15851/0.45775. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.14694/0.46897. Took 0.14 sec\n",
      "Epoch 81, Loss(train/val) 0.15673/0.43285. Took 0.16 sec\n",
      "Epoch 82, Loss(train/val) 0.14832/0.48942. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) 0.14703/0.49383. Took 0.15 sec\n",
      "Epoch 84, Loss(train/val) 0.14904/0.49234. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.14650/0.48719. Took 0.15 sec\n",
      "Epoch 86, Loss(train/val) 0.15036/0.49420. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.14480/0.48767. Took 0.15 sec\n",
      "Epoch 88, Loss(train/val) 0.14324/0.43350. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.14484/0.44391. Took 0.15 sec\n",
      "Epoch 90, Loss(train/val) 0.14400/0.43440. Took 0.14 sec\n",
      "Epoch 91, Loss(train/val) 0.13442/0.50454. Took 0.15 sec\n",
      "Epoch 92, Loss(train/val) 0.13950/0.47685. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.15028/0.47543. Took 0.15 sec\n",
      "Epoch 94, Loss(train/val) 0.13879/0.51889. Took 0.14 sec\n",
      "Epoch 95, Loss(train/val) 0.13944/0.48002. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.12999/0.50482. Took 0.14 sec\n",
      "Epoch 97, Loss(train/val) 0.13719/0.53750. Took 0.15 sec\n",
      "Epoch 98, Loss(train/val) 0.13370/0.50454. Took 0.14 sec\n",
      "Epoch 99, Loss(train/val) 0.12985/0.50852. Took 0.14 sec\n",
      "ACC: 0.6875, MCC: 0.41023298028761596\n",
      "Epoch 0, Loss(train/val) 0.49373/0.48791. Took 0.16 sec\n",
      "Epoch 1, Loss(train/val) 0.46952/0.46984. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.42667/0.41764. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.40059/0.38005. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.38560/0.36858. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.37872/0.35335. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.37230/0.36654. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.35917/0.36542. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.35666/0.36962. Took 0.15 sec\n",
      "Epoch 9, Loss(train/val) 0.34114/0.38412. Took 0.15 sec\n",
      "Epoch 10, Loss(train/val) 0.33648/0.34284. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.32688/0.36921. Took 0.16 sec\n",
      "Epoch 12, Loss(train/val) 0.31639/0.30080. Took 0.16 sec\n",
      "Epoch 13, Loss(train/val) 0.31534/0.38035. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.30983/0.30652. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.28895/0.32379. Took 0.16 sec\n",
      "Epoch 16, Loss(train/val) 0.31495/0.40629. Took 0.15 sec\n",
      "Epoch 17, Loss(train/val) 0.31007/0.26530. Took 0.16 sec\n",
      "Epoch 18, Loss(train/val) 0.28721/0.35160. Took 0.15 sec\n",
      "Epoch 19, Loss(train/val) 0.28546/0.40757. Took 0.15 sec\n",
      "Epoch 20, Loss(train/val) 0.28091/0.41431. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.27237/0.35780. Took 0.17 sec\n",
      "Epoch 22, Loss(train/val) 0.27336/0.28292. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.26752/0.34851. Took 0.16 sec\n",
      "Epoch 24, Loss(train/val) 0.26471/0.33071. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.25930/0.35471. Took 0.16 sec\n",
      "Epoch 26, Loss(train/val) 0.27632/0.41642. Took 0.16 sec\n",
      "Epoch 27, Loss(train/val) 0.26571/0.28495. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.25432/0.28493. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.25647/0.33100. Took 0.17 sec\n",
      "Epoch 30, Loss(train/val) 0.24975/0.31356. Took 0.16 sec\n",
      "Epoch 31, Loss(train/val) 0.24822/0.33265. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.25027/0.31381. Took 0.16 sec\n",
      "Epoch 33, Loss(train/val) 0.24420/0.35306. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.22566/0.36725. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.25221/0.33306. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.23471/0.28887. Took 0.16 sec\n",
      "Epoch 37, Loss(train/val) 0.22696/0.31026. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.22560/0.33098. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.22180/0.33614. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.21516/0.29670. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.22611/0.31238. Took 0.15 sec\n",
      "Epoch 42, Loss(train/val) 0.22856/0.30465. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.22227/0.31995. Took 0.15 sec\n",
      "Epoch 44, Loss(train/val) 0.20536/0.28786. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.22190/0.30268. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.21060/0.30022. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.21241/0.29001. Took 0.15 sec\n",
      "Epoch 48, Loss(train/val) 0.19851/0.29679. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.20171/0.28746. Took 0.15 sec\n",
      "Epoch 50, Loss(train/val) 0.20146/0.30507. Took 0.14 sec\n",
      "Epoch 51, Loss(train/val) 0.19923/0.28210. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.19238/0.29764. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.19559/0.30773. Took 0.15 sec\n",
      "Epoch 54, Loss(train/val) 0.19407/0.29638. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.20107/0.29119. Took 0.15 sec\n",
      "Epoch 56, Loss(train/val) 0.19647/0.30388. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.18963/0.30190. Took 0.15 sec\n",
      "Epoch 58, Loss(train/val) 0.18614/0.30922. Took 0.14 sec\n",
      "Epoch 59, Loss(train/val) 0.20052/0.29846. Took 0.15 sec\n",
      "Epoch 60, Loss(train/val) 0.18688/0.28496. Took 0.14 sec\n",
      "Epoch 61, Loss(train/val) 0.18323/0.28996. Took 0.15 sec\n",
      "Epoch 62, Loss(train/val) 0.18234/0.27560. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.18506/0.27956. Took 0.15 sec\n",
      "Epoch 64, Loss(train/val) 0.18385/0.30794. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.20115/0.28641. Took 0.15 sec\n",
      "Epoch 66, Loss(train/val) 0.18764/0.27856. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.17224/0.34976. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.17139/0.31482. Took 0.14 sec\n",
      "Epoch 69, Loss(train/val) 0.17453/0.31864. Took 0.15 sec\n",
      "Epoch 70, Loss(train/val) 0.17325/0.30010. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.17491/0.31426. Took 0.15 sec\n",
      "Epoch 72, Loss(train/val) 0.16650/0.29384. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.17008/0.34736. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.16012/0.35196. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) 0.16182/0.33829. Took 0.15 sec\n",
      "Epoch 76, Loss(train/val) 0.15027/0.39595. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.15455/0.33450. Took 0.15 sec\n",
      "Epoch 78, Loss(train/val) 0.15859/0.34333. Took 0.15 sec\n",
      "Epoch 79, Loss(train/val) 0.16015/0.28622. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.15418/0.29871. Took 0.14 sec\n",
      "Epoch 81, Loss(train/val) 0.14599/0.31177. Took 0.15 sec\n",
      "Epoch 82, Loss(train/val) 0.14947/0.30832. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.15131/0.33806. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.14117/0.29965. Took 0.15 sec\n",
      "Epoch 85, Loss(train/val) 0.14457/0.30121. Took 0.15 sec\n",
      "Epoch 86, Loss(train/val) 0.14132/0.32057. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.14594/0.33004. Took 0.15 sec\n",
      "Epoch 88, Loss(train/val) 0.15147/0.31910. Took 0.14 sec\n",
      "Epoch 89, Loss(train/val) 0.14763/0.37669. Took 0.15 sec\n",
      "Epoch 90, Loss(train/val) 0.14489/0.34469. Took 0.14 sec\n",
      "Epoch 91, Loss(train/val) 0.14328/0.31830. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.14593/0.27989. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.13892/0.32790. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.13653/0.39215. Took 0.14 sec\n",
      "Epoch 95, Loss(train/val) 0.14552/0.34134. Took 0.15 sec\n",
      "Epoch 96, Loss(train/val) 0.13634/0.27766. Took 0.14 sec\n",
      "Epoch 97, Loss(train/val) 0.13951/0.31841. Took 0.15 sec\n",
      "Epoch 98, Loss(train/val) 0.14292/0.30803. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.13907/0.29229. Took 0.15 sec\n",
      "ACC: 0.53125, MCC: 0.12225843615495345\n",
      "Epoch 0, Loss(train/val) 0.49481/0.48600. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.47789/0.46364. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.45114/0.42343. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.41475/0.38403. Took 0.15 sec\n",
      "Epoch 4, Loss(train/val) 0.39391/0.36687. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.38241/0.37412. Took 0.15 sec\n",
      "Epoch 6, Loss(train/val) 0.36730/0.37437. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.35811/0.37587. Took 0.15 sec\n",
      "Epoch 8, Loss(train/val) 0.34612/0.41275. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.33382/0.43781. Took 0.16 sec\n",
      "Epoch 10, Loss(train/val) 0.33434/0.40829. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.32163/0.43330. Took 0.16 sec\n",
      "Epoch 12, Loss(train/val) 0.31190/0.42353. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.31520/0.43553. Took 0.16 sec\n",
      "Epoch 14, Loss(train/val) 0.30453/0.37181. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.29607/0.37300. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.28344/0.37315. Took 0.15 sec\n",
      "Epoch 17, Loss(train/val) 0.28809/0.33774. Took 0.16 sec\n",
      "Epoch 18, Loss(train/val) 0.28142/0.37093. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.27754/0.42061. Took 0.15 sec\n",
      "Epoch 20, Loss(train/val) 0.27721/0.35935. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.27691/0.41299. Took 0.16 sec\n",
      "Epoch 22, Loss(train/val) 0.26434/0.38275. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.25869/0.39477. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.26243/0.38480. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.26658/0.43938. Took 0.16 sec\n",
      "Epoch 26, Loss(train/val) 0.26786/0.33199. Took 0.15 sec\n",
      "Epoch 27, Loss(train/val) 0.25477/0.41870. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.24116/0.39463. Took 0.16 sec\n",
      "Epoch 29, Loss(train/val) 0.24952/0.41664. Took 0.17 sec\n",
      "Epoch 30, Loss(train/val) 0.24862/0.37445. Took 0.16 sec\n",
      "Epoch 31, Loss(train/val) 0.25250/0.36460. Took 0.16 sec\n",
      "Epoch 32, Loss(train/val) 0.23956/0.41388. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.23924/0.48187. Took 0.16 sec\n",
      "Epoch 34, Loss(train/val) 0.23443/0.43284. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.23235/0.38453. Took 0.18 sec\n",
      "Epoch 36, Loss(train/val) 0.24912/0.35890. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.23112/0.43499. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.22546/0.42788. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.22053/0.41523. Took 0.15 sec\n",
      "Epoch 40, Loss(train/val) 0.22112/0.43163. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.23237/0.41969. Took 0.15 sec\n",
      "Epoch 42, Loss(train/val) 0.23062/0.43597. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.23933/0.42376. Took 0.15 sec\n",
      "Epoch 44, Loss(train/val) 0.23026/0.42181. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) 0.21582/0.41802. Took 0.15 sec\n",
      "Epoch 46, Loss(train/val) 0.21479/0.43541. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.21621/0.44499. Took 0.15 sec\n",
      "Epoch 48, Loss(train/val) 0.22150/0.41055. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.21313/0.40988. Took 0.15 sec\n",
      "Epoch 50, Loss(train/val) 0.20689/0.41059. Took 0.14 sec\n",
      "Epoch 51, Loss(train/val) 0.21028/0.41303. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.20862/0.41603. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.19940/0.41719. Took 0.15 sec\n",
      "Epoch 54, Loss(train/val) 0.19843/0.41208. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.19940/0.40986. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.19602/0.41414. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.19351/0.40079. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.19745/0.39878. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.19209/0.41080. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.20476/0.41488. Took 0.14 sec\n",
      "Epoch 61, Loss(train/val) 0.20176/0.44119. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.19315/0.42415. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.18949/0.40829. Took 0.15 sec\n",
      "Epoch 64, Loss(train/val) 0.19159/0.42458. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.19185/0.41192. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.18768/0.41176. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) 0.18194/0.42136. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.18403/0.38548. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.17767/0.42052. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.17968/0.40743. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.18224/0.40244. Took 0.15 sec\n",
      "Epoch 72, Loss(train/val) 0.17926/0.40799. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.17547/0.40071. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.17672/0.39523. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) 0.17093/0.40744. Took 0.15 sec\n",
      "Epoch 76, Loss(train/val) 0.16666/0.41667. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.17658/0.43169. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.17646/0.40174. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.16493/0.44076. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.15774/0.37869. Took 0.14 sec\n",
      "Epoch 81, Loss(train/val) 0.16346/0.42947. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.16141/0.43942. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) 0.15801/0.38532. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.15642/0.39706. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.15399/0.43162. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.16918/0.42724. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.16033/0.43948. Took 0.15 sec\n",
      "Epoch 88, Loss(train/val) 0.15579/0.45328. Took 0.14 sec\n",
      "Epoch 89, Loss(train/val) 0.15002/0.44040. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.15323/0.42840. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.15500/0.42519. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.15506/0.40494. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.14174/0.45410. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.15471/0.42929. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.14885/0.40797. Took 0.15 sec\n",
      "Epoch 96, Loss(train/val) 0.14330/0.44197. Took 0.14 sec\n",
      "Epoch 97, Loss(train/val) 0.14021/0.44718. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.15047/0.43935. Took 0.14 sec\n",
      "Epoch 99, Loss(train/val) 0.14506/0.43507. Took 0.15 sec\n",
      "ACC: 0.734375, MCC: 0.4718556237543456\n",
      "Epoch 0, Loss(train/val) 0.49235/0.49972. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.47215/0.48821. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.44727/0.45501. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.42092/0.39644. Took 0.16 sec\n",
      "Epoch 4, Loss(train/val) 0.39877/0.36860. Took 0.16 sec\n",
      "Epoch 5, Loss(train/val) 0.38575/0.37510. Took 0.15 sec\n",
      "Epoch 6, Loss(train/val) 0.37183/0.38775. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.35685/0.40009. Took 0.20 sec\n",
      "Epoch 8, Loss(train/val) 0.34359/0.38656. Took 0.19 sec\n",
      "Epoch 9, Loss(train/val) 0.33664/0.38322. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.33035/0.39036. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.31884/0.40459. Took 0.16 sec\n",
      "Epoch 12, Loss(train/val) 0.31786/0.39609. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.30595/0.39156. Took 0.17 sec\n",
      "Epoch 14, Loss(train/val) 0.30609/0.39219. Took 0.15 sec\n",
      "Epoch 15, Loss(train/val) 0.29857/0.39356. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.29655/0.37656. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.29196/0.37428. Took 0.16 sec\n",
      "Epoch 18, Loss(train/val) 0.27422/0.38506. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.27738/0.35968. Took 0.16 sec\n",
      "Epoch 20, Loss(train/val) 0.26793/0.40865. Took 0.15 sec\n",
      "Epoch 21, Loss(train/val) 0.26333/0.42108. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.25011/0.40331. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.25477/0.40902. Took 0.16 sec\n",
      "Epoch 24, Loss(train/val) 0.25374/0.42772. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.24681/0.37665. Took 0.17 sec\n",
      "Epoch 26, Loss(train/val) 0.24507/0.41662. Took 0.16 sec\n",
      "Epoch 27, Loss(train/val) 0.23345/0.36891. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.23307/0.40177. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.22729/0.38493. Took 0.16 sec\n",
      "Epoch 30, Loss(train/val) 0.22802/0.34409. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.21999/0.39831. Took 0.17 sec\n",
      "Epoch 32, Loss(train/val) 0.21804/0.34067. Took 0.17 sec\n",
      "Epoch 33, Loss(train/val) 0.21921/0.37874. Took 0.17 sec\n",
      "Epoch 34, Loss(train/val) 0.21557/0.38133. Took 0.16 sec\n",
      "Epoch 35, Loss(train/val) 0.20481/0.37934. Took 0.15 sec\n",
      "Epoch 36, Loss(train/val) 0.20368/0.40717. Took 0.13 sec\n",
      "Epoch 37, Loss(train/val) 0.19827/0.39889. Took 0.15 sec\n",
      "Epoch 38, Loss(train/val) 0.19454/0.39804. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.20288/0.34532. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.19095/0.38863. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.18808/0.41218. Took 0.15 sec\n",
      "Epoch 42, Loss(train/val) 0.20194/0.41248. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.19006/0.36202. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.18331/0.40650. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) 0.17961/0.41950. Took 0.15 sec\n",
      "Epoch 46, Loss(train/val) 0.19030/0.38139. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.18669/0.42129. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.19515/0.38925. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.17177/0.39999. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.16589/0.38655. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.16921/0.38728. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.16224/0.39269. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.16537/0.38334. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.15963/0.40022. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.16802/0.41660. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.15868/0.39344. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.15840/0.38207. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.14534/0.37318. Took 0.14 sec\n",
      "Epoch 59, Loss(train/val) 0.15620/0.39500. Took 0.15 sec\n",
      "Epoch 60, Loss(train/val) 0.15104/0.38588. Took 0.14 sec\n",
      "Epoch 61, Loss(train/val) 0.15567/0.42738. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.14677/0.40885. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.14283/0.38574. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.15187/0.41117. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.14575/0.39262. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.14587/0.38677. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.13926/0.42040. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.13795/0.37479. Took 0.14 sec\n",
      "Epoch 69, Loss(train/val) 0.13091/0.37636. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.14036/0.38120. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.14202/0.40529. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.12442/0.40979. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.12919/0.40183. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.13824/0.41580. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) 0.13397/0.38285. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.14063/0.39614. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.13121/0.39399. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.13308/0.39777. Took 0.14 sec\n",
      "Epoch 79, Loss(train/val) 0.12190/0.39686. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.12307/0.41530. Took 0.14 sec\n",
      "Epoch 81, Loss(train/val) 0.12898/0.39899. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.11875/0.39152. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) 0.11575/0.39765. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.12538/0.39600. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.11684/0.42018. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.11443/0.39625. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.10482/0.39492. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.11037/0.38866. Took 0.14 sec\n",
      "Epoch 89, Loss(train/val) 0.12202/0.41401. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.11615/0.38081. Took 0.15 sec\n",
      "Epoch 91, Loss(train/val) 0.11090/0.40800. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.10932/0.38973. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.10832/0.38256. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.10481/0.36078. Took 0.14 sec\n",
      "Epoch 95, Loss(train/val) 0.10341/0.36835. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.10011/0.37807. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.09869/0.39149. Took 0.15 sec\n",
      "Epoch 98, Loss(train/val) 0.10251/0.39183. Took 0.14 sec\n",
      "Epoch 99, Loss(train/val) 0.10347/0.39570. Took 0.14 sec\n",
      "ACC: 0.625, MCC: 0.23293977699307994\n",
      "Epoch 0, Loss(train/val) 0.49360/0.48097. Took 0.16 sec\n",
      "Epoch 1, Loss(train/val) 0.47134/0.45727. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.44282/0.43808. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.41059/0.43466. Took 0.15 sec\n",
      "Epoch 4, Loss(train/val) 0.38734/0.41877. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.37362/0.39815. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.36539/0.38048. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.35926/0.36213. Took 0.15 sec\n",
      "Epoch 8, Loss(train/val) 0.35028/0.34471. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.34719/0.35515. Took 0.15 sec\n",
      "Epoch 10, Loss(train/val) 0.33840/0.35608. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.33863/0.32891. Took 0.15 sec\n",
      "Epoch 12, Loss(train/val) 0.32575/0.34555. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.32036/0.35159. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.31353/0.34943. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.30672/0.33073. Took 0.16 sec\n",
      "Epoch 16, Loss(train/val) 0.28731/0.34438. Took 0.15 sec\n",
      "Epoch 17, Loss(train/val) 0.28941/0.34206. Took 0.16 sec\n",
      "Epoch 18, Loss(train/val) 0.27651/0.34276. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.27160/0.34448. Took 0.16 sec\n",
      "Epoch 20, Loss(train/val) 0.26809/0.34499. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.26464/0.33771. Took 0.16 sec\n",
      "Epoch 22, Loss(train/val) 0.25779/0.35835. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.24357/0.37412. Took 0.16 sec\n",
      "Epoch 24, Loss(train/val) 0.24905/0.36980. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.24436/0.34560. Took 0.16 sec\n",
      "Epoch 26, Loss(train/val) 0.22824/0.36433. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.23190/0.36013. Took 0.16 sec\n",
      "Epoch 28, Loss(train/val) 0.23272/0.35641. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.22282/0.34855. Took 0.16 sec\n",
      "Epoch 30, Loss(train/val) 0.22561/0.40148. Took 0.16 sec\n",
      "Epoch 31, Loss(train/val) 0.22346/0.36504. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.21323/0.39832. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.21951/0.39137. Took 0.16 sec\n",
      "Epoch 34, Loss(train/val) 0.20920/0.34387. Took 0.17 sec\n",
      "Epoch 35, Loss(train/val) 0.20821/0.37775. Took 0.15 sec\n",
      "Epoch 36, Loss(train/val) 0.20437/0.40099. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.20277/0.41095. Took 0.17 sec\n",
      "Epoch 38, Loss(train/val) 0.20191/0.36950. Took 0.15 sec\n",
      "Epoch 39, Loss(train/val) 0.19728/0.38568. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.19547/0.40368. Took 0.15 sec\n",
      "Epoch 41, Loss(train/val) 0.19567/0.37499. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.18518/0.36670. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.18773/0.41939. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.19000/0.38010. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) 0.19269/0.40717. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.17853/0.41600. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.17945/0.41610. Took 0.15 sec\n",
      "Epoch 48, Loss(train/val) 0.18937/0.40610. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.17404/0.38918. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.16696/0.40806. Took 0.14 sec\n",
      "Epoch 51, Loss(train/val) 0.16593/0.40985. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.15913/0.38898. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.17329/0.36640. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.15948/0.40841. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.16185/0.41281. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.15630/0.40030. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.16104/0.39143. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.15265/0.40227. Took 0.15 sec\n",
      "Epoch 59, Loss(train/val) 0.15475/0.38557. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.15007/0.39835. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.15006/0.40361. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.15745/0.38494. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.14151/0.41084. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.15695/0.39775. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.14889/0.41211. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.16261/0.41073. Took 0.15 sec\n",
      "Epoch 67, Loss(train/val) 0.15294/0.40880. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.14642/0.36778. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.14550/0.39806. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.14073/0.42860. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.14080/0.41235. Took 0.15 sec\n",
      "Epoch 72, Loss(train/val) 0.14533/0.40646. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.13913/0.40567. Took 0.15 sec\n",
      "Epoch 74, Loss(train/val) 0.14074/0.38841. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) 0.13232/0.40034. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.13179/0.41369. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.13675/0.40640. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.13493/0.39998. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.12582/0.40963. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.12974/0.40138. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.13077/0.38383. Took 0.15 sec\n",
      "Epoch 82, Loss(train/val) 0.12209/0.40224. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.12492/0.41393. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.13350/0.39695. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.12529/0.37374. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.13139/0.39655. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.11833/0.39950. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.12534/0.39382. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.11723/0.37511. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.12283/0.41721. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.12771/0.40114. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.12471/0.40153. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.11945/0.38966. Took 0.15 sec\n",
      "Epoch 94, Loss(train/val) 0.11621/0.40931. Took 0.14 sec\n",
      "Epoch 95, Loss(train/val) 0.11758/0.38987. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.11150/0.41031. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.10782/0.40356. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.11257/0.39521. Took 0.14 sec\n",
      "Epoch 99, Loss(train/val) 0.10653/0.38547. Took 0.14 sec\n",
      "ACC: 0.640625, MCC: 0.28593741948180657\n",
      "Epoch 0, Loss(train/val) 0.49325/0.48838. Took 0.16 sec\n",
      "Epoch 1, Loss(train/val) 0.47270/0.46959. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.44174/0.44860. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.40784/0.41980. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.38322/0.39208. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.37116/0.38710. Took 0.15 sec\n",
      "Epoch 6, Loss(train/val) 0.36581/0.39759. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.36567/0.36252. Took 0.16 sec\n",
      "Epoch 8, Loss(train/val) 0.35997/0.39339. Took 0.15 sec\n",
      "Epoch 9, Loss(train/val) 0.35574/0.39712. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.34586/0.40744. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.34744/0.41122. Took 0.15 sec\n",
      "Epoch 12, Loss(train/val) 0.34592/0.40319. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.33780/0.40457. Took 0.16 sec\n",
      "Epoch 14, Loss(train/val) 0.32992/0.40465. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.32910/0.40423. Took 0.16 sec\n",
      "Epoch 16, Loss(train/val) 0.31650/0.39087. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.31529/0.39159. Took 0.16 sec\n",
      "Epoch 18, Loss(train/val) 0.30773/0.39148. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.30393/0.33731. Took 0.16 sec\n",
      "Epoch 20, Loss(train/val) 0.28856/0.36162. Took 0.15 sec\n",
      "Epoch 21, Loss(train/val) 0.29064/0.35079. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.30582/0.36486. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.28928/0.33291. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.27751/0.34717. Took 0.15 sec\n",
      "Epoch 25, Loss(train/val) 0.26694/0.36574. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.26469/0.36289. Took 0.15 sec\n",
      "Epoch 27, Loss(train/val) 0.25746/0.36759. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.24415/0.35566. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.24822/0.37637. Took 0.16 sec\n",
      "Epoch 30, Loss(train/val) 0.23973/0.37947. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.24379/0.34758. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.23304/0.34257. Took 0.16 sec\n",
      "Epoch 33, Loss(train/val) 0.22425/0.33125. Took 0.16 sec\n",
      "Epoch 34, Loss(train/val) 0.22692/0.35624. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.21615/0.36462. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.22223/0.36515. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.21581/0.35843. Took 0.15 sec\n",
      "Epoch 38, Loss(train/val) 0.21360/0.36904. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.20677/0.38880. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.20878/0.36259. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.20882/0.37366. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.20671/0.38255. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.20142/0.39056. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.19490/0.35047. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) 0.20315/0.34660. Took 0.15 sec\n",
      "Epoch 46, Loss(train/val) 0.19448/0.39020. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.18601/0.40651. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.19524/0.36625. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.19564/0.35435. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.19580/0.37416. Took 0.14 sec\n",
      "Epoch 51, Loss(train/val) 0.18121/0.35395. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.18364/0.34583. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) 0.18106/0.36180. Took 0.15 sec\n",
      "Epoch 54, Loss(train/val) 0.16792/0.37833. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.16958/0.36480. Took 0.15 sec\n",
      "Epoch 56, Loss(train/val) 0.17505/0.35111. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.16181/0.34915. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.17003/0.38533. Took 0.14 sec\n",
      "Epoch 59, Loss(train/val) 0.15998/0.37238. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.16324/0.34258. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.16635/0.36143. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.16430/0.37989. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.16290/0.36150. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.16561/0.37027. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.15404/0.33439. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.15980/0.34651. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) 0.15770/0.33451. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.15787/0.37342. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.15218/0.34428. Took 0.15 sec\n",
      "Epoch 70, Loss(train/val) 0.15073/0.34822. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.15200/0.35281. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.14467/0.32720. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.14042/0.36526. Took 0.15 sec\n",
      "Epoch 74, Loss(train/val) 0.14695/0.33892. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) 0.14857/0.34323. Took 0.16 sec\n",
      "Epoch 76, Loss(train/val) 0.14203/0.38352. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.14566/0.35103. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.14012/0.35457. Took 0.14 sec\n",
      "Epoch 79, Loss(train/val) 0.15560/0.35548. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.15915/0.33667. Took 0.14 sec\n",
      "Epoch 81, Loss(train/val) 0.14412/0.37569. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.14495/0.34334. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) 0.14139/0.34774. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.13896/0.32948. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.13884/0.33344. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.13513/0.31478. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.13774/0.33811. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.13069/0.31166. Took 0.14 sec\n",
      "Epoch 89, Loss(train/val) 0.12025/0.33973. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.11911/0.31641. Took 0.14 sec\n",
      "Epoch 91, Loss(train/val) 0.12221/0.33438. Took 0.15 sec\n",
      "Epoch 92, Loss(train/val) 0.12208/0.30941. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.12802/0.35975. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.12230/0.35080. Took 0.14 sec\n",
      "Epoch 95, Loss(train/val) 0.12831/0.37090. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.11681/0.33025. Took 0.14 sec\n",
      "Epoch 97, Loss(train/val) 0.12389/0.32097. Took 0.15 sec\n",
      "Epoch 98, Loss(train/val) 0.11654/0.36251. Took 0.14 sec\n",
      "Epoch 99, Loss(train/val) 0.12834/0.32793. Took 0.15 sec\n",
      "ACC: 0.609375, MCC: 0.21425126095413888\n",
      "Epoch 0, Loss(train/val) 0.49571/0.49194. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.47491/0.46964. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.44483/0.44333. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.41079/0.45043. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.38719/0.43930. Took 0.15 sec\n",
      "Epoch 5, Loss(train/val) 0.37206/0.43419. Took 0.15 sec\n",
      "Epoch 6, Loss(train/val) 0.36291/0.42145. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.35434/0.41678. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.35489/0.42542. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.34618/0.41441. Took 0.16 sec\n",
      "Epoch 10, Loss(train/val) 0.34006/0.40974. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.33687/0.41796. Took 0.16 sec\n",
      "Epoch 12, Loss(train/val) 0.32967/0.41665. Took 0.15 sec\n",
      "Epoch 13, Loss(train/val) 0.32269/0.42939. Took 0.16 sec\n",
      "Epoch 14, Loss(train/val) 0.31863/0.41893. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.31314/0.43996. Took 0.16 sec\n",
      "Epoch 16, Loss(train/val) 0.31085/0.41756. Took 0.16 sec\n",
      "Epoch 17, Loss(train/val) 0.30686/0.42427. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.30017/0.42846. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.28842/0.41555. Took 0.16 sec\n",
      "Epoch 20, Loss(train/val) 0.29072/0.40888. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.27822/0.40173. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.28907/0.43202. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.27446/0.40672. Took 0.16 sec\n",
      "Epoch 24, Loss(train/val) 0.26170/0.40760. Took 0.15 sec\n",
      "Epoch 25, Loss(train/val) 0.25408/0.40917. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.25631/0.39745. Took 0.15 sec\n",
      "Epoch 27, Loss(train/val) 0.25199/0.39553. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.25220/0.40317. Took 0.17 sec\n",
      "Epoch 29, Loss(train/val) 0.23470/0.41785. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.23256/0.41466. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.22522/0.41782. Took 0.17 sec\n",
      "Epoch 32, Loss(train/val) 0.22776/0.40783. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.22559/0.41033. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.23340/0.40766. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.22382/0.41459. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.21898/0.41494. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.22549/0.42414. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.21365/0.41552. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.21743/0.40937. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.20702/0.41107. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.22196/0.40454. Took 0.15 sec\n",
      "Epoch 42, Loss(train/val) 0.22746/0.40374. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.20214/0.40090. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.20957/0.41429. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) 0.19995/0.38417. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.20119/0.36929. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.19116/0.39616. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.19993/0.39294. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.18700/0.38376. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.18883/0.38953. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.18171/0.38735. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.18775/0.39676. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) 0.17864/0.40553. Took 0.15 sec\n",
      "Epoch 54, Loss(train/val) 0.17794/0.42548. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.18345/0.40389. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.16718/0.39785. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.16938/0.38490. Took 0.15 sec\n",
      "Epoch 58, Loss(train/val) 0.17479/0.35851. Took 0.14 sec\n",
      "Epoch 59, Loss(train/val) 0.17476/0.37606. Took 0.15 sec\n",
      "Epoch 60, Loss(train/val) 0.18425/0.39128. Took 0.14 sec\n",
      "Epoch 61, Loss(train/val) 0.17677/0.39845. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.17069/0.37411. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.16486/0.40846. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.16045/0.39727. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.16423/0.41004. Took 0.16 sec\n",
      "Epoch 66, Loss(train/val) 0.17165/0.39250. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) 0.15021/0.39111. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.15555/0.38665. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.16361/0.39586. Took 0.15 sec\n",
      "Epoch 70, Loss(train/val) 0.16503/0.34980. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.15214/0.40311. Took 0.15 sec\n",
      "Epoch 72, Loss(train/val) 0.15293/0.39080. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.15308/0.38912. Took 0.15 sec\n",
      "Epoch 74, Loss(train/val) 0.15689/0.39506. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) 0.16247/0.35638. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.14295/0.37454. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.15021/0.36376. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.14984/0.38246. Took 0.14 sec\n",
      "Epoch 79, Loss(train/val) 0.14745/0.37411. Took 0.15 sec\n",
      "Epoch 80, Loss(train/val) 0.14758/0.36572. Took 0.14 sec\n",
      "Epoch 81, Loss(train/val) 0.14577/0.36366. Took 0.15 sec\n",
      "Epoch 82, Loss(train/val) 0.14291/0.34925. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.14342/0.36988. Took 0.15 sec\n",
      "Epoch 84, Loss(train/val) 0.13784/0.35387. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.13385/0.36373. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.13985/0.39129. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.13406/0.35510. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.12816/0.37015. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.13351/0.35869. Took 0.15 sec\n",
      "Epoch 90, Loss(train/val) 0.13238/0.39686. Took 0.14 sec\n",
      "Epoch 91, Loss(train/val) 0.12694/0.35670. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.12832/0.38207. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.11719/0.35474. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.12002/0.38423. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.11641/0.36743. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.12465/0.37145. Took 0.14 sec\n",
      "Epoch 97, Loss(train/val) 0.12141/0.40038. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.12239/0.37669. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.11885/0.36635. Took 0.14 sec\n",
      "ACC: 0.609375, MCC: 0.18262637225482492\n",
      "Epoch 0, Loss(train/val) 0.49072/0.47865. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.46869/0.45161. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.43457/0.42708. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.40334/0.39373. Took 0.15 sec\n",
      "Epoch 4, Loss(train/val) 0.38175/0.35739. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.37292/0.35114. Took 0.15 sec\n",
      "Epoch 6, Loss(train/val) 0.35742/0.34129. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.35569/0.33029. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.35160/0.31961. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.34430/0.35269. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.33492/0.33801. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.33554/0.33283. Took 0.15 sec\n",
      "Epoch 12, Loss(train/val) 0.31815/0.33514. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.31536/0.42036. Took 0.16 sec\n",
      "Epoch 14, Loss(train/val) 0.30616/0.31750. Took 0.15 sec\n",
      "Epoch 15, Loss(train/val) 0.31071/0.31733. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.29672/0.33499. Took 0.16 sec\n",
      "Epoch 17, Loss(train/val) 0.29389/0.30654. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.29896/0.40753. Took 0.16 sec\n",
      "Epoch 19, Loss(train/val) 0.29074/0.30015. Took 0.15 sec\n",
      "Epoch 20, Loss(train/val) 0.28098/0.31614. Took 0.15 sec\n",
      "Epoch 21, Loss(train/val) 0.27759/0.38067. Took 0.16 sec\n",
      "Epoch 22, Loss(train/val) 0.28318/0.35142. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.27707/0.39531. Took 0.16 sec\n",
      "Epoch 24, Loss(train/val) 0.27724/0.37583. Took 0.15 sec\n",
      "Epoch 25, Loss(train/val) 0.27320/0.33919. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.25800/0.36566. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.27122/0.41305. Took 0.16 sec\n",
      "Epoch 28, Loss(train/val) 0.27431/0.48009. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.26562/0.44011. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.26300/0.39260. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.24891/0.39237. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.24748/0.39047. Took 0.17 sec\n",
      "Epoch 33, Loss(train/val) 0.25283/0.44792. Took 0.16 sec\n",
      "Epoch 34, Loss(train/val) 0.24937/0.40709. Took 0.17 sec\n",
      "Epoch 35, Loss(train/val) 0.24782/0.40952. Took 0.15 sec\n",
      "Epoch 36, Loss(train/val) 0.24070/0.43875. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.23788/0.39199. Took 0.17 sec\n",
      "Epoch 38, Loss(train/val) 0.22876/0.41091. Took 0.16 sec\n",
      "Epoch 39, Loss(train/val) 0.23589/0.37901. Took 0.16 sec\n",
      "Epoch 40, Loss(train/val) 0.23120/0.39574. Took 0.16 sec\n",
      "Epoch 41, Loss(train/val) 0.22595/0.38696. Took 0.18 sec\n",
      "Epoch 42, Loss(train/val) 0.22386/0.38205. Took 0.16 sec\n",
      "Epoch 43, Loss(train/val) 0.21189/0.35993. Took 0.15 sec\n",
      "Epoch 44, Loss(train/val) 0.22231/0.37839. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) 0.21617/0.40910. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.21384/0.37469. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.21127/0.39864. Took 0.15 sec\n",
      "Epoch 48, Loss(train/val) 0.21045/0.39073. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.20770/0.38684. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.20734/0.38414. Took 0.14 sec\n",
      "Epoch 51, Loss(train/val) 0.20449/0.38980. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.20424/0.39332. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.19458/0.38899. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.19719/0.38885. Took 0.15 sec\n",
      "Epoch 55, Loss(train/val) 0.20234/0.38147. Took 0.15 sec\n",
      "Epoch 56, Loss(train/val) 0.18537/0.40649. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.18977/0.38490. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.19469/0.39554. Took 0.14 sec\n",
      "Epoch 59, Loss(train/val) 0.19285/0.38774. Took 0.15 sec\n",
      "Epoch 60, Loss(train/val) 0.18163/0.40240. Took 0.14 sec\n",
      "Epoch 61, Loss(train/val) 0.18213/0.36608. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.18079/0.39545. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.17769/0.36985. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.18243/0.41214. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.18022/0.39488. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.17641/0.41658. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) 0.17244/0.42035. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.17426/0.41545. Took 0.14 sec\n",
      "Epoch 69, Loss(train/val) 0.17394/0.42039. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.17524/0.39033. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.17797/0.40096. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.15210/0.39670. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.17355/0.37857. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.16970/0.40743. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.15579/0.40041. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.15851/0.41363. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.16363/0.38518. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.15288/0.41538. Took 0.14 sec\n",
      "Epoch 79, Loss(train/val) 0.15344/0.40989. Took 0.15 sec\n",
      "Epoch 80, Loss(train/val) 0.15918/0.37697. Took 0.14 sec\n",
      "Epoch 81, Loss(train/val) 0.15019/0.35433. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.14889/0.38918. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) 0.15009/0.40831. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.14123/0.40110. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.13791/0.40697. Took 0.20 sec\n",
      "Epoch 86, Loss(train/val) 0.14042/0.40379. Took 0.17 sec\n",
      "Epoch 87, Loss(train/val) 0.14356/0.38747. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.14280/0.39542. Took 0.14 sec\n",
      "Epoch 89, Loss(train/val) 0.13889/0.38674. Took 0.16 sec\n",
      "Epoch 90, Loss(train/val) 0.13745/0.39009. Took 0.14 sec\n",
      "Epoch 91, Loss(train/val) 0.13374/0.36916. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.14115/0.39002. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.14566/0.39258. Took 0.16 sec\n",
      "Epoch 94, Loss(train/val) 0.13869/0.40153. Took 0.15 sec\n",
      "Epoch 95, Loss(train/val) 0.13704/0.37319. Took 0.16 sec\n",
      "Epoch 96, Loss(train/val) 0.13225/0.39117. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.12907/0.40076. Took 0.15 sec\n",
      "Epoch 98, Loss(train/val) 0.14267/0.38797. Took 0.14 sec\n",
      "Epoch 99, Loss(train/val) 0.13636/0.36385. Took 0.14 sec\n",
      "ACC: 0.578125, MCC: 0.14379213277409608\n",
      "Epoch 0, Loss(train/val) 0.49137/0.49380. Took 0.22 sec\n",
      "Epoch 1, Loss(train/val) 0.46801/0.48362. Took 0.17 sec\n",
      "Epoch 2, Loss(train/val) 0.43481/0.46286. Took 0.16 sec\n",
      "Epoch 3, Loss(train/val) 0.40729/0.43983. Took 0.16 sec\n",
      "Epoch 4, Loss(train/val) 0.38649/0.43683. Took 0.19 sec\n",
      "Epoch 5, Loss(train/val) 0.37235/0.44696. Took 0.16 sec\n",
      "Epoch 6, Loss(train/val) 0.36395/0.44547. Took 0.15 sec\n",
      "Epoch 7, Loss(train/val) 0.35718/0.44039. Took 0.17 sec\n",
      "Epoch 8, Loss(train/val) 0.35322/0.44235. Took 0.18 sec\n",
      "Epoch 9, Loss(train/val) 0.34562/0.44220. Took 0.17 sec\n",
      "Epoch 10, Loss(train/val) 0.34368/0.44492. Took 0.17 sec\n",
      "Epoch 11, Loss(train/val) 0.34270/0.44101. Took 0.18 sec\n",
      "Epoch 12, Loss(train/val) 0.33986/0.43838. Took 0.17 sec\n",
      "Epoch 13, Loss(train/val) 0.33384/0.42346. Took 0.18 sec\n",
      "Epoch 14, Loss(train/val) 0.32682/0.42061. Took 0.18 sec\n",
      "Epoch 15, Loss(train/val) 0.31453/0.41740. Took 0.17 sec\n",
      "Epoch 16, Loss(train/val) 0.30147/0.44027. Took 0.21 sec\n",
      "Epoch 17, Loss(train/val) 0.29328/0.43856. Took 0.18 sec\n",
      "Epoch 18, Loss(train/val) 0.29368/0.41362. Took 0.18 sec\n",
      "Epoch 19, Loss(train/val) 0.27257/0.43167. Took 0.17 sec\n",
      "Epoch 20, Loss(train/val) 0.27803/0.45824. Took 0.17 sec\n",
      "Epoch 21, Loss(train/val) 0.29333/0.40298. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.27998/0.41563. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.26163/0.45237. Took 0.17 sec\n",
      "Epoch 24, Loss(train/val) 0.26386/0.45793. Took 0.17 sec\n",
      "Epoch 25, Loss(train/val) 0.25430/0.44089. Took 0.18 sec\n",
      "Epoch 26, Loss(train/val) 0.24509/0.43885. Took 0.16 sec\n",
      "Epoch 27, Loss(train/val) 0.24538/0.45274. Took 0.16 sec\n",
      "Epoch 28, Loss(train/val) 0.24022/0.43944. Took 0.19 sec\n",
      "Epoch 29, Loss(train/val) 0.23989/0.46239. Took 0.19 sec\n",
      "Epoch 30, Loss(train/val) 0.23678/0.40513. Took 0.16 sec\n",
      "Epoch 31, Loss(train/val) 0.24002/0.41812. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.23530/0.42030. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.22315/0.41193. Took 0.16 sec\n",
      "Epoch 34, Loss(train/val) 0.21954/0.40982. Took 0.16 sec\n",
      "Epoch 35, Loss(train/val) 0.21670/0.41384. Took 0.16 sec\n",
      "Epoch 36, Loss(train/val) 0.22479/0.39744. Took 0.16 sec\n",
      "Epoch 37, Loss(train/val) 0.20761/0.42184. Took 0.15 sec\n",
      "Epoch 38, Loss(train/val) 0.20769/0.43754. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.21757/0.44293. Took 0.15 sec\n",
      "Epoch 40, Loss(train/val) 0.20132/0.44885. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.19856/0.41051. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.18981/0.41660. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.19801/0.43849. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.19572/0.45912. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.18998/0.43180. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.18357/0.40974. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.19082/0.40802. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.18520/0.39597. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.18328/0.40498. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.18385/0.42716. Took 0.14 sec\n",
      "Epoch 51, Loss(train/val) 0.18468/0.39944. Took 0.16 sec\n",
      "Epoch 52, Loss(train/val) 0.18166/0.40199. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.16753/0.40673. Took 0.15 sec\n",
      "Epoch 54, Loss(train/val) 0.17394/0.39841. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.16997/0.40281. Took 0.15 sec\n",
      "Epoch 56, Loss(train/val) 0.16718/0.41032. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.15845/0.40931. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.15851/0.44612. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.15420/0.42523. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.15576/0.41595. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.15032/0.42586. Took 0.15 sec\n",
      "Epoch 62, Loss(train/val) 0.15723/0.41064. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.15295/0.46621. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.15502/0.42755. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.15351/0.42956. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.14504/0.39570. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) 0.14411/0.40541. Took 0.15 sec\n",
      "Epoch 68, Loss(train/val) 0.14191/0.40673. Took 0.14 sec\n",
      "Epoch 69, Loss(train/val) 0.14499/0.41423. Took 0.15 sec\n",
      "Epoch 70, Loss(train/val) 0.13859/0.43457. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.13216/0.41830. Took 0.15 sec\n",
      "Epoch 72, Loss(train/val) 0.13240/0.43079. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.13182/0.40796. Took 0.15 sec\n",
      "Epoch 74, Loss(train/val) 0.14126/0.41808. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.14072/0.40320. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.13896/0.39978. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.12776/0.42285. Took 0.15 sec\n",
      "Epoch 78, Loss(train/val) 0.12947/0.39539. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.11992/0.37360. Took 0.15 sec\n",
      "Epoch 80, Loss(train/val) 0.12774/0.40464. Took 0.14 sec\n",
      "Epoch 81, Loss(train/val) 0.12652/0.44030. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.12395/0.42951. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.12775/0.38617. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.12588/0.38023. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.12048/0.42450. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.12467/0.39949. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.12358/0.42708. Took 0.15 sec\n",
      "Epoch 88, Loss(train/val) 0.11621/0.45409. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.11076/0.42330. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.11701/0.45586. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.11760/0.44593. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.11032/0.44090. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.10778/0.45040. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.11228/0.39788. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.10745/0.42541. Took 0.15 sec\n",
      "Epoch 96, Loss(train/val) 0.11099/0.40289. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.09700/0.42386. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.10964/0.41419. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.10647/0.39218. Took 0.14 sec\n",
      "ACC: 0.59375, MCC: 0.23498401923230525\n",
      "Epoch 0, Loss(train/val) 0.49775/0.49287. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.47934/0.46889. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.45041/0.42969. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.42165/0.39514. Took 0.15 sec\n",
      "Epoch 4, Loss(train/val) 0.40146/0.37764. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.38074/0.35197. Took 0.15 sec\n",
      "Epoch 6, Loss(train/val) 0.37308/0.33712. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.35910/0.33359. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.34350/0.33296. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.32830/0.33475. Took 0.15 sec\n",
      "Epoch 10, Loss(train/val) 0.32073/0.33652. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.30997/0.32155. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.29924/0.31603. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.28868/0.32522. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.29431/0.36293. Took 0.15 sec\n",
      "Epoch 15, Loss(train/val) 0.27833/0.32539. Took 0.18 sec\n",
      "Epoch 16, Loss(train/val) 0.29050/0.36638. Took 0.15 sec\n",
      "Epoch 17, Loss(train/val) 0.27765/0.33915. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.27538/0.31316. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.25480/0.38439. Took 0.15 sec\n",
      "Epoch 20, Loss(train/val) 0.26293/0.35941. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.25637/0.31101. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.25475/0.38759. Took 0.15 sec\n",
      "Epoch 23, Loss(train/val) 0.24809/0.31152. Took 0.17 sec\n",
      "Epoch 24, Loss(train/val) 0.24712/0.36422. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.23672/0.33736. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.24181/0.35235. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.23779/0.30175. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.23119/0.31088. Took 0.13 sec\n",
      "Epoch 29, Loss(train/val) 0.22572/0.30892. Took 0.16 sec\n",
      "Epoch 30, Loss(train/val) 0.21689/0.30343. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.21523/0.32555. Took 0.16 sec\n",
      "Epoch 32, Loss(train/val) 0.22014/0.32570. Took 0.16 sec\n",
      "Epoch 33, Loss(train/val) 0.21914/0.34140. Took 0.16 sec\n",
      "Epoch 34, Loss(train/val) 0.20831/0.34013. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.20555/0.33908. Took 0.16 sec\n",
      "Epoch 36, Loss(train/val) 0.21089/0.31304. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.20578/0.35947. Took 0.15 sec\n",
      "Epoch 38, Loss(train/val) 0.20719/0.32527. Took 0.15 sec\n",
      "Epoch 39, Loss(train/val) 0.20548/0.33767. Took 0.16 sec\n",
      "Epoch 40, Loss(train/val) 0.19538/0.36540. Took 0.15 sec\n",
      "Epoch 41, Loss(train/val) 0.19817/0.33710. Took 0.16 sec\n",
      "Epoch 42, Loss(train/val) 0.20148/0.34559. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.18773/0.37501. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.18787/0.34549. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.18995/0.37292. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.19268/0.34347. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.18301/0.37402. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.18321/0.36685. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.17930/0.37462. Took 0.15 sec\n",
      "Epoch 50, Loss(train/val) 0.17546/0.36769. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.16959/0.37997. Took 0.15 sec\n",
      "Epoch 52, Loss(train/val) 0.17343/0.36338. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.17422/0.35452. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.16550/0.37050. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.15511/0.40315. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.16157/0.37910. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.16741/0.38906. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.16066/0.35912. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.15389/0.38380. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.15885/0.37818. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.15755/0.39756. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.14504/0.39757. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.14396/0.38023. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.15930/0.37016. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.14299/0.37743. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.14619/0.36727. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) 0.14033/0.37520. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.13845/0.38622. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.14545/0.37463. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.14769/0.39637. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.14050/0.37840. Took 0.15 sec\n",
      "Epoch 72, Loss(train/val) 0.12976/0.39706. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.13142/0.37757. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.13686/0.38408. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) 0.14029/0.40021. Took 0.15 sec\n",
      "Epoch 76, Loss(train/val) 0.13210/0.40721. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.12899/0.40725. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.13681/0.40432. Took 0.14 sec\n",
      "Epoch 79, Loss(train/val) 0.12635/0.38939. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.13213/0.37382. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.12635/0.37706. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.13221/0.38038. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) 0.12694/0.38467. Took 0.16 sec\n",
      "Epoch 84, Loss(train/val) 0.13097/0.37248. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.12483/0.37056. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.12251/0.36714. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.12287/0.37975. Took 0.15 sec\n",
      "Epoch 88, Loss(train/val) 0.12285/0.37888. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.12292/0.35697. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.12417/0.37679. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.12390/0.38121. Took 0.15 sec\n",
      "Epoch 92, Loss(train/val) 0.11879/0.37461. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.12030/0.36721. Took 0.15 sec\n",
      "Epoch 94, Loss(train/val) 0.11239/0.37153. Took 0.14 sec\n",
      "Epoch 95, Loss(train/val) 0.11124/0.39081. Took 0.15 sec\n",
      "Epoch 96, Loss(train/val) 0.11313/0.39548. Took 0.14 sec\n",
      "Epoch 97, Loss(train/val) 0.12068/0.38242. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.12130/0.40266. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.12228/0.38488. Took 0.14 sec\n",
      "ACC: 0.671875, MCC: 0.3583436921783118\n",
      "Epoch 0, Loss(train/val) 0.49396/0.48976. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.47184/0.46723. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.44608/0.43415. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.41901/0.40995. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.39697/0.39382. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.37612/0.37736. Took 0.15 sec\n",
      "Epoch 6, Loss(train/val) 0.36145/0.35575. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.35054/0.33277. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.33661/0.31719. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.32044/0.30875. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.31383/0.30306. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.29871/0.30038. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.29636/0.28838. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.28326/0.27758. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.27521/0.27505. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.26342/0.29458. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.26182/0.28448. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.25531/0.30704. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.25542/0.30797. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.25787/0.32176. Took 0.18 sec\n",
      "Epoch 20, Loss(train/val) 0.24799/0.32538. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.23549/0.30572. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.23193/0.31169. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.23363/0.28837. Took 0.16 sec\n",
      "Epoch 24, Loss(train/val) 0.22241/0.30281. Took 0.15 sec\n",
      "Epoch 25, Loss(train/val) 0.23747/0.28898. Took 0.16 sec\n",
      "Epoch 26, Loss(train/val) 0.22388/0.30504. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.21909/0.31864. Took 0.16 sec\n",
      "Epoch 28, Loss(train/val) 0.21457/0.32290. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.22422/0.31113. Took 0.13 sec\n",
      "Epoch 30, Loss(train/val) 0.21494/0.32030. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.21417/0.32482. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.21740/0.31194. Took 0.13 sec\n",
      "Epoch 33, Loss(train/val) 0.20208/0.30798. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.20428/0.32088. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.20976/0.29668. Took 0.13 sec\n",
      "Epoch 36, Loss(train/val) 0.19777/0.30696. Took 0.13 sec\n",
      "Epoch 37, Loss(train/val) 0.19521/0.31085. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.19286/0.31358. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.19376/0.31252. Took 0.16 sec\n",
      "Epoch 40, Loss(train/val) 0.18775/0.30834. Took 0.15 sec\n",
      "Epoch 41, Loss(train/val) 0.19750/0.31080. Took 0.17 sec\n",
      "Epoch 42, Loss(train/val) 0.19089/0.31037. Took 0.15 sec\n",
      "Epoch 43, Loss(train/val) 0.19021/0.31697. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.18517/0.31678. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) 0.17929/0.31812. Took 0.16 sec\n",
      "Epoch 46, Loss(train/val) 0.18300/0.31809. Took 0.15 sec\n",
      "Epoch 47, Loss(train/val) 0.17990/0.31741. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.17386/0.29991. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.17580/0.30059. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.16965/0.30467. Took 0.14 sec\n",
      "Epoch 51, Loss(train/val) 0.16539/0.31107. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.16941/0.29736. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.16450/0.30501. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.16826/0.30039. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.15692/0.29117. Took 0.15 sec\n",
      "Epoch 56, Loss(train/val) 0.15792/0.27720. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.15252/0.30083. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.15998/0.30022. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.15778/0.29012. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.15560/0.30165. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.15433/0.31011. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.14777/0.28476. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.15295/0.28923. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.15692/0.30477. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.15274/0.29907. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.14547/0.29707. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.15101/0.30423. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.14165/0.27115. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.14771/0.28833. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.13964/0.27750. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.14092/0.30957. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.14439/0.31343. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.13405/0.31501. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.13081/0.30075. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.13756/0.30134. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.13731/0.27514. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.15236/0.29941. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.14719/0.32163. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.13270/0.30465. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.13031/0.31144. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.13366/0.30980. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.12578/0.30859. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.12218/0.31256. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.12546/0.30608. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.13254/0.31483. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.12837/0.32653. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.12657/0.32293. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.12156/0.32601. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.12654/0.30959. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.12167/0.31350. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.12965/0.32105. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.12467/0.31492. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.12701/0.29415. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.11835/0.30857. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.12233/0.32641. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.12280/0.33291. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.12422/0.33395. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.11906/0.32011. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.11505/0.32125. Took 0.14 sec\n",
      "ACC: 0.71875, MCC: 0.44810278287677535\n",
      "Epoch 0, Loss(train/val) 0.49276/0.49038. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.46959/0.47210. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.43567/0.44054. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.40715/0.43067. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.39010/0.42568. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.37563/0.41581. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.36266/0.41190. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.34808/0.41700. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.34027/0.41293. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.32832/0.40632. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.32557/0.39853. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.31192/0.39742. Took 0.15 sec\n",
      "Epoch 12, Loss(train/val) 0.30356/0.38234. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.30248/0.36424. Took 0.16 sec\n",
      "Epoch 14, Loss(train/val) 0.30475/0.32098. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.30124/0.33495. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.30215/0.38623. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.28993/0.36243. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.27915/0.32834. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.27062/0.36339. Took 0.15 sec\n",
      "Epoch 20, Loss(train/val) 0.28106/0.33096. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.29006/0.38325. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.27076/0.35498. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.26814/0.39011. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.26353/0.37332. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.25343/0.36105. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.24310/0.33320. Took 0.13 sec\n",
      "Epoch 27, Loss(train/val) 0.25626/0.33556. Took 0.13 sec\n",
      "Epoch 28, Loss(train/val) 0.25183/0.33641. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.24719/0.36542. Took 0.16 sec\n",
      "Epoch 30, Loss(train/val) 0.25318/0.32097. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.23354/0.37552. Took 0.13 sec\n",
      "Epoch 32, Loss(train/val) 0.23559/0.37383. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.24137/0.38649. Took 0.16 sec\n",
      "Epoch 34, Loss(train/val) 0.23505/0.37990. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.22540/0.30894. Took 0.16 sec\n",
      "Epoch 36, Loss(train/val) 0.22136/0.35920. Took 0.16 sec\n",
      "Epoch 37, Loss(train/val) 0.21431/0.36570. Took 0.15 sec\n",
      "Epoch 38, Loss(train/val) 0.22088/0.34898. Took 0.15 sec\n",
      "Epoch 39, Loss(train/val) 0.22375/0.35141. Took 0.16 sec\n",
      "Epoch 40, Loss(train/val) 0.21243/0.34482. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.21584/0.34013. Took 0.15 sec\n",
      "Epoch 42, Loss(train/val) 0.20879/0.34818. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.20554/0.38460. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.20738/0.33032. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.20158/0.36011. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.20062/0.35738. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.19420/0.35186. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.20052/0.36169. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.20118/0.37907. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.20342/0.34641. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.19749/0.37364. Took 0.15 sec\n",
      "Epoch 52, Loss(train/val) 0.18804/0.38627. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.19725/0.35865. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.18374/0.36720. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.19124/0.37195. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.18244/0.37882. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.19004/0.35740. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.19965/0.37402. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.19643/0.36428. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.18386/0.37705. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.18281/0.36964. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.17699/0.36755. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.18505/0.36965. Took 0.15 sec\n",
      "Epoch 64, Loss(train/val) 0.17333/0.36526. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.17305/0.35955. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.16683/0.38816. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.17758/0.37765. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.17383/0.38304. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.16900/0.36171. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.16701/0.35807. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.16850/0.37500. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.17355/0.36085. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.16757/0.36792. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.16649/0.38460. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.16688/0.37272. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.15956/0.37524. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.15774/0.36390. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.15297/0.37745. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.15016/0.37936. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.16143/0.37832. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.15816/0.36941. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.16313/0.38241. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.16077/0.38025. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.15387/0.37581. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.14687/0.37187. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.15597/0.37121. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.15051/0.38383. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.14462/0.39357. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.15176/0.39336. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.14901/0.38220. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.15321/0.39177. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.15144/0.39870. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.15324/0.39846. Took 0.15 sec\n",
      "Epoch 94, Loss(train/val) 0.14991/0.38011. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.14594/0.39256. Took 0.15 sec\n",
      "Epoch 96, Loss(train/val) 0.15381/0.39140. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.13550/0.39023. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.13560/0.38642. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.14642/0.37124. Took 0.14 sec\n",
      "ACC: 0.65625, MCC: 0.3349671627754999\n",
      "Epoch 0, Loss(train/val) 0.49555/0.49056. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.47945/0.47046. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.45865/0.42922. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.42708/0.38310. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.40229/0.36935. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.38649/0.34947. Took 0.15 sec\n",
      "Epoch 6, Loss(train/val) 0.37096/0.34194. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.35700/0.32457. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.34479/0.30512. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.32558/0.29283. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.31564/0.32814. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.31077/0.31443. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.30250/0.30362. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.30045/0.29142. Took 0.16 sec\n",
      "Epoch 14, Loss(train/val) 0.29406/0.29221. Took 0.15 sec\n",
      "Epoch 15, Loss(train/val) 0.30062/0.29444. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.28973/0.30189. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.27497/0.31083. Took 0.16 sec\n",
      "Epoch 18, Loss(train/val) 0.28676/0.29587. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.27099/0.29282. Took 0.15 sec\n",
      "Epoch 20, Loss(train/val) 0.27006/0.28810. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.27053/0.28415. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.25603/0.28258. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.25644/0.29014. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.24321/0.28805. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.24539/0.28939. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.25045/0.29075. Took 0.13 sec\n",
      "Epoch 27, Loss(train/val) 0.24031/0.30682. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.23151/0.28527. Took 0.13 sec\n",
      "Epoch 29, Loss(train/val) 0.23127/0.28644. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.22653/0.30469. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.22262/0.31637. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.22547/0.31026. Took 0.13 sec\n",
      "Epoch 33, Loss(train/val) 0.22805/0.32097. Took 0.16 sec\n",
      "Epoch 34, Loss(train/val) 0.22545/0.30249. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.22345/0.29674. Took 0.17 sec\n",
      "Epoch 36, Loss(train/val) 0.21865/0.30845. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.21785/0.32455. Took 0.15 sec\n",
      "Epoch 38, Loss(train/val) 0.21528/0.31983. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.21005/0.32084. Took 0.15 sec\n",
      "Epoch 40, Loss(train/val) 0.20463/0.30072. Took 0.15 sec\n",
      "Epoch 41, Loss(train/val) 0.20851/0.31602. Took 0.16 sec\n",
      "Epoch 42, Loss(train/val) 0.20117/0.32918. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.19946/0.32466. Took 0.15 sec\n",
      "Epoch 44, Loss(train/val) 0.20156/0.31371. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.20414/0.33085. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.20023/0.31940. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.20101/0.31716. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.19589/0.31225. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.18468/0.31654. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.18626/0.34731. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.18650/0.33545. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.18681/0.32157. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.18343/0.32671. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.18187/0.33174. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.18407/0.31120. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.17599/0.34463. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.16871/0.33253. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.17245/0.33905. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.17675/0.32628. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.17429/0.33450. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.16995/0.34656. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.17159/0.31486. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.16219/0.33175. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.16397/0.34419. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.16689/0.31555. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.16238/0.34636. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.15537/0.31131. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.15269/0.32432. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.15047/0.31185. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.14619/0.32211. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.14882/0.33614. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.15271/0.31206. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.15518/0.30754. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.14608/0.32369. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.13076/0.32548. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.13142/0.32556. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.14427/0.31354. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.14058/0.34133. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.14479/0.31739. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.14085/0.30511. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.13644/0.30618. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.13809/0.31112. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.14736/0.31623. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.14062/0.30744. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.13249/0.31218. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.13375/0.31739. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.13111/0.31469. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.12943/0.30933. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.12659/0.32470. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.13341/0.31463. Took 0.14 sec\n",
      "Epoch 91, Loss(train/val) 0.13153/0.30595. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.12340/0.32111. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.12509/0.32294. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.12175/0.33049. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.12314/0.31819. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.12730/0.32564. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.12837/0.31374. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.12149/0.32617. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.12336/0.32586. Took 0.13 sec\n",
      "ACC: 0.65625, MCC: 0.314970394174356\n",
      "Epoch 0, Loss(train/val) 0.48596/0.46971. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.45581/0.42406. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.42724/0.39868. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.39990/0.39642. Took 0.17 sec\n",
      "Epoch 4, Loss(train/val) 0.37903/0.38684. Took 0.19 sec\n",
      "Epoch 5, Loss(train/val) 0.36464/0.36287. Took 0.15 sec\n",
      "Epoch 6, Loss(train/val) 0.35199/0.33826. Took 0.17 sec\n",
      "Epoch 7, Loss(train/val) 0.34320/0.33348. Took 0.16 sec\n",
      "Epoch 8, Loss(train/val) 0.33260/0.28074. Took 0.16 sec\n",
      "Epoch 9, Loss(train/val) 0.32479/0.27602. Took 0.17 sec\n",
      "Epoch 10, Loss(train/val) 0.31433/0.26139. Took 0.17 sec\n",
      "Epoch 11, Loss(train/val) 0.30977/0.26255. Took 0.16 sec\n",
      "Epoch 12, Loss(train/val) 0.31112/0.26708. Took 0.15 sec\n",
      "Epoch 13, Loss(train/val) 0.30642/0.29192. Took 0.17 sec\n",
      "Epoch 14, Loss(train/val) 0.29644/0.30110. Took 0.16 sec\n",
      "Epoch 15, Loss(train/val) 0.30525/0.34343. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.28914/0.30095. Took 0.15 sec\n",
      "Epoch 17, Loss(train/val) 0.28542/0.30047. Took 0.19 sec\n",
      "Epoch 18, Loss(train/val) 0.29369/0.30843. Took 0.19 sec\n",
      "Epoch 19, Loss(train/val) 0.28152/0.30444. Took 0.16 sec\n",
      "Epoch 20, Loss(train/val) 0.27268/0.31411. Took 0.17 sec\n",
      "Epoch 21, Loss(train/val) 0.26641/0.32020. Took 0.16 sec\n",
      "Epoch 22, Loss(train/val) 0.26372/0.31794. Took 0.16 sec\n",
      "Epoch 23, Loss(train/val) 0.25602/0.32076. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.25015/0.31183. Took 0.15 sec\n",
      "Epoch 25, Loss(train/val) 0.24886/0.31641. Took 0.17 sec\n",
      "Epoch 26, Loss(train/val) 0.24303/0.33170. Took 0.15 sec\n",
      "Epoch 27, Loss(train/val) 0.24307/0.32629. Took 0.16 sec\n",
      "Epoch 28, Loss(train/val) 0.23522/0.33841. Took 0.13 sec\n",
      "Epoch 29, Loss(train/val) 0.24157/0.35081. Took 0.16 sec\n",
      "Epoch 30, Loss(train/val) 0.22645/0.33549. Took 0.18 sec\n",
      "Epoch 31, Loss(train/val) 0.22724/0.32852. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.22054/0.37668. Took 0.16 sec\n",
      "Epoch 33, Loss(train/val) 0.21350/0.36292. Took 0.19 sec\n",
      "Epoch 34, Loss(train/val) 0.21906/0.36739. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.21247/0.37695. Took 0.16 sec\n",
      "Epoch 36, Loss(train/val) 0.21046/0.38100. Took 0.16 sec\n",
      "Epoch 37, Loss(train/val) 0.21430/0.42132. Took 0.18 sec\n",
      "Epoch 38, Loss(train/val) 0.21557/0.40536. Took 0.23 sec\n",
      "Epoch 39, Loss(train/val) 0.22116/0.42688. Took 0.19 sec\n",
      "Epoch 40, Loss(train/val) 0.21099/0.40421. Took 0.19 sec\n",
      "Epoch 41, Loss(train/val) 0.20514/0.44285. Took 0.16 sec\n",
      "Epoch 42, Loss(train/val) 0.21106/0.41616. Took 0.16 sec\n",
      "Epoch 43, Loss(train/val) 0.20452/0.42566. Took 0.15 sec\n",
      "Epoch 44, Loss(train/val) 0.20236/0.41103. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) 0.19535/0.41019. Took 0.15 sec\n",
      "Epoch 46, Loss(train/val) 0.18929/0.40535. Took 0.16 sec\n",
      "Epoch 47, Loss(train/val) 0.19338/0.42754. Took 0.16 sec\n",
      "Epoch 48, Loss(train/val) 0.19326/0.43175. Took 0.15 sec\n",
      "Epoch 49, Loss(train/val) 0.18258/0.43328. Took 0.15 sec\n",
      "Epoch 50, Loss(train/val) 0.18843/0.40270. Took 0.17 sec\n",
      "Epoch 51, Loss(train/val) 0.18601/0.39752. Took 0.15 sec\n",
      "Epoch 52, Loss(train/val) 0.17953/0.41038. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) 0.17887/0.43237. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.17588/0.43160. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.17289/0.40179. Took 0.15 sec\n",
      "Epoch 56, Loss(train/val) 0.17489/0.39811. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.17135/0.40375. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.16942/0.39088. Took 0.14 sec\n",
      "Epoch 59, Loss(train/val) 0.16916/0.39371. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.17283/0.38495. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.17863/0.36597. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.17573/0.41139. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.17409/0.43094. Took 0.15 sec\n",
      "Epoch 64, Loss(train/val) 0.16628/0.41541. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.17040/0.40479. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.16573/0.41538. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) 0.16456/0.38726. Took 0.15 sec\n",
      "Epoch 68, Loss(train/val) 0.17471/0.39736. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.16602/0.39787. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.15411/0.40512. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.16542/0.40345. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.16340/0.38912. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.16349/0.42016. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.16246/0.40555. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.15382/0.41977. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.16429/0.41065. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.15318/0.40890. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.16159/0.41720. Took 0.15 sec\n",
      "Epoch 79, Loss(train/val) 0.15477/0.40709. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.15124/0.42051. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.14869/0.40119. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.14872/0.43558. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) 0.14948/0.42052. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.14720/0.43245. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.15141/0.40426. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.14657/0.42964. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.14555/0.43285. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.14280/0.42089. Took 0.14 sec\n",
      "Epoch 89, Loss(train/val) 0.14929/0.42110. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.14031/0.41460. Took 0.14 sec\n",
      "Epoch 91, Loss(train/val) 0.15151/0.43164. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.14984/0.44386. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.14553/0.44147. Took 0.15 sec\n",
      "Epoch 94, Loss(train/val) 0.14378/0.42658. Took 0.14 sec\n",
      "Epoch 95, Loss(train/val) 0.15170/0.43200. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.14306/0.36834. Took 0.14 sec\n",
      "Epoch 97, Loss(train/val) 0.13898/0.37878. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.14101/0.40442. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.14693/0.43376. Took 0.14 sec\n",
      "ACC: 0.703125, MCC: 0.43308539706144195\n",
      "Epoch 0, Loss(train/val) 0.48517/0.46964. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.45427/0.43486. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.42954/0.40606. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.40423/0.38213. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.37665/0.37818. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.35852/0.37251. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.34719/0.36835. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.33529/0.36674. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.33036/0.36333. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.32348/0.36066. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.32140/0.34908. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.31444/0.34863. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.31058/0.34468. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.30434/0.33856. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.29831/0.33595. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.29192/0.32815. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.28240/0.32490. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.27747/0.32814. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.27642/0.32142. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.27227/0.29330. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.27079/0.30613. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.26141/0.31482. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.26133/0.28628. Took 0.16 sec\n",
      "Epoch 23, Loss(train/val) 0.25478/0.30270. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.25784/0.27661. Took 0.16 sec\n",
      "Epoch 25, Loss(train/val) 0.25530/0.29276. Took 0.19 sec\n",
      "Epoch 26, Loss(train/val) 0.25073/0.28848. Took 0.20 sec\n",
      "Epoch 27, Loss(train/val) 0.23700/0.26038. Took 0.16 sec\n",
      "Epoch 28, Loss(train/val) 0.23791/0.28138. Took 0.18 sec\n",
      "Epoch 29, Loss(train/val) 0.24418/0.29862. Took 0.20 sec\n",
      "Epoch 30, Loss(train/val) 0.23369/0.28872. Took 0.20 sec\n",
      "Epoch 31, Loss(train/val) 0.22913/0.28845. Took 0.16 sec\n",
      "Epoch 32, Loss(train/val) 0.22698/0.27969. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.23002/0.30099. Took 0.16 sec\n",
      "Epoch 34, Loss(train/val) 0.22115/0.26821. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.21952/0.30550. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.21784/0.30371. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.21957/0.31313. Took 0.13 sec\n",
      "Epoch 38, Loss(train/val) 0.21833/0.30399. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.21199/0.31820. Took 0.15 sec\n",
      "Epoch 40, Loss(train/val) 0.20919/0.31366. Took 0.15 sec\n",
      "Epoch 41, Loss(train/val) 0.20537/0.31871. Took 0.16 sec\n",
      "Epoch 42, Loss(train/val) 0.21377/0.30508. Took 0.15 sec\n",
      "Epoch 43, Loss(train/val) 0.20589/0.30459. Took 0.15 sec\n",
      "Epoch 44, Loss(train/val) 0.20679/0.29969. Took 0.19 sec\n",
      "Epoch 45, Loss(train/val) 0.20337/0.29152. Took 0.21 sec\n",
      "Epoch 46, Loss(train/val) 0.19488/0.28458. Took 0.23 sec\n",
      "Epoch 47, Loss(train/val) 0.19549/0.29941. Took 0.18 sec\n",
      "Epoch 48, Loss(train/val) 0.19388/0.30839. Took 0.18 sec\n",
      "Epoch 49, Loss(train/val) 0.21266/0.28760. Took 0.16 sec\n",
      "Epoch 50, Loss(train/val) 0.19783/0.30194. Took 0.18 sec\n",
      "Epoch 51, Loss(train/val) 0.18571/0.31439. Took 0.16 sec\n",
      "Epoch 52, Loss(train/val) 0.18603/0.29602. Took 0.15 sec\n",
      "Epoch 53, Loss(train/val) 0.19629/0.33285. Took 0.17 sec\n",
      "Epoch 54, Loss(train/val) 0.18329/0.33242. Took 0.15 sec\n",
      "Epoch 55, Loss(train/val) 0.18083/0.32425. Took 0.15 sec\n",
      "Epoch 56, Loss(train/val) 0.17448/0.31964. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.17544/0.33823. Took 0.16 sec\n",
      "Epoch 58, Loss(train/val) 0.17016/0.31795. Took 0.16 sec\n",
      "Epoch 59, Loss(train/val) 0.16888/0.32039. Took 0.16 sec\n",
      "Epoch 60, Loss(train/val) 0.16796/0.31296. Took 0.15 sec\n",
      "Epoch 61, Loss(train/val) 0.17228/0.34121. Took 0.15 sec\n",
      "Epoch 62, Loss(train/val) 0.17169/0.29568. Took 0.16 sec\n",
      "Epoch 63, Loss(train/val) 0.15895/0.30322. Took 0.16 sec\n",
      "Epoch 64, Loss(train/val) 0.16987/0.32392. Took 0.15 sec\n",
      "Epoch 65, Loss(train/val) 0.15905/0.34348. Took 0.16 sec\n",
      "Epoch 66, Loss(train/val) 0.16227/0.30529. Took 0.17 sec\n",
      "Epoch 67, Loss(train/val) 0.15475/0.34199. Took 0.15 sec\n",
      "Epoch 68, Loss(train/val) 0.15676/0.31993. Took 0.15 sec\n",
      "Epoch 69, Loss(train/val) 0.15273/0.31317. Took 0.16 sec\n",
      "Epoch 70, Loss(train/val) 0.16152/0.31747. Took 0.16 sec\n",
      "Epoch 71, Loss(train/val) 0.14381/0.31536. Took 0.17 sec\n",
      "Epoch 72, Loss(train/val) 0.15182/0.30732. Took 0.16 sec\n",
      "Epoch 73, Loss(train/val) 0.15122/0.30407. Took 0.17 sec\n",
      "Epoch 74, Loss(train/val) 0.15114/0.33305. Took 0.15 sec\n",
      "Epoch 75, Loss(train/val) 0.15119/0.34102. Took 0.18 sec\n",
      "Epoch 76, Loss(train/val) 0.15046/0.33489. Took 0.16 sec\n",
      "Epoch 77, Loss(train/val) 0.14734/0.30401. Took 0.16 sec\n",
      "Epoch 78, Loss(train/val) 0.14046/0.30392. Took 0.16 sec\n",
      "Epoch 79, Loss(train/val) 0.13360/0.29642. Took 0.17 sec\n",
      "Epoch 80, Loss(train/val) 0.14488/0.32069. Took 0.16 sec\n",
      "Epoch 81, Loss(train/val) 0.14654/0.31140. Took 0.21 sec\n",
      "Epoch 82, Loss(train/val) 0.13134/0.30547. Took 0.17 sec\n",
      "Epoch 83, Loss(train/val) 0.13127/0.30568. Took 0.19 sec\n",
      "Epoch 84, Loss(train/val) 0.13029/0.28621. Took 0.20 sec\n",
      "Epoch 85, Loss(train/val) 0.13370/0.35845. Took 0.16 sec\n",
      "Epoch 86, Loss(train/val) 0.13526/0.31178. Took 0.17 sec\n",
      "Epoch 87, Loss(train/val) 0.12624/0.33117. Took 0.17 sec\n",
      "Epoch 88, Loss(train/val) 0.12856/0.33280. Took 0.15 sec\n",
      "Epoch 89, Loss(train/val) 0.12526/0.28748. Took 0.16 sec\n",
      "Epoch 90, Loss(train/val) 0.12769/0.30891. Took 0.17 sec\n",
      "Epoch 91, Loss(train/val) 0.12170/0.32055. Took 0.16 sec\n",
      "Epoch 92, Loss(train/val) 0.12377/0.31403. Took 0.15 sec\n",
      "Epoch 93, Loss(train/val) 0.12821/0.32334. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.12575/0.29316. Took 0.16 sec\n",
      "Epoch 95, Loss(train/val) 0.12444/0.30436. Took 0.15 sec\n",
      "Epoch 96, Loss(train/val) 0.12397/0.30073. Took 0.15 sec\n",
      "Epoch 97, Loss(train/val) 0.12008/0.30506. Took 0.16 sec\n",
      "Epoch 98, Loss(train/val) 0.12790/0.32340. Took 0.15 sec\n",
      "Epoch 99, Loss(train/val) 0.12624/0.31914. Took 0.16 sec\n",
      "ACC: 0.640625, MCC: 0.2771507137113173\n",
      "Epoch 0, Loss(train/val) 0.49358/0.49235. Took 0.17 sec\n",
      "Epoch 1, Loss(train/val) 0.46364/0.48222. Took 0.15 sec\n",
      "Epoch 2, Loss(train/val) 0.42606/0.45079. Took 0.18 sec\n",
      "Epoch 3, Loss(train/val) 0.39245/0.43696. Took 0.17 sec\n",
      "Epoch 4, Loss(train/val) 0.36617/0.39822. Took 0.19 sec\n",
      "Epoch 5, Loss(train/val) 0.34195/0.35758. Took 0.16 sec\n",
      "Epoch 6, Loss(train/val) 0.32740/0.32991. Took 0.19 sec\n",
      "Epoch 7, Loss(train/val) 0.31738/0.32297. Took 0.19 sec\n",
      "Epoch 8, Loss(train/val) 0.31108/0.31340. Took 0.16 sec\n",
      "Epoch 9, Loss(train/val) 0.30341/0.29150. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.30098/0.30875. Took 0.17 sec\n",
      "Epoch 11, Loss(train/val) 0.28966/0.26647. Took 0.19 sec\n",
      "Epoch 12, Loss(train/val) 0.28478/0.40130. Took 0.20 sec\n",
      "Epoch 13, Loss(train/val) 0.27425/0.40839. Took 0.19 sec\n",
      "Epoch 14, Loss(train/val) 0.25836/0.33939. Took 0.19 sec\n",
      "Epoch 15, Loss(train/val) 0.25503/0.40193. Took 0.17 sec\n",
      "Epoch 16, Loss(train/val) 0.26909/0.29976. Took 0.17 sec\n",
      "Epoch 17, Loss(train/val) 0.24899/0.34920. Took 0.18 sec\n",
      "Epoch 18, Loss(train/val) 0.25348/0.38903. Took 0.19 sec\n",
      "Epoch 19, Loss(train/val) 0.25588/0.32569. Took 0.17 sec\n",
      "Epoch 20, Loss(train/val) 0.24728/0.34297. Took 0.17 sec\n",
      "Epoch 21, Loss(train/val) 0.24419/0.35516. Took 0.16 sec\n",
      "Epoch 22, Loss(train/val) 0.24220/0.36142. Took 0.21 sec\n",
      "Epoch 23, Loss(train/val) 0.23634/0.33232. Took 0.19 sec\n",
      "Epoch 24, Loss(train/val) 0.23388/0.37759. Took 0.17 sec\n",
      "Epoch 25, Loss(train/val) 0.22951/0.33512. Took 0.21 sec\n",
      "Epoch 26, Loss(train/val) 0.23158/0.39668. Took 0.17 sec\n",
      "Epoch 27, Loss(train/val) 0.23340/0.34907. Took 0.18 sec\n",
      "Epoch 28, Loss(train/val) 0.22011/0.39795. Took 0.19 sec\n",
      "Epoch 29, Loss(train/val) 0.22508/0.32728. Took 0.21 sec\n",
      "Epoch 30, Loss(train/val) 0.22143/0.35695. Took 0.18 sec\n",
      "Epoch 31, Loss(train/val) 0.22145/0.33565. Took 0.18 sec\n",
      "Epoch 32, Loss(train/val) 0.22322/0.31206. Took 0.17 sec\n",
      "Epoch 33, Loss(train/val) 0.21438/0.33319. Took 0.24 sec\n",
      "Epoch 34, Loss(train/val) 0.21045/0.32035. Took 0.20 sec\n",
      "Epoch 35, Loss(train/val) 0.21333/0.32826. Took 0.18 sec\n",
      "Epoch 36, Loss(train/val) 0.19856/0.34916. Took 0.18 sec\n",
      "Epoch 37, Loss(train/val) 0.19310/0.33744. Took 0.25 sec\n",
      "Epoch 38, Loss(train/val) 0.19972/0.31140. Took 0.19 sec\n",
      "Epoch 39, Loss(train/val) 0.19697/0.27819. Took 0.20 sec\n",
      "Epoch 40, Loss(train/val) 0.19154/0.29842. Took 0.21 sec\n",
      "Epoch 41, Loss(train/val) 0.19487/0.27431. Took 0.17 sec\n",
      "Epoch 42, Loss(train/val) 0.20272/0.27801. Took 0.20 sec\n",
      "Epoch 43, Loss(train/val) 0.19166/0.34044. Took 0.16 sec\n",
      "Epoch 44, Loss(train/val) 0.19029/0.33644. Took 0.16 sec\n",
      "Epoch 45, Loss(train/val) 0.19387/0.29625. Took 0.15 sec\n",
      "Epoch 46, Loss(train/val) 0.18375/0.32211. Took 0.15 sec\n",
      "Epoch 47, Loss(train/val) 0.19257/0.33819. Took 0.15 sec\n",
      "Epoch 48, Loss(train/val) 0.18879/0.33180. Took 0.16 sec\n",
      "Epoch 49, Loss(train/val) 0.17797/0.33965. Took 0.16 sec\n",
      "Epoch 50, Loss(train/val) 0.17694/0.33901. Took 0.15 sec\n",
      "Epoch 51, Loss(train/val) 0.18359/0.36477. Took 0.17 sec\n",
      "Epoch 52, Loss(train/val) 0.17285/0.37011. Took 0.16 sec\n",
      "Epoch 53, Loss(train/val) 0.18267/0.35484. Took 0.15 sec\n",
      "Epoch 54, Loss(train/val) 0.16693/0.35704. Took 0.16 sec\n",
      "Epoch 55, Loss(train/val) 0.17224/0.35077. Took 0.18 sec\n",
      "Epoch 56, Loss(train/val) 0.17515/0.33998. Took 0.16 sec\n",
      "Epoch 57, Loss(train/val) 0.17774/0.30512. Took 0.15 sec\n",
      "Epoch 58, Loss(train/val) 0.17028/0.28623. Took 0.15 sec\n",
      "Epoch 59, Loss(train/val) 0.15971/0.38042. Took 0.17 sec\n",
      "Epoch 60, Loss(train/val) 0.16604/0.34710. Took 0.15 sec\n",
      "Epoch 61, Loss(train/val) 0.16828/0.34869. Took 0.15 sec\n",
      "Epoch 62, Loss(train/val) 0.16567/0.37425. Took 0.15 sec\n",
      "Epoch 63, Loss(train/val) 0.16014/0.34609. Took 0.17 sec\n",
      "Epoch 64, Loss(train/val) 0.16256/0.36702. Took 0.15 sec\n",
      "Epoch 65, Loss(train/val) 0.15101/0.36402. Took 0.15 sec\n",
      "Epoch 66, Loss(train/val) 0.15930/0.36601. Took 0.16 sec\n",
      "Epoch 67, Loss(train/val) 0.16305/0.35926. Took 0.16 sec\n",
      "Epoch 68, Loss(train/val) 0.15512/0.35950. Took 0.15 sec\n",
      "Epoch 69, Loss(train/val) 0.14979/0.39013. Took 0.15 sec\n",
      "Epoch 70, Loss(train/val) 0.15621/0.35285. Took 0.18 sec\n",
      "Epoch 71, Loss(train/val) 0.14936/0.39840. Took 0.15 sec\n",
      "Epoch 72, Loss(train/val) 0.15232/0.35629. Took 0.15 sec\n",
      "Epoch 73, Loss(train/val) 0.14920/0.38365. Took 0.18 sec\n",
      "Epoch 74, Loss(train/val) 0.16243/0.42239. Took 0.16 sec\n",
      "Epoch 75, Loss(train/val) 0.14814/0.39168. Took 0.15 sec\n",
      "Epoch 76, Loss(train/val) 0.14644/0.37403. Took 0.15 sec\n",
      "Epoch 77, Loss(train/val) 0.14291/0.41001. Took 0.15 sec\n",
      "Epoch 78, Loss(train/val) 0.14461/0.39743. Took 0.15 sec\n",
      "Epoch 79, Loss(train/val) 0.15167/0.40911. Took 0.15 sec\n",
      "Epoch 80, Loss(train/val) 0.14741/0.36439. Took 0.16 sec\n",
      "Epoch 81, Loss(train/val) 0.14649/0.38946. Took 0.15 sec\n",
      "Epoch 82, Loss(train/val) 0.14784/0.37815. Took 0.15 sec\n",
      "Epoch 83, Loss(train/val) 0.14313/0.38643. Took 0.18 sec\n",
      "Epoch 84, Loss(train/val) 0.13884/0.38042. Took 0.17 sec\n",
      "Epoch 85, Loss(train/val) 0.13635/0.37581. Took 0.16 sec\n",
      "Epoch 86, Loss(train/val) 0.13631/0.37533. Took 0.17 sec\n",
      "Epoch 87, Loss(train/val) 0.13259/0.36272. Took 0.20 sec\n",
      "Epoch 88, Loss(train/val) 0.13044/0.36333. Took 0.18 sec\n",
      "Epoch 89, Loss(train/val) 0.13372/0.38530. Took 0.16 sec\n",
      "Epoch 90, Loss(train/val) 0.13651/0.38362. Took 0.16 sec\n",
      "Epoch 91, Loss(train/val) 0.13716/0.38119. Took 0.17 sec\n",
      "Epoch 92, Loss(train/val) 0.13940/0.38984. Took 0.15 sec\n",
      "Epoch 93, Loss(train/val) 0.13438/0.37860. Took 0.17 sec\n",
      "Epoch 94, Loss(train/val) 0.13123/0.37979. Took 0.16 sec\n",
      "Epoch 95, Loss(train/val) 0.12944/0.36737. Took 0.17 sec\n",
      "Epoch 96, Loss(train/val) 0.13438/0.38518. Took 0.16 sec\n",
      "Epoch 97, Loss(train/val) 0.13272/0.37139. Took 0.17 sec\n",
      "Epoch 98, Loss(train/val) 0.12999/0.36100. Took 0.16 sec\n",
      "Epoch 99, Loss(train/val) 0.13761/0.37120. Took 0.16 sec\n",
      "ACC: 0.609375, MCC: 0.15114173098063566\n",
      "Epoch 0, Loss(train/val) 0.48951/0.46692. Took 0.18 sec\n",
      "Epoch 1, Loss(train/val) 0.45816/0.41525. Took 0.15 sec\n",
      "Epoch 2, Loss(train/val) 0.42451/0.37783. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.39662/0.35472. Took 0.15 sec\n",
      "Epoch 4, Loss(train/val) 0.37659/0.34456. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.36541/0.34485. Took 0.16 sec\n",
      "Epoch 6, Loss(train/val) 0.35974/0.34217. Took 0.15 sec\n",
      "Epoch 7, Loss(train/val) 0.34549/0.34389. Took 0.16 sec\n",
      "Epoch 8, Loss(train/val) 0.33368/0.33632. Took 0.15 sec\n",
      "Epoch 9, Loss(train/val) 0.31935/0.33302. Took 0.16 sec\n",
      "Epoch 10, Loss(train/val) 0.32074/0.34004. Took 0.15 sec\n",
      "Epoch 11, Loss(train/val) 0.30016/0.34289. Took 0.16 sec\n",
      "Epoch 12, Loss(train/val) 0.30045/0.34512. Took 0.17 sec\n",
      "Epoch 13, Loss(train/val) 0.29660/0.35062. Took 0.20 sec\n",
      "Epoch 14, Loss(train/val) 0.28567/0.34154. Took 0.21 sec\n",
      "Epoch 15, Loss(train/val) 0.28806/0.32951. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.28181/0.32356. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.26611/0.32268. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.26535/0.32307. Took 0.16 sec\n",
      "Epoch 19, Loss(train/val) 0.26133/0.31743. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.26097/0.33243. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.26021/0.28778. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.25428/0.34633. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.24699/0.35079. Took 0.16 sec\n",
      "Epoch 24, Loss(train/val) 0.24563/0.31719. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.24494/0.31343. Took 0.16 sec\n",
      "Epoch 26, Loss(train/val) 0.22587/0.32181. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.23795/0.32985. Took 0.17 sec\n",
      "Epoch 28, Loss(train/val) 0.24040/0.30601. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.22980/0.31928. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.22689/0.29746. Took 0.16 sec\n",
      "Epoch 31, Loss(train/val) 0.22549/0.34797. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.22832/0.31177. Took 0.16 sec\n",
      "Epoch 33, Loss(train/val) 0.21176/0.28116. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.22273/0.27664. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.21182/0.30116. Took 0.15 sec\n",
      "Epoch 36, Loss(train/val) 0.21692/0.30151. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.22214/0.30826. Took 0.16 sec\n",
      "Epoch 38, Loss(train/val) 0.20774/0.33031. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.20294/0.28269. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.19796/0.28414. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.20699/0.28025. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.19322/0.27848. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.19549/0.28100. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.19103/0.29283. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.19685/0.29424. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.18276/0.28331. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.19427/0.27938. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.18417/0.27452. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.18534/0.28117. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.20217/0.27698. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.20653/0.30844. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.18474/0.26723. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.18955/0.28038. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.18126/0.27374. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.18231/0.29411. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.18982/0.27844. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.18931/0.27587. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.18600/0.28157. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.18379/0.27790. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.17389/0.28661. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.18523/0.27404. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.17862/0.27895. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.17560/0.27306. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.17123/0.27301. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.17149/0.27498. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.16783/0.27766. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.17519/0.28198. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.16259/0.27633. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.16414/0.26926. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.16572/0.27884. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.16477/0.28409. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.16198/0.24818. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.16068/0.27290. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.16567/0.26625. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.16364/0.26449. Took 0.15 sec\n",
      "Epoch 76, Loss(train/val) 0.15794/0.30274. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.16334/0.26339. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.15777/0.27697. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.15907/0.26310. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.15688/0.26561. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.16125/0.28913. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.15726/0.27631. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.15334/0.28519. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.15135/0.32362. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.14618/0.27891. Took 0.15 sec\n",
      "Epoch 86, Loss(train/val) 0.14582/0.30151. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.15132/0.27921. Took 0.15 sec\n",
      "Epoch 88, Loss(train/val) 0.15674/0.25121. Took 0.14 sec\n",
      "Epoch 89, Loss(train/val) 0.14203/0.25711. Took 0.15 sec\n",
      "Epoch 90, Loss(train/val) 0.14700/0.27530. Took 0.14 sec\n",
      "Epoch 91, Loss(train/val) 0.14848/0.28628. Took 0.15 sec\n",
      "Epoch 92, Loss(train/val) 0.15028/0.27877. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.15030/0.28080. Took 0.15 sec\n",
      "Epoch 94, Loss(train/val) 0.14794/0.29070. Took 0.16 sec\n",
      "Epoch 95, Loss(train/val) 0.15617/0.26473. Took 0.19 sec\n",
      "Epoch 96, Loss(train/val) 0.15563/0.28111. Took 0.21 sec\n",
      "Epoch 97, Loss(train/val) 0.14338/0.27688. Took 0.17 sec\n",
      "Epoch 98, Loss(train/val) 0.14420/0.28787. Took 0.17 sec\n",
      "Epoch 99, Loss(train/val) 0.13760/0.28107. Took 0.15 sec\n",
      "ACC: 0.671875, MCC: 0.38363854103795736\n",
      "Epoch 0, Loss(train/val) 0.47895/0.48354. Took 0.16 sec\n",
      "Epoch 1, Loss(train/val) 0.43894/0.45711. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.40981/0.40762. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.38629/0.35860. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.36829/0.32914. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.35090/0.31979. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.33549/0.32106. Took 0.15 sec\n",
      "Epoch 7, Loss(train/val) 0.32235/0.31655. Took 0.17 sec\n",
      "Epoch 8, Loss(train/val) 0.30876/0.31198. Took 0.17 sec\n",
      "Epoch 9, Loss(train/val) 0.29912/0.30761. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.29098/0.29917. Took 0.16 sec\n",
      "Epoch 11, Loss(train/val) 0.28732/0.29808. Took 0.20 sec\n",
      "Epoch 12, Loss(train/val) 0.27853/0.27757. Took 0.17 sec\n",
      "Epoch 13, Loss(train/val) 0.27509/0.27584. Took 0.18 sec\n",
      "Epoch 14, Loss(train/val) 0.26332/0.27323. Took 0.16 sec\n",
      "Epoch 15, Loss(train/val) 0.26887/0.28041. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.25557/0.27810. Took 0.17 sec\n",
      "Epoch 17, Loss(train/val) 0.25883/0.28855. Took 0.16 sec\n",
      "Epoch 18, Loss(train/val) 0.26349/0.29472. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.26006/0.28930. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.25325/0.29044. Took 0.16 sec\n",
      "Epoch 21, Loss(train/val) 0.25152/0.29371. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.25128/0.29124. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.24994/0.32733. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.24872/0.28422. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.24126/0.28975. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.23810/0.29194. Took 0.16 sec\n",
      "Epoch 27, Loss(train/val) 0.24168/0.28585. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.24413/0.31008. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.24332/0.30207. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.23611/0.33635. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.23139/0.29421. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.22097/0.31785. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.22288/0.30760. Took 0.17 sec\n",
      "Epoch 34, Loss(train/val) 0.21216/0.30059. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.22595/0.31429. Took 0.16 sec\n",
      "Epoch 36, Loss(train/val) 0.22293/0.30193. Took 0.13 sec\n",
      "Epoch 37, Loss(train/val) 0.21227/0.30852. Took 0.15 sec\n",
      "Epoch 38, Loss(train/val) 0.20066/0.31509. Took 0.17 sec\n",
      "Epoch 39, Loss(train/val) 0.19906/0.30282. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.19926/0.29962. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.20380/0.29655. Took 0.16 sec\n",
      "Epoch 42, Loss(train/val) 0.21298/0.32895. Took 0.17 sec\n",
      "Epoch 43, Loss(train/val) 0.19855/0.32555. Took 0.16 sec\n",
      "Epoch 44, Loss(train/val) 0.19041/0.29802. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) 0.19597/0.29889. Took 0.18 sec\n",
      "Epoch 46, Loss(train/val) 0.20160/0.30120. Took 0.16 sec\n",
      "Epoch 47, Loss(train/val) 0.21226/0.30166. Took 0.16 sec\n",
      "Epoch 48, Loss(train/val) 0.19107/0.30532. Took 0.16 sec\n",
      "Epoch 49, Loss(train/val) 0.17771/0.30852. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.18359/0.32284. Took 0.14 sec\n",
      "Epoch 51, Loss(train/val) 0.18895/0.29893. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.17829/0.31192. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.17458/0.29948. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.18737/0.30440. Took 0.17 sec\n",
      "Epoch 55, Loss(train/val) 0.17966/0.28826. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.16683/0.29120. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.18029/0.32014. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.17612/0.28055. Took 0.14 sec\n",
      "Epoch 59, Loss(train/val) 0.17215/0.28523. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.17174/0.28295. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.17122/0.27314. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.16541/0.28309. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.15432/0.27650. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.16812/0.29134. Took 0.15 sec\n",
      "Epoch 65, Loss(train/val) 0.15158/0.27064. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.15177/0.27081. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) 0.16229/0.26473. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.15982/0.25188. Took 0.16 sec\n",
      "Epoch 69, Loss(train/val) 0.15466/0.26333. Took 0.15 sec\n",
      "Epoch 70, Loss(train/val) 0.14990/0.25859. Took 0.16 sec\n",
      "Epoch 71, Loss(train/val) 0.15411/0.26191. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.14467/0.25867. Took 0.16 sec\n",
      "Epoch 73, Loss(train/val) 0.13679/0.25478. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.14231/0.26577. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) 0.13909/0.28222. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.15339/0.26657. Took 0.15 sec\n",
      "Epoch 77, Loss(train/val) 0.14995/0.26666. Took 0.16 sec\n",
      "Epoch 78, Loss(train/val) 0.14423/0.28500. Took 0.19 sec\n",
      "Epoch 79, Loss(train/val) 0.14472/0.26604. Took 0.16 sec\n",
      "Epoch 80, Loss(train/val) 0.13664/0.26465. Took 0.14 sec\n",
      "Epoch 81, Loss(train/val) 0.13020/0.26408. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.12597/0.26587. Took 0.16 sec\n",
      "Epoch 83, Loss(train/val) 0.14524/0.25583. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.13019/0.26146. Took 0.15 sec\n",
      "Epoch 85, Loss(train/val) 0.14156/0.23740. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.13452/0.25147. Took 0.15 sec\n",
      "Epoch 87, Loss(train/val) 0.13050/0.24529. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.12452/0.25142. Took 0.16 sec\n",
      "Epoch 89, Loss(train/val) 0.13229/0.24961. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.12991/0.25222. Took 0.15 sec\n",
      "Epoch 91, Loss(train/val) 0.12788/0.27164. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.12428/0.25121. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.12285/0.25449. Took 0.17 sec\n",
      "Epoch 94, Loss(train/val) 0.12631/0.25565. Took 0.16 sec\n",
      "Epoch 95, Loss(train/val) 0.12631/0.26410. Took 0.15 sec\n",
      "Epoch 96, Loss(train/val) 0.11961/0.25129. Took 0.16 sec\n",
      "Epoch 97, Loss(train/val) 0.12063/0.27089. Took 0.15 sec\n",
      "Epoch 98, Loss(train/val) 0.12774/0.25417. Took 0.14 sec\n",
      "Epoch 99, Loss(train/val) 0.11828/0.26031. Took 0.13 sec\n",
      "ACC: 0.75, MCC: 0.35976048897510887\n",
      "Epoch 0, Loss(train/val) 0.48792/0.44072. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.45517/0.34875. Took 0.17 sec\n",
      "Epoch 2, Loss(train/val) 0.41994/0.29699. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.38889/0.28163. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.36984/0.27057. Took 0.16 sec\n",
      "Epoch 5, Loss(train/val) 0.35547/0.26255. Took 0.15 sec\n",
      "Epoch 6, Loss(train/val) 0.34610/0.26239. Took 0.16 sec\n",
      "Epoch 7, Loss(train/val) 0.33406/0.25925. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.32010/0.25120. Took 0.15 sec\n",
      "Epoch 9, Loss(train/val) 0.31313/0.24194. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.30865/0.24919. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.30393/0.26503. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.28924/0.25346. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.28745/0.27014. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.27956/0.24866. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.27778/0.24077. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.29591/0.24387. Took 0.15 sec\n",
      "Epoch 17, Loss(train/val) 0.28087/0.25664. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.28131/0.24868. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.27185/0.24772. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.25994/0.24560. Took 0.16 sec\n",
      "Epoch 21, Loss(train/val) 0.26707/0.25301. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.26790/0.23516. Took 0.15 sec\n",
      "Epoch 23, Loss(train/val) 0.27388/0.23631. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.25153/0.23509. Took 0.16 sec\n",
      "Epoch 25, Loss(train/val) 0.25121/0.23537. Took 0.16 sec\n",
      "Epoch 26, Loss(train/val) 0.24771/0.23518. Took 0.19 sec\n",
      "Epoch 27, Loss(train/val) 0.24540/0.24331. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.25525/0.24308. Took 0.16 sec\n",
      "Epoch 29, Loss(train/val) 0.24405/0.24106. Took 0.17 sec\n",
      "Epoch 30, Loss(train/val) 0.24723/0.24912. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.24076/0.25141. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.23533/0.24806. Took 0.17 sec\n",
      "Epoch 33, Loss(train/val) 0.24944/0.24697. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.23701/0.25168. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.22277/0.25487. Took 0.17 sec\n",
      "Epoch 36, Loss(train/val) 0.22729/0.24982. Took 0.18 sec\n",
      "Epoch 37, Loss(train/val) 0.22290/0.25771. Took 0.16 sec\n",
      "Epoch 38, Loss(train/val) 0.22373/0.24983. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.22498/0.24648. Took 0.15 sec\n",
      "Epoch 40, Loss(train/val) 0.21959/0.24225. Took 0.18 sec\n",
      "Epoch 41, Loss(train/val) 0.21602/0.24063. Took 0.15 sec\n",
      "Epoch 42, Loss(train/val) 0.21566/0.22435. Took 0.15 sec\n",
      "Epoch 43, Loss(train/val) 0.19861/0.23834. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.21232/0.23835. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) 0.20427/0.23788. Took 0.15 sec\n",
      "Epoch 46, Loss(train/val) 0.20700/0.24923. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.20502/0.22776. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.21478/0.22112. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.19690/0.22049. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.19525/0.23293. Took 0.14 sec\n",
      "Epoch 51, Loss(train/val) 0.19904/0.23470. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.20007/0.22485. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.19457/0.21787. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.18447/0.23788. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.18983/0.23532. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.18882/0.22166. Took 0.15 sec\n",
      "Epoch 57, Loss(train/val) 0.18963/0.23432. Took 0.15 sec\n",
      "Epoch 58, Loss(train/val) 0.18177/0.22335. Took 0.15 sec\n",
      "Epoch 59, Loss(train/val) 0.18667/0.22337. Took 0.16 sec\n",
      "Epoch 60, Loss(train/val) 0.19446/0.21398. Took 0.14 sec\n",
      "Epoch 61, Loss(train/val) 0.17747/0.22234. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.18461/0.20764. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.17825/0.21686. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.17257/0.21069. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.17865/0.22530. Took 0.15 sec\n",
      "Epoch 66, Loss(train/val) 0.16906/0.22800. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) 0.16410/0.21809. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.16645/0.20313. Took 0.15 sec\n",
      "Epoch 69, Loss(train/val) 0.17079/0.21551. Took 0.17 sec\n",
      "Epoch 70, Loss(train/val) 0.16746/0.21431. Took 0.16 sec\n",
      "Epoch 71, Loss(train/val) 0.17160/0.23557. Took 0.15 sec\n",
      "Epoch 72, Loss(train/val) 0.18272/0.21513. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.17353/0.22317. Took 0.15 sec\n",
      "Epoch 74, Loss(train/val) 0.15490/0.22485. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) 0.16584/0.21246. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.16654/0.22205. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.15580/0.20108. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.16255/0.21566. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.16620/0.22253. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.14768/0.21637. Took 0.16 sec\n",
      "Epoch 81, Loss(train/val) 0.15781/0.23394. Took 0.15 sec\n",
      "Epoch 82, Loss(train/val) 0.16450/0.21854. Took 0.16 sec\n",
      "Epoch 83, Loss(train/val) 0.14993/0.21175. Took 0.15 sec\n",
      "Epoch 84, Loss(train/val) 0.15566/0.21578. Took 0.15 sec\n",
      "Epoch 85, Loss(train/val) 0.16064/0.21087. Took 0.18 sec\n",
      "Epoch 86, Loss(train/val) 0.15372/0.22518. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.14436/0.19991. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.14991/0.20286. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.14849/0.21866. Took 0.15 sec\n",
      "Epoch 90, Loss(train/val) 0.15599/0.19735. Took 0.14 sec\n",
      "Epoch 91, Loss(train/val) 0.14704/0.21294. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.14446/0.20158. Took 0.16 sec\n",
      "Epoch 93, Loss(train/val) 0.14655/0.19212. Took 0.16 sec\n",
      "Epoch 94, Loss(train/val) 0.15879/0.20079. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.15080/0.19569. Took 0.15 sec\n",
      "Epoch 96, Loss(train/val) 0.14505/0.20263. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.15446/0.22238. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.14524/0.21067. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.14453/0.20558. Took 0.13 sec\n",
      "ACC: 0.578125, MCC: 0.1271849058234485\n",
      "Epoch 0, Loss(train/val) 0.48091/0.46908. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.44041/0.43916. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.40084/0.42753. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.37611/0.40949. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.35936/0.41037. Took 0.15 sec\n",
      "Epoch 5, Loss(train/val) 0.35232/0.39825. Took 0.16 sec\n",
      "Epoch 6, Loss(train/val) 0.34313/0.38592. Took 0.15 sec\n",
      "Epoch 7, Loss(train/val) 0.33592/0.38119. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.32280/0.34689. Took 0.15 sec\n",
      "Epoch 9, Loss(train/val) 0.32319/0.33853. Took 0.15 sec\n",
      "Epoch 10, Loss(train/val) 0.30862/0.32851. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.29896/0.33320. Took 0.16 sec\n",
      "Epoch 12, Loss(train/val) 0.29300/0.35850. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.28495/0.36307. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.28701/0.32258. Took 0.15 sec\n",
      "Epoch 15, Loss(train/val) 0.27353/0.34546. Took 0.17 sec\n",
      "Epoch 16, Loss(train/val) 0.26468/0.32711. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.27395/0.31804. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.26271/0.32647. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.26068/0.32225. Took 0.16 sec\n",
      "Epoch 20, Loss(train/val) 0.26429/0.35682. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.26019/0.29309. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.25480/0.34373. Took 0.16 sec\n",
      "Epoch 23, Loss(train/val) 0.24760/0.33297. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.25236/0.33590. Took 0.15 sec\n",
      "Epoch 25, Loss(train/val) 0.24296/0.34013. Took 0.16 sec\n",
      "Epoch 26, Loss(train/val) 0.24956/0.30828. Took 0.15 sec\n",
      "Epoch 27, Loss(train/val) 0.24309/0.31588. Took 0.16 sec\n",
      "Epoch 28, Loss(train/val) 0.23761/0.32602. Took 0.16 sec\n",
      "Epoch 29, Loss(train/val) 0.22292/0.32542. Took 0.22 sec\n",
      "Epoch 30, Loss(train/val) 0.22785/0.33924. Took 0.19 sec\n",
      "Epoch 31, Loss(train/val) 0.21738/0.31065. Took 0.18 sec\n",
      "Epoch 32, Loss(train/val) 0.21367/0.30751. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.23017/0.33471. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.22279/0.31049. Took 0.19 sec\n",
      "Epoch 35, Loss(train/val) 0.22142/0.31641. Took 0.21 sec\n",
      "Epoch 36, Loss(train/val) 0.20916/0.30488. Took 0.16 sec\n",
      "Epoch 37, Loss(train/val) 0.20503/0.31393. Took 0.17 sec\n",
      "Epoch 38, Loss(train/val) 0.19851/0.30515. Took 0.15 sec\n",
      "Epoch 39, Loss(train/val) 0.20758/0.32151. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.19670/0.31393. Took 0.15 sec\n",
      "Epoch 41, Loss(train/val) 0.19763/0.32428. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.20520/0.34859. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.18982/0.32985. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.20207/0.32691. Took 0.15 sec\n",
      "Epoch 45, Loss(train/val) 0.20265/0.33628. Took 0.16 sec\n",
      "Epoch 46, Loss(train/val) 0.18348/0.32992. Took 0.17 sec\n",
      "Epoch 47, Loss(train/val) 0.18555/0.30650. Took 0.16 sec\n",
      "Epoch 48, Loss(train/val) 0.18097/0.32225. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.18274/0.31245. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.17951/0.32301. Took 0.17 sec\n",
      "Epoch 51, Loss(train/val) 0.18120/0.32794. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.18030/0.31142. Took 0.18 sec\n",
      "Epoch 53, Loss(train/val) 0.18904/0.33312. Took 0.16 sec\n",
      "Epoch 54, Loss(train/val) 0.17892/0.32564. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.17825/0.32846. Took 0.15 sec\n",
      "Epoch 56, Loss(train/val) 0.18206/0.31965. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.16830/0.29506. Took 0.15 sec\n",
      "Epoch 58, Loss(train/val) 0.17277/0.30585. Took 0.16 sec\n",
      "Epoch 59, Loss(train/val) 0.16995/0.30220. Took 0.17 sec\n",
      "Epoch 60, Loss(train/val) 0.17545/0.30190. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.16950/0.29286. Took 0.15 sec\n",
      "Epoch 62, Loss(train/val) 0.16415/0.29285. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.16502/0.30331. Took 0.15 sec\n",
      "Epoch 64, Loss(train/val) 0.15889/0.29990. Took 0.15 sec\n",
      "Epoch 65, Loss(train/val) 0.16063/0.29869. Took 0.18 sec\n",
      "Epoch 66, Loss(train/val) 0.16684/0.30831. Took 0.15 sec\n",
      "Epoch 67, Loss(train/val) 0.17380/0.29686. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.16377/0.30296. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.15303/0.31153. Took 0.15 sec\n",
      "Epoch 70, Loss(train/val) 0.15589/0.30142. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.16671/0.32667. Took 0.16 sec\n",
      "Epoch 72, Loss(train/val) 0.15098/0.33955. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.15454/0.32001. Took 0.15 sec\n",
      "Epoch 74, Loss(train/val) 0.15005/0.32169. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.16118/0.32691. Took 0.15 sec\n",
      "Epoch 76, Loss(train/val) 0.15085/0.32356. Took 0.16 sec\n",
      "Epoch 77, Loss(train/val) 0.15175/0.33266. Took 0.16 sec\n",
      "Epoch 78, Loss(train/val) 0.14325/0.31535. Took 0.15 sec\n",
      "Epoch 79, Loss(train/val) 0.14884/0.32098. Took 0.15 sec\n",
      "Epoch 80, Loss(train/val) 0.15476/0.32702. Took 0.14 sec\n",
      "Epoch 81, Loss(train/val) 0.14539/0.34355. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.14442/0.32723. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.15163/0.33416. Took 0.15 sec\n",
      "Epoch 84, Loss(train/val) 0.15693/0.34589. Took 0.15 sec\n",
      "Epoch 85, Loss(train/val) 0.14956/0.32978. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.14458/0.35026. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.14325/0.33047. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.14460/0.35294. Took 0.15 sec\n",
      "Epoch 89, Loss(train/val) 0.14659/0.33594. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.13767/0.33275. Took 0.15 sec\n",
      "Epoch 91, Loss(train/val) 0.14208/0.35575. Took 0.17 sec\n",
      "Epoch 92, Loss(train/val) 0.13751/0.33619. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.14007/0.33440. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.13197/0.34926. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.14397/0.32237. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.13185/0.33082. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.14244/0.34827. Took 0.15 sec\n",
      "Epoch 98, Loss(train/val) 0.12669/0.34909. Took 0.14 sec\n",
      "Epoch 99, Loss(train/val) 0.12794/0.35374. Took 0.17 sec\n",
      "ACC: 0.640625, MCC: 0.31839711195475123\n",
      "Epoch 0, Loss(train/val) 0.48425/0.48758. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.44907/0.46546. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.41748/0.42747. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.38354/0.41509. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.36214/0.36681. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.34684/0.37290. Took 0.18 sec\n",
      "Epoch 6, Loss(train/val) 0.33497/0.31054. Took 0.15 sec\n",
      "Epoch 7, Loss(train/val) 0.32969/0.32898. Took 0.16 sec\n",
      "Epoch 8, Loss(train/val) 0.31802/0.33644. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.31543/0.38938. Took 0.20 sec\n",
      "Epoch 10, Loss(train/val) 0.32133/0.34922. Took 0.16 sec\n",
      "Epoch 11, Loss(train/val) 0.31472/0.32095. Took 0.16 sec\n",
      "Epoch 12, Loss(train/val) 0.30931/0.34429. Took 0.20 sec\n",
      "Epoch 13, Loss(train/val) 0.32134/0.44705. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.32996/0.37946. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.31770/0.34848. Took 0.16 sec\n",
      "Epoch 16, Loss(train/val) 0.30711/0.34939. Took 0.17 sec\n",
      "Epoch 17, Loss(train/val) 0.29906/0.34100. Took 0.17 sec\n",
      "Epoch 18, Loss(train/val) 0.29478/0.33717. Took 0.16 sec\n",
      "Epoch 19, Loss(train/val) 0.29052/0.33346. Took 0.15 sec\n",
      "Epoch 20, Loss(train/val) 0.28001/0.31714. Took 0.15 sec\n",
      "Epoch 21, Loss(train/val) 0.27501/0.31656. Took 0.16 sec\n",
      "Epoch 22, Loss(train/val) 0.27394/0.28643. Took 0.18 sec\n",
      "Epoch 23, Loss(train/val) 0.27882/0.29439. Took 0.17 sec\n",
      "Epoch 24, Loss(train/val) 0.27696/0.30470. Took 0.18 sec\n",
      "Epoch 25, Loss(train/val) 0.27310/0.32367. Took 0.18 sec\n",
      "Epoch 26, Loss(train/val) 0.26096/0.34466. Took 0.17 sec\n",
      "Epoch 27, Loss(train/val) 0.25859/0.35734. Took 0.19 sec\n",
      "Epoch 28, Loss(train/val) 0.25313/0.36470. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.25690/0.33766. Took 0.18 sec\n",
      "Epoch 30, Loss(train/val) 0.24751/0.34400. Took 0.19 sec\n",
      "Epoch 31, Loss(train/val) 0.24276/0.33217. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.23120/0.32056. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.23617/0.33118. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.23638/0.30824. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.22833/0.34260. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.23480/0.33045. Took 0.17 sec\n",
      "Epoch 37, Loss(train/val) 0.21911/0.29113. Took 0.18 sec\n",
      "Epoch 38, Loss(train/val) 0.22629/0.36621. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.22497/0.35853. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.22351/0.31937. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.22044/0.32964. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.22081/0.33045. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.21504/0.29679. Took 0.16 sec\n",
      "Epoch 44, Loss(train/val) 0.20992/0.29509. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.20958/0.30671. Took 0.15 sec\n",
      "Epoch 46, Loss(train/val) 0.20243/0.29663. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.20813/0.32060. Took 0.15 sec\n",
      "Epoch 48, Loss(train/val) 0.19225/0.31363. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.19642/0.31604. Took 0.16 sec\n",
      "Epoch 50, Loss(train/val) 0.18766/0.33102. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.19302/0.31615. Took 0.15 sec\n",
      "Epoch 52, Loss(train/val) 0.18452/0.30852. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.18299/0.29777. Took 0.15 sec\n",
      "Epoch 54, Loss(train/val) 0.17289/0.32604. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.18097/0.29935. Took 0.15 sec\n",
      "Epoch 56, Loss(train/val) 0.17324/0.33812. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.17127/0.32505. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.16906/0.32633. Took 0.15 sec\n",
      "Epoch 59, Loss(train/val) 0.16798/0.32372. Took 0.17 sec\n",
      "Epoch 60, Loss(train/val) 0.17076/0.30860. Took 0.15 sec\n",
      "Epoch 61, Loss(train/val) 0.16970/0.33811. Took 0.18 sec\n",
      "Epoch 62, Loss(train/val) 0.16889/0.31395. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.16514/0.31570. Took 0.16 sec\n",
      "Epoch 64, Loss(train/val) 0.16207/0.30479. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.16056/0.33394. Took 0.16 sec\n",
      "Epoch 66, Loss(train/val) 0.16400/0.32949. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) 0.14908/0.33441. Took 0.15 sec\n",
      "Epoch 68, Loss(train/val) 0.14950/0.34020. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.15447/0.35760. Took 0.15 sec\n",
      "Epoch 70, Loss(train/val) 0.15495/0.36227. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.14741/0.33626. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.14952/0.36420. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.14699/0.32795. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.14332/0.34247. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.14271/0.32651. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.14129/0.31912. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.13846/0.37383. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.14502/0.36471. Took 0.14 sec\n",
      "Epoch 79, Loss(train/val) 0.13987/0.38415. Took 0.15 sec\n",
      "Epoch 80, Loss(train/val) 0.13446/0.37441. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.12815/0.33393. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.13754/0.31180. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.13613/0.32185. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.13649/0.32186. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.13176/0.36304. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.13371/0.31435. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.13244/0.33349. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.12758/0.30515. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.11767/0.35273. Took 0.15 sec\n",
      "Epoch 90, Loss(train/val) 0.12452/0.31282. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.12220/0.34468. Took 0.16 sec\n",
      "Epoch 92, Loss(train/val) 0.12216/0.32001. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.11741/0.30252. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.11786/0.28968. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.12959/0.30313. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.12052/0.32399. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.12715/0.30202. Took 0.15 sec\n",
      "Epoch 98, Loss(train/val) 0.12731/0.33434. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.11828/0.30769. Took 0.15 sec\n",
      "ACC: 0.609375, MCC: 0.24764219818702876\n",
      "Epoch 0, Loss(train/val) 0.48782/0.49485. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.45386/0.48494. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.42122/0.47066. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.38997/0.45800. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.37251/0.44512. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.35642/0.43637. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.34202/0.43079. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.33128/0.42398. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.32542/0.42003. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.30526/0.41603. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.30289/0.40899. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.29735/0.41135. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.28247/0.38777. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.28166/0.39229. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.27761/0.37821. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.27803/0.37630. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.26595/0.40402. Took 0.16 sec\n",
      "Epoch 17, Loss(train/val) 0.27112/0.38793. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.25959/0.40368. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.25769/0.40633. Took 0.15 sec\n",
      "Epoch 20, Loss(train/val) 0.25549/0.39696. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.24443/0.38241. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.24959/0.39146. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.24643/0.38680. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.23125/0.38565. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.23974/0.36882. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.22802/0.38361. Took 0.13 sec\n",
      "Epoch 27, Loss(train/val) 0.23339/0.39590. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.22515/0.37567. Took 0.13 sec\n",
      "Epoch 29, Loss(train/val) 0.21841/0.40321. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.21542/0.39333. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.21450/0.39277. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.21183/0.36979. Took 0.13 sec\n",
      "Epoch 33, Loss(train/val) 0.21165/0.37381. Took 0.16 sec\n",
      "Epoch 34, Loss(train/val) 0.21864/0.40041. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.22082/0.39526. Took 0.15 sec\n",
      "Epoch 36, Loss(train/val) 0.22192/0.37142. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.21210/0.37689. Took 0.15 sec\n",
      "Epoch 38, Loss(train/val) 0.21282/0.39805. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.21301/0.40630. Took 0.16 sec\n",
      "Epoch 40, Loss(train/val) 0.19519/0.39390. Took 0.15 sec\n",
      "Epoch 41, Loss(train/val) 0.20414/0.38520. Took 0.16 sec\n",
      "Epoch 42, Loss(train/val) 0.20010/0.40526. Took 0.15 sec\n",
      "Epoch 43, Loss(train/val) 0.19740/0.40800. Took 0.16 sec\n",
      "Epoch 44, Loss(train/val) 0.19590/0.39695. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.18796/0.39849. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.17852/0.38037. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.18135/0.37596. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.17701/0.38581. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.17179/0.37692. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.16924/0.40768. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.17823/0.36173. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.16632/0.38278. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.16840/0.36242. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.16782/0.38828. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.16590/0.39822. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.16652/0.39933. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.15638/0.38266. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.15441/0.38830. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.15795/0.37304. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.15643/0.38204. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.14959/0.36523. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.14593/0.38157. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.14923/0.38247. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.15588/0.37980. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.14317/0.37955. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.14358/0.37589. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) 0.14221/0.38439. Took 0.15 sec\n",
      "Epoch 68, Loss(train/val) 0.13660/0.37868. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.13567/0.38199. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.13290/0.37519. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.13620/0.39548. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.13036/0.35459. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.12983/0.40655. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.13532/0.38906. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.12914/0.36898. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.13091/0.38233. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.12709/0.39147. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.13049/0.37862. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.12352/0.36698. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.12009/0.37289. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.12227/0.36932. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.11888/0.39186. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.12008/0.36818. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.11563/0.40064. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.11995/0.35249. Took 0.15 sec\n",
      "Epoch 86, Loss(train/val) 0.11719/0.36743. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.11826/0.39388. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.12142/0.38414. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.11223/0.35233. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.11398/0.35972. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.11619/0.38388. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.10750/0.36008. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.10981/0.38476. Took 0.15 sec\n",
      "Epoch 94, Loss(train/val) 0.11466/0.36628. Took 0.14 sec\n",
      "Epoch 95, Loss(train/val) 0.10588/0.38281. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.12219/0.35471. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.10941/0.37450. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.10492/0.39833. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.10579/0.35782. Took 0.13 sec\n",
      "ACC: 0.703125, MCC: 0.4078191053434671\n",
      "Epoch 0, Loss(train/val) 0.49134/0.48642. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.46282/0.45996. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.42887/0.40857. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.39604/0.37426. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.37905/0.34709. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.36548/0.35049. Took 0.15 sec\n",
      "Epoch 6, Loss(train/val) 0.34898/0.35257. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.33473/0.34731. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.32553/0.32709. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.30990/0.31987. Took 0.15 sec\n",
      "Epoch 10, Loss(train/val) 0.30731/0.29558. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.31097/0.29301. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.29702/0.30025. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.29460/0.32348. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.29659/0.31867. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.29645/0.30531. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.29627/0.29165. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.28546/0.33562. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.28854/0.30133. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.28175/0.31236. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.27880/0.30184. Took 0.16 sec\n",
      "Epoch 21, Loss(train/val) 0.27400/0.30204. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.26859/0.29886. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.26152/0.29955. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.26174/0.30298. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.24730/0.31038. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.25992/0.31806. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.24917/0.29646. Took 0.16 sec\n",
      "Epoch 28, Loss(train/val) 0.24523/0.30638. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.24913/0.31224. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.24143/0.30465. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.23623/0.30310. Took 0.16 sec\n",
      "Epoch 32, Loss(train/val) 0.23737/0.29633. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.23326/0.30375. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.24205/0.29861. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.22883/0.30151. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.23627/0.29526. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.23278/0.30943. Took 0.16 sec\n",
      "Epoch 38, Loss(train/val) 0.22770/0.32508. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.22598/0.30838. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.22688/0.29002. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.21449/0.30924. Took 0.15 sec\n",
      "Epoch 42, Loss(train/val) 0.21788/0.29987. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.22075/0.29561. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.21333/0.30590. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.21800/0.34296. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.21487/0.30537. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.21100/0.29852. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.20565/0.32810. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.20318/0.31434. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.20466/0.32615. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.20307/0.32148. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.20175/0.30768. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.19607/0.28407. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.19333/0.30551. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.19858/0.31187. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.20207/0.29508. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.19551/0.31918. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.18932/0.29483. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.19020/0.32567. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.18427/0.30905. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.18099/0.30532. Took 0.15 sec\n",
      "Epoch 62, Loss(train/val) 0.18726/0.30278. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.19008/0.32439. Took 0.15 sec\n",
      "Epoch 64, Loss(train/val) 0.17898/0.29565. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.18762/0.32046. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.18111/0.30838. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.17845/0.31134. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.17962/0.32917. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.18608/0.30876. Took 0.15 sec\n",
      "Epoch 70, Loss(train/val) 0.18036/0.30557. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.17380/0.31293. Took 0.17 sec\n",
      "Epoch 72, Loss(train/val) 0.17426/0.31721. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.16731/0.30338. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.16094/0.31137. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) 0.16414/0.29166. Took 0.15 sec\n",
      "Epoch 76, Loss(train/val) 0.16867/0.30988. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.16622/0.29283. Took 0.18 sec\n",
      "Epoch 78, Loss(train/val) 0.15981/0.29321. Took 0.14 sec\n",
      "Epoch 79, Loss(train/val) 0.16900/0.30051. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.15946/0.32891. Took 0.15 sec\n",
      "Epoch 81, Loss(train/val) 0.16840/0.29219. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.15535/0.29717. Took 0.15 sec\n",
      "Epoch 83, Loss(train/val) 0.16107/0.30426. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.15778/0.31916. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.15717/0.29956. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.15531/0.30203. Took 0.18 sec\n",
      "Epoch 87, Loss(train/val) 0.14311/0.32477. Took 0.17 sec\n",
      "Epoch 88, Loss(train/val) 0.14605/0.31389. Took 0.15 sec\n",
      "Epoch 89, Loss(train/val) 0.14924/0.29932. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.15234/0.31860. Took 0.15 sec\n",
      "Epoch 91, Loss(train/val) 0.14544/0.31549. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.14657/0.32368. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.14846/0.31567. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.14182/0.30438. Took 0.17 sec\n",
      "Epoch 95, Loss(train/val) 0.14156/0.30791. Took 0.15 sec\n",
      "Epoch 96, Loss(train/val) 0.13419/0.29298. Took 0.14 sec\n",
      "Epoch 97, Loss(train/val) 0.14142/0.29187. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.14723/0.31488. Took 0.15 sec\n",
      "Epoch 99, Loss(train/val) 0.13419/0.28699. Took 0.14 sec\n",
      "ACC: 0.65625, MCC: 0.30536993950476427\n",
      "Epoch 0, Loss(train/val) 0.49311/0.47846. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.47576/0.44522. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.44597/0.40608. Took 0.15 sec\n",
      "Epoch 3, Loss(train/val) 0.41294/0.37968. Took 0.20 sec\n",
      "Epoch 4, Loss(train/val) 0.39586/0.37453. Took 0.17 sec\n",
      "Epoch 5, Loss(train/val) 0.38327/0.37707. Took 0.19 sec\n",
      "Epoch 6, Loss(train/val) 0.37606/0.38635. Took 0.16 sec\n",
      "Epoch 7, Loss(train/val) 0.36766/0.40122. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.35989/0.37504. Took 0.16 sec\n",
      "Epoch 9, Loss(train/val) 0.35550/0.38623. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.34710/0.37929. Took 0.16 sec\n",
      "Epoch 11, Loss(train/val) 0.33817/0.38702. Took 0.17 sec\n",
      "Epoch 12, Loss(train/val) 0.32934/0.38799. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.32187/0.36932. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.31508/0.35648. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.30311/0.36098. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.29128/0.34823. Took 0.16 sec\n",
      "Epoch 17, Loss(train/val) 0.29416/0.31799. Took 0.16 sec\n",
      "Epoch 18, Loss(train/val) 0.28924/0.32961. Took 0.16 sec\n",
      "Epoch 19, Loss(train/val) 0.28489/0.31365. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.27799/0.31240. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.27369/0.32718. Took 0.16 sec\n",
      "Epoch 22, Loss(train/val) 0.26685/0.30989. Took 0.15 sec\n",
      "Epoch 23, Loss(train/val) 0.25713/0.29698. Took 0.17 sec\n",
      "Epoch 24, Loss(train/val) 0.25839/0.32902. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.25278/0.32053. Took 0.18 sec\n",
      "Epoch 26, Loss(train/val) 0.24475/0.30677. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.24830/0.31134. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.24652/0.30970. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.23999/0.31726. Took 0.16 sec\n",
      "Epoch 30, Loss(train/val) 0.24537/0.30668. Took 0.16 sec\n",
      "Epoch 31, Loss(train/val) 0.23407/0.30665. Took 0.16 sec\n",
      "Epoch 32, Loss(train/val) 0.22898/0.31424. Took 0.17 sec\n",
      "Epoch 33, Loss(train/val) 0.23180/0.30158. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.22697/0.31168. Took 0.17 sec\n",
      "Epoch 35, Loss(train/val) 0.22438/0.30299. Took 0.19 sec\n",
      "Epoch 36, Loss(train/val) 0.22650/0.30529. Took 0.16 sec\n",
      "Epoch 37, Loss(train/val) 0.22798/0.32371. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.22794/0.31002. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.21947/0.31716. Took 0.15 sec\n",
      "Epoch 40, Loss(train/val) 0.22148/0.30372. Took 0.15 sec\n",
      "Epoch 41, Loss(train/val) 0.21041/0.31317. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.20708/0.32603. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.20271/0.32645. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.20027/0.31355. Took 0.15 sec\n",
      "Epoch 45, Loss(train/val) 0.20201/0.33954. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.20096/0.31175. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.20007/0.33320. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.20138/0.32390. Took 0.15 sec\n",
      "Epoch 49, Loss(train/val) 0.20392/0.32159. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.19277/0.33142. Took 0.15 sec\n",
      "Epoch 51, Loss(train/val) 0.18323/0.33713. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.19525/0.32350. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) 0.18726/0.33534. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.18538/0.31195. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.17750/0.33545. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.16895/0.33326. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.17736/0.33634. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.18616/0.33625. Took 0.15 sec\n",
      "Epoch 59, Loss(train/val) 0.18819/0.32907. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.17410/0.35585. Took 0.15 sec\n",
      "Epoch 61, Loss(train/val) 0.17079/0.35733. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.17335/0.34411. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.17531/0.33909. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.16717/0.35293. Took 0.18 sec\n",
      "Epoch 65, Loss(train/val) 0.16397/0.34130. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.16356/0.34570. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) 0.15949/0.34910. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.15319/0.34846. Took 0.15 sec\n",
      "Epoch 69, Loss(train/val) 0.15448/0.35841. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.15869/0.36004. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.15386/0.35367. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.16006/0.37514. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.15015/0.34359. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.15174/0.37240. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.15307/0.36115. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.14570/0.36757. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.14153/0.36356. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.14320/0.36659. Took 0.14 sec\n",
      "Epoch 79, Loss(train/val) 0.14193/0.37650. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.14001/0.36688. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.13639/0.37942. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.14022/0.37431. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) 0.13283/0.35128. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.13576/0.35433. Took 0.15 sec\n",
      "Epoch 85, Loss(train/val) 0.13376/0.36811. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.14064/0.34647. Took 0.15 sec\n",
      "Epoch 87, Loss(train/val) 0.13381/0.36562. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.13550/0.36009. Took 0.14 sec\n",
      "Epoch 89, Loss(train/val) 0.12915/0.35544. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.13174/0.37570. Took 0.15 sec\n",
      "Epoch 91, Loss(train/val) 0.12978/0.37749. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.13147/0.38194. Took 0.15 sec\n",
      "Epoch 93, Loss(train/val) 0.13170/0.37633. Took 0.15 sec\n",
      "Epoch 94, Loss(train/val) 0.12919/0.37591. Took 0.18 sec\n",
      "Epoch 95, Loss(train/val) 0.13257/0.39512. Took 0.15 sec\n",
      "Epoch 96, Loss(train/val) 0.12515/0.38387. Took 0.14 sec\n",
      "Epoch 97, Loss(train/val) 0.12200/0.37065. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.12576/0.36798. Took 0.15 sec\n",
      "Epoch 99, Loss(train/val) 0.12142/0.38988. Took 0.13 sec\n",
      "ACC: 0.609375, MCC: 0.21489596171766712\n",
      "Epoch 0, Loss(train/val) 0.49655/0.49034. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.48424/0.47408. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.46343/0.44808. Took 0.17 sec\n",
      "Epoch 3, Loss(train/val) 0.43058/0.41471. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.40283/0.39291. Took 0.15 sec\n",
      "Epoch 5, Loss(train/val) 0.38357/0.40519. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.37441/0.41020. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.36404/0.38230. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.35892/0.41223. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.35114/0.40338. Took 0.15 sec\n",
      "Epoch 10, Loss(train/val) 0.34969/0.39895. Took 0.15 sec\n",
      "Epoch 11, Loss(train/val) 0.34272/0.38457. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.33786/0.40322. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.33682/0.35171. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.33444/0.40388. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.33871/0.37643. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.33182/0.39124. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.32910/0.35315. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.32156/0.40341. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.32208/0.35450. Took 0.16 sec\n",
      "Epoch 20, Loss(train/val) 0.31275/0.38198. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.31023/0.36844. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.30821/0.32111. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.30416/0.36442. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.30078/0.31448. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.29519/0.31447. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.28801/0.32337. Took 0.15 sec\n",
      "Epoch 27, Loss(train/val) 0.29117/0.33357. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.29061/0.31072. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.28605/0.31747. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.27440/0.34096. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.27258/0.32007. Took 0.16 sec\n",
      "Epoch 32, Loss(train/val) 0.26631/0.31644. Took 0.17 sec\n",
      "Epoch 33, Loss(train/val) 0.25976/0.29668. Took 0.16 sec\n",
      "Epoch 34, Loss(train/val) 0.25871/0.30072. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.24907/0.31165. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.24904/0.30331. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.25208/0.29519. Took 0.16 sec\n",
      "Epoch 38, Loss(train/val) 0.25078/0.30400. Took 0.15 sec\n",
      "Epoch 39, Loss(train/val) 0.25063/0.32196. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.24654/0.29648. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.24256/0.31001. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.23828/0.29491. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.22955/0.28439. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.21677/0.29693. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.21861/0.32208. Took 0.15 sec\n",
      "Epoch 46, Loss(train/val) 0.21700/0.29061. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.21941/0.29495. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.22458/0.29157. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.21061/0.30058. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.21697/0.31446. Took 0.14 sec\n",
      "Epoch 51, Loss(train/val) 0.21426/0.29300. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.21816/0.29356. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.20163/0.28221. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.21051/0.29458. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.19693/0.28730. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.20552/0.30037. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.19673/0.31816. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.19465/0.33653. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.19207/0.31429. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.19903/0.30244. Took 0.14 sec\n",
      "Epoch 61, Loss(train/val) 0.20224/0.29711. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.19449/0.31246. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.18682/0.33303. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.19913/0.29022. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.19227/0.30638. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.18853/0.33479. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.18861/0.35105. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.17803/0.29973. Took 0.14 sec\n",
      "Epoch 69, Loss(train/val) 0.18680/0.32880. Took 0.15 sec\n",
      "Epoch 70, Loss(train/val) 0.18064/0.31915. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.17827/0.32343. Took 0.15 sec\n",
      "Epoch 72, Loss(train/val) 0.17782/0.31176. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.17449/0.30947. Took 0.15 sec\n",
      "Epoch 74, Loss(train/val) 0.18360/0.32599. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.18997/0.32862. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.17641/0.31503. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.17827/0.35129. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.18188/0.33502. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.17357/0.33049. Took 0.15 sec\n",
      "Epoch 80, Loss(train/val) 0.17507/0.34900. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.17470/0.31922. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.17549/0.35107. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.17615/0.33633. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.16287/0.33240. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.17278/0.35534. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.16884/0.33924. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.17211/0.33063. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.16953/0.32462. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.16765/0.35349. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.17021/0.34285. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.16017/0.34824. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.16228/0.31760. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.16183/0.32609. Took 0.15 sec\n",
      "Epoch 94, Loss(train/val) 0.16370/0.31663. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.16362/0.32926. Took 0.15 sec\n",
      "Epoch 96, Loss(train/val) 0.17235/0.33787. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.16541/0.36097. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.16739/0.34772. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.15604/0.34176. Took 0.15 sec\n",
      "ACC: 0.625, MCC: 0.2631806779839076\n",
      "Epoch 0, Loss(train/val) 0.49706/0.49603. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.48387/0.48700. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.45899/0.46722. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.41731/0.45433. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.39042/0.45793. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.38014/0.44043. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.36819/0.42816. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.35717/0.42379. Took 0.15 sec\n",
      "Epoch 8, Loss(train/val) 0.35482/0.42764. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.34605/0.42480. Took 0.16 sec\n",
      "Epoch 10, Loss(train/val) 0.33668/0.40866. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.33552/0.42855. Took 0.15 sec\n",
      "Epoch 12, Loss(train/val) 0.32421/0.42101. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.31633/0.38268. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.31417/0.38982. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.31313/0.39297. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.30013/0.38236. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.30106/0.37455. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.29871/0.37738. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.29355/0.37455. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.29027/0.39614. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.28949/0.39919. Took 0.16 sec\n",
      "Epoch 22, Loss(train/val) 0.28089/0.38075. Took 0.15 sec\n",
      "Epoch 23, Loss(train/val) 0.28061/0.41345. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.28244/0.39647. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.27964/0.39575. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.26769/0.38844. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.27389/0.39420. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.26644/0.39831. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.25913/0.39326. Took 0.17 sec\n",
      "Epoch 30, Loss(train/val) 0.26235/0.39194. Took 0.16 sec\n",
      "Epoch 31, Loss(train/val) 0.27083/0.39048. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.25577/0.39323. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.25015/0.39841. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.25246/0.39641. Took 0.16 sec\n",
      "Epoch 35, Loss(train/val) 0.26080/0.39091. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.25119/0.39992. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.24297/0.39394. Took 0.16 sec\n",
      "Epoch 38, Loss(train/val) 0.24975/0.38877. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.24868/0.39039. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.23661/0.38344. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.23117/0.39027. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.24460/0.40328. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.24684/0.37663. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.25175/0.39252. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.23526/0.40382. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.23913/0.40052. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.23041/0.40063. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.22737/0.39605. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.22970/0.39509. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.22058/0.36807. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.22432/0.40790. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.23942/0.40359. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.23504/0.39834. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.20825/0.40031. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.21599/0.40685. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.21737/0.40558. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.21386/0.42174. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.21043/0.41100. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.21445/0.41334. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.20695/0.41940. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.22419/0.41073. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.20399/0.40546. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.19695/0.38958. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.20928/0.40880. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.20283/0.41503. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.19851/0.40064. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.19752/0.40921. Took 0.15 sec\n",
      "Epoch 68, Loss(train/val) 0.19402/0.39884. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.17903/0.39684. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.18340/0.39646. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.20002/0.38892. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.18684/0.37005. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.19818/0.41632. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.18368/0.38159. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.19814/0.38895. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.17649/0.38194. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.17919/0.38269. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.18033/0.40485. Took 0.14 sec\n",
      "Epoch 79, Loss(train/val) 0.17385/0.39361. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.17209/0.41545. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.16922/0.38716. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.17330/0.40077. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.16857/0.41961. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.16587/0.38868. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.16710/0.38553. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.16598/0.41500. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.17796/0.39101. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.16445/0.41891. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.16917/0.41827. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.16264/0.39728. Took 0.14 sec\n",
      "Epoch 91, Loss(train/val) 0.15672/0.40457. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.16632/0.40902. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.17216/0.39843. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.16105/0.41592. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.15913/0.40801. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.15534/0.40657. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.15613/0.39956. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.14531/0.40819. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.15378/0.41110. Took 0.13 sec\n",
      "ACC: 0.71875, MCC: 0.4879500364742666\n",
      "Epoch 0, Loss(train/val) 0.49488/0.47659. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.47952/0.44569. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.45429/0.40353. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.41906/0.37315. Took 0.15 sec\n",
      "Epoch 4, Loss(train/val) 0.39647/0.35376. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.38508/0.34640. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.37397/0.33723. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.37199/0.32915. Took 0.15 sec\n",
      "Epoch 8, Loss(train/val) 0.36812/0.33086. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.35299/0.32999. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.34941/0.31167. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.34078/0.29886. Took 0.16 sec\n",
      "Epoch 12, Loss(train/val) 0.34115/0.30610. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.33498/0.28929. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.33432/0.29615. Took 0.15 sec\n",
      "Epoch 15, Loss(train/val) 0.33291/0.27518. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.31417/0.28255. Took 0.16 sec\n",
      "Epoch 17, Loss(train/val) 0.32064/0.25521. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.31793/0.29439. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.30815/0.27209. Took 0.15 sec\n",
      "Epoch 20, Loss(train/val) 0.29657/0.25077. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.29643/0.25684. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.29249/0.24935. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.28158/0.21476. Took 0.16 sec\n",
      "Epoch 24, Loss(train/val) 0.28106/0.24508. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.28076/0.24135. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.26874/0.23692. Took 0.13 sec\n",
      "Epoch 27, Loss(train/val) 0.26879/0.23069. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.25999/0.24486. Took 0.13 sec\n",
      "Epoch 29, Loss(train/val) 0.25465/0.22935. Took 0.16 sec\n",
      "Epoch 30, Loss(train/val) 0.25244/0.22361. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.25097/0.22058. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.25621/0.21226. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.24335/0.22400. Took 0.16 sec\n",
      "Epoch 34, Loss(train/val) 0.24488/0.21601. Took 0.16 sec\n",
      "Epoch 35, Loss(train/val) 0.25622/0.19848. Took 0.15 sec\n",
      "Epoch 36, Loss(train/val) 0.27843/0.24285. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.24382/0.22883. Took 0.16 sec\n",
      "Epoch 38, Loss(train/val) 0.24693/0.22621. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.24228/0.24052. Took 0.15 sec\n",
      "Epoch 40, Loss(train/val) 0.22970/0.24962. Took 0.15 sec\n",
      "Epoch 41, Loss(train/val) 0.24450/0.25331. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.23338/0.29222. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.22849/0.25650. Took 0.15 sec\n",
      "Epoch 44, Loss(train/val) 0.21925/0.21932. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) 0.21626/0.22791. Took 0.15 sec\n",
      "Epoch 46, Loss(train/val) 0.21255/0.21425. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.20932/0.22688. Took 0.15 sec\n",
      "Epoch 48, Loss(train/val) 0.20663/0.24027. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.20767/0.23864. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.20988/0.22103. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.20139/0.25302. Took 0.15 sec\n",
      "Epoch 52, Loss(train/val) 0.20971/0.24067. Took 0.16 sec\n",
      "Epoch 53, Loss(train/val) 0.20686/0.21017. Took 0.17 sec\n",
      "Epoch 54, Loss(train/val) 0.19346/0.23077. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.19708/0.21626. Took 0.15 sec\n",
      "Epoch 56, Loss(train/val) 0.19607/0.25215. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.19028/0.20401. Took 0.15 sec\n",
      "Epoch 58, Loss(train/val) 0.18832/0.25925. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.19708/0.21704. Took 0.15 sec\n",
      "Epoch 60, Loss(train/val) 0.19093/0.20203. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.18684/0.18545. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.19227/0.20564. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.18846/0.23084. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.18554/0.22650. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.17856/0.23065. Took 0.15 sec\n",
      "Epoch 66, Loss(train/val) 0.17486/0.21998. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) 0.17755/0.21571. Took 0.16 sec\n",
      "Epoch 68, Loss(train/val) 0.16474/0.21059. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.16833/0.22817. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.15957/0.21144. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.16376/0.20707. Took 0.15 sec\n",
      "Epoch 72, Loss(train/val) 0.16327/0.20379. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.17361/0.22960. Took 0.15 sec\n",
      "Epoch 74, Loss(train/val) 0.16844/0.23999. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) 0.16061/0.24116. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.16010/0.21908. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.16238/0.22847. Took 0.15 sec\n",
      "Epoch 78, Loss(train/val) 0.15652/0.21992. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.15485/0.23037. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.15678/0.21352. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.14310/0.21206. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.15616/0.23555. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.15254/0.21651. Took 0.15 sec\n",
      "Epoch 84, Loss(train/val) 0.13829/0.21940. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.14191/0.22913. Took 0.15 sec\n",
      "Epoch 86, Loss(train/val) 0.13917/0.23986. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.14041/0.23780. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.13733/0.22082. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.14133/0.24216. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.13941/0.22194. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.14197/0.21682. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.13325/0.20586. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.14433/0.24597. Took 0.15 sec\n",
      "Epoch 94, Loss(train/val) 0.13129/0.26226. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.13872/0.21917. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.12865/0.22005. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.13983/0.21752. Took 0.15 sec\n",
      "Epoch 98, Loss(train/val) 0.13603/0.22612. Took 0.14 sec\n",
      "Epoch 99, Loss(train/val) 0.12492/0.22172. Took 0.14 sec\n",
      "ACC: 0.65625, MCC: 0.31159465034477757\n",
      "Epoch 0, Loss(train/val) 0.49836/0.49100. Took 0.16 sec\n",
      "Epoch 1, Loss(train/val) 0.48373/0.47289. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.45896/0.43068. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.42217/0.39185. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.39904/0.37566. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.38024/0.36272. Took 0.15 sec\n",
      "Epoch 6, Loss(train/val) 0.36819/0.34879. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.35980/0.33355. Took 0.15 sec\n",
      "Epoch 8, Loss(train/val) 0.34725/0.32353. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.34030/0.33728. Took 0.15 sec\n",
      "Epoch 10, Loss(train/val) 0.33181/0.36187. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.32236/0.38529. Took 0.16 sec\n",
      "Epoch 12, Loss(train/val) 0.31811/0.34489. Took 0.16 sec\n",
      "Epoch 13, Loss(train/val) 0.31055/0.33337. Took 0.16 sec\n",
      "Epoch 14, Loss(train/val) 0.31503/0.35417. Took 0.15 sec\n",
      "Epoch 15, Loss(train/val) 0.29685/0.34674. Took 0.19 sec\n",
      "Epoch 16, Loss(train/val) 0.29897/0.37615. Took 0.17 sec\n",
      "Epoch 17, Loss(train/val) 0.30111/0.39063. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.28976/0.37726. Took 0.15 sec\n",
      "Epoch 19, Loss(train/val) 0.29261/0.37824. Took 0.16 sec\n",
      "Epoch 20, Loss(train/val) 0.28229/0.32204. Took 0.16 sec\n",
      "Epoch 21, Loss(train/val) 0.27978/0.32861. Took 0.17 sec\n",
      "Epoch 22, Loss(train/val) 0.27974/0.39114. Took 0.15 sec\n",
      "Epoch 23, Loss(train/val) 0.27382/0.32397. Took 0.16 sec\n",
      "Epoch 24, Loss(train/val) 0.27297/0.36620. Took 0.15 sec\n",
      "Epoch 25, Loss(train/val) 0.26876/0.36389. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.25167/0.35025. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.26436/0.33453. Took 0.16 sec\n",
      "Epoch 28, Loss(train/val) 0.26553/0.32405. Took 0.13 sec\n",
      "Epoch 29, Loss(train/val) 0.24986/0.34839. Took 0.16 sec\n",
      "Epoch 30, Loss(train/val) 0.25020/0.32391. Took 0.16 sec\n",
      "Epoch 31, Loss(train/val) 0.25229/0.39757. Took 0.20 sec\n",
      "Epoch 32, Loss(train/val) 0.25019/0.34114. Took 0.17 sec\n",
      "Epoch 33, Loss(train/val) 0.24922/0.32955. Took 0.16 sec\n",
      "Epoch 34, Loss(train/val) 0.23124/0.32763. Took 0.17 sec\n",
      "Epoch 35, Loss(train/val) 0.23855/0.35030. Took 0.21 sec\n",
      "Epoch 36, Loss(train/val) 0.21745/0.33694. Took 0.16 sec\n",
      "Epoch 37, Loss(train/val) 0.23173/0.33145. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.22631/0.35628. Took 0.18 sec\n",
      "Epoch 39, Loss(train/val) 0.22153/0.35873. Took 0.15 sec\n",
      "Epoch 40, Loss(train/val) 0.21975/0.37850. Took 0.15 sec\n",
      "Epoch 41, Loss(train/val) 0.21320/0.34773. Took 0.16 sec\n",
      "Epoch 42, Loss(train/val) 0.21078/0.33336. Took 0.15 sec\n",
      "Epoch 43, Loss(train/val) 0.22035/0.33405. Took 0.15 sec\n",
      "Epoch 44, Loss(train/val) 0.20963/0.32988. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.21036/0.37063. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.21342/0.35326. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.21413/0.35192. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.21007/0.33680. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.21383/0.33993. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.20424/0.32963. Took 0.14 sec\n",
      "Epoch 51, Loss(train/val) 0.20105/0.32119. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.21017/0.30338. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) 0.19922/0.33009. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.19478/0.32538. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.19636/0.32961. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.19881/0.31490. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.19473/0.32601. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.19626/0.29402. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.19512/0.29852. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.18722/0.32642. Took 0.14 sec\n",
      "Epoch 61, Loss(train/val) 0.18099/0.30405. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.18232/0.29491. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.17557/0.28457. Took 0.17 sec\n",
      "Epoch 64, Loss(train/val) 0.18310/0.28951. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.18037/0.29036. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.18188/0.29663. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.18270/0.27644. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.18683/0.31926. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.18167/0.32918. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.17846/0.33164. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.17281/0.28481. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.17039/0.34123. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.18126/0.33796. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.16874/0.31397. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) 0.17434/0.31713. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.16573/0.35605. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.16496/0.32886. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.16296/0.30275. Took 0.14 sec\n",
      "Epoch 79, Loss(train/val) 0.17040/0.35205. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.16293/0.29039. Took 0.14 sec\n",
      "Epoch 81, Loss(train/val) 0.17453/0.32987. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.15528/0.31814. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.15994/0.30309. Took 0.17 sec\n",
      "Epoch 84, Loss(train/val) 0.15494/0.32606. Took 0.16 sec\n",
      "Epoch 85, Loss(train/val) 0.16612/0.29911. Took 0.15 sec\n",
      "Epoch 86, Loss(train/val) 0.14968/0.31075. Took 0.15 sec\n",
      "Epoch 87, Loss(train/val) 0.14622/0.29055. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.16699/0.33165. Took 0.14 sec\n",
      "Epoch 89, Loss(train/val) 0.16150/0.31845. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.14625/0.33955. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.15724/0.32192. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.14782/0.31308. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.15350/0.32412. Took 0.15 sec\n",
      "Epoch 94, Loss(train/val) 0.14869/0.28998. Took 0.14 sec\n",
      "Epoch 95, Loss(train/val) 0.15279/0.28419. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.14216/0.28339. Took 0.14 sec\n",
      "Epoch 97, Loss(train/val) 0.14973/0.31279. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.14304/0.32909. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.14705/0.33824. Took 0.14 sec\n",
      "ACC: 0.6875, MCC: 0.36073955268291136\n",
      "Epoch 0, Loss(train/val) 0.48971/0.47225. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.46851/0.43457. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.44450/0.41437. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.41171/0.42925. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.39045/0.41010. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.37380/0.38753. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.36128/0.37764. Took 0.19 sec\n",
      "Epoch 7, Loss(train/val) 0.34296/0.38912. Took 0.15 sec\n",
      "Epoch 8, Loss(train/val) 0.33816/0.36000. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.31833/0.38814. Took 0.16 sec\n",
      "Epoch 10, Loss(train/val) 0.31024/0.37867. Took 0.15 sec\n",
      "Epoch 11, Loss(train/val) 0.31051/0.35803. Took 0.17 sec\n",
      "Epoch 12, Loss(train/val) 0.30415/0.34121. Took 0.16 sec\n",
      "Epoch 13, Loss(train/val) 0.30962/0.27710. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.29922/0.35758. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.28929/0.34648. Took 0.17 sec\n",
      "Epoch 16, Loss(train/val) 0.27929/0.34066. Took 0.18 sec\n",
      "Epoch 17, Loss(train/val) 0.27699/0.37272. Took 0.17 sec\n",
      "Epoch 18, Loss(train/val) 0.27342/0.37140. Took 0.19 sec\n",
      "Epoch 19, Loss(train/val) 0.26637/0.34906. Took 0.16 sec\n",
      "Epoch 20, Loss(train/val) 0.26611/0.36208. Took 0.15 sec\n",
      "Epoch 21, Loss(train/val) 0.25894/0.38103. Took 0.16 sec\n",
      "Epoch 22, Loss(train/val) 0.25571/0.35667. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.24714/0.34926. Took 0.16 sec\n",
      "Epoch 24, Loss(train/val) 0.24924/0.37035. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.24918/0.36110. Took 0.19 sec\n",
      "Epoch 26, Loss(train/val) 0.24949/0.38553. Took 0.17 sec\n",
      "Epoch 27, Loss(train/val) 0.23868/0.36667. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.23632/0.36439. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.23141/0.36583. Took 0.17 sec\n",
      "Epoch 30, Loss(train/val) 0.22133/0.35587. Took 0.17 sec\n",
      "Epoch 31, Loss(train/val) 0.22127/0.35939. Took 0.20 sec\n",
      "Epoch 32, Loss(train/val) 0.22366/0.36495. Took 0.18 sec\n",
      "Epoch 33, Loss(train/val) 0.21568/0.37503. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.21105/0.38831. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.21779/0.36249. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.21048/0.35270. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.20746/0.35655. Took 0.15 sec\n",
      "Epoch 38, Loss(train/val) 0.20573/0.36527. Took 0.15 sec\n",
      "Epoch 39, Loss(train/val) 0.19713/0.36938. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.19539/0.35770. Took 0.15 sec\n",
      "Epoch 41, Loss(train/val) 0.20422/0.38012. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.20497/0.38603. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.20192/0.39197. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.19818/0.36978. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.18310/0.37721. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.18470/0.39065. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.19010/0.36677. Took 0.15 sec\n",
      "Epoch 48, Loss(train/val) 0.18913/0.39279. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.18482/0.36443. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.18537/0.37196. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.16461/0.38448. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.16532/0.38522. Took 0.17 sec\n",
      "Epoch 53, Loss(train/val) 0.17308/0.38893. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.18144/0.37563. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.15851/0.36404. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.17013/0.35599. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.16146/0.35836. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.16621/0.35566. Took 0.14 sec\n",
      "Epoch 59, Loss(train/val) 0.15802/0.36792. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.15931/0.37957. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.15415/0.36387. Took 0.17 sec\n",
      "Epoch 62, Loss(train/val) 0.15990/0.36390. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.16131/0.36235. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.14829/0.35496. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.15117/0.36016. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.14709/0.37088. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.14922/0.36084. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.15802/0.33971. Took 0.14 sec\n",
      "Epoch 69, Loss(train/val) 0.15561/0.36321. Took 0.16 sec\n",
      "Epoch 70, Loss(train/val) 0.15134/0.35412. Took 0.15 sec\n",
      "Epoch 71, Loss(train/val) 0.15072/0.36602. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.13928/0.36485. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.14414/0.36098. Took 0.15 sec\n",
      "Epoch 74, Loss(train/val) 0.14505/0.33703. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) 0.14818/0.35747. Took 0.15 sec\n",
      "Epoch 76, Loss(train/val) 0.14124/0.35231. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.13587/0.37110. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.12786/0.35269. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.13384/0.34956. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.13527/0.37416. Took 0.14 sec\n",
      "Epoch 81, Loss(train/val) 0.12556/0.36899. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.13310/0.37898. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.13053/0.36549. Took 0.18 sec\n",
      "Epoch 84, Loss(train/val) 0.13485/0.36759. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.13570/0.34734. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.12676/0.38301. Took 0.15 sec\n",
      "Epoch 87, Loss(train/val) 0.13711/0.35661. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.13084/0.36490. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.12554/0.36190. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.12134/0.33614. Took 0.14 sec\n",
      "Epoch 91, Loss(train/val) 0.11955/0.34396. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.12469/0.31639. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.11890/0.33855. Took 0.15 sec\n",
      "Epoch 94, Loss(train/val) 0.11994/0.34842. Took 0.15 sec\n",
      "Epoch 95, Loss(train/val) 0.12387/0.35283. Took 0.15 sec\n",
      "Epoch 96, Loss(train/val) 0.12163/0.33508. Took 0.14 sec\n",
      "Epoch 97, Loss(train/val) 0.12291/0.32946. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.12031/0.36190. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.11869/0.35757. Took 0.13 sec\n",
      "ACC: 0.5625, MCC: 0.13156218570112832\n",
      "Epoch 0, Loss(train/val) 0.49039/0.49260. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.46718/0.47746. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.43402/0.45435. Took 0.15 sec\n",
      "Epoch 3, Loss(train/val) 0.40385/0.43748. Took 0.16 sec\n",
      "Epoch 4, Loss(train/val) 0.38421/0.43233. Took 0.15 sec\n",
      "Epoch 5, Loss(train/val) 0.37128/0.43260. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.35392/0.41129. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.33960/0.44667. Took 0.15 sec\n",
      "Epoch 8, Loss(train/val) 0.32769/0.45003. Took 0.15 sec\n",
      "Epoch 9, Loss(train/val) 0.31348/0.45581. Took 0.16 sec\n",
      "Epoch 10, Loss(train/val) 0.30363/0.42719. Took 0.15 sec\n",
      "Epoch 11, Loss(train/val) 0.29472/0.42631. Took 0.16 sec\n",
      "Epoch 12, Loss(train/val) 0.29925/0.46082. Took 0.18 sec\n",
      "Epoch 13, Loss(train/val) 0.29885/0.44883. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.29050/0.43119. Took 0.15 sec\n",
      "Epoch 15, Loss(train/val) 0.28909/0.44946. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.29166/0.42859. Took 0.15 sec\n",
      "Epoch 17, Loss(train/val) 0.28774/0.44916. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.28709/0.44928. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.27296/0.46748. Took 0.15 sec\n",
      "Epoch 20, Loss(train/val) 0.27361/0.46151. Took 0.15 sec\n",
      "Epoch 21, Loss(train/val) 0.26119/0.45867. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.25649/0.45065. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.25598/0.45246. Took 0.16 sec\n",
      "Epoch 24, Loss(train/val) 0.25260/0.44966. Took 0.16 sec\n",
      "Epoch 25, Loss(train/val) 0.24972/0.44033. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.25806/0.44951. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.24985/0.41562. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.24859/0.38697. Took 0.16 sec\n",
      "Epoch 29, Loss(train/val) 0.25448/0.39352. Took 0.16 sec\n",
      "Epoch 30, Loss(train/val) 0.24498/0.40516. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.24317/0.40773. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.24484/0.42814. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.23627/0.40473. Took 0.16 sec\n",
      "Epoch 34, Loss(train/val) 0.23671/0.39664. Took 0.16 sec\n",
      "Epoch 35, Loss(train/val) 0.23325/0.40778. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.23180/0.38819. Took 0.17 sec\n",
      "Epoch 37, Loss(train/val) 0.23622/0.40960. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.22007/0.39368. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.23887/0.38072. Took 0.15 sec\n",
      "Epoch 40, Loss(train/val) 0.22551/0.43196. Took 0.17 sec\n",
      "Epoch 41, Loss(train/val) 0.21749/0.41427. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.22163/0.37929. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.22002/0.36456. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.21733/0.42894. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) 0.21777/0.40279. Took 0.15 sec\n",
      "Epoch 46, Loss(train/val) 0.21255/0.37761. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.21693/0.42241. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.19727/0.42595. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.19487/0.39582. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.20343/0.37459. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.19466/0.41220. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.19491/0.41578. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.18362/0.40040. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.18744/0.39135. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.18642/0.37146. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.18972/0.36519. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.19082/0.39091. Took 0.15 sec\n",
      "Epoch 58, Loss(train/val) 0.18251/0.36469. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.17847/0.36337. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.17939/0.35137. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.17118/0.36492. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.17280/0.35326. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.16709/0.35892. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.16433/0.38033. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.17298/0.37722. Took 0.15 sec\n",
      "Epoch 66, Loss(train/val) 0.16729/0.37044. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.15578/0.37118. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.15740/0.35518. Took 0.14 sec\n",
      "Epoch 69, Loss(train/val) 0.17002/0.36541. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.15392/0.36868. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.15157/0.37287. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.14841/0.39627. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.15009/0.39274. Took 0.15 sec\n",
      "Epoch 74, Loss(train/val) 0.14754/0.39686. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.14984/0.37520. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.14877/0.37635. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.14946/0.39046. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.15524/0.38497. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.13339/0.37882. Took 0.15 sec\n",
      "Epoch 80, Loss(train/val) 0.15223/0.39118. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.13763/0.36809. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.13852/0.37846. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.14216/0.38445. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.14149/0.39185. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.14154/0.38486. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.14286/0.39133. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.13565/0.39032. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.15091/0.39316. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.13489/0.41796. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.13610/0.42701. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.13250/0.43145. Took 0.15 sec\n",
      "Epoch 92, Loss(train/val) 0.13156/0.42998. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.12748/0.42278. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.13278/0.42740. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.13136/0.41294. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.13133/0.40251. Took 0.14 sec\n",
      "Epoch 97, Loss(train/val) 0.12355/0.43162. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.11630/0.43401. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.12168/0.43498. Took 0.14 sec\n",
      "ACC: 0.625, MCC: 0.28128128128128127\n",
      "Epoch 0, Loss(train/val) 0.49165/0.48102. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.47010/0.44867. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.43940/0.40724. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.40927/0.39460. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.38899/0.38456. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.37608/0.37510. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.36191/0.35490. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.35651/0.45630. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.33690/0.39723. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.33760/0.40737. Took 0.15 sec\n",
      "Epoch 10, Loss(train/val) 0.32626/0.47822. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.33036/0.41202. Took 0.15 sec\n",
      "Epoch 12, Loss(train/val) 0.32253/0.35688. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.32059/0.33068. Took 0.16 sec\n",
      "Epoch 14, Loss(train/val) 0.31366/0.39316. Took 0.15 sec\n",
      "Epoch 15, Loss(train/val) 0.30825/0.38625. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.31216/0.40223. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.29527/0.35101. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.29449/0.40374. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.28671/0.42740. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.27878/0.39049. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.26833/0.49212. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.27125/0.42957. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.27195/0.37227. Took 0.16 sec\n",
      "Epoch 24, Loss(train/val) 0.25899/0.36644. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.27627/0.39809. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.26499/0.36145. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.25713/0.37301. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.26044/0.38375. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.25537/0.36800. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.24702/0.38614. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.24693/0.38154. Took 0.16 sec\n",
      "Epoch 32, Loss(train/val) 0.24766/0.37862. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.23690/0.38105. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.23450/0.39207. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.23194/0.37518. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.22417/0.36996. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.22494/0.42211. Took 0.15 sec\n",
      "Epoch 38, Loss(train/val) 0.22136/0.40477. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.21861/0.38101. Took 0.17 sec\n",
      "Epoch 40, Loss(train/val) 0.21198/0.37477. Took 0.15 sec\n",
      "Epoch 41, Loss(train/val) 0.20230/0.39177. Took 0.15 sec\n",
      "Epoch 42, Loss(train/val) 0.21486/0.37763. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.20856/0.39118. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.19559/0.39789. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.20051/0.37658. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.20677/0.40158. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.19418/0.38991. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.19383/0.39915. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.19014/0.39494. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.17877/0.38142. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.18261/0.37835. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.17827/0.42756. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.18427/0.35573. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.17888/0.37126. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.17901/0.37682. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.18577/0.38905. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.16960/0.37994. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.17033/0.37780. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.16449/0.39439. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.16047/0.39194. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.16401/0.38542. Took 0.15 sec\n",
      "Epoch 62, Loss(train/val) 0.15654/0.38079. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.16760/0.38510. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.15063/0.39200. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.16190/0.38526. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.14646/0.36935. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.14523/0.37243. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.15148/0.36493. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.14508/0.35972. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.15712/0.34303. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.15162/0.35852. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.16246/0.37748. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.14749/0.37654. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.14810/0.34080. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.15155/0.33385. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.14232/0.35315. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.13895/0.34638. Took 0.15 sec\n",
      "Epoch 78, Loss(train/val) 0.13989/0.36638. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.13152/0.38583. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.13909/0.35258. Took 0.14 sec\n",
      "Epoch 81, Loss(train/val) 0.13183/0.34998. Took 0.15 sec\n",
      "Epoch 82, Loss(train/val) 0.12759/0.36222. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) 0.13369/0.37070. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.13073/0.33780. Took 0.17 sec\n",
      "Epoch 85, Loss(train/val) 0.12648/0.34553. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.13844/0.35156. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.12056/0.31936. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.13490/0.33116. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.13523/0.33958. Took 0.15 sec\n",
      "Epoch 90, Loss(train/val) 0.12311/0.35486. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.12747/0.32471. Took 0.15 sec\n",
      "Epoch 92, Loss(train/val) 0.12449/0.33242. Took 0.17 sec\n",
      "Epoch 93, Loss(train/val) 0.12489/0.34162. Took 0.15 sec\n",
      "Epoch 94, Loss(train/val) 0.13216/0.34195. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.12221/0.34914. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.12203/0.37048. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.12084/0.36860. Took 0.15 sec\n",
      "Epoch 98, Loss(train/val) 0.11940/0.33331. Took 0.14 sec\n",
      "Epoch 99, Loss(train/val) 0.12219/0.34085. Took 0.14 sec\n",
      "ACC: 0.671875, MCC: 0.3438507522858819\n",
      "Epoch 0, Loss(train/val) 0.49414/0.49479. Took 0.16 sec\n",
      "Epoch 1, Loss(train/val) 0.47495/0.47984. Took 0.15 sec\n",
      "Epoch 2, Loss(train/val) 0.44720/0.44060. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.40995/0.40665. Took 0.15 sec\n",
      "Epoch 4, Loss(train/val) 0.38445/0.38536. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.37193/0.37242. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.35352/0.36803. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.34634/0.36528. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.32998/0.36799. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.33477/0.36367. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.31416/0.37308. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.30843/0.36744. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.29746/0.33492. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.28972/0.34684. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.28812/0.32661. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.28410/0.31251. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.28128/0.34364. Took 0.15 sec\n",
      "Epoch 17, Loss(train/val) 0.26761/0.30827. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.27260/0.32304. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.26248/0.33394. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.27350/0.34329. Took 0.15 sec\n",
      "Epoch 21, Loss(train/val) 0.26255/0.30323. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.25088/0.31801. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.25845/0.30980. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.25588/0.32696. Took 0.15 sec\n",
      "Epoch 25, Loss(train/val) 0.25443/0.35241. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.24374/0.33298. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.24740/0.33981. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.23740/0.32055. Took 0.17 sec\n",
      "Epoch 29, Loss(train/val) 0.23930/0.28248. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.23613/0.30297. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.22730/0.30386. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.22718/0.29847. Took 0.21 sec\n",
      "Epoch 33, Loss(train/val) 0.22829/0.31517. Took 0.21 sec\n",
      "Epoch 34, Loss(train/val) 0.22037/0.29744. Took 0.18 sec\n",
      "Epoch 35, Loss(train/val) 0.21804/0.31671. Took 0.22 sec\n",
      "Epoch 36, Loss(train/val) 0.22822/0.33324. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.21420/0.29764. Took 0.16 sec\n",
      "Epoch 38, Loss(train/val) 0.21196/0.31049. Took 0.15 sec\n",
      "Epoch 39, Loss(train/val) 0.21328/0.32155. Took 0.18 sec\n",
      "Epoch 40, Loss(train/val) 0.21019/0.32904. Took 0.17 sec\n",
      "Epoch 41, Loss(train/val) 0.19974/0.31839. Took 0.15 sec\n",
      "Epoch 42, Loss(train/val) 0.20343/0.33939. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.20650/0.31897. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.20499/0.33411. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) 0.20464/0.32040. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.20365/0.30856. Took 0.15 sec\n",
      "Epoch 47, Loss(train/val) 0.19674/0.32801. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.19799/0.32108. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.18876/0.32805. Took 0.16 sec\n",
      "Epoch 50, Loss(train/val) 0.19240/0.30018. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.18741/0.31705. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.18783/0.31918. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) 0.18272/0.31165. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.18163/0.32066. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.17934/0.30374. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.18441/0.31378. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.17352/0.31620. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.17918/0.32948. Took 0.14 sec\n",
      "Epoch 59, Loss(train/val) 0.17833/0.32438. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.16847/0.30542. Took 0.14 sec\n",
      "Epoch 61, Loss(train/val) 0.17107/0.30494. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.16892/0.30881. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.16940/0.30788. Took 0.15 sec\n",
      "Epoch 64, Loss(train/val) 0.16623/0.31607. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.16773/0.31654. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.15908/0.31487. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.16379/0.31994. Took 0.15 sec\n",
      "Epoch 68, Loss(train/val) 0.16236/0.31801. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.15965/0.31609. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.16106/0.30778. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.15405/0.30574. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.15824/0.31381. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.15600/0.32260. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.15571/0.31731. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) 0.15551/0.31548. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.15214/0.31940. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.16023/0.32279. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.15123/0.30912. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.14871/0.31260. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.14881/0.31010. Took 0.15 sec\n",
      "Epoch 81, Loss(train/val) 0.14511/0.32329. Took 0.15 sec\n",
      "Epoch 82, Loss(train/val) 0.15919/0.30391. Took 0.15 sec\n",
      "Epoch 83, Loss(train/val) 0.15473/0.31874. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.15526/0.32170. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.14554/0.30016. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.13949/0.32179. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.14492/0.30240. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.14586/0.32150. Took 0.15 sec\n",
      "Epoch 89, Loss(train/val) 0.14030/0.30238. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.14156/0.30898. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.13825/0.30349. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.13564/0.31839. Took 0.15 sec\n",
      "Epoch 93, Loss(train/val) 0.14873/0.31902. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.14171/0.31487. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.14142/0.31616. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.14402/0.32636. Took 0.14 sec\n",
      "Epoch 97, Loss(train/val) 0.13792/0.32470. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.13641/0.32523. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.14902/0.33602. Took 0.13 sec\n",
      "ACC: 0.640625, MCC: 0.27286371951943134\n",
      "Epoch 0, Loss(train/val) 0.49075/0.47979. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.46885/0.44519. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.43338/0.40794. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.39533/0.39134. Took 0.15 sec\n",
      "Epoch 4, Loss(train/val) 0.37419/0.37929. Took 0.15 sec\n",
      "Epoch 5, Loss(train/val) 0.36912/0.36887. Took 0.15 sec\n",
      "Epoch 6, Loss(train/val) 0.35465/0.36776. Took 0.15 sec\n",
      "Epoch 7, Loss(train/val) 0.34864/0.36492. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.34434/0.35686. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.33230/0.35395. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.32944/0.34514. Took 0.15 sec\n",
      "Epoch 11, Loss(train/val) 0.32428/0.35161. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.31411/0.34413. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.30987/0.33836. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.30199/0.33079. Took 0.15 sec\n",
      "Epoch 15, Loss(train/val) 0.29574/0.33553. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.28425/0.33224. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.28119/0.32460. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.27445/0.34042. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.25804/0.36040. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.25543/0.31736. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.25271/0.33786. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.26070/0.31746. Took 0.15 sec\n",
      "Epoch 23, Loss(train/val) 0.24530/0.32100. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.23329/0.31832. Took 0.15 sec\n",
      "Epoch 25, Loss(train/val) 0.23994/0.32911. Took 0.16 sec\n",
      "Epoch 26, Loss(train/val) 0.22159/0.31049. Took 0.17 sec\n",
      "Epoch 27, Loss(train/val) 0.23283/0.32850. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.23007/0.30760. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.22482/0.32261. Took 0.16 sec\n",
      "Epoch 30, Loss(train/val) 0.21845/0.31184. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.23580/0.31436. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.21790/0.30465. Took 0.13 sec\n",
      "Epoch 33, Loss(train/val) 0.22256/0.31156. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.21868/0.33242. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.21576/0.31825. Took 0.16 sec\n",
      "Epoch 36, Loss(train/val) 0.21322/0.32316. Took 0.16 sec\n",
      "Epoch 37, Loss(train/val) 0.21468/0.33011. Took 0.15 sec\n",
      "Epoch 38, Loss(train/val) 0.20854/0.34409. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.19929/0.32279. Took 0.17 sec\n",
      "Epoch 40, Loss(train/val) 0.19696/0.32965. Took 0.17 sec\n",
      "Epoch 41, Loss(train/val) 0.20391/0.31040. Took 0.15 sec\n",
      "Epoch 42, Loss(train/val) 0.20091/0.31364. Took 0.15 sec\n",
      "Epoch 43, Loss(train/val) 0.19077/0.33610. Took 0.17 sec\n",
      "Epoch 44, Loss(train/val) 0.18073/0.32001. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) 0.19486/0.34031. Took 0.17 sec\n",
      "Epoch 46, Loss(train/val) 0.18379/0.32962. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.19390/0.29634. Took 0.17 sec\n",
      "Epoch 48, Loss(train/val) 0.18888/0.30573. Took 0.16 sec\n",
      "Epoch 49, Loss(train/val) 0.18678/0.31003. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.17755/0.32020. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.18529/0.33215. Took 0.15 sec\n",
      "Epoch 52, Loss(train/val) 0.17732/0.29381. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) 0.18808/0.29946. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.17467/0.30921. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.17841/0.30099. Took 0.15 sec\n",
      "Epoch 56, Loss(train/val) 0.16635/0.30641. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.17303/0.31216. Took 0.17 sec\n",
      "Epoch 58, Loss(train/val) 0.17172/0.31908. Took 0.15 sec\n",
      "Epoch 59, Loss(train/val) 0.16524/0.31384. Took 0.15 sec\n",
      "Epoch 60, Loss(train/val) 0.17560/0.34913. Took 0.15 sec\n",
      "Epoch 61, Loss(train/val) 0.17739/0.30119. Took 0.17 sec\n",
      "Epoch 62, Loss(train/val) 0.16709/0.30524. Took 0.17 sec\n",
      "Epoch 63, Loss(train/val) 0.15777/0.29954. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.16534/0.29808. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.15804/0.29798. Took 0.15 sec\n",
      "Epoch 66, Loss(train/val) 0.16274/0.31284. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) 0.16064/0.30684. Took 0.15 sec\n",
      "Epoch 68, Loss(train/val) 0.16395/0.31277. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.16628/0.29151. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.15825/0.29347. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.16351/0.30059. Took 0.15 sec\n",
      "Epoch 72, Loss(train/val) 0.15062/0.32982. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.15246/0.32641. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.14850/0.32064. Took 0.15 sec\n",
      "Epoch 75, Loss(train/val) 0.15978/0.33042. Took 0.16 sec\n",
      "Epoch 76, Loss(train/val) 0.14855/0.32639. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.14347/0.31048. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.14259/0.32090. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.15258/0.31632. Took 0.15 sec\n",
      "Epoch 80, Loss(train/val) 0.15145/0.32431. Took 0.14 sec\n",
      "Epoch 81, Loss(train/val) 0.14744/0.32684. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.13967/0.32365. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.13869/0.32327. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.14037/0.32095. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.13101/0.33275. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.13946/0.33648. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.14153/0.34068. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.13971/0.33895. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.13419/0.34002. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.13947/0.34959. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.13495/0.34006. Took 0.15 sec\n",
      "Epoch 92, Loss(train/val) 0.13579/0.34697. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.13061/0.34890. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.12936/0.33658. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.12374/0.33631. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.12804/0.33872. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.13557/0.32763. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.12779/0.31951. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.12786/0.34566. Took 0.14 sec\n",
      "ACC: 0.703125, MCC: 0.4058141068348118\n",
      "Epoch 0, Loss(train/val) 0.48855/0.46939. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.46408/0.42199. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.43257/0.37075. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.40527/0.34361. Took 0.16 sec\n",
      "Epoch 4, Loss(train/val) 0.38180/0.32415. Took 0.16 sec\n",
      "Epoch 5, Loss(train/val) 0.35970/0.29787. Took 0.15 sec\n",
      "Epoch 6, Loss(train/val) 0.34696/0.28606. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.32331/0.26910. Took 0.16 sec\n",
      "Epoch 8, Loss(train/val) 0.31035/0.25441. Took 0.16 sec\n",
      "Epoch 9, Loss(train/val) 0.29551/0.25028. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.28595/0.25240. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.28289/0.24433. Took 0.15 sec\n",
      "Epoch 12, Loss(train/val) 0.27623/0.24955. Took 0.15 sec\n",
      "Epoch 13, Loss(train/val) 0.26482/0.24835. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.25571/0.24673. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.25495/0.28216. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.25262/0.27874. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.24905/0.26970. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.24379/0.28830. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.24292/0.26963. Took 0.15 sec\n",
      "Epoch 20, Loss(train/val) 0.23278/0.26386. Took 0.16 sec\n",
      "Epoch 21, Loss(train/val) 0.22966/0.26040. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.22051/0.27526. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.22078/0.27268. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.21844/0.28056. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.21225/0.27620. Took 0.16 sec\n",
      "Epoch 26, Loss(train/val) 0.22094/0.27719. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.20900/0.26797. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.21359/0.27476. Took 0.13 sec\n",
      "Epoch 29, Loss(train/val) 0.20954/0.28478. Took 0.16 sec\n",
      "Epoch 30, Loss(train/val) 0.20226/0.27326. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.19752/0.29058. Took 0.17 sec\n",
      "Epoch 32, Loss(train/val) 0.19499/0.27550. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.18762/0.31379. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.19033/0.29736. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.18348/0.30242. Took 0.16 sec\n",
      "Epoch 36, Loss(train/val) 0.18241/0.28722. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.18764/0.30990. Took 0.16 sec\n",
      "Epoch 38, Loss(train/val) 0.18837/0.29084. Took 0.15 sec\n",
      "Epoch 39, Loss(train/val) 0.18197/0.30230. Took 0.16 sec\n",
      "Epoch 40, Loss(train/val) 0.17880/0.29334. Took 0.15 sec\n",
      "Epoch 41, Loss(train/val) 0.17020/0.30473. Took 0.15 sec\n",
      "Epoch 42, Loss(train/val) 0.17744/0.30808. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.17599/0.30668. Took 0.16 sec\n",
      "Epoch 44, Loss(train/val) 0.17072/0.29746. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.16987/0.30261. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.16980/0.29369. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.16278/0.28655. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.16914/0.29304. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.16623/0.32402. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.15532/0.29171. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.15777/0.29385. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.16071/0.31190. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.16372/0.29686. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.15698/0.29244. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.15247/0.32848. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.15623/0.30250. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.15230/0.30523. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.15685/0.29593. Took 0.14 sec\n",
      "Epoch 59, Loss(train/val) 0.15385/0.31483. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.14398/0.31139. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.15142/0.30157. Took 0.15 sec\n",
      "Epoch 62, Loss(train/val) 0.14864/0.28207. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.14358/0.28834. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.14809/0.30336. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.14616/0.29756. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.14589/0.29751. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.14810/0.29273. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.13812/0.31349. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.13893/0.31379. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.13825/0.31404. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.14069/0.32505. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.14381/0.33069. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.13767/0.31196. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.13783/0.33252. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.14105/0.31451. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.13367/0.28967. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.13681/0.29119. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.13910/0.30572. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.13885/0.28580. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.14299/0.33758. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.13436/0.30313. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.13755/0.29272. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.12741/0.30458. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.12794/0.32798. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.13813/0.28328. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.12750/0.30955. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.12877/0.28677. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.12812/0.31460. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.12355/0.29944. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.12356/0.29662. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.12226/0.31480. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.12394/0.28900. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.13166/0.32508. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.12357/0.32162. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.12265/0.28009. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.12467/0.29106. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.12407/0.30510. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.11719/0.32125. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.11633/0.32052. Took 0.14 sec\n",
      "ACC: 0.671875, MCC: 0.27373668712677574\n",
      "Epoch 0, Loss(train/val) 0.49327/0.47564. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.46832/0.42213. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.42955/0.36379. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.39338/0.34354. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.37197/0.32901. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.35345/0.33569. Took 0.15 sec\n",
      "Epoch 6, Loss(train/val) 0.33987/0.35684. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.32268/0.37396. Took 0.15 sec\n",
      "Epoch 8, Loss(train/val) 0.30897/0.38819. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.31323/0.41911. Took 0.16 sec\n",
      "Epoch 10, Loss(train/val) 0.30637/0.34111. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.30957/0.37527. Took 0.16 sec\n",
      "Epoch 12, Loss(train/val) 0.29353/0.37383. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.28791/0.37089. Took 0.16 sec\n",
      "Epoch 14, Loss(train/val) 0.29081/0.37958. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.29065/0.44781. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.28587/0.48807. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.29839/0.41888. Took 0.16 sec\n",
      "Epoch 18, Loss(train/val) 0.29145/0.46242. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.28115/0.44455. Took 0.16 sec\n",
      "Epoch 20, Loss(train/val) 0.26871/0.52591. Took 0.15 sec\n",
      "Epoch 21, Loss(train/val) 0.27100/0.49839. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.27252/0.45834. Took 0.15 sec\n",
      "Epoch 23, Loss(train/val) 0.29048/0.45337. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.27056/0.38971. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.27526/0.41722. Took 0.16 sec\n",
      "Epoch 26, Loss(train/val) 0.26727/0.42463. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.26719/0.42755. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.25267/0.41297. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.25634/0.42759. Took 0.16 sec\n",
      "Epoch 30, Loss(train/val) 0.25426/0.40982. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.25121/0.38197. Took 0.16 sec\n",
      "Epoch 32, Loss(train/val) 0.25524/0.38559. Took 0.20 sec\n",
      "Epoch 33, Loss(train/val) 0.24875/0.37906. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.24029/0.42503. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.23494/0.37476. Took 0.15 sec\n",
      "Epoch 36, Loss(train/val) 0.24445/0.37191. Took 0.19 sec\n",
      "Epoch 37, Loss(train/val) 0.24020/0.36923. Took 0.16 sec\n",
      "Epoch 38, Loss(train/val) 0.23436/0.38707. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.24154/0.40407. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.23957/0.37356. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.24072/0.37146. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.23053/0.36781. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.22330/0.37297. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.22789/0.42196. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) 0.22970/0.40235. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.22529/0.39465. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.21852/0.37065. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.21162/0.37310. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.21540/0.37605. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.20455/0.39600. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.21114/0.37501. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.22405/0.37983. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.22034/0.42404. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.20984/0.37814. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.21735/0.40548. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.21381/0.42876. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.20693/0.37305. Took 0.15 sec\n",
      "Epoch 58, Loss(train/val) 0.21086/0.36674. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.20883/0.38514. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.19662/0.38855. Took 0.15 sec\n",
      "Epoch 61, Loss(train/val) 0.19508/0.42011. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.20480/0.47436. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.19454/0.42575. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.18910/0.42649. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.20385/0.38402. Took 0.15 sec\n",
      "Epoch 66, Loss(train/val) 0.19332/0.40755. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.19230/0.40181. Took 0.15 sec\n",
      "Epoch 68, Loss(train/val) 0.19650/0.44089. Took 0.14 sec\n",
      "Epoch 69, Loss(train/val) 0.19885/0.40353. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.19464/0.42618. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.19184/0.42081. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.18400/0.40062. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.19509/0.39657. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.18434/0.38416. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.17245/0.44259. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.18082/0.43245. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.18881/0.39213. Took 0.15 sec\n",
      "Epoch 78, Loss(train/val) 0.18849/0.40418. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.18551/0.41318. Took 0.15 sec\n",
      "Epoch 80, Loss(train/val) 0.18583/0.39155. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.17404/0.38204. Took 0.15 sec\n",
      "Epoch 82, Loss(train/val) 0.17281/0.39161. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.17901/0.36903. Took 0.15 sec\n",
      "Epoch 84, Loss(train/val) 0.18788/0.37243. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.17890/0.36182. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.17626/0.37117. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.17350/0.39730. Took 0.16 sec\n",
      "Epoch 88, Loss(train/val) 0.16865/0.38256. Took 0.14 sec\n",
      "Epoch 89, Loss(train/val) 0.17464/0.41036. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.17784/0.39349. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.17572/0.38591. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.17797/0.38513. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.16709/0.39879. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.17075/0.38553. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.16536/0.40261. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.16638/0.37741. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.16107/0.37344. Took 0.15 sec\n",
      "Epoch 98, Loss(train/val) 0.17209/0.42659. Took 0.14 sec\n",
      "Epoch 99, Loss(train/val) 0.17179/0.37641. Took 0.15 sec\n",
      "ACC: 0.578125, MCC: 0.1563263498701806\n",
      "Epoch 0, Loss(train/val) 0.48967/0.49540. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.46496/0.48607. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.43243/0.47333. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.40634/0.47351. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.38605/0.46364. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.37494/0.44088. Took 0.18 sec\n",
      "Epoch 6, Loss(train/val) 0.35839/0.42164. Took 0.17 sec\n",
      "Epoch 7, Loss(train/val) 0.34325/0.41128. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.32755/0.41676. Took 0.15 sec\n",
      "Epoch 9, Loss(train/val) 0.30945/0.38855. Took 0.20 sec\n",
      "Epoch 10, Loss(train/val) 0.30789/0.46025. Took 0.18 sec\n",
      "Epoch 11, Loss(train/val) 0.29231/0.45355. Took 0.19 sec\n",
      "Epoch 12, Loss(train/val) 0.29471/0.43867. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.29410/0.43825. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.28190/0.40246. Took 0.15 sec\n",
      "Epoch 15, Loss(train/val) 0.27826/0.45858. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.26913/0.45697. Took 0.16 sec\n",
      "Epoch 17, Loss(train/val) 0.26666/0.44610. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.26111/0.41542. Took 0.16 sec\n",
      "Epoch 19, Loss(train/val) 0.26454/0.46311. Took 0.18 sec\n",
      "Epoch 20, Loss(train/val) 0.25929/0.44537. Took 0.16 sec\n",
      "Epoch 21, Loss(train/val) 0.25239/0.45381. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.25627/0.45964. Took 0.15 sec\n",
      "Epoch 23, Loss(train/val) 0.25040/0.47342. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.24282/0.47473. Took 0.17 sec\n",
      "Epoch 25, Loss(train/val) 0.24152/0.44841. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.23947/0.46544. Took 0.16 sec\n",
      "Epoch 27, Loss(train/val) 0.24222/0.46269. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.24457/0.46612. Took 0.18 sec\n",
      "Epoch 29, Loss(train/val) 0.23556/0.45954. Took 0.16 sec\n",
      "Epoch 30, Loss(train/val) 0.23415/0.46963. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.23509/0.48297. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.22427/0.48127. Took 0.17 sec\n",
      "Epoch 33, Loss(train/val) 0.21840/0.47824. Took 0.16 sec\n",
      "Epoch 34, Loss(train/val) 0.21823/0.48492. Took 0.19 sec\n",
      "Epoch 35, Loss(train/val) 0.21967/0.48758. Took 0.17 sec\n",
      "Epoch 36, Loss(train/val) 0.21800/0.48167. Took 0.16 sec\n",
      "Epoch 37, Loss(train/val) 0.20467/0.48380. Took 0.15 sec\n",
      "Epoch 38, Loss(train/val) 0.20721/0.47141. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.20816/0.48093. Took 0.13 sec\n",
      "Epoch 40, Loss(train/val) 0.20683/0.48502. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.20582/0.47544. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.20036/0.48185. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.20233/0.45067. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.21107/0.47917. Took 0.15 sec\n",
      "Epoch 45, Loss(train/val) 0.20503/0.47907. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.19951/0.44969. Took 0.15 sec\n",
      "Epoch 47, Loss(train/val) 0.19390/0.47085. Took 0.16 sec\n",
      "Epoch 48, Loss(train/val) 0.19539/0.48180. Took 0.17 sec\n",
      "Epoch 49, Loss(train/val) 0.18872/0.46749. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.19414/0.47531. Took 0.14 sec\n",
      "Epoch 51, Loss(train/val) 0.19537/0.46765. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.19459/0.46500. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) 0.19104/0.46955. Took 0.16 sec\n",
      "Epoch 54, Loss(train/val) 0.18910/0.46128. Took 0.17 sec\n",
      "Epoch 55, Loss(train/val) 0.18125/0.45178. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.17620/0.45827. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.18478/0.46281. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.18505/0.46858. Took 0.15 sec\n",
      "Epoch 59, Loss(train/val) 0.18029/0.44489. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.18079/0.47055. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.17768/0.46001. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.17869/0.46024. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.17290/0.46888. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.18534/0.45560. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.17763/0.46728. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.17633/0.39513. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) 0.17774/0.46117. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.16994/0.45184. Took 0.15 sec\n",
      "Epoch 69, Loss(train/val) 0.17696/0.44734. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.17595/0.45483. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.17509/0.42651. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.17494/0.45336. Took 0.15 sec\n",
      "Epoch 73, Loss(train/val) 0.17089/0.39626. Took 0.15 sec\n",
      "Epoch 74, Loss(train/val) 0.17946/0.43632. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) 0.17179/0.42955. Took 0.15 sec\n",
      "Epoch 76, Loss(train/val) 0.16792/0.45183. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.16178/0.43498. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.16938/0.45871. Took 0.14 sec\n",
      "Epoch 79, Loss(train/val) 0.16238/0.44842. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.15939/0.45856. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.15717/0.46462. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.15914/0.45659. Took 0.15 sec\n",
      "Epoch 83, Loss(train/val) 0.15797/0.46719. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.16217/0.41644. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.16114/0.46117. Took 0.16 sec\n",
      "Epoch 86, Loss(train/val) 0.15109/0.45699. Took 0.17 sec\n",
      "Epoch 87, Loss(train/val) 0.15510/0.45564. Took 0.15 sec\n",
      "Epoch 88, Loss(train/val) 0.15803/0.45712. Took 0.14 sec\n",
      "Epoch 89, Loss(train/val) 0.15938/0.47079. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.15041/0.45037. Took 0.15 sec\n",
      "Epoch 91, Loss(train/val) 0.14611/0.45786. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.14932/0.47569. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.15296/0.46521. Took 0.17 sec\n",
      "Epoch 94, Loss(train/val) 0.14949/0.45718. Took 0.15 sec\n",
      "Epoch 95, Loss(train/val) 0.14906/0.46981. Took 0.15 sec\n",
      "Epoch 96, Loss(train/val) 0.14282/0.47958. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.14642/0.45435. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.14573/0.48125. Took 0.15 sec\n",
      "Epoch 99, Loss(train/val) 0.14300/0.43977. Took 0.15 sec\n",
      "ACC: 0.671875, MCC: 0.36947940080890257\n",
      "Epoch 0, Loss(train/val) 0.48406/0.47246. Took 0.17 sec\n",
      "Epoch 1, Loss(train/val) 0.45413/0.44541. Took 0.15 sec\n",
      "Epoch 2, Loss(train/val) 0.43045/0.41824. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.40374/0.38760. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.38306/0.37863. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.36399/0.37888. Took 0.15 sec\n",
      "Epoch 6, Loss(train/val) 0.35168/0.38271. Took 0.15 sec\n",
      "Epoch 7, Loss(train/val) 0.33827/0.38269. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.32567/0.39263. Took 0.16 sec\n",
      "Epoch 9, Loss(train/val) 0.30639/0.40612. Took 0.15 sec\n",
      "Epoch 10, Loss(train/val) 0.29840/0.41456. Took 0.15 sec\n",
      "Epoch 11, Loss(train/val) 0.28850/0.43592. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.28006/0.43294. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.27084/0.42318. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.26741/0.42999. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.26361/0.42634. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.26581/0.44941. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.25764/0.45441. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.25120/0.45077. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.25816/0.41978. Took 0.15 sec\n",
      "Epoch 20, Loss(train/val) 0.25198/0.46259. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.24516/0.42578. Took 0.16 sec\n",
      "Epoch 22, Loss(train/val) 0.24808/0.41900. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.24221/0.46408. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.23999/0.45357. Took 0.15 sec\n",
      "Epoch 25, Loss(train/val) 0.23831/0.43680. Took 0.16 sec\n",
      "Epoch 26, Loss(train/val) 0.23920/0.41880. Took 0.16 sec\n",
      "Epoch 27, Loss(train/val) 0.23506/0.43990. Took 0.16 sec\n",
      "Epoch 28, Loss(train/val) 0.23158/0.43299. Took 0.16 sec\n",
      "Epoch 29, Loss(train/val) 0.22912/0.40818. Took 0.17 sec\n",
      "Epoch 30, Loss(train/val) 0.22789/0.47161. Took 0.16 sec\n",
      "Epoch 31, Loss(train/val) 0.21851/0.44666. Took 0.17 sec\n",
      "Epoch 32, Loss(train/val) 0.22002/0.42359. Took 0.21 sec\n",
      "Epoch 33, Loss(train/val) 0.21362/0.40801. Took 0.18 sec\n",
      "Epoch 34, Loss(train/val) 0.22057/0.40196. Took 0.17 sec\n",
      "Epoch 35, Loss(train/val) 0.22377/0.40065. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.21400/0.40603. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.21438/0.40447. Took 0.16 sec\n",
      "Epoch 38, Loss(train/val) 0.22115/0.42860. Took 0.17 sec\n",
      "Epoch 39, Loss(train/val) 0.20481/0.44319. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.20988/0.41616. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.21070/0.40512. Took 0.15 sec\n",
      "Epoch 42, Loss(train/val) 0.22127/0.38666. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.21237/0.42670. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.20825/0.45033. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) 0.19834/0.39867. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.20223/0.40597. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.19859/0.42509. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.19502/0.42125. Took 0.17 sec\n",
      "Epoch 49, Loss(train/val) 0.19701/0.36740. Took 0.16 sec\n",
      "Epoch 50, Loss(train/val) 0.19440/0.42823. Took 0.14 sec\n",
      "Epoch 51, Loss(train/val) 0.18652/0.40217. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.19148/0.37289. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) 0.19477/0.38144. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.18693/0.35974. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.18520/0.37350. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.17818/0.35749. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.19117/0.36067. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.18709/0.33923. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.18532/0.37854. Took 0.17 sec\n",
      "Epoch 60, Loss(train/val) 0.18912/0.38016. Took 0.14 sec\n",
      "Epoch 61, Loss(train/val) 0.17670/0.35865. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.17479/0.36570. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.17319/0.38030. Took 0.15 sec\n",
      "Epoch 64, Loss(train/val) 0.17224/0.39057. Took 0.16 sec\n",
      "Epoch 65, Loss(train/val) 0.17083/0.36190. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.18001/0.37206. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.16643/0.39887. Took 0.15 sec\n",
      "Epoch 68, Loss(train/val) 0.17120/0.35507. Took 0.14 sec\n",
      "Epoch 69, Loss(train/val) 0.16036/0.38372. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.16587/0.41291. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.16329/0.43386. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.15880/0.38383. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.16800/0.38893. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.15528/0.42846. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) 0.15434/0.39235. Took 0.15 sec\n",
      "Epoch 76, Loss(train/val) 0.15837/0.37362. Took 0.15 sec\n",
      "Epoch 77, Loss(train/val) 0.15438/0.39472. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.15258/0.39652. Took 0.14 sec\n",
      "Epoch 79, Loss(train/val) 0.15235/0.39194. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.14957/0.39026. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.15352/0.36808. Took 0.16 sec\n",
      "Epoch 82, Loss(train/val) 0.14939/0.38437. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) 0.14549/0.37017. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.14811/0.35969. Took 0.15 sec\n",
      "Epoch 85, Loss(train/val) 0.15819/0.37682. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.14483/0.39890. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.14207/0.41508. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.14288/0.38929. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.13623/0.40600. Took 0.16 sec\n",
      "Epoch 90, Loss(train/val) 0.14012/0.40519. Took 0.15 sec\n",
      "Epoch 91, Loss(train/val) 0.13516/0.36589. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.13652/0.39593. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.13599/0.40361. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.13063/0.39664. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.12718/0.38996. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.12939/0.39510. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.13635/0.37740. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.12951/0.42058. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.13240/0.37984. Took 0.14 sec\n",
      "ACC: 0.640625, MCC: 0.2805550872420795\n",
      "Epoch 0, Loss(train/val) 0.48782/0.44618. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.45609/0.35744. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.42419/0.31020. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.40246/0.31797. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.38397/0.33337. Took 0.15 sec\n",
      "Epoch 5, Loss(train/val) 0.36891/0.37591. Took 0.15 sec\n",
      "Epoch 6, Loss(train/val) 0.35122/0.38081. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.33272/0.40303. Took 0.15 sec\n",
      "Epoch 8, Loss(train/val) 0.31382/0.43500. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.29313/0.46011. Took 0.16 sec\n",
      "Epoch 10, Loss(train/val) 0.28751/0.53286. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.27504/0.49987. Took 0.17 sec\n",
      "Epoch 12, Loss(train/val) 0.27821/0.47683. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.27304/0.47947. Took 0.17 sec\n",
      "Epoch 14, Loss(train/val) 0.25716/0.49617. Took 0.15 sec\n",
      "Epoch 15, Loss(train/val) 0.26267/0.51616. Took 0.16 sec\n",
      "Epoch 16, Loss(train/val) 0.25797/0.56997. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.24875/0.60195. Took 0.16 sec\n",
      "Epoch 18, Loss(train/val) 0.25189/0.63175. Took 0.16 sec\n",
      "Epoch 19, Loss(train/val) 0.25044/0.54660. Took 0.15 sec\n",
      "Epoch 20, Loss(train/val) 0.24352/0.59523. Took 0.15 sec\n",
      "Epoch 21, Loss(train/val) 0.23911/0.60726. Took 0.16 sec\n",
      "Epoch 22, Loss(train/val) 0.23707/0.54521. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.23339/0.54902. Took 0.16 sec\n",
      "Epoch 24, Loss(train/val) 0.23429/0.59091. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.23203/0.63102. Took 0.17 sec\n",
      "Epoch 26, Loss(train/val) 0.22731/0.55351. Took 0.19 sec\n",
      "Epoch 27, Loss(train/val) 0.23946/0.53860. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.22717/0.50891. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.23121/0.54699. Took 0.17 sec\n",
      "Epoch 30, Loss(train/val) 0.22518/0.53189. Took 0.16 sec\n",
      "Epoch 31, Loss(train/val) 0.22404/0.52903. Took 0.16 sec\n",
      "Epoch 32, Loss(train/val) 0.21705/0.55162. Took 0.17 sec\n",
      "Epoch 33, Loss(train/val) 0.21065/0.50503. Took 0.17 sec\n",
      "Epoch 34, Loss(train/val) 0.21135/0.58804. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.21375/0.52941. Took 0.16 sec\n",
      "Epoch 36, Loss(train/val) 0.20628/0.51729. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.21259/0.51888. Took 0.15 sec\n",
      "Epoch 38, Loss(train/val) 0.20855/0.52291. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.20043/0.51630. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.19872/0.51054. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.19325/0.45438. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.19634/0.48918. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.19381/0.49039. Took 0.17 sec\n",
      "Epoch 44, Loss(train/val) 0.18993/0.51073. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.18984/0.46267. Took 0.15 sec\n",
      "Epoch 46, Loss(train/val) 0.18453/0.48307. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.18598/0.45079. Took 0.16 sec\n",
      "Epoch 48, Loss(train/val) 0.17993/0.44214. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.18900/0.48770. Took 0.17 sec\n",
      "Epoch 50, Loss(train/val) 0.18116/0.48468. Took 0.15 sec\n",
      "Epoch 51, Loss(train/val) 0.18939/0.50178. Took 0.16 sec\n",
      "Epoch 52, Loss(train/val) 0.18101/0.38897. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.19326/0.48707. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.18006/0.47275. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.17943/0.49441. Took 0.15 sec\n",
      "Epoch 56, Loss(train/val) 0.17942/0.44023. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.17716/0.49008. Took 0.15 sec\n",
      "Epoch 58, Loss(train/val) 0.18064/0.49911. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.18908/0.48312. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.17932/0.50932. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.17748/0.47762. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.17890/0.48139. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.16959/0.46854. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.17291/0.46484. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.16823/0.46673. Took 0.15 sec\n",
      "Epoch 66, Loss(train/val) 0.17169/0.39894. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.18295/0.38635. Took 0.15 sec\n",
      "Epoch 68, Loss(train/val) 0.17824/0.48763. Took 0.14 sec\n",
      "Epoch 69, Loss(train/val) 0.16988/0.46081. Took 0.16 sec\n",
      "Epoch 70, Loss(train/val) 0.16826/0.46338. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.17177/0.42091. Took 0.16 sec\n",
      "Epoch 72, Loss(train/val) 0.16469/0.44133. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.16669/0.45297. Took 0.15 sec\n",
      "Epoch 74, Loss(train/val) 0.16306/0.40083. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.16671/0.38887. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.15914/0.40000. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.16101/0.38570. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.15585/0.39553. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.16599/0.38559. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.15854/0.33515. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.15994/0.34823. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.15870/0.34347. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.16546/0.42539. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.15914/0.42616. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.15923/0.40171. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.16200/0.36415. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.15998/0.36573. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.15561/0.37073. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.15858/0.36504. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.15542/0.35326. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.15780/0.37852. Took 0.15 sec\n",
      "Epoch 92, Loss(train/val) 0.15234/0.37141. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.16313/0.36633. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.14589/0.40315. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.14899/0.36560. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.15539/0.34356. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.15262/0.38663. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.14841/0.36167. Took 0.14 sec\n",
      "Epoch 99, Loss(train/val) 0.14906/0.35695. Took 0.14 sec\n",
      "ACC: 0.71875, MCC: 0.4383570037596047\n",
      "Epoch 0, Loss(train/val) 0.48764/0.46777. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.45515/0.41926. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.42385/0.36102. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.39862/0.32562. Took 0.15 sec\n",
      "Epoch 4, Loss(train/val) 0.38257/0.31007. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.36597/0.29417. Took 0.15 sec\n",
      "Epoch 6, Loss(train/val) 0.35778/0.28965. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.34498/0.28406. Took 0.15 sec\n",
      "Epoch 8, Loss(train/val) 0.33600/0.28867. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.33097/0.31614. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.31957/0.28155. Took 0.16 sec\n",
      "Epoch 11, Loss(train/val) 0.30692/0.26168. Took 0.19 sec\n",
      "Epoch 12, Loss(train/val) 0.29994/0.27362. Took 0.19 sec\n",
      "Epoch 13, Loss(train/val) 0.29338/0.31039. Took 0.16 sec\n",
      "Epoch 14, Loss(train/val) 0.28494/0.28199. Took 0.16 sec\n",
      "Epoch 15, Loss(train/val) 0.28284/0.27692. Took 0.16 sec\n",
      "Epoch 16, Loss(train/val) 0.28209/0.29528. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.26895/0.28141. Took 0.17 sec\n",
      "Epoch 18, Loss(train/val) 0.26764/0.29356. Took 0.15 sec\n",
      "Epoch 19, Loss(train/val) 0.26285/0.30102. Took 0.18 sec\n",
      "Epoch 20, Loss(train/val) 0.26110/0.30522. Took 0.19 sec\n",
      "Epoch 21, Loss(train/val) 0.25218/0.29838. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.25148/0.33155. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.24969/0.28798. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.24903/0.31571. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.24675/0.32340. Took 0.16 sec\n",
      "Epoch 26, Loss(train/val) 0.23889/0.30778. Took 0.15 sec\n",
      "Epoch 27, Loss(train/val) 0.24033/0.33114. Took 0.16 sec\n",
      "Epoch 28, Loss(train/val) 0.24130/0.32189. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.24188/0.32776. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.23941/0.31032. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.23520/0.32973. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.22409/0.34293. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.21410/0.34324. Took 0.17 sec\n",
      "Epoch 34, Loss(train/val) 0.21296/0.31221. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.21406/0.35993. Took 0.17 sec\n",
      "Epoch 36, Loss(train/val) 0.21230/0.31701. Took 0.17 sec\n",
      "Epoch 37, Loss(train/val) 0.21030/0.30880. Took 0.17 sec\n",
      "Epoch 38, Loss(train/val) 0.20902/0.33917. Took 0.18 sec\n",
      "Epoch 39, Loss(train/val) 0.21365/0.33055. Took 0.17 sec\n",
      "Epoch 40, Loss(train/val) 0.21134/0.32906. Took 0.15 sec\n",
      "Epoch 41, Loss(train/val) 0.20211/0.31364. Took 0.21 sec\n",
      "Epoch 42, Loss(train/val) 0.21310/0.34917. Took 0.18 sec\n",
      "Epoch 43, Loss(train/val) 0.20483/0.28496. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.20610/0.26927. Took 0.15 sec\n",
      "Epoch 45, Loss(train/val) 0.20436/0.35222. Took 0.17 sec\n",
      "Epoch 46, Loss(train/val) 0.21073/0.33821. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.19559/0.31655. Took 0.15 sec\n",
      "Epoch 48, Loss(train/val) 0.18999/0.33076. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.19476/0.29079. Took 0.15 sec\n",
      "Epoch 50, Loss(train/val) 0.19632/0.28839. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.19490/0.30524. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.18378/0.28981. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.18649/0.27791. Took 0.15 sec\n",
      "Epoch 54, Loss(train/val) 0.18207/0.30829. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.17916/0.29199. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.17803/0.29744. Took 0.17 sec\n",
      "Epoch 57, Loss(train/val) 0.18404/0.28059. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.18752/0.27763. Took 0.14 sec\n",
      "Epoch 59, Loss(train/val) 0.17777/0.30604. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.17450/0.28804. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.18003/0.28314. Took 0.15 sec\n",
      "Epoch 62, Loss(train/val) 0.17951/0.27918. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.17110/0.28276. Took 0.15 sec\n",
      "Epoch 64, Loss(train/val) 0.17731/0.28586. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.16205/0.29467. Took 0.15 sec\n",
      "Epoch 66, Loss(train/val) 0.17218/0.28402. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.16949/0.28282. Took 0.15 sec\n",
      "Epoch 68, Loss(train/val) 0.16553/0.28502. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.16633/0.28241. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.16313/0.27915. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.16231/0.27536. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.16741/0.27138. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.15558/0.28118. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.15716/0.28361. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) 0.15898/0.27941. Took 0.16 sec\n",
      "Epoch 76, Loss(train/val) 0.16873/0.29535. Took 0.15 sec\n",
      "Epoch 77, Loss(train/val) 0.14642/0.30082. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.14875/0.28242. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.15184/0.28822. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.15705/0.29711. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.14880/0.30159. Took 0.15 sec\n",
      "Epoch 82, Loss(train/val) 0.15594/0.27935. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.15194/0.28471. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.14341/0.27938. Took 0.15 sec\n",
      "Epoch 85, Loss(train/val) 0.14831/0.28047. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.14707/0.30660. Took 0.17 sec\n",
      "Epoch 87, Loss(train/val) 0.14322/0.28646. Took 0.15 sec\n",
      "Epoch 88, Loss(train/val) 0.15471/0.27955. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.14469/0.28995. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.13954/0.29500. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.14621/0.29822. Took 0.15 sec\n",
      "Epoch 92, Loss(train/val) 0.14614/0.30457. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.14050/0.29563. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.14458/0.29670. Took 0.16 sec\n",
      "Epoch 95, Loss(train/val) 0.14061/0.28757. Took 0.15 sec\n",
      "Epoch 96, Loss(train/val) 0.13589/0.29330. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.13591/0.28406. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.13340/0.29091. Took 0.14 sec\n",
      "Epoch 99, Loss(train/val) 0.13410/0.28623. Took 0.14 sec\n",
      "ACC: 0.6875, MCC: 0.374902769779907\n",
      "Epoch 0, Loss(train/val) 0.48706/0.48596. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.45470/0.46309. Took 0.16 sec\n",
      "Epoch 2, Loss(train/val) 0.42415/0.43492. Took 0.16 sec\n",
      "Epoch 3, Loss(train/val) 0.40182/0.40195. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.38699/0.37541. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.37845/0.35268. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.36347/0.34875. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.34942/0.34259. Took 0.16 sec\n",
      "Epoch 8, Loss(train/val) 0.33681/0.34451. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.31972/0.33664. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.31381/0.37128. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.30144/0.37361. Took 0.16 sec\n",
      "Epoch 12, Loss(train/val) 0.29944/0.41135. Took 0.15 sec\n",
      "Epoch 13, Loss(train/val) 0.30307/0.40859. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.29083/0.45426. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.28186/0.44549. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.28011/0.44059. Took 0.15 sec\n",
      "Epoch 17, Loss(train/val) 0.26993/0.40123. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.26575/0.35862. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.26453/0.40006. Took 0.16 sec\n",
      "Epoch 20, Loss(train/val) 0.25662/0.41362. Took 0.15 sec\n",
      "Epoch 21, Loss(train/val) 0.25638/0.36001. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.25555/0.35417. Took 0.16 sec\n",
      "Epoch 23, Loss(train/val) 0.24915/0.37581. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.24955/0.34569. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.25054/0.37003. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.24235/0.39692. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.24653/0.39749. Took 0.16 sec\n",
      "Epoch 28, Loss(train/val) 0.24268/0.36139. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.23677/0.37263. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.22803/0.35217. Took 0.16 sec\n",
      "Epoch 31, Loss(train/val) 0.22251/0.36502. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.22729/0.45075. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.21727/0.37233. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.21566/0.37860. Took 0.17 sec\n",
      "Epoch 35, Loss(train/val) 0.20472/0.37346. Took 0.17 sec\n",
      "Epoch 36, Loss(train/val) 0.21033/0.39521. Took 0.17 sec\n",
      "Epoch 37, Loss(train/val) 0.20982/0.39731. Took 0.17 sec\n",
      "Epoch 38, Loss(train/val) 0.19975/0.37789. Took 0.19 sec\n",
      "Epoch 39, Loss(train/val) 0.20645/0.40277. Took 0.15 sec\n",
      "Epoch 40, Loss(train/val) 0.19878/0.36131. Took 0.17 sec\n",
      "Epoch 41, Loss(train/val) 0.21219/0.36133. Took 0.16 sec\n",
      "Epoch 42, Loss(train/val) 0.20974/0.36711. Took 0.17 sec\n",
      "Epoch 43, Loss(train/val) 0.19485/0.36142. Took 0.16 sec\n",
      "Epoch 44, Loss(train/val) 0.19702/0.35145. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.20021/0.34995. Took 0.16 sec\n",
      "Epoch 46, Loss(train/val) 0.19435/0.33811. Took 0.16 sec\n",
      "Epoch 47, Loss(train/val) 0.19266/0.34176. Took 0.16 sec\n",
      "Epoch 48, Loss(train/val) 0.18628/0.33604. Took 0.15 sec\n",
      "Epoch 49, Loss(train/val) 0.19618/0.33716. Took 0.15 sec\n",
      "Epoch 50, Loss(train/val) 0.19721/0.35695. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.18306/0.34710. Took 0.15 sec\n",
      "Epoch 52, Loss(train/val) 0.18334/0.35237. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.17859/0.33784. Took 0.15 sec\n",
      "Epoch 54, Loss(train/val) 0.18383/0.37402. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.19320/0.35614. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.18574/0.34006. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.18587/0.36243. Took 0.16 sec\n",
      "Epoch 58, Loss(train/val) 0.16799/0.37185. Took 0.14 sec\n",
      "Epoch 59, Loss(train/val) 0.17110/0.36431. Took 0.15 sec\n",
      "Epoch 60, Loss(train/val) 0.17560/0.35208. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.17656/0.31946. Took 0.16 sec\n",
      "Epoch 62, Loss(train/val) 0.16821/0.32201. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.17397/0.35744. Took 0.15 sec\n",
      "Epoch 64, Loss(train/val) 0.16380/0.33406. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.16698/0.38941. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.17371/0.37907. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.16403/0.34941. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.15569/0.37594. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.16212/0.35874. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.15582/0.32330. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.15919/0.38367. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.16154/0.31644. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.15705/0.37861. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.15805/0.34926. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.15905/0.31138. Took 0.16 sec\n",
      "Epoch 76, Loss(train/val) 0.15785/0.33270. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.15285/0.36045. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.15243/0.34482. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.14375/0.34695. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.14174/0.33495. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.14306/0.30240. Took 0.15 sec\n",
      "Epoch 82, Loss(train/val) 0.15299/0.33371. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.14660/0.36216. Took 0.15 sec\n",
      "Epoch 84, Loss(train/val) 0.14888/0.35571. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.13451/0.38207. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.13557/0.35251. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.13141/0.36143. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.13569/0.35770. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.13634/0.35418. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.13364/0.35313. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.13810/0.34177. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.13683/0.34213. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.13403/0.33106. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.12825/0.34887. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.14209/0.36430. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.13176/0.36572. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.13536/0.38609. Took 0.15 sec\n",
      "Epoch 98, Loss(train/val) 0.12906/0.37993. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.13024/0.38394. Took 0.13 sec\n",
      "ACC: 0.65625, MCC: 0.30056323700963117\n",
      "Epoch 0, Loss(train/val) 0.48960/0.49696. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.46006/0.47927. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.42657/0.42993. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.39990/0.38420. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.38111/0.36085. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.36703/0.33521. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.35479/0.33213. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.34945/0.30194. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.33738/0.32040. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.32726/0.29467. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.31802/0.30379. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.31725/0.29282. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.30257/0.28385. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.30276/0.30634. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.29565/0.34209. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.29082/0.31573. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.29024/0.31847. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.28013/0.31036. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.27431/0.28168. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.27238/0.26250. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.27981/0.31596. Took 0.15 sec\n",
      "Epoch 21, Loss(train/val) 0.28091/0.28891. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.25831/0.32146. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.26495/0.23780. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.25792/0.30699. Took 0.15 sec\n",
      "Epoch 25, Loss(train/val) 0.25488/0.28369. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.26341/0.30472. Took 0.15 sec\n",
      "Epoch 27, Loss(train/val) 0.25433/0.26609. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.25670/0.28490. Took 0.13 sec\n",
      "Epoch 29, Loss(train/val) 0.24331/0.28520. Took 0.13 sec\n",
      "Epoch 30, Loss(train/val) 0.23769/0.26701. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.24901/0.30938. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.25657/0.38398. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.25213/0.28905. Took 0.16 sec\n",
      "Epoch 34, Loss(train/val) 0.24519/0.28968. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.23992/0.32828. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.22530/0.30960. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.23735/0.26809. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.22474/0.29729. Took 0.16 sec\n",
      "Epoch 39, Loss(train/val) 0.22058/0.29338. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.22245/0.28957. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.23845/0.32367. Took 0.16 sec\n",
      "Epoch 42, Loss(train/val) 0.23051/0.29327. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.22846/0.27876. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.21481/0.28846. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.21153/0.26576. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.21137/0.25076. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.21664/0.28618. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.20925/0.24744. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.20425/0.24719. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.20331/0.25464. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.20118/0.24632. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.19906/0.27312. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.20018/0.28836. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.19296/0.24396. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.20616/0.29228. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.19626/0.27100. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.19857/0.27990. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.19050/0.30643. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.19494/0.26853. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.18107/0.27245. Took 0.14 sec\n",
      "Epoch 61, Loss(train/val) 0.19008/0.31017. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.18033/0.31632. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.17087/0.27408. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.18384/0.28936. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.17781/0.28920. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.17789/0.27195. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.17092/0.26877. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.17448/0.26592. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.16930/0.27545. Took 0.15 sec\n",
      "Epoch 70, Loss(train/val) 0.17243/0.27810. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.17383/0.28039. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.16474/0.27484. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.16042/0.26695. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.16590/0.28278. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.16359/0.27389. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.16583/0.27326. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.16454/0.29777. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.15964/0.28501. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.15953/0.27960. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.15762/0.28229. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.15660/0.29045. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.15318/0.28830. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.15231/0.29924. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.15158/0.30148. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.15106/0.30878. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.15076/0.31733. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.15460/0.32976. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.15581/0.29426. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.14493/0.31904. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.14328/0.31519. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.14038/0.30914. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.14144/0.32672. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.14299/0.30115. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.14154/0.29979. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.13843/0.30542. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.14124/0.32136. Took 0.14 sec\n",
      "Epoch 97, Loss(train/val) 0.13776/0.30606. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.13186/0.31062. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.13451/0.32791. Took 0.14 sec\n",
      "ACC: 0.65625, MCC: 0.24370871833797697\n",
      "Epoch 0, Loss(train/val) 0.49350/0.51212. Took 0.13 sec\n",
      "Epoch 1, Loss(train/val) 0.47227/0.50879. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.44185/0.45797. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.40930/0.39315. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.38274/0.36464. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.36204/0.37099. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.34288/0.33382. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.33449/0.37645. Took 0.15 sec\n",
      "Epoch 8, Loss(train/val) 0.31735/0.37842. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.31007/0.45557. Took 0.15 sec\n",
      "Epoch 10, Loss(train/val) 0.30225/0.48447. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.29164/0.41197. Took 0.16 sec\n",
      "Epoch 12, Loss(train/val) 0.29475/0.47099. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.28831/0.47146. Took 0.16 sec\n",
      "Epoch 14, Loss(train/val) 0.28059/0.37659. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.27877/0.48431. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.27147/0.44864. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.26797/0.47120. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.26537/0.45691. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.25935/0.46437. Took 0.15 sec\n",
      "Epoch 20, Loss(train/val) 0.25123/0.45070. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.24923/0.46315. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.24403/0.45643. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.23558/0.49865. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.23176/0.44294. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.22848/0.45611. Took 0.16 sec\n",
      "Epoch 26, Loss(train/val) 0.22130/0.43916. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.21691/0.43430. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.20781/0.47344. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.21100/0.47864. Took 0.16 sec\n",
      "Epoch 30, Loss(train/val) 0.20820/0.44855. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.19508/0.50593. Took 0.17 sec\n",
      "Epoch 32, Loss(train/val) 0.20030/0.48992. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.20344/0.44473. Took 0.16 sec\n",
      "Epoch 34, Loss(train/val) 0.19430/0.47273. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.19579/0.44670. Took 0.16 sec\n",
      "Epoch 36, Loss(train/val) 0.19425/0.43941. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.19348/0.46870. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.18600/0.47005. Took 0.15 sec\n",
      "Epoch 39, Loss(train/val) 0.18396/0.46279. Took 0.15 sec\n",
      "Epoch 40, Loss(train/val) 0.18038/0.44932. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.17723/0.42741. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.17533/0.46757. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.17270/0.48030. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.17141/0.46940. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.17182/0.40336. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.17333/0.48620. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.17295/0.46350. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.16593/0.43451. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.15963/0.45604. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.16619/0.43868. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.15722/0.44989. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.16068/0.46548. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.15661/0.41129. Took 0.15 sec\n",
      "Epoch 54, Loss(train/val) 0.15530/0.40002. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.15748/0.45135. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.15680/0.46345. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.15968/0.43856. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.15408/0.42777. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.15399/0.44310. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.15389/0.45326. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.15060/0.46705. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.14605/0.45612. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.14817/0.46941. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.14543/0.50218. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.15567/0.42142. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.15671/0.48775. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.14901/0.46459. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.13828/0.46737. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.14011/0.45995. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.14084/0.47542. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.13951/0.44712. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.13555/0.47027. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.13871/0.46234. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.14084/0.43354. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.13406/0.48803. Took 0.15 sec\n",
      "Epoch 76, Loss(train/val) 0.13233/0.44362. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.13563/0.49526. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.13164/0.46008. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.13365/0.43990. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.13946/0.45009. Took 0.14 sec\n",
      "Epoch 81, Loss(train/val) 0.13142/0.44842. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.13403/0.44811. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.13088/0.43807. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.12534/0.42546. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.12717/0.43561. Took 0.15 sec\n",
      "Epoch 86, Loss(train/val) 0.13044/0.45717. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.12749/0.43954. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.13086/0.44788. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.12860/0.42990. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.12575/0.41553. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.12369/0.46992. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.13014/0.44312. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.12776/0.43303. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.12651/0.44240. Took 0.14 sec\n",
      "Epoch 95, Loss(train/val) 0.12404/0.42000. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.12106/0.42917. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.12399/0.43686. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.12199/0.42303. Took 0.14 sec\n",
      "Epoch 99, Loss(train/val) 0.11764/0.43136. Took 0.15 sec\n",
      "ACC: 0.609375, MCC: 0.21199759950972125\n",
      "Epoch 0, Loss(train/val) 0.49805/0.49072. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.48014/0.48033. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.45242/0.46347. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.41787/0.45131. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.39152/0.44437. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.37742/0.43235. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.36383/0.42520. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.35701/0.41310. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.34132/0.44352. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.35328/0.46881. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.34394/0.44496. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.33632/0.44491. Took 0.15 sec\n",
      "Epoch 12, Loss(train/val) 0.32791/0.43880. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.31700/0.45049. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.31909/0.44206. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.30955/0.43476. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.31367/0.42529. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.29545/0.44302. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.31252/0.44240. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.29601/0.44134. Took 0.15 sec\n",
      "Epoch 20, Loss(train/val) 0.29395/0.42293. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.28249/0.43971. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.27208/0.43473. Took 0.15 sec\n",
      "Epoch 23, Loss(train/val) 0.28541/0.40491. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.27475/0.43180. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.26965/0.41235. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.26614/0.42853. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.26261/0.41940. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.25942/0.40237. Took 0.13 sec\n",
      "Epoch 29, Loss(train/val) 0.25241/0.43085. Took 0.13 sec\n",
      "Epoch 30, Loss(train/val) 0.24609/0.39514. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.24362/0.38413. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.23862/0.43017. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.24534/0.41916. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.24105/0.40775. Took 0.17 sec\n",
      "Epoch 35, Loss(train/val) 0.23073/0.40305. Took 0.15 sec\n",
      "Epoch 36, Loss(train/val) 0.23101/0.41570. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.22624/0.41168. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.22806/0.39966. Took 0.15 sec\n",
      "Epoch 39, Loss(train/val) 0.21868/0.40384. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.22343/0.40513. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.21555/0.40912. Took 0.17 sec\n",
      "Epoch 42, Loss(train/val) 0.21441/0.40781. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.21323/0.41045. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.20600/0.41788. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.20423/0.43508. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.20446/0.44472. Took 0.16 sec\n",
      "Epoch 47, Loss(train/val) 0.20087/0.43664. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.21411/0.40854. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.20239/0.44922. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.19819/0.42790. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.19661/0.44523. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.19313/0.44730. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) 0.20005/0.44266. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.19612/0.44214. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.20311/0.42388. Took 0.15 sec\n",
      "Epoch 56, Loss(train/val) 0.19319/0.44087. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.19339/0.44275. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.18281/0.43941. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.17928/0.41613. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.18015/0.41193. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.18043/0.41764. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.17754/0.42783. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.18337/0.42513. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.17841/0.44295. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.17664/0.42469. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.17346/0.41234. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.17490/0.42852. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.17553/0.42560. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.17118/0.41930. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.16422/0.42711. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.17374/0.42831. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.16193/0.42104. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.16371/0.43136. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.15533/0.42218. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.15349/0.42366. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.16402/0.40753. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.15960/0.41541. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.16140/0.41490. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.15275/0.41818. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.15259/0.42137. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.15364/0.41170. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.15561/0.40331. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.14870/0.40761. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.14838/0.41428. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.15123/0.40836. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.15434/0.39630. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.14231/0.40972. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.14813/0.38487. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.14236/0.40178. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.14752/0.40298. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.14831/0.39601. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.14159/0.40706. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.14469/0.39855. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.13533/0.41418. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.13525/0.41764. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.14589/0.40583. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.13797/0.41693. Took 0.15 sec\n",
      "Epoch 98, Loss(train/val) 0.13864/0.40785. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.13672/0.40535. Took 0.14 sec\n",
      "ACC: 0.640625, MCC: 0.3065084568545984\n",
      "Epoch 0, Loss(train/val) 0.49283/0.48784. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.47284/0.46305. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.43892/0.42817. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.40720/0.41020. Took 0.18 sec\n",
      "Epoch 4, Loss(train/val) 0.38629/0.36462. Took 0.16 sec\n",
      "Epoch 5, Loss(train/val) 0.37625/0.33424. Took 0.15 sec\n",
      "Epoch 6, Loss(train/val) 0.36398/0.33606. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.35669/0.32879. Took 0.15 sec\n",
      "Epoch 8, Loss(train/val) 0.34639/0.33783. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.33795/0.32040. Took 0.15 sec\n",
      "Epoch 10, Loss(train/val) 0.32887/0.33802. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.32170/0.36759. Took 0.16 sec\n",
      "Epoch 12, Loss(train/val) 0.31455/0.30462. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.31223/0.35645. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.30123/0.33504. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.30660/0.30459. Took 0.16 sec\n",
      "Epoch 16, Loss(train/val) 0.29212/0.30835. Took 0.16 sec\n",
      "Epoch 17, Loss(train/val) 0.29500/0.34187. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.28599/0.30977. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.29224/0.35014. Took 0.16 sec\n",
      "Epoch 20, Loss(train/val) 0.27853/0.28777. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.27446/0.32840. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.27358/0.34530. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.27218/0.31271. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.26486/0.29298. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.26940/0.35000. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.25554/0.33837. Took 0.13 sec\n",
      "Epoch 27, Loss(train/val) 0.25593/0.33816. Took 0.16 sec\n",
      "Epoch 28, Loss(train/val) 0.26020/0.34339. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.25699/0.33871. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.25098/0.35435. Took 0.16 sec\n",
      "Epoch 31, Loss(train/val) 0.25592/0.33827. Took 0.16 sec\n",
      "Epoch 32, Loss(train/val) 0.23704/0.34814. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.23760/0.34910. Took 0.16 sec\n",
      "Epoch 34, Loss(train/val) 0.22979/0.32033. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.23563/0.34613. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.22240/0.33395. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.22685/0.33372. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.22583/0.32236. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.22897/0.32157. Took 0.16 sec\n",
      "Epoch 40, Loss(train/val) 0.22502/0.33087. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.22706/0.32137. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.21813/0.31220. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.21271/0.33651. Took 0.15 sec\n",
      "Epoch 44, Loss(train/val) 0.21909/0.33588. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.22851/0.33508. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.22797/0.32555. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.20659/0.32392. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.20579/0.33310. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.20873/0.32263. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.20280/0.33620. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.20986/0.30026. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.20642/0.33006. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.20020/0.31151. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.18699/0.30590. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.19401/0.31430. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.19038/0.34013. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.19214/0.35213. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.19337/0.35181. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.18963/0.32331. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.19754/0.32080. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.19130/0.32326. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.20001/0.32080. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.19428/0.32790. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.18888/0.33176. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.19377/0.38329. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.19600/0.34347. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.19241/0.36501. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.17792/0.35776. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.17806/0.35725. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.17642/0.38057. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.17819/0.36606. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.17613/0.38525. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.16588/0.36192. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.16877/0.38333. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.16736/0.38697. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.17808/0.42960. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.17514/0.37055. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.17328/0.36985. Took 0.14 sec\n",
      "Epoch 79, Loss(train/val) 0.17352/0.40918. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.16941/0.36997. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.17083/0.43957. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.18191/0.37419. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.17148/0.39279. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.16877/0.37819. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.16278/0.35259. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.17180/0.42724. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.17112/0.40189. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.16759/0.40418. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.15680/0.39261. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.16214/0.35072. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.16701/0.35347. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.16405/0.38748. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.15928/0.36265. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.15406/0.36757. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.15187/0.37307. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.14282/0.36685. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.15021/0.37582. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.16090/0.38258. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.15586/0.36665. Took 0.15 sec\n",
      "ACC: 0.6875, MCC: 0.3578300267477955\n",
      "Epoch 0, Loss(train/val) 0.49614/0.49435. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.48007/0.47660. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.44864/0.42172. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.40539/0.38369. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.38377/0.35748. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.36350/0.34944. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.34910/0.37103. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.33840/0.34443. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.32725/0.36542. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.31763/0.36881. Took 0.15 sec\n",
      "Epoch 10, Loss(train/val) 0.32432/0.36718. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.30680/0.33320. Took 0.16 sec\n",
      "Epoch 12, Loss(train/val) 0.31010/0.33557. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.29465/0.37135. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.29398/0.34429. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.28995/0.37981. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.28725/0.41977. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.27655/0.40353. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.27273/0.32286. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.27690/0.32389. Took 0.15 sec\n",
      "Epoch 20, Loss(train/val) 0.27624/0.40939. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.27457/0.42540. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.26662/0.40569. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.25919/0.34560. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.26110/0.43647. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.26011/0.43466. Took 0.16 sec\n",
      "Epoch 26, Loss(train/val) 0.25840/0.38877. Took 0.13 sec\n",
      "Epoch 27, Loss(train/val) 0.25036/0.41286. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.23637/0.38639. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.23897/0.42607. Took 0.16 sec\n",
      "Epoch 30, Loss(train/val) 0.23298/0.41296. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.22969/0.41644. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.23662/0.43475. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.22710/0.44073. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.21791/0.44221. Took 0.16 sec\n",
      "Epoch 35, Loss(train/val) 0.22021/0.44214. Took 0.15 sec\n",
      "Epoch 36, Loss(train/val) 0.21809/0.44281. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.21949/0.43698. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.21082/0.42439. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.21839/0.43229. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.22225/0.41747. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.21053/0.43808. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.20381/0.43962. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.20690/0.42364. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.20142/0.41100. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.20108/0.40892. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.20533/0.43865. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.18773/0.41111. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.19636/0.44485. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.19035/0.40782. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.20253/0.42192. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.18668/0.43018. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.19197/0.43680. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.18859/0.42484. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.18748/0.42939. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.19125/0.43300. Took 0.15 sec\n",
      "Epoch 56, Loss(train/val) 0.17789/0.43790. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.18011/0.44121. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.17248/0.43868. Took 0.14 sec\n",
      "Epoch 59, Loss(train/val) 0.18069/0.42925. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.18215/0.40991. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.18171/0.41726. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.17856/0.41071. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.17387/0.41978. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.17548/0.42027. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.16616/0.42653. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.16406/0.42398. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.16778/0.39501. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.16096/0.42398. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.17080/0.44301. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.16184/0.42519. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.16297/0.41710. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.17100/0.42132. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.16825/0.43131. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.16517/0.42236. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.15993/0.43903. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.15665/0.42171. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.16282/0.41810. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.15656/0.41875. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.16136/0.42410. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.15491/0.42292. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.14884/0.40911. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.15046/0.40141. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.15079/0.41101. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.15244/0.39533. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.14840/0.38825. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.14719/0.40721. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.14546/0.39397. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.15452/0.38377. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.14750/0.39195. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.14601/0.38896. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.14306/0.41169. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.14133/0.40049. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.14317/0.39480. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.13319/0.41556. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.13890/0.40607. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.14092/0.40256. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.13894/0.41461. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.13778/0.40118. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.13804/0.43262. Took 0.14 sec\n",
      "ACC: 0.671875, MCC: 0.37070626838932386\n",
      "Epoch 0, Loss(train/val) 0.49432/0.48509. Took 0.16 sec\n",
      "Epoch 1, Loss(train/val) 0.47714/0.46179. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.44851/0.43090. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.41618/0.41692. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.39559/0.41150. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.38270/0.40502. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.36650/0.38364. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.35962/0.36512. Took 0.15 sec\n",
      "Epoch 8, Loss(train/val) 0.34923/0.35265. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.34601/0.34430. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.32852/0.27879. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.31778/0.32304. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.31310/0.32623. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.31293/0.28102. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.30904/0.28843. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.29446/0.28667. Took 0.16 sec\n",
      "Epoch 16, Loss(train/val) 0.29581/0.31432. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.28368/0.26642. Took 0.16 sec\n",
      "Epoch 18, Loss(train/val) 0.28420/0.32281. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.27458/0.31005. Took 0.15 sec\n",
      "Epoch 20, Loss(train/val) 0.26820/0.24965. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.27188/0.23516. Took 0.16 sec\n",
      "Epoch 22, Loss(train/val) 0.27572/0.25495. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.27519/0.29371. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.26884/0.30457. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.26723/0.27993. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.26862/0.25069. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.25549/0.27643. Took 0.16 sec\n",
      "Epoch 28, Loss(train/val) 0.24733/0.23836. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.25245/0.27686. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.24396/0.28205. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.24526/0.30351. Took 0.16 sec\n",
      "Epoch 32, Loss(train/val) 0.23690/0.24932. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.23974/0.26931. Took 0.16 sec\n",
      "Epoch 34, Loss(train/val) 0.23902/0.28289. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.23113/0.28096. Took 0.16 sec\n",
      "Epoch 36, Loss(train/val) 0.23368/0.25310. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.23675/0.27889. Took 0.17 sec\n",
      "Epoch 38, Loss(train/val) 0.24455/0.27514. Took 0.16 sec\n",
      "Epoch 39, Loss(train/val) 0.23645/0.30507. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.21784/0.32689. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.22746/0.32002. Took 0.17 sec\n",
      "Epoch 42, Loss(train/val) 0.21826/0.33318. Took 0.15 sec\n",
      "Epoch 43, Loss(train/val) 0.22084/0.31534. Took 0.16 sec\n",
      "Epoch 44, Loss(train/val) 0.21944/0.36442. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) 0.21629/0.35082. Took 0.15 sec\n",
      "Epoch 46, Loss(train/val) 0.21209/0.33373. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.22001/0.42553. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.21434/0.37651. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.21108/0.37716. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.20336/0.36445. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.20586/0.33215. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.20583/0.35778. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.19975/0.34133. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.20361/0.35789. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.20637/0.37559. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.19928/0.33631. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.20138/0.32298. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.19651/0.28029. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.19902/0.32461. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.20402/0.32677. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.20068/0.37195. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.19940/0.36040. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.19340/0.35695. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.19677/0.35693. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.19661/0.36782. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.18573/0.35368. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.18411/0.35764. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.18881/0.36656. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.18898/0.34291. Took 0.15 sec\n",
      "Epoch 70, Loss(train/val) 0.17818/0.30582. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.19068/0.32882. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.18860/0.35195. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.17619/0.35306. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.18667/0.36521. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.18476/0.36514. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.18296/0.35399. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.18307/0.35064. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.17130/0.36141. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.17688/0.32096. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.17269/0.31531. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.17741/0.32120. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.17813/0.33002. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.17810/0.34186. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.17218/0.35155. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.17337/0.33089. Took 0.15 sec\n",
      "Epoch 86, Loss(train/val) 0.16729/0.31720. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.17239/0.29667. Took 0.15 sec\n",
      "Epoch 88, Loss(train/val) 0.18035/0.35985. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.17105/0.29649. Took 0.15 sec\n",
      "Epoch 90, Loss(train/val) 0.16688/0.35027. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.16874/0.39590. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.17017/0.31242. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.16394/0.32205. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.16281/0.33942. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.16955/0.29944. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.16490/0.32638. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.17028/0.33043. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.17040/0.32705. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.16555/0.31968. Took 0.13 sec\n",
      "ACC: 0.734375, MCC: 0.46728681053303844\n",
      "Epoch 0, Loss(train/val) 0.49493/0.47222. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.47713/0.41105. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.44456/0.32040. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.40887/0.26888. Took 0.15 sec\n",
      "Epoch 4, Loss(train/val) 0.38114/0.25750. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.35827/0.24631. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.34909/0.23805. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.33211/0.23702. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.31489/0.29223. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.30686/0.26868. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.29923/0.24691. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.29932/0.25359. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.29555/0.23729. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.29030/0.23566. Took 0.16 sec\n",
      "Epoch 14, Loss(train/val) 0.28129/0.26621. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.27039/0.29440. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.28011/0.25623. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.26868/0.25811. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.26026/0.24752. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.26064/0.24963. Took 0.15 sec\n",
      "Epoch 20, Loss(train/val) 0.25794/0.24527. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.25835/0.24224. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.25533/0.26453. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.25885/0.27759. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.24480/0.26004. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.25288/0.26366. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.24627/0.25483. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.24722/0.25685. Took 0.16 sec\n",
      "Epoch 28, Loss(train/val) 0.24283/0.24808. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.23235/0.24604. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.24406/0.24313. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.23451/0.25543. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.23827/0.28862. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.23634/0.30951. Took 0.16 sec\n",
      "Epoch 34, Loss(train/val) 0.24436/0.28925. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.23921/0.25745. Took 0.18 sec\n",
      "Epoch 36, Loss(train/val) 0.22520/0.26587. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.22520/0.27227. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.23622/0.26794. Took 0.16 sec\n",
      "Epoch 39, Loss(train/val) 0.23304/0.28210. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.22638/0.29522. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.21842/0.27595. Took 0.16 sec\n",
      "Epoch 42, Loss(train/val) 0.21766/0.28876. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.21672/0.26055. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.22101/0.25016. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.21978/0.26653. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.23190/0.27273. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.23433/0.27520. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.21181/0.22889. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.20888/0.28907. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.20805/0.26688. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.20825/0.28452. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.21553/0.28506. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.20599/0.27811. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.20845/0.24158. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.20223/0.28384. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.21125/0.26330. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.19438/0.25360. Took 0.15 sec\n",
      "Epoch 58, Loss(train/val) 0.19394/0.25878. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.19436/0.25906. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.19523/0.27732. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.20546/0.30516. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.22230/0.32102. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.19871/0.28347. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.22152/0.31829. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.21025/0.25597. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.19301/0.26482. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.19015/0.26545. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.19233/0.28651. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.19470/0.25926. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.18043/0.28789. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.18058/0.28124. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.19007/0.27222. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.18490/0.27529. Took 0.15 sec\n",
      "Epoch 74, Loss(train/val) 0.18534/0.27257. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) 0.18177/0.24999. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.17912/0.24358. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.18262/0.27745. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.17920/0.29659. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.18427/0.24808. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.17959/0.29033. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.17726/0.26507. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.20145/0.26405. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.18729/0.28412. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.18445/0.23581. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.17584/0.27140. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.17756/0.24508. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.17619/0.24452. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.16877/0.24440. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.17218/0.25842. Took 0.15 sec\n",
      "Epoch 90, Loss(train/val) 0.17637/0.28793. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.16956/0.26684. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.16079/0.28480. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.17461/0.24807. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.17052/0.26797. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.16670/0.25876. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.17084/0.27592. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.16830/0.28036. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.16201/0.25258. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.16862/0.25179. Took 0.14 sec\n",
      "ACC: 0.640625, MCC: 0.2771507137113173\n",
      "Epoch 0, Loss(train/val) 0.49202/0.49093. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.47115/0.46486. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.43734/0.42522. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.40512/0.39789. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.38618/0.37274. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.37773/0.37296. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.36313/0.35506. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.35398/0.37079. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.33871/0.35783. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.32923/0.33480. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.32466/0.32306. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.31244/0.31471. Took 0.16 sec\n",
      "Epoch 12, Loss(train/val) 0.31160/0.30220. Took 0.17 sec\n",
      "Epoch 13, Loss(train/val) 0.30586/0.30188. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.30119/0.28678. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.29097/0.30944. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.29237/0.29169. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.28768/0.29049. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.27966/0.28890. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.27254/0.30962. Took 0.16 sec\n",
      "Epoch 20, Loss(train/val) 0.27979/0.34600. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.27854/0.29578. Took 0.16 sec\n",
      "Epoch 22, Loss(train/val) 0.27509/0.28887. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.26855/0.25974. Took 0.16 sec\n",
      "Epoch 24, Loss(train/val) 0.26078/0.27166. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.25498/0.26619. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.26044/0.31256. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.27063/0.29604. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.26134/0.30473. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.25089/0.29192. Took 0.16 sec\n",
      "Epoch 30, Loss(train/val) 0.24466/0.28381. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.23762/0.28407. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.24188/0.32687. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.23984/0.29118. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.23319/0.31581. Took 0.16 sec\n",
      "Epoch 35, Loss(train/val) 0.23501/0.29820. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.24022/0.29740. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.22919/0.31260. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.23259/0.29451. Took 0.16 sec\n",
      "Epoch 39, Loss(train/val) 0.21600/0.30047. Took 0.16 sec\n",
      "Epoch 40, Loss(train/val) 0.21678/0.28759. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.22386/0.28884. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.21659/0.29130. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.21231/0.29073. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.21394/0.32938. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) 0.21854/0.31070. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.21896/0.29440. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.21370/0.28415. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.21281/0.30735. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.20466/0.30126. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.19483/0.29238. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.20616/0.29431. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.19845/0.29800. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.20121/0.30034. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.20533/0.28249. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.19784/0.28280. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.20252/0.29125. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.19336/0.30175. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.19980/0.29875. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.18956/0.30403. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.18668/0.32612. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.19370/0.30747. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.18345/0.30263. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.18735/0.31518. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.18170/0.32613. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.18967/0.31987. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.18603/0.31336. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) 0.18435/0.30367. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.18516/0.30594. Took 0.14 sec\n",
      "Epoch 69, Loss(train/val) 0.17758/0.31252. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.17794/0.32126. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.17105/0.33773. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.17502/0.29500. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.18298/0.31698. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.17103/0.29870. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.17069/0.32845. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.18374/0.31452. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.18246/0.29353. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.17468/0.30549. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.17208/0.30606. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.16972/0.30504. Took 0.14 sec\n",
      "Epoch 81, Loss(train/val) 0.18144/0.32611. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.17236/0.30864. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.16069/0.32350. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.16446/0.32321. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.16672/0.31257. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.15575/0.30610. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.16344/0.30722. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.16271/0.32668. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.16130/0.33366. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.15986/0.33864. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.15981/0.31021. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.16208/0.30573. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.17247/0.32613. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.15732/0.31173. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.15201/0.29851. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.14680/0.29378. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.15382/0.31430. Took 0.15 sec\n",
      "Epoch 98, Loss(train/val) 0.15794/0.32976. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.15813/0.31564. Took 0.14 sec\n",
      "ACC: 0.75, MCC: 0.5058823529411764\n",
      "Epoch 0, Loss(train/val) 0.49323/0.48447. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.47455/0.45584. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.44314/0.41987. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.41054/0.39484. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.38851/0.38030. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.37424/0.36762. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.36357/0.34590. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.35346/0.33015. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.33663/0.31172. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.31829/0.30108. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.31921/0.28434. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.30765/0.28774. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.29662/0.29875. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.29277/0.28650. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.28683/0.33132. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.27909/0.30896. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.28374/0.35860. Took 0.15 sec\n",
      "Epoch 17, Loss(train/val) 0.29773/0.31733. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.27618/0.29853. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.27921/0.31558. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.27692/0.30320. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.26641/0.31371. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.26547/0.32134. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.25912/0.29498. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.26266/0.28437. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.26346/0.28687. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.25075/0.28488. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.24642/0.29172. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.23997/0.28070. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.23495/0.27610. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.23503/0.27927. Took 0.13 sec\n",
      "Epoch 31, Loss(train/val) 0.23217/0.28672. Took 0.13 sec\n",
      "Epoch 32, Loss(train/val) 0.23238/0.29149. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.23775/0.27246. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.22446/0.28367. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.21462/0.31297. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.22087/0.29749. Took 0.16 sec\n",
      "Epoch 37, Loss(train/val) 0.22406/0.27128. Took 0.16 sec\n",
      "Epoch 38, Loss(train/val) 0.20261/0.29169. Took 0.15 sec\n",
      "Epoch 39, Loss(train/val) 0.20779/0.30409. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.22147/0.29185. Took 0.16 sec\n",
      "Epoch 41, Loss(train/val) 0.21874/0.29438. Took 0.15 sec\n",
      "Epoch 42, Loss(train/val) 0.20833/0.30641. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.21454/0.37360. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.21697/0.33375. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) 0.22434/0.31295. Took 0.16 sec\n",
      "Epoch 46, Loss(train/val) 0.20054/0.26315. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.20429/0.26437. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.19197/0.26170. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.21041/0.31718. Took 0.15 sec\n",
      "Epoch 50, Loss(train/val) 0.20148/0.30259. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.19531/0.26734. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.19264/0.27238. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.19057/0.26913. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.19624/0.28765. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.18084/0.29470. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.19371/0.32919. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.18963/0.28825. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.19066/0.31369. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.18371/0.27545. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.18178/0.28690. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.17386/0.27820. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.17611/0.31214. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.17298/0.29556. Took 0.15 sec\n",
      "Epoch 64, Loss(train/val) 0.16660/0.29299. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.18109/0.28690. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.17293/0.28590. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.17498/0.30948. Took 0.15 sec\n",
      "Epoch 68, Loss(train/val) 0.17232/0.31279. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.17790/0.31524. Took 0.15 sec\n",
      "Epoch 70, Loss(train/val) 0.16546/0.28075. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.16589/0.31441. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.16744/0.31360. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.16001/0.31151. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.15661/0.30338. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.16205/0.29336. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.16209/0.30373. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.16627/0.27818. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.16282/0.29505. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.15515/0.31122. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.15361/0.28427. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.15980/0.31361. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.15886/0.32628. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.15250/0.30195. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.15375/0.32092. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.16293/0.31027. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.15182/0.30863. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.14936/0.31983. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.16305/0.28974. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.15576/0.30991. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.14984/0.36636. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.15405/0.30546. Took 0.15 sec\n",
      "Epoch 92, Loss(train/val) 0.14874/0.32341. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.14560/0.31757. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.14414/0.32315. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.14196/0.32820. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.14532/0.31927. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.13815/0.31463. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.13281/0.33383. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.13390/0.33979. Took 0.14 sec\n",
      "ACC: 0.703125, MCC: 0.414743266617645\n",
      "Epoch 0, Loss(train/val) 0.49542/0.48513. Took 0.16 sec\n",
      "Epoch 1, Loss(train/val) 0.48091/0.45838. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.45432/0.42200. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.41901/0.40134. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.39769/0.39088. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.37952/0.36217. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.35934/0.34203. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.34378/0.33761. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.33867/0.31670. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.32198/0.31892. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.31806/0.30429. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.30101/0.31267. Took 0.15 sec\n",
      "Epoch 12, Loss(train/val) 0.30652/0.31832. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.29268/0.31601. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.29487/0.30279. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.28919/0.33524. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.28724/0.31593. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.28001/0.31148. Took 0.16 sec\n",
      "Epoch 18, Loss(train/val) 0.28611/0.30433. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.27255/0.30048. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.27886/0.33341. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.28568/0.32293. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.27157/0.31970. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.26885/0.31342. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.26513/0.30147. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.26344/0.28222. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.25405/0.30687. Took 0.15 sec\n",
      "Epoch 27, Loss(train/val) 0.26090/0.29027. Took 0.21 sec\n",
      "Epoch 28, Loss(train/val) 0.25128/0.31973. Took 0.16 sec\n",
      "Epoch 29, Loss(train/val) 0.25523/0.32814. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.24496/0.30519. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.24774/0.30714. Took 0.17 sec\n",
      "Epoch 32, Loss(train/val) 0.24997/0.29503. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.26264/0.30181. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.23384/0.32210. Took 0.19 sec\n",
      "Epoch 35, Loss(train/val) 0.23327/0.31354. Took 0.20 sec\n",
      "Epoch 36, Loss(train/val) 0.23424/0.30831. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.24485/0.31447. Took 0.16 sec\n",
      "Epoch 38, Loss(train/val) 0.23112/0.30818. Took 0.15 sec\n",
      "Epoch 39, Loss(train/val) 0.23583/0.30675. Took 0.17 sec\n",
      "Epoch 40, Loss(train/val) 0.22578/0.30412. Took 0.15 sec\n",
      "Epoch 41, Loss(train/val) 0.22286/0.30279. Took 0.16 sec\n",
      "Epoch 42, Loss(train/val) 0.23390/0.30967. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.23284/0.29518. Took 0.15 sec\n",
      "Epoch 44, Loss(train/val) 0.22481/0.30845. Took 0.15 sec\n",
      "Epoch 45, Loss(train/val) 0.23211/0.30221. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.21988/0.30540. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.22105/0.31146. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.21991/0.29854. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.21960/0.31750. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.21994/0.31192. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.21252/0.30736. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.20772/0.30725. Took 0.15 sec\n",
      "Epoch 53, Loss(train/val) 0.20635/0.30804. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.20536/0.30966. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.21511/0.31447. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.20270/0.32530. Took 0.15 sec\n",
      "Epoch 57, Loss(train/val) 0.19827/0.31260. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.20187/0.30620. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.19708/0.31713. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.20444/0.31474. Took 0.14 sec\n",
      "Epoch 61, Loss(train/val) 0.19452/0.31212. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.21026/0.33114. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.19536/0.31115. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.19721/0.31316. Took 0.15 sec\n",
      "Epoch 65, Loss(train/val) 0.19080/0.31002. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.19170/0.32046. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) 0.19420/0.30601. Took 0.15 sec\n",
      "Epoch 68, Loss(train/val) 0.19473/0.31230. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.19905/0.32464. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.19572/0.31835. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.18417/0.32378. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.17512/0.31937. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.18665/0.31790. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.17783/0.32554. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.20351/0.30789. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.18174/0.31519. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.18702/0.31683. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.17816/0.29430. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.17809/0.32410. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.18559/0.30512. Took 0.15 sec\n",
      "Epoch 81, Loss(train/val) 0.18522/0.28664. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.18163/0.29754. Took 0.15 sec\n",
      "Epoch 83, Loss(train/val) 0.17821/0.30202. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.18097/0.31594. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.18259/0.31940. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.17406/0.32108. Took 0.15 sec\n",
      "Epoch 87, Loss(train/val) 0.17643/0.32314. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.17977/0.31825. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.17578/0.32065. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.17407/0.32234. Took 0.14 sec\n",
      "Epoch 91, Loss(train/val) 0.17101/0.32410. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.17977/0.32233. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.16738/0.31881. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.16602/0.31437. Took 0.15 sec\n",
      "Epoch 95, Loss(train/val) 0.17163/0.31812. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.17573/0.32249. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.16595/0.31488. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.16388/0.32744. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.16600/0.32587. Took 0.13 sec\n",
      "ACC: 0.765625, MCC: 0.5345086526345906\n",
      "Epoch 0, Loss(train/val) 0.49562/0.48444. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.47943/0.45714. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.45101/0.41564. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.41840/0.36066. Took 0.15 sec\n",
      "Epoch 4, Loss(train/val) 0.39654/0.33459. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.38357/0.29369. Took 0.15 sec\n",
      "Epoch 6, Loss(train/val) 0.37175/0.29406. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.34663/0.29027. Took 0.15 sec\n",
      "Epoch 8, Loss(train/val) 0.32249/0.28992. Took 0.16 sec\n",
      "Epoch 9, Loss(train/val) 0.30996/0.29291. Took 0.16 sec\n",
      "Epoch 10, Loss(train/val) 0.30976/0.29312. Took 0.15 sec\n",
      "Epoch 11, Loss(train/val) 0.30388/0.28065. Took 0.16 sec\n",
      "Epoch 12, Loss(train/val) 0.29781/0.28401. Took 0.16 sec\n",
      "Epoch 13, Loss(train/val) 0.28852/0.28786. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.28042/0.26277. Took 0.15 sec\n",
      "Epoch 15, Loss(train/val) 0.27864/0.28290. Took 0.18 sec\n",
      "Epoch 16, Loss(train/val) 0.27848/0.28032. Took 0.17 sec\n",
      "Epoch 17, Loss(train/val) 0.26955/0.32822. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.27092/0.30561. Took 0.15 sec\n",
      "Epoch 19, Loss(train/val) 0.26507/0.30820. Took 0.16 sec\n",
      "Epoch 20, Loss(train/val) 0.26940/0.31846. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.25540/0.32935. Took 0.17 sec\n",
      "Epoch 22, Loss(train/val) 0.25111/0.29111. Took 0.17 sec\n",
      "Epoch 23, Loss(train/val) 0.26754/0.35050. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.25325/0.33285. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.24902/0.29768. Took 0.16 sec\n",
      "Epoch 26, Loss(train/val) 0.24376/0.29254. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.26128/0.28327. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.23314/0.28220. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.23571/0.29241. Took 0.16 sec\n",
      "Epoch 30, Loss(train/val) 0.22959/0.29846. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.23090/0.29229. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.23064/0.29247. Took 0.16 sec\n",
      "Epoch 33, Loss(train/val) 0.22008/0.29339. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.21381/0.29997. Took 0.16 sec\n",
      "Epoch 35, Loss(train/val) 0.22034/0.29427. Took 0.15 sec\n",
      "Epoch 36, Loss(train/val) 0.23028/0.29296. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.21929/0.29557. Took 0.15 sec\n",
      "Epoch 38, Loss(train/val) 0.23126/0.27978. Took 0.17 sec\n",
      "Epoch 39, Loss(train/val) 0.22560/0.28276. Took 0.15 sec\n",
      "Epoch 40, Loss(train/val) 0.22156/0.27976. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.21496/0.28469. Took 0.16 sec\n",
      "Epoch 42, Loss(train/val) 0.21726/0.28592. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.20705/0.28930. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.20789/0.27486. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) 0.20406/0.27135. Took 0.15 sec\n",
      "Epoch 46, Loss(train/val) 0.21075/0.27722. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.20089/0.27753. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.20728/0.27596. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.21428/0.27991. Took 0.16 sec\n",
      "Epoch 50, Loss(train/val) 0.19621/0.28987. Took 0.15 sec\n",
      "Epoch 51, Loss(train/val) 0.19249/0.29815. Took 0.16 sec\n",
      "Epoch 52, Loss(train/val) 0.20321/0.29381. Took 0.15 sec\n",
      "Epoch 53, Loss(train/val) 0.19425/0.28313. Took 0.16 sec\n",
      "Epoch 54, Loss(train/val) 0.19611/0.27605. Took 0.15 sec\n",
      "Epoch 55, Loss(train/val) 0.19380/0.28252. Took 0.17 sec\n",
      "Epoch 56, Loss(train/val) 0.18819/0.28001. Took 0.15 sec\n",
      "Epoch 57, Loss(train/val) 0.19662/0.28662. Took 0.15 sec\n",
      "Epoch 58, Loss(train/val) 0.20697/0.29796. Took 0.14 sec\n",
      "Epoch 59, Loss(train/val) 0.18789/0.28795. Took 0.17 sec\n",
      "Epoch 60, Loss(train/val) 0.18078/0.28264. Took 0.15 sec\n",
      "Epoch 61, Loss(train/val) 0.18842/0.28419. Took 0.15 sec\n",
      "Epoch 62, Loss(train/val) 0.18216/0.29487. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.17180/0.28599. Took 0.15 sec\n",
      "Epoch 64, Loss(train/val) 0.18105/0.27581. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.19188/0.31736. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.18917/0.30374. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.17894/0.28347. Took 0.15 sec\n",
      "Epoch 68, Loss(train/val) 0.17807/0.29277. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.16988/0.28515. Took 0.16 sec\n",
      "Epoch 70, Loss(train/val) 0.17460/0.28830. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.18446/0.28063. Took 0.15 sec\n",
      "Epoch 72, Loss(train/val) 0.18375/0.33502. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.17908/0.29527. Took 0.15 sec\n",
      "Epoch 74, Loss(train/val) 0.17316/0.31737. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.16353/0.30650. Took 0.15 sec\n",
      "Epoch 76, Loss(train/val) 0.17064/0.28510. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.17184/0.29387. Took 0.15 sec\n",
      "Epoch 78, Loss(train/val) 0.16552/0.29508. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.16905/0.28094. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.16679/0.29876. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.16244/0.26397. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.16443/0.28663. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.16521/0.34558. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.17128/0.32037. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.16937/0.30911. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.15655/0.29845. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.15931/0.29560. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.16001/0.31582. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.16736/0.33062. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.16631/0.29080. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.16917/0.32886. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.15031/0.32241. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.15890/0.32968. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.15713/0.31432. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.15242/0.29017. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.15153/0.28652. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.15949/0.29611. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.15571/0.29244. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.16152/0.34595. Took 0.14 sec\n",
      "ACC: 0.671875, MCC: 0.233856117159244\n",
      "Epoch 0, Loss(train/val) 0.49572/0.48180. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.48186/0.45741. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.45537/0.41343. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.41713/0.38974. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.38677/0.40078. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.36228/0.40385. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.35557/0.37853. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.34019/0.34984. Took 0.16 sec\n",
      "Epoch 8, Loss(train/val) 0.32427/0.33847. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.32441/0.35717. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.30039/0.33808. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.30947/0.35598. Took 0.16 sec\n",
      "Epoch 12, Loss(train/val) 0.30313/0.33840. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.30467/0.31810. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.29526/0.31493. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.28802/0.34548. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.28809/0.34454. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.27660/0.34987. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.28668/0.34081. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.28057/0.33460. Took 0.15 sec\n",
      "Epoch 20, Loss(train/val) 0.27397/0.30846. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.27163/0.36249. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.26695/0.35717. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.26198/0.31263. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.26000/0.32285. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.24611/0.35360. Took 0.16 sec\n",
      "Epoch 26, Loss(train/val) 0.24835/0.35451. Took 0.15 sec\n",
      "Epoch 27, Loss(train/val) 0.24906/0.32572. Took 0.13 sec\n",
      "Epoch 28, Loss(train/val) 0.24935/0.36397. Took 0.17 sec\n",
      "Epoch 29, Loss(train/val) 0.24033/0.34675. Took 0.16 sec\n",
      "Epoch 30, Loss(train/val) 0.24186/0.35360. Took 0.16 sec\n",
      "Epoch 31, Loss(train/val) 0.23020/0.36808. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.22753/0.34063. Took 0.18 sec\n",
      "Epoch 33, Loss(train/val) 0.22071/0.33380. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.23612/0.31600. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.22826/0.35261. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.21722/0.31662. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.22425/0.31377. Took 0.16 sec\n",
      "Epoch 38, Loss(train/val) 0.23134/0.37347. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.21591/0.35892. Took 0.15 sec\n",
      "Epoch 40, Loss(train/val) 0.21712/0.37972. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.21004/0.37463. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.21519/0.35978. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.21223/0.37075. Took 0.15 sec\n",
      "Epoch 44, Loss(train/val) 0.20243/0.36500. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.20797/0.37327. Took 0.16 sec\n",
      "Epoch 46, Loss(train/val) 0.21614/0.32386. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.20427/0.37059. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.20130/0.36781. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.19924/0.37908. Took 0.15 sec\n",
      "Epoch 50, Loss(train/val) 0.19604/0.39140. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.19596/0.37492. Took 0.15 sec\n",
      "Epoch 52, Loss(train/val) 0.19038/0.37222. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.19173/0.35667. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.18722/0.37779. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.19540/0.36174. Took 0.15 sec\n",
      "Epoch 56, Loss(train/val) 0.19241/0.37401. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.18732/0.36914. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.18536/0.37490. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.17616/0.38170. Took 0.15 sec\n",
      "Epoch 60, Loss(train/val) 0.18810/0.36451. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.18609/0.34833. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.18273/0.37305. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.17481/0.36621. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.17267/0.38937. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.17124/0.37532. Took 0.15 sec\n",
      "Epoch 66, Loss(train/val) 0.17846/0.37178. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.16387/0.38538. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.16960/0.37122. Took 0.14 sec\n",
      "Epoch 69, Loss(train/val) 0.17153/0.36267. Took 0.16 sec\n",
      "Epoch 70, Loss(train/val) 0.16637/0.37146. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.16716/0.37345. Took 0.15 sec\n",
      "Epoch 72, Loss(train/val) 0.15968/0.36925. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.15765/0.35849. Took 0.15 sec\n",
      "Epoch 74, Loss(train/val) 0.16268/0.38511. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.16037/0.37224. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.15777/0.37229. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.15876/0.36337. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.15114/0.38274. Took 0.15 sec\n",
      "Epoch 79, Loss(train/val) 0.15110/0.36643. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.15482/0.37366. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.14910/0.37942. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.15217/0.39688. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) 0.14699/0.36987. Took 0.15 sec\n",
      "Epoch 84, Loss(train/val) 0.14647/0.36279. Took 0.15 sec\n",
      "Epoch 85, Loss(train/val) 0.15170/0.37727. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.13975/0.38242. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.13993/0.37045. Took 0.15 sec\n",
      "Epoch 88, Loss(train/val) 0.14365/0.37055. Took 0.15 sec\n",
      "Epoch 89, Loss(train/val) 0.14339/0.36946. Took 0.17 sec\n",
      "Epoch 90, Loss(train/val) 0.14245/0.37780. Took 0.14 sec\n",
      "Epoch 91, Loss(train/val) 0.14059/0.37953. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.14284/0.38885. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.13484/0.38879. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.13777/0.38073. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.14015/0.37985. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.13643/0.38487. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.13052/0.39382. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.13418/0.41001. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.13403/0.41173. Took 0.14 sec\n",
      "ACC: 0.640625, MCC: 0.28049997001672616\n",
      "Epoch 0, Loss(train/val) 0.49636/0.48775. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.47710/0.46553. Took 0.16 sec\n",
      "Epoch 2, Loss(train/val) 0.44598/0.43107. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.41142/0.40627. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.39076/0.38271. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.37818/0.37507. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.36045/0.36579. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.34578/0.36930. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.34133/0.36318. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.32736/0.35836. Took 0.16 sec\n",
      "Epoch 10, Loss(train/val) 0.32691/0.34924. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.31483/0.36218. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.32290/0.36311. Took 0.15 sec\n",
      "Epoch 13, Loss(train/val) 0.30915/0.36300. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.30357/0.36372. Took 0.15 sec\n",
      "Epoch 15, Loss(train/val) 0.29698/0.38638. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.29800/0.35735. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.28631/0.35302. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.28511/0.34671. Took 0.15 sec\n",
      "Epoch 19, Loss(train/val) 0.28111/0.33888. Took 0.16 sec\n",
      "Epoch 20, Loss(train/val) 0.27994/0.34541. Took 0.15 sec\n",
      "Epoch 21, Loss(train/val) 0.27903/0.34887. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.26764/0.37589. Took 0.15 sec\n",
      "Epoch 23, Loss(train/val) 0.27240/0.34654. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.26919/0.36943. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.28238/0.35477. Took 0.16 sec\n",
      "Epoch 26, Loss(train/val) 0.29559/0.43724. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.26022/0.35653. Took 0.16 sec\n",
      "Epoch 28, Loss(train/val) 0.26743/0.36696. Took 0.16 sec\n",
      "Epoch 29, Loss(train/val) 0.27122/0.37670. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.26467/0.34897. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.25667/0.35970. Took 0.17 sec\n",
      "Epoch 32, Loss(train/val) 0.24975/0.39234. Took 0.16 sec\n",
      "Epoch 33, Loss(train/val) 0.25331/0.38656. Took 0.17 sec\n",
      "Epoch 34, Loss(train/val) 0.25283/0.39092. Took 0.18 sec\n",
      "Epoch 35, Loss(train/val) 0.23809/0.41806. Took 0.21 sec\n",
      "Epoch 36, Loss(train/val) 0.24413/0.35292. Took 0.19 sec\n",
      "Epoch 37, Loss(train/val) 0.24338/0.34401. Took 0.17 sec\n",
      "Epoch 38, Loss(train/val) 0.24246/0.35235. Took 0.15 sec\n",
      "Epoch 39, Loss(train/val) 0.23393/0.36830. Took 0.15 sec\n",
      "Epoch 40, Loss(train/val) 0.23627/0.37279. Took 0.17 sec\n",
      "Epoch 41, Loss(train/val) 0.25707/0.36399. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.22992/0.36970. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.23888/0.38541. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.22439/0.38253. Took 0.15 sec\n",
      "Epoch 45, Loss(train/val) 0.22830/0.37141. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.22116/0.40044. Took 0.15 sec\n",
      "Epoch 47, Loss(train/val) 0.23153/0.38516. Took 0.16 sec\n",
      "Epoch 48, Loss(train/val) 0.22641/0.39473. Took 0.18 sec\n",
      "Epoch 49, Loss(train/val) 0.22848/0.41874. Took 0.15 sec\n",
      "Epoch 50, Loss(train/val) 0.22751/0.39735. Took 0.15 sec\n",
      "Epoch 51, Loss(train/val) 0.21719/0.38502. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.21163/0.40184. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) 0.21131/0.39431. Took 0.16 sec\n",
      "Epoch 54, Loss(train/val) 0.22163/0.39350. Took 0.16 sec\n",
      "Epoch 55, Loss(train/val) 0.21161/0.39358. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.20397/0.39178. Took 0.15 sec\n",
      "Epoch 57, Loss(train/val) 0.22030/0.39959. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.21568/0.40023. Took 0.18 sec\n",
      "Epoch 59, Loss(train/val) 0.21024/0.39663. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.21063/0.40410. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.20296/0.39530. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.19635/0.39812. Took 0.15 sec\n",
      "Epoch 63, Loss(train/val) 0.20086/0.39580. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.20740/0.40960. Took 0.16 sec\n",
      "Epoch 65, Loss(train/val) 0.19540/0.40520. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.19914/0.39892. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) 0.20205/0.39874. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.21554/0.38794. Took 0.15 sec\n",
      "Epoch 69, Loss(train/val) 0.20824/0.37951. Took 0.15 sec\n",
      "Epoch 70, Loss(train/val) 0.20931/0.41489. Took 0.15 sec\n",
      "Epoch 71, Loss(train/val) 0.19239/0.40842. Took 0.15 sec\n",
      "Epoch 72, Loss(train/val) 0.19590/0.40962. Took 0.16 sec\n",
      "Epoch 73, Loss(train/val) 0.19372/0.41285. Took 0.16 sec\n",
      "Epoch 74, Loss(train/val) 0.19252/0.41311. Took 0.16 sec\n",
      "Epoch 75, Loss(train/val) 0.19211/0.41022. Took 0.16 sec\n",
      "Epoch 76, Loss(train/val) 0.18987/0.39355. Took 0.15 sec\n",
      "Epoch 77, Loss(train/val) 0.18413/0.39777. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.19398/0.38057. Took 0.14 sec\n",
      "Epoch 79, Loss(train/val) 0.20782/0.40129. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.18597/0.40520. Took 0.14 sec\n",
      "Epoch 81, Loss(train/val) 0.19037/0.39744. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.17762/0.41361. Took 0.15 sec\n",
      "Epoch 83, Loss(train/val) 0.18640/0.39210. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.18741/0.42964. Took 0.15 sec\n",
      "Epoch 85, Loss(train/val) 0.18609/0.42078. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.18968/0.42405. Took 0.16 sec\n",
      "Epoch 87, Loss(train/val) 0.17923/0.43583. Took 0.16 sec\n",
      "Epoch 88, Loss(train/val) 0.17894/0.39334. Took 0.14 sec\n",
      "Epoch 89, Loss(train/val) 0.17908/0.39570. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.18345/0.38735. Took 0.15 sec\n",
      "Epoch 91, Loss(train/val) 0.19296/0.40264. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.18265/0.38546. Took 0.15 sec\n",
      "Epoch 93, Loss(train/val) 0.18459/0.38950. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.17806/0.40137. Took 0.14 sec\n",
      "Epoch 95, Loss(train/val) 0.16886/0.40410. Took 0.15 sec\n",
      "Epoch 96, Loss(train/val) 0.16983/0.40677. Took 0.16 sec\n",
      "Epoch 97, Loss(train/val) 0.17557/0.40005. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.16251/0.42345. Took 0.15 sec\n",
      "Epoch 99, Loss(train/val) 0.16937/0.44424. Took 0.15 sec\n",
      "ACC: 0.640625, MCC: 0.2933526131391837\n",
      "Epoch 0, Loss(train/val) 0.49520/0.48420. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.47224/0.45464. Took 0.15 sec\n",
      "Epoch 2, Loss(train/val) 0.44155/0.43500. Took 0.16 sec\n",
      "Epoch 3, Loss(train/val) 0.40832/0.42741. Took 0.19 sec\n",
      "Epoch 4, Loss(train/val) 0.38225/0.42253. Took 0.21 sec\n",
      "Epoch 5, Loss(train/val) 0.36486/0.40955. Took 0.15 sec\n",
      "Epoch 6, Loss(train/val) 0.35168/0.40905. Took 0.15 sec\n",
      "Epoch 7, Loss(train/val) 0.34865/0.42015. Took 0.21 sec\n",
      "Epoch 8, Loss(train/val) 0.34444/0.39167. Took 0.20 sec\n",
      "Epoch 9, Loss(train/val) 0.33331/0.41494. Took 0.20 sec\n",
      "Epoch 10, Loss(train/val) 0.33314/0.39723. Took 0.15 sec\n",
      "Epoch 11, Loss(train/val) 0.31954/0.40985. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.31118/0.41013. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.30724/0.38102. Took 0.16 sec\n",
      "Epoch 14, Loss(train/val) 0.30612/0.40071. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.29443/0.39080. Took 0.17 sec\n",
      "Epoch 16, Loss(train/val) 0.29209/0.39688. Took 0.15 sec\n",
      "Epoch 17, Loss(train/val) 0.29055/0.39327. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.27697/0.38518. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.27623/0.38564. Took 0.16 sec\n",
      "Epoch 20, Loss(train/val) 0.27211/0.38414. Took 0.18 sec\n",
      "Epoch 21, Loss(train/val) 0.26676/0.38109. Took 0.17 sec\n",
      "Epoch 22, Loss(train/val) 0.26209/0.37810. Took 0.18 sec\n",
      "Epoch 23, Loss(train/val) 0.25852/0.38046. Took 0.16 sec\n",
      "Epoch 24, Loss(train/val) 0.25209/0.36597. Took 0.15 sec\n",
      "Epoch 25, Loss(train/val) 0.25141/0.38687. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.25308/0.39308. Took 0.20 sec\n",
      "Epoch 27, Loss(train/val) 0.25401/0.37144. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.24847/0.39290. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.24679/0.36632. Took 0.17 sec\n",
      "Epoch 30, Loss(train/val) 0.23841/0.37605. Took 0.16 sec\n",
      "Epoch 31, Loss(train/val) 0.22987/0.36987. Took 0.16 sec\n",
      "Epoch 32, Loss(train/val) 0.22670/0.35700. Took 0.19 sec\n",
      "Epoch 33, Loss(train/val) 0.22198/0.37244. Took 0.18 sec\n",
      "Epoch 34, Loss(train/val) 0.22458/0.36700. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.22634/0.36696. Took 0.15 sec\n",
      "Epoch 36, Loss(train/val) 0.21363/0.37421. Took 0.17 sec\n",
      "Epoch 37, Loss(train/val) 0.21932/0.37747. Took 0.19 sec\n",
      "Epoch 38, Loss(train/val) 0.20979/0.38021. Took 0.17 sec\n",
      "Epoch 39, Loss(train/val) 0.20666/0.37076. Took 0.15 sec\n",
      "Epoch 40, Loss(train/val) 0.22460/0.37443. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.21511/0.35743. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.21237/0.37451. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.21329/0.36301. Took 0.17 sec\n",
      "Epoch 44, Loss(train/val) 0.20726/0.36951. Took 0.16 sec\n",
      "Epoch 45, Loss(train/val) 0.19875/0.37475. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.20178/0.36885. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.20082/0.36867. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.19937/0.36951. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.20148/0.36942. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.18703/0.35870. Took 0.14 sec\n",
      "Epoch 51, Loss(train/val) 0.19728/0.36146. Took 0.15 sec\n",
      "Epoch 52, Loss(train/val) 0.18757/0.36168. Took 0.16 sec\n",
      "Epoch 53, Loss(train/val) 0.18821/0.36842. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.19162/0.35076. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.19213/0.34546. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.18802/0.35858. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.19220/0.38464. Took 0.16 sec\n",
      "Epoch 58, Loss(train/val) 0.19122/0.38951. Took 0.15 sec\n",
      "Epoch 59, Loss(train/val) 0.18767/0.37502. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.18675/0.35331. Took 0.14 sec\n",
      "Epoch 61, Loss(train/val) 0.18860/0.37408. Took 0.15 sec\n",
      "Epoch 62, Loss(train/val) 0.18829/0.36811. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.17920/0.37134. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.18023/0.34544. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.19107/0.38277. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.17143/0.37776. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.17049/0.36699. Took 0.15 sec\n",
      "Epoch 68, Loss(train/val) 0.18072/0.34160. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.16942/0.33966. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.16289/0.36886. Took 0.15 sec\n",
      "Epoch 71, Loss(train/val) 0.15753/0.36710. Took 0.17 sec\n",
      "Epoch 72, Loss(train/val) 0.16436/0.36476. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.15763/0.34421. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.16443/0.36181. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.16249/0.36656. Took 0.15 sec\n",
      "Epoch 76, Loss(train/val) 0.16772/0.37912. Took 0.16 sec\n",
      "Epoch 77, Loss(train/val) 0.15322/0.39662. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.16723/0.36234. Took 0.15 sec\n",
      "Epoch 79, Loss(train/val) 0.14958/0.35701. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.15350/0.36489. Took 0.15 sec\n",
      "Epoch 81, Loss(train/val) 0.15046/0.36787. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.15005/0.38672. Took 0.16 sec\n",
      "Epoch 83, Loss(train/val) 0.14490/0.35994. Took 0.16 sec\n",
      "Epoch 84, Loss(train/val) 0.14184/0.35892. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.14671/0.36002. Took 0.15 sec\n",
      "Epoch 86, Loss(train/val) 0.14380/0.34417. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.13645/0.35167. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.14691/0.36038. Took 0.15 sec\n",
      "Epoch 89, Loss(train/val) 0.13783/0.37410. Took 0.17 sec\n",
      "Epoch 90, Loss(train/val) 0.13496/0.35396. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.13310/0.37129. Took 0.16 sec\n",
      "Epoch 92, Loss(train/val) 0.13457/0.35944. Took 0.16 sec\n",
      "Epoch 93, Loss(train/val) 0.13124/0.36482. Took 0.17 sec\n",
      "Epoch 94, Loss(train/val) 0.13290/0.37103. Took 0.14 sec\n",
      "Epoch 95, Loss(train/val) 0.13379/0.38005. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.13517/0.37087. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.13204/0.37049. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.12583/0.35054. Took 0.14 sec\n",
      "Epoch 99, Loss(train/val) 0.11915/0.36500. Took 0.15 sec\n",
      "ACC: 0.59375, MCC: 0.18385116779128288\n",
      "Epoch 0, Loss(train/val) 0.49758/0.48469. Took 0.17 sec\n",
      "Epoch 1, Loss(train/val) 0.47465/0.45076. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.44310/0.41411. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.41159/0.39627. Took 0.15 sec\n",
      "Epoch 4, Loss(train/val) 0.39013/0.38446. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.37275/0.36086. Took 0.16 sec\n",
      "Epoch 6, Loss(train/val) 0.35711/0.35796. Took 0.17 sec\n",
      "Epoch 7, Loss(train/val) 0.34550/0.34786. Took 0.15 sec\n",
      "Epoch 8, Loss(train/val) 0.33992/0.34638. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.33228/0.33878. Took 0.15 sec\n",
      "Epoch 10, Loss(train/val) 0.32423/0.33829. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.32160/0.34210. Took 0.15 sec\n",
      "Epoch 12, Loss(train/val) 0.32196/0.33930. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.31072/0.35004. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.30615/0.35765. Took 0.20 sec\n",
      "Epoch 15, Loss(train/val) 0.32521/0.35737. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.30595/0.34788. Took 0.16 sec\n",
      "Epoch 17, Loss(train/val) 0.30448/0.34934. Took 0.17 sec\n",
      "Epoch 18, Loss(train/val) 0.29679/0.35323. Took 0.15 sec\n",
      "Epoch 19, Loss(train/val) 0.29260/0.34469. Took 0.15 sec\n",
      "Epoch 20, Loss(train/val) 0.28804/0.36296. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.29850/0.34139. Took 0.16 sec\n",
      "Epoch 22, Loss(train/val) 0.28308/0.38526. Took 0.19 sec\n",
      "Epoch 23, Loss(train/val) 0.28709/0.36875. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.27973/0.37038. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.27556/0.36453. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.28131/0.36661. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.27315/0.37391. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.26909/0.39320. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.27262/0.36296. Took 0.16 sec\n",
      "Epoch 30, Loss(train/val) 0.26302/0.36991. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.26359/0.38280. Took 0.16 sec\n",
      "Epoch 32, Loss(train/val) 0.25426/0.37787. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.25458/0.37324. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.25646/0.36873. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.25374/0.38645. Took 0.16 sec\n",
      "Epoch 36, Loss(train/val) 0.25641/0.38130. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.25408/0.37522. Took 0.15 sec\n",
      "Epoch 38, Loss(train/val) 0.24542/0.38273. Took 0.16 sec\n",
      "Epoch 39, Loss(train/val) 0.25472/0.37144. Took 0.15 sec\n",
      "Epoch 40, Loss(train/val) 0.24625/0.37660. Took 0.16 sec\n",
      "Epoch 41, Loss(train/val) 0.24078/0.37469. Took 0.16 sec\n",
      "Epoch 42, Loss(train/val) 0.24353/0.37580. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.25010/0.34525. Took 0.15 sec\n",
      "Epoch 44, Loss(train/val) 0.24572/0.33646. Took 0.16 sec\n",
      "Epoch 45, Loss(train/val) 0.23423/0.36820. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.24266/0.37053. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.23235/0.34163. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.22842/0.33804. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.22831/0.32952. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.23073/0.34083. Took 0.14 sec\n",
      "Epoch 51, Loss(train/val) 0.22152/0.36397. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.21737/0.37435. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) 0.22021/0.38055. Took 0.15 sec\n",
      "Epoch 54, Loss(train/val) 0.21348/0.37339. Took 0.15 sec\n",
      "Epoch 55, Loss(train/val) 0.21929/0.35578. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.21627/0.38532. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.22141/0.38291. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.20740/0.37203. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.21184/0.37705. Took 0.15 sec\n",
      "Epoch 60, Loss(train/val) 0.20661/0.37398. Took 0.14 sec\n",
      "Epoch 61, Loss(train/val) 0.19931/0.34823. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.20870/0.37716. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.20152/0.37600. Took 0.15 sec\n",
      "Epoch 64, Loss(train/val) 0.19999/0.37329. Took 0.16 sec\n",
      "Epoch 65, Loss(train/val) 0.19654/0.35829. Took 0.16 sec\n",
      "Epoch 66, Loss(train/val) 0.19633/0.38663. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.20540/0.35258. Took 0.15 sec\n",
      "Epoch 68, Loss(train/val) 0.19594/0.37066. Took 0.15 sec\n",
      "Epoch 69, Loss(train/val) 0.19125/0.37126. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.19302/0.37386. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.18795/0.37850. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.19898/0.35812. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.19577/0.37709. Took 0.15 sec\n",
      "Epoch 74, Loss(train/val) 0.18456/0.37332. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.18020/0.35354. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.17983/0.38320. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.17177/0.36957. Took 0.15 sec\n",
      "Epoch 78, Loss(train/val) 0.16981/0.37459. Took 0.17 sec\n",
      "Epoch 79, Loss(train/val) 0.17964/0.37428. Took 0.17 sec\n",
      "Epoch 80, Loss(train/val) 0.16589/0.37959. Took 0.15 sec\n",
      "Epoch 81, Loss(train/val) 0.16927/0.37349. Took 0.15 sec\n",
      "Epoch 82, Loss(train/val) 0.17015/0.37951. Took 0.15 sec\n",
      "Epoch 83, Loss(train/val) 0.17671/0.37410. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.16275/0.37160. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.16324/0.36881. Took 0.15 sec\n",
      "Epoch 86, Loss(train/val) 0.16171/0.36992. Took 0.16 sec\n",
      "Epoch 87, Loss(train/val) 0.16214/0.38256. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.16122/0.36861. Took 0.15 sec\n",
      "Epoch 89, Loss(train/val) 0.16352/0.37950. Took 0.15 sec\n",
      "Epoch 90, Loss(train/val) 0.15321/0.36398. Took 0.17 sec\n",
      "Epoch 91, Loss(train/val) 0.16204/0.37029. Took 0.15 sec\n",
      "Epoch 92, Loss(train/val) 0.17025/0.38766. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.17845/0.37093. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.16278/0.37872. Took 0.18 sec\n",
      "Epoch 95, Loss(train/val) 0.15543/0.38305. Took 0.16 sec\n",
      "Epoch 96, Loss(train/val) 0.16892/0.38344. Took 0.14 sec\n",
      "Epoch 97, Loss(train/val) 0.15269/0.36503. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.14366/0.36490. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.15175/0.37421. Took 0.15 sec\n",
      "ACC: 0.5625, MCC: 0.19267460195827915\n",
      "Epoch 0, Loss(train/val) 0.49821/0.49154. Took 0.17 sec\n",
      "Epoch 1, Loss(train/val) 0.47898/0.48805. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.45164/0.46866. Took 0.16 sec\n",
      "Epoch 3, Loss(train/val) 0.42259/0.43174. Took 0.17 sec\n",
      "Epoch 4, Loss(train/val) 0.39939/0.41921. Took 0.16 sec\n",
      "Epoch 5, Loss(train/val) 0.38306/0.39218. Took 0.15 sec\n",
      "Epoch 6, Loss(train/val) 0.37149/0.39438. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.35942/0.37940. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.34499/0.42590. Took 0.15 sec\n",
      "Epoch 9, Loss(train/val) 0.34971/0.36984. Took 0.15 sec\n",
      "Epoch 10, Loss(train/val) 0.35256/0.36322. Took 0.15 sec\n",
      "Epoch 11, Loss(train/val) 0.32875/0.43183. Took 0.16 sec\n",
      "Epoch 12, Loss(train/val) 0.32773/0.43622. Took 0.19 sec\n",
      "Epoch 13, Loss(train/val) 0.31459/0.42623. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.31331/0.39620. Took 0.16 sec\n",
      "Epoch 15, Loss(train/val) 0.30485/0.37053. Took 0.17 sec\n",
      "Epoch 16, Loss(train/val) 0.30171/0.36692. Took 0.16 sec\n",
      "Epoch 17, Loss(train/val) 0.29645/0.35878. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.28019/0.36063. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.27993/0.36355. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.27534/0.35584. Took 0.18 sec\n",
      "Epoch 21, Loss(train/val) 0.26821/0.35682. Took 0.16 sec\n",
      "Epoch 22, Loss(train/val) 0.27415/0.35269. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.26219/0.35265. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.26388/0.35263. Took 0.15 sec\n",
      "Epoch 25, Loss(train/val) 0.25850/0.35923. Took 0.18 sec\n",
      "Epoch 26, Loss(train/val) 0.24810/0.34830. Took 0.16 sec\n",
      "Epoch 27, Loss(train/val) 0.24953/0.34469. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.24494/0.34081. Took 0.18 sec\n",
      "Epoch 29, Loss(train/val) 0.24516/0.35434. Took 0.16 sec\n",
      "Epoch 30, Loss(train/val) 0.23456/0.34569. Took 0.17 sec\n",
      "Epoch 31, Loss(train/val) 0.23070/0.34823. Took 0.16 sec\n",
      "Epoch 32, Loss(train/val) 0.23281/0.34436. Took 0.18 sec\n",
      "Epoch 33, Loss(train/val) 0.23376/0.33789. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.22213/0.33162. Took 0.18 sec\n",
      "Epoch 35, Loss(train/val) 0.22512/0.34905. Took 0.18 sec\n",
      "Epoch 36, Loss(train/val) 0.20663/0.33783. Took 0.18 sec\n",
      "Epoch 37, Loss(train/val) 0.20445/0.33526. Took 0.16 sec\n",
      "Epoch 38, Loss(train/val) 0.20630/0.34944. Took 0.17 sec\n",
      "Epoch 39, Loss(train/val) 0.19959/0.34782. Took 0.15 sec\n",
      "Epoch 40, Loss(train/val) 0.19905/0.34401. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.19904/0.34988. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.19534/0.34544. Took 0.16 sec\n",
      "Epoch 43, Loss(train/val) 0.18596/0.33334. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.18678/0.33526. Took 0.16 sec\n",
      "Epoch 45, Loss(train/val) 0.19537/0.34209. Took 0.15 sec\n",
      "Epoch 46, Loss(train/val) 0.18092/0.33302. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.18834/0.33712. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.18409/0.34650. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.19014/0.34532. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.19191/0.36088. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.17520/0.34483. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.17273/0.34177. Took 0.15 sec\n",
      "Epoch 53, Loss(train/val) 0.16908/0.34498. Took 0.17 sec\n",
      "Epoch 54, Loss(train/val) 0.17141/0.36945. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.16850/0.33939. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.17298/0.33883. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.16906/0.34624. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.16092/0.33864. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.16411/0.34440. Took 0.17 sec\n",
      "Epoch 60, Loss(train/val) 0.16100/0.34201. Took 0.14 sec\n",
      "Epoch 61, Loss(train/val) 0.15735/0.34276. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.15753/0.33932. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.15404/0.33185. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.15891/0.33509. Took 0.15 sec\n",
      "Epoch 65, Loss(train/val) 0.15429/0.32866. Took 0.17 sec\n",
      "Epoch 66, Loss(train/val) 0.15076/0.34376. Took 0.19 sec\n",
      "Epoch 67, Loss(train/val) 0.15436/0.33856. Took 0.15 sec\n",
      "Epoch 68, Loss(train/val) 0.15719/0.33380. Took 0.14 sec\n",
      "Epoch 69, Loss(train/val) 0.15628/0.32197. Took 0.15 sec\n",
      "Epoch 70, Loss(train/val) 0.14872/0.33487. Took 0.15 sec\n",
      "Epoch 71, Loss(train/val) 0.15612/0.31296. Took 0.15 sec\n",
      "Epoch 72, Loss(train/val) 0.14139/0.33903. Took 0.15 sec\n",
      "Epoch 73, Loss(train/val) 0.14919/0.32037. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.14915/0.31952. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) 0.14327/0.32593. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.14752/0.30916. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.14400/0.30770. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.13098/0.32282. Took 0.14 sec\n",
      "Epoch 79, Loss(train/val) 0.13700/0.29908. Took 0.15 sec\n",
      "Epoch 80, Loss(train/val) 0.13862/0.32469. Took 0.16 sec\n",
      "Epoch 81, Loss(train/val) 0.13641/0.33360. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.14028/0.32447. Took 0.15 sec\n",
      "Epoch 83, Loss(train/val) 0.13601/0.32438. Took 0.15 sec\n",
      "Epoch 84, Loss(train/val) 0.14011/0.32246. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.14328/0.33633. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.14260/0.29147. Took 0.15 sec\n",
      "Epoch 87, Loss(train/val) 0.13789/0.32704. Took 0.16 sec\n",
      "Epoch 88, Loss(train/val) 0.13963/0.31572. Took 0.15 sec\n",
      "Epoch 89, Loss(train/val) 0.13918/0.31545. Took 0.16 sec\n",
      "Epoch 90, Loss(train/val) 0.13408/0.29063. Took 0.14 sec\n",
      "Epoch 91, Loss(train/val) 0.13476/0.29891. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.14248/0.30286. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.13325/0.30485. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.13573/0.29824. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.13447/0.29869. Took 0.15 sec\n",
      "Epoch 96, Loss(train/val) 0.12786/0.33478. Took 0.14 sec\n",
      "Epoch 97, Loss(train/val) 0.13148/0.27969. Took 0.15 sec\n",
      "Epoch 98, Loss(train/val) 0.12462/0.29686. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.13247/0.28267. Took 0.13 sec\n",
      "ACC: 0.671875, MCC: 0.3946931870602078\n",
      "Epoch 0, Loss(train/val) 0.49452/0.48281. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.47542/0.46192. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.44855/0.44728. Took 0.15 sec\n",
      "Epoch 3, Loss(train/val) 0.42267/0.43035. Took 0.16 sec\n",
      "Epoch 4, Loss(train/val) 0.40368/0.40489. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.38910/0.37403. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.37832/0.35939. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.36916/0.34977. Took 0.15 sec\n",
      "Epoch 8, Loss(train/val) 0.36130/0.34447. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.34711/0.33214. Took 0.16 sec\n",
      "Epoch 10, Loss(train/val) 0.33235/0.32834. Took 0.17 sec\n",
      "Epoch 11, Loss(train/val) 0.32089/0.32661. Took 0.15 sec\n",
      "Epoch 12, Loss(train/val) 0.30652/0.32070. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.30319/0.31925. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.30034/0.30191. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.29076/0.28853. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.29724/0.31824. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.29220/0.30185. Took 0.16 sec\n",
      "Epoch 18, Loss(train/val) 0.28306/0.29974. Took 0.16 sec\n",
      "Epoch 19, Loss(train/val) 0.28014/0.30737. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.27406/0.31476. Took 0.15 sec\n",
      "Epoch 21, Loss(train/val) 0.27762/0.29402. Took 0.19 sec\n",
      "Epoch 22, Loss(train/val) 0.27939/0.30941. Took 0.19 sec\n",
      "Epoch 23, Loss(train/val) 0.26266/0.30078. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.26841/0.30142. Took 0.15 sec\n",
      "Epoch 25, Loss(train/val) 0.26342/0.30281. Took 0.17 sec\n",
      "Epoch 26, Loss(train/val) 0.26517/0.32008. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.26426/0.32900. Took 0.16 sec\n",
      "Epoch 28, Loss(train/val) 0.25993/0.32879. Took 0.16 sec\n",
      "Epoch 29, Loss(train/val) 0.25067/0.31059. Took 0.16 sec\n",
      "Epoch 30, Loss(train/val) 0.25060/0.30409. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.25572/0.35872. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.24249/0.33009. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.24681/0.29873. Took 0.18 sec\n",
      "Epoch 34, Loss(train/val) 0.25268/0.31794. Took 0.19 sec\n",
      "Epoch 35, Loss(train/val) 0.24462/0.32875. Took 0.16 sec\n",
      "Epoch 36, Loss(train/val) 0.24374/0.33494. Took 0.17 sec\n",
      "Epoch 37, Loss(train/val) 0.23224/0.31048. Took 0.18 sec\n",
      "Epoch 38, Loss(train/val) 0.23642/0.29515. Took 0.17 sec\n",
      "Epoch 39, Loss(train/val) 0.24172/0.31634. Took 0.15 sec\n",
      "Epoch 40, Loss(train/val) 0.23760/0.31926. Took 0.15 sec\n",
      "Epoch 41, Loss(train/val) 0.23622/0.31025. Took 0.19 sec\n",
      "Epoch 42, Loss(train/val) 0.23627/0.34476. Took 0.17 sec\n",
      "Epoch 43, Loss(train/val) 0.23318/0.31725. Took 0.15 sec\n",
      "Epoch 44, Loss(train/val) 0.24761/0.30458. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) 0.24292/0.31948. Took 0.17 sec\n",
      "Epoch 46, Loss(train/val) 0.23104/0.35159. Took 0.16 sec\n",
      "Epoch 47, Loss(train/val) 0.23513/0.35274. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.22938/0.32289. Took 0.15 sec\n",
      "Epoch 49, Loss(train/val) 0.22688/0.30163. Took 0.16 sec\n",
      "Epoch 50, Loss(train/val) 0.22006/0.33602. Took 0.14 sec\n",
      "Epoch 51, Loss(train/val) 0.22036/0.34858. Took 0.15 sec\n",
      "Epoch 52, Loss(train/val) 0.22603/0.32136. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.22555/0.31591. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.22722/0.29855. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.21993/0.30855. Took 0.16 sec\n",
      "Epoch 56, Loss(train/val) 0.22177/0.32035. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.20708/0.33601. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.21353/0.32912. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.21254/0.32250. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.20336/0.32850. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.21576/0.31834. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.20709/0.33224. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.20474/0.34068. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.20868/0.32172. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.20141/0.34660. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.20036/0.35059. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.20702/0.34392. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.20218/0.34561. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.19264/0.34408. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.21343/0.27419. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.20807/0.30776. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.19444/0.29618. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.19630/0.28021. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.19034/0.29412. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.19631/0.32807. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.19105/0.31221. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.19288/0.31062. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.19109/0.33824. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.19752/0.29868. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.18959/0.33125. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.18513/0.32591. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.19445/0.30826. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.19022/0.31638. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.18690/0.29711. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.18542/0.30129. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.18179/0.31247. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.18780/0.32229. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.17950/0.32533. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.18335/0.30178. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.18183/0.35222. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.18993/0.33366. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.18796/0.32547. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.19843/0.33873. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.18588/0.36380. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.19053/0.40978. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.19313/0.35160. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.17566/0.32620. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.17500/0.31615. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.18020/0.31128. Took 0.13 sec\n",
      "ACC: 0.640625, MCC: 0.29644295610503363\n",
      "Epoch 0, Loss(train/val) 0.49257/0.46627. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.46937/0.41428. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.43891/0.34889. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.40503/0.26588. Took 0.15 sec\n",
      "Epoch 4, Loss(train/val) 0.38193/0.23066. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.36422/0.23652. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.35653/0.25989. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.34738/0.26547. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.33117/0.23987. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.32452/0.24997. Took 0.16 sec\n",
      "Epoch 10, Loss(train/val) 0.32181/0.28839. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.30747/0.33862. Took 0.15 sec\n",
      "Epoch 12, Loss(train/val) 0.30433/0.29846. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.29558/0.29761. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.29313/0.31540. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.28440/0.30082. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.27240/0.27331. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.28456/0.29292. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.27480/0.29246. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.26317/0.28589. Took 0.15 sec\n",
      "Epoch 20, Loss(train/val) 0.27153/0.27745. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.26661/0.26052. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.25601/0.26149. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.24858/0.25346. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.25991/0.27406. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.26160/0.27508. Took 0.16 sec\n",
      "Epoch 26, Loss(train/val) 0.24988/0.26550. Took 0.13 sec\n",
      "Epoch 27, Loss(train/val) 0.25052/0.25325. Took 0.16 sec\n",
      "Epoch 28, Loss(train/val) 0.24716/0.25580. Took 0.16 sec\n",
      "Epoch 29, Loss(train/val) 0.23188/0.24274. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.22979/0.25644. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.22295/0.25815. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.22522/0.25651. Took 0.17 sec\n",
      "Epoch 33, Loss(train/val) 0.22213/0.25964. Took 0.16 sec\n",
      "Epoch 34, Loss(train/val) 0.22057/0.26908. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.23139/0.25575. Took 0.16 sec\n",
      "Epoch 36, Loss(train/val) 0.21846/0.23936. Took 0.20 sec\n",
      "Epoch 37, Loss(train/val) 0.21545/0.23660. Took 0.15 sec\n",
      "Epoch 38, Loss(train/val) 0.22310/0.25447. Took 0.16 sec\n",
      "Epoch 39, Loss(train/val) 0.20543/0.26428. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.20474/0.27109. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.21234/0.32324. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.20914/0.25502. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.20652/0.27539. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.19459/0.28188. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.18590/0.28199. Took 0.15 sec\n",
      "Epoch 46, Loss(train/val) 0.18719/0.26525. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.18682/0.27330. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.18281/0.27191. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.18107/0.25326. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.18030/0.26044. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.18640/0.27570. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.17225/0.28200. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.17889/0.27954. Took 0.15 sec\n",
      "Epoch 54, Loss(train/val) 0.17477/0.29790. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.17591/0.25779. Took 0.15 sec\n",
      "Epoch 56, Loss(train/val) 0.17893/0.27368. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.17709/0.27865. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.17777/0.28580. Took 0.15 sec\n",
      "Epoch 59, Loss(train/val) 0.16916/0.27940. Took 0.16 sec\n",
      "Epoch 60, Loss(train/val) 0.17183/0.29160. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.17059/0.26813. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.16007/0.26919. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.15714/0.27759. Took 0.15 sec\n",
      "Epoch 64, Loss(train/val) 0.15710/0.28702. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.15726/0.29828. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.15734/0.30651. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.15714/0.31522. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.14834/0.30979. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.15474/0.33194. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.14793/0.32207. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.14732/0.31337. Took 0.15 sec\n",
      "Epoch 72, Loss(train/val) 0.14353/0.29767. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.15640/0.27953. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.14587/0.29931. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) 0.13836/0.28937. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.13973/0.28480. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.14585/0.28711. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.14114/0.26217. Took 0.15 sec\n",
      "Epoch 79, Loss(train/val) 0.15144/0.30826. Took 0.15 sec\n",
      "Epoch 80, Loss(train/val) 0.14615/0.28398. Took 0.15 sec\n",
      "Epoch 81, Loss(train/val) 0.13518/0.27639. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.13499/0.29605. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) 0.13559/0.29726. Took 0.15 sec\n",
      "Epoch 84, Loss(train/val) 0.13881/0.34591. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.13282/0.30627. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.14057/0.28715. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.12436/0.29486. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.13565/0.33888. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.13980/0.33238. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.12841/0.32735. Took 0.14 sec\n",
      "Epoch 91, Loss(train/val) 0.12860/0.29586. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.12721/0.29515. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.11660/0.31280. Took 0.15 sec\n",
      "Epoch 94, Loss(train/val) 0.13317/0.28690. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.13386/0.32074. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.13636/0.31267. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.12048/0.29508. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.12384/0.29132. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.12404/0.30764. Took 0.14 sec\n",
      "ACC: 0.609375, MCC: 0.22604490834610982\n",
      "Epoch 0, Loss(train/val) 0.49542/0.49283. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.46696/0.47415. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.42849/0.43008. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.39332/0.39459. Took 0.18 sec\n",
      "Epoch 4, Loss(train/val) 0.37270/0.39207. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.35613/0.39623. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.34420/0.39208. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.33356/0.38875. Took 0.15 sec\n",
      "Epoch 8, Loss(train/val) 0.32307/0.38874. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.31663/0.35760. Took 0.15 sec\n",
      "Epoch 10, Loss(train/val) 0.31211/0.37204. Took 0.15 sec\n",
      "Epoch 11, Loss(train/val) 0.30268/0.34278. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.29627/0.33726. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.29302/0.33188. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.29073/0.35345. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.28391/0.32742. Took 0.16 sec\n",
      "Epoch 16, Loss(train/val) 0.28645/0.34150. Took 0.16 sec\n",
      "Epoch 17, Loss(train/val) 0.28060/0.34142. Took 0.16 sec\n",
      "Epoch 18, Loss(train/val) 0.28198/0.31732. Took 0.15 sec\n",
      "Epoch 19, Loss(train/val) 0.27447/0.29707. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.27293/0.28184. Took 0.15 sec\n",
      "Epoch 21, Loss(train/val) 0.27608/0.31656. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.26658/0.28433. Took 0.16 sec\n",
      "Epoch 23, Loss(train/val) 0.27180/0.27713. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.25815/0.27984. Took 0.15 sec\n",
      "Epoch 25, Loss(train/val) 0.25956/0.28155. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.24669/0.28727. Took 0.17 sec\n",
      "Epoch 27, Loss(train/val) 0.25046/0.29122. Took 0.17 sec\n",
      "Epoch 28, Loss(train/val) 0.23579/0.28353. Took 0.16 sec\n",
      "Epoch 29, Loss(train/val) 0.24438/0.28682. Took 0.16 sec\n",
      "Epoch 30, Loss(train/val) 0.24411/0.29146. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.24127/0.26326. Took 0.19 sec\n",
      "Epoch 32, Loss(train/val) 0.24393/0.27843. Took 0.20 sec\n",
      "Epoch 33, Loss(train/val) 0.24083/0.27808. Took 0.17 sec\n",
      "Epoch 34, Loss(train/val) 0.23439/0.26439. Took 0.18 sec\n",
      "Epoch 35, Loss(train/val) 0.23660/0.25225. Took 0.19 sec\n",
      "Epoch 36, Loss(train/val) 0.23123/0.27369. Took 0.23 sec\n",
      "Epoch 37, Loss(train/val) 0.22448/0.26357. Took 0.18 sec\n",
      "Epoch 38, Loss(train/val) 0.22362/0.25574. Took 0.16 sec\n",
      "Epoch 39, Loss(train/val) 0.22946/0.26264. Took 0.16 sec\n",
      "Epoch 40, Loss(train/val) 0.21794/0.26016. Took 0.15 sec\n",
      "Epoch 41, Loss(train/val) 0.23403/0.26575. Took 0.15 sec\n",
      "Epoch 42, Loss(train/val) 0.22672/0.26035. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.21811/0.27720. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.21566/0.27665. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.21550/0.26208. Took 0.17 sec\n",
      "Epoch 46, Loss(train/val) 0.19840/0.28874. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.20717/0.25088. Took 0.16 sec\n",
      "Epoch 48, Loss(train/val) 0.20079/0.26893. Took 0.15 sec\n",
      "Epoch 49, Loss(train/val) 0.20202/0.26588. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.20843/0.28637. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.20731/0.26495. Took 0.15 sec\n",
      "Epoch 52, Loss(train/val) 0.19289/0.26510. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) 0.20798/0.25163. Took 0.15 sec\n",
      "Epoch 54, Loss(train/val) 0.20657/0.26580. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.19787/0.28894. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.19659/0.25738. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.19560/0.24570. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.18839/0.28550. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.18496/0.28009. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.17600/0.28518. Took 0.14 sec\n",
      "Epoch 61, Loss(train/val) 0.18052/0.29037. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.17506/0.29068. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.17763/0.27441. Took 0.15 sec\n",
      "Epoch 64, Loss(train/val) 0.17750/0.30032. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.17177/0.29043. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.17713/0.31188. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.17031/0.31122. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.16837/0.27949. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.17338/0.29534. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.17505/0.34523. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.16977/0.29618. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.17488/0.29367. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.16306/0.30621. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.16762/0.30219. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.16443/0.30956. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.16181/0.29173. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.15339/0.29680. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.16361/0.28961. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.15933/0.29024. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.15790/0.30468. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.15869/0.31262. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.15037/0.29126. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.15586/0.30766. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.15484/0.30908. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.15316/0.32024. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.15027/0.29721. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.14872/0.32489. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.14325/0.32629. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.14843/0.31637. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.14496/0.35268. Took 0.15 sec\n",
      "Epoch 91, Loss(train/val) 0.14375/0.31462. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.14343/0.27898. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.13528/0.31208. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.14217/0.31942. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.14123/0.32074. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.14069/0.31981. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.14100/0.34328. Took 0.15 sec\n",
      "Epoch 98, Loss(train/val) 0.13722/0.33347. Took 0.14 sec\n",
      "Epoch 99, Loss(train/val) 0.14070/0.37261. Took 0.15 sec\n",
      "ACC: 0.6875, MCC: 0.39477101697586137\n",
      "Epoch 0, Loss(train/val) 0.48911/0.48073. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.46547/0.44997. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.43598/0.41179. Took 0.15 sec\n",
      "Epoch 3, Loss(train/val) 0.40224/0.38106. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.38191/0.36472. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.36296/0.34814. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.34771/0.32459. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.32983/0.29562. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.32139/0.28043. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.31103/0.29477. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.30223/0.26989. Took 0.15 sec\n",
      "Epoch 11, Loss(train/val) 0.30250/0.27338. Took 0.15 sec\n",
      "Epoch 12, Loss(train/val) 0.29979/0.27685. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.28153/0.28215. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.28557/0.28207. Took 0.15 sec\n",
      "Epoch 15, Loss(train/val) 0.28395/0.28241. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.28603/0.29045. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.27695/0.28393. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.27118/0.30088. Took 0.15 sec\n",
      "Epoch 19, Loss(train/val) 0.27929/0.28699. Took 0.15 sec\n",
      "Epoch 20, Loss(train/val) 0.25921/0.28586. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.25792/0.28159. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.25196/0.29387. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.26254/0.29724. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.25177/0.30861. Took 0.16 sec\n",
      "Epoch 25, Loss(train/val) 0.26786/0.28138. Took 0.19 sec\n",
      "Epoch 26, Loss(train/val) 0.25735/0.29528. Took 0.18 sec\n",
      "Epoch 27, Loss(train/val) 0.24331/0.27767. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.23245/0.29118. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.25078/0.28555. Took 0.13 sec\n",
      "Epoch 30, Loss(train/val) 0.23795/0.27290. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.24024/0.29153. Took 0.16 sec\n",
      "Epoch 32, Loss(train/val) 0.23601/0.26706. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.23587/0.26859. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.22269/0.27422. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.22833/0.26423. Took 0.15 sec\n",
      "Epoch 36, Loss(train/val) 0.22557/0.26980. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.22304/0.26281. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.22918/0.27267. Took 0.17 sec\n",
      "Epoch 39, Loss(train/val) 0.21992/0.28386. Took 0.15 sec\n",
      "Epoch 40, Loss(train/val) 0.21026/0.26392. Took 0.16 sec\n",
      "Epoch 41, Loss(train/val) 0.21416/0.26044. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.21043/0.26043. Took 0.15 sec\n",
      "Epoch 43, Loss(train/val) 0.21402/0.25158. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.21112/0.25110. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.21557/0.25852. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.20373/0.24659. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.21129/0.24710. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.20539/0.24034. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.19674/0.22360. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.20260/0.24136. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.21686/0.23618. Took 0.15 sec\n",
      "Epoch 52, Loss(train/val) 0.21325/0.25418. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) 0.19885/0.25655. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.19333/0.23962. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.19554/0.26402. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.19224/0.25833. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.18626/0.25024. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.18749/0.25180. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.18813/0.24056. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.18375/0.26595. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.20041/0.25169. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.18629/0.25876. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.19015/0.24919. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.18145/0.28338. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.19727/0.26236. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.17859/0.25850. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.18271/0.25881. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.18014/0.24549. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.19273/0.26613. Took 0.15 sec\n",
      "Epoch 70, Loss(train/val) 0.18852/0.26011. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.19132/0.26669. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.17564/0.27418. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.17910/0.26135. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.17312/0.26464. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.17213/0.24302. Took 0.15 sec\n",
      "Epoch 76, Loss(train/val) 0.16559/0.25006. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.16949/0.23987. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.16879/0.24676. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.17060/0.25410. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.17303/0.25102. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.16622/0.29095. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.16634/0.26857. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.17182/0.27434. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.15998/0.27676. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.15678/0.26420. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.15753/0.26559. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.16402/0.27976. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.15666/0.26216. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.15140/0.27596. Took 0.17 sec\n",
      "Epoch 90, Loss(train/val) 0.16352/0.28466. Took 0.14 sec\n",
      "Epoch 91, Loss(train/val) 0.15832/0.25693. Took 0.15 sec\n",
      "Epoch 92, Loss(train/val) 0.15956/0.27244. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.15128/0.27404. Took 0.15 sec\n",
      "Epoch 94, Loss(train/val) 0.15354/0.28275. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.16328/0.27761. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.16001/0.29452. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.15075/0.28362. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.15320/0.27906. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.14697/0.26100. Took 0.14 sec\n",
      "ACC: 0.734375, MCC: 0.47082361543075835\n",
      "Epoch 0, Loss(train/val) 0.49127/0.48003. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.46138/0.43263. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.41434/0.36965. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.37652/0.32774. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.35831/0.32048. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.34542/0.31493. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.33237/0.30918. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.32428/0.32171. Took 0.16 sec\n",
      "Epoch 8, Loss(train/val) 0.31597/0.31244. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.30888/0.31331. Took 0.15 sec\n",
      "Epoch 10, Loss(train/val) 0.30787/0.31787. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.30715/0.31876. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.29913/0.30934. Took 0.15 sec\n",
      "Epoch 13, Loss(train/val) 0.29334/0.30009. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.28463/0.31882. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.28385/0.32848. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.28829/0.30857. Took 0.15 sec\n",
      "Epoch 17, Loss(train/val) 0.28291/0.33081. Took 0.16 sec\n",
      "Epoch 18, Loss(train/val) 0.27934/0.31835. Took 0.15 sec\n",
      "Epoch 19, Loss(train/val) 0.27785/0.32862. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.26414/0.31040. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.26818/0.31117. Took 0.16 sec\n",
      "Epoch 22, Loss(train/val) 0.27009/0.30586. Took 0.15 sec\n",
      "Epoch 23, Loss(train/val) 0.26415/0.30362. Took 0.17 sec\n",
      "Epoch 24, Loss(train/val) 0.25621/0.30860. Took 0.16 sec\n",
      "Epoch 25, Loss(train/val) 0.25330/0.31176. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.25284/0.29971. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.25746/0.30911. Took 0.16 sec\n",
      "Epoch 28, Loss(train/val) 0.24684/0.31736. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.25015/0.33072. Took 0.17 sec\n",
      "Epoch 30, Loss(train/val) 0.24940/0.32786. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.25425/0.32210. Took 0.16 sec\n",
      "Epoch 32, Loss(train/val) 0.24525/0.31433. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.24962/0.30292. Took 0.19 sec\n",
      "Epoch 34, Loss(train/val) 0.24617/0.32493. Took 0.20 sec\n",
      "Epoch 35, Loss(train/val) 0.23010/0.29991. Took 0.16 sec\n",
      "Epoch 36, Loss(train/val) 0.24593/0.32854. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.23761/0.33685. Took 0.17 sec\n",
      "Epoch 38, Loss(train/val) 0.22690/0.33166. Took 0.16 sec\n",
      "Epoch 39, Loss(train/val) 0.22513/0.32222. Took 0.16 sec\n",
      "Epoch 40, Loss(train/val) 0.22759/0.32997. Took 0.16 sec\n",
      "Epoch 41, Loss(train/val) 0.22712/0.32349. Took 0.16 sec\n",
      "Epoch 42, Loss(train/val) 0.22820/0.34352. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.22719/0.31222. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.22553/0.32097. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.22569/0.32218. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.23233/0.33429. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.22465/0.32039. Took 0.15 sec\n",
      "Epoch 48, Loss(train/val) 0.22092/0.33422. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.24528/0.33787. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.24845/0.38368. Took 0.14 sec\n",
      "Epoch 51, Loss(train/val) 0.23332/0.36945. Took 0.15 sec\n",
      "Epoch 52, Loss(train/val) 0.21499/0.36536. Took 0.15 sec\n",
      "Epoch 53, Loss(train/val) 0.21234/0.35742. Took 0.17 sec\n",
      "Epoch 54, Loss(train/val) 0.21600/0.35444. Took 0.15 sec\n",
      "Epoch 55, Loss(train/val) 0.20882/0.37189. Took 0.15 sec\n",
      "Epoch 56, Loss(train/val) 0.20761/0.35340. Took 0.15 sec\n",
      "Epoch 57, Loss(train/val) 0.20226/0.36571. Took 0.15 sec\n",
      "Epoch 58, Loss(train/val) 0.20641/0.33641. Took 0.15 sec\n",
      "Epoch 59, Loss(train/val) 0.20220/0.35123. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.20374/0.33270. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.19950/0.35043. Took 0.16 sec\n",
      "Epoch 62, Loss(train/val) 0.19859/0.36464. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.19524/0.37186. Took 0.16 sec\n",
      "Epoch 64, Loss(train/val) 0.20646/0.35579. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.18496/0.36765. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.19833/0.35829. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.19556/0.35586. Took 0.17 sec\n",
      "Epoch 68, Loss(train/val) 0.18759/0.36381. Took 0.15 sec\n",
      "Epoch 69, Loss(train/val) 0.19154/0.36377. Took 0.15 sec\n",
      "Epoch 70, Loss(train/val) 0.19696/0.36914. Took 0.15 sec\n",
      "Epoch 71, Loss(train/val) 0.18695/0.34703. Took 0.18 sec\n",
      "Epoch 72, Loss(train/val) 0.17852/0.35651. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.18229/0.35596. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.17782/0.36396. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) 0.18664/0.33173. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.18203/0.34240. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.17793/0.34645. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.18484/0.37196. Took 0.14 sec\n",
      "Epoch 79, Loss(train/val) 0.18477/0.36461. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.18277/0.36397. Took 0.14 sec\n",
      "Epoch 81, Loss(train/val) 0.18225/0.36072. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.18046/0.37295. Took 0.16 sec\n",
      "Epoch 83, Loss(train/val) 0.17012/0.36885. Took 0.15 sec\n",
      "Epoch 84, Loss(train/val) 0.16955/0.37698. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.16995/0.35983. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.17202/0.34950. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.17058/0.34640. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.17494/0.34994. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.16974/0.35389. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.16452/0.37886. Took 0.14 sec\n",
      "Epoch 91, Loss(train/val) 0.16400/0.37909. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.15961/0.38324. Took 0.16 sec\n",
      "Epoch 93, Loss(train/val) 0.17904/0.38329. Took 0.17 sec\n",
      "Epoch 94, Loss(train/val) 0.17153/0.37128. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.17088/0.35896. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.16678/0.38041. Took 0.14 sec\n",
      "Epoch 97, Loss(train/val) 0.16817/0.36616. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.16399/0.39081. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.16764/0.37862. Took 0.15 sec\n",
      "ACC: 0.625, MCC: 0.1901668471529859\n",
      "Epoch 0, Loss(train/val) 0.49171/0.49516. Took 0.16 sec\n",
      "Epoch 1, Loss(train/val) 0.46497/0.47684. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.42140/0.43610. Took 0.15 sec\n",
      "Epoch 3, Loss(train/val) 0.38633/0.41462. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.36768/0.40209. Took 0.15 sec\n",
      "Epoch 5, Loss(train/val) 0.35503/0.37920. Took 0.17 sec\n",
      "Epoch 6, Loss(train/val) 0.34657/0.37830. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.33601/0.37061. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.32951/0.35320. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.31204/0.35386. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.30133/0.35989. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.28653/0.33392. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.28331/0.33471. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.28018/0.33541. Took 0.16 sec\n",
      "Epoch 14, Loss(train/val) 0.27630/0.35950. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.27049/0.35009. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.26751/0.36090. Took 0.16 sec\n",
      "Epoch 17, Loss(train/val) 0.27867/0.39172. Took 0.16 sec\n",
      "Epoch 18, Loss(train/val) 0.26985/0.36885. Took 0.16 sec\n",
      "Epoch 19, Loss(train/val) 0.26773/0.40240. Took 0.17 sec\n",
      "Epoch 20, Loss(train/val) 0.26150/0.33235. Took 0.15 sec\n",
      "Epoch 21, Loss(train/val) 0.26759/0.38536. Took 0.16 sec\n",
      "Epoch 22, Loss(train/val) 0.25550/0.39047. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.25295/0.36673. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.24465/0.40369. Took 0.16 sec\n",
      "Epoch 25, Loss(train/val) 0.24629/0.41962. Took 0.18 sec\n",
      "Epoch 26, Loss(train/val) 0.24501/0.33480. Took 0.15 sec\n",
      "Epoch 27, Loss(train/val) 0.24000/0.34517. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.24253/0.37718. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.23447/0.39419. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.22938/0.42192. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.23834/0.40556. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.23036/0.43621. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.22734/0.41028. Took 0.16 sec\n",
      "Epoch 34, Loss(train/val) 0.23413/0.40965. Took 0.19 sec\n",
      "Epoch 35, Loss(train/val) 0.22407/0.40495. Took 0.19 sec\n",
      "Epoch 36, Loss(train/val) 0.22784/0.40950. Took 0.20 sec\n",
      "Epoch 37, Loss(train/val) 0.22042/0.41156. Took 0.15 sec\n",
      "Epoch 38, Loss(train/val) 0.21319/0.33745. Took 0.15 sec\n",
      "Epoch 39, Loss(train/val) 0.21459/0.34569. Took 0.17 sec\n",
      "Epoch 40, Loss(train/val) 0.21338/0.34291. Took 0.16 sec\n",
      "Epoch 41, Loss(train/val) 0.20889/0.34036. Took 0.15 sec\n",
      "Epoch 42, Loss(train/val) 0.21719/0.35620. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.21251/0.35941. Took 0.18 sec\n",
      "Epoch 44, Loss(train/val) 0.20861/0.34571. Took 0.16 sec\n",
      "Epoch 45, Loss(train/val) 0.21447/0.34313. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.20605/0.33586. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.20571/0.35782. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.20901/0.42682. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.20113/0.43223. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.19918/0.42860. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.20657/0.37097. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.19639/0.38215. Took 0.15 sec\n",
      "Epoch 53, Loss(train/val) 0.21424/0.36939. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.20245/0.34984. Took 0.15 sec\n",
      "Epoch 55, Loss(train/val) 0.20008/0.38513. Took 0.15 sec\n",
      "Epoch 56, Loss(train/val) 0.19706/0.34091. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.20032/0.35147. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.19192/0.33812. Took 0.15 sec\n",
      "Epoch 59, Loss(train/val) 0.19322/0.34783. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.18785/0.39119. Took 0.14 sec\n",
      "Epoch 61, Loss(train/val) 0.18978/0.35541. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.19335/0.37826. Took 0.15 sec\n",
      "Epoch 63, Loss(train/val) 0.19717/0.37036. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.18558/0.33661. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.18572/0.36137. Took 0.16 sec\n",
      "Epoch 66, Loss(train/val) 0.19151/0.36175. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) 0.19172/0.38703. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.19328/0.37881. Took 0.14 sec\n",
      "Epoch 69, Loss(train/val) 0.18502/0.34944. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.17854/0.35073. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.17824/0.37975. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.18455/0.37048. Took 0.15 sec\n",
      "Epoch 73, Loss(train/val) 0.18042/0.33983. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.18931/0.33035. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) 0.17957/0.35532. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.17951/0.37052. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.17791/0.36480. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.18081/0.35293. Took 0.15 sec\n",
      "Epoch 79, Loss(train/val) 0.17782/0.36539. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.17810/0.35292. Took 0.16 sec\n",
      "Epoch 81, Loss(train/val) 0.17552/0.35983. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.17147/0.36744. Took 0.17 sec\n",
      "Epoch 83, Loss(train/val) 0.17224/0.35775. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.16605/0.37379. Took 0.16 sec\n",
      "Epoch 85, Loss(train/val) 0.18118/0.36085. Took 0.15 sec\n",
      "Epoch 86, Loss(train/val) 0.18009/0.36005. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.16660/0.35688. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.16829/0.35631. Took 0.15 sec\n",
      "Epoch 89, Loss(train/val) 0.17297/0.36102. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.17425/0.38524. Took 0.15 sec\n",
      "Epoch 91, Loss(train/val) 0.16952/0.37381. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.17891/0.36216. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.17146/0.39081. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.16965/0.36921. Took 0.15 sec\n",
      "Epoch 95, Loss(train/val) 0.16328/0.37812. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.16358/0.39180. Took 0.17 sec\n",
      "Epoch 97, Loss(train/val) 0.16489/0.38555. Took 0.16 sec\n",
      "Epoch 98, Loss(train/val) 0.16343/0.36943. Took 0.15 sec\n",
      "Epoch 99, Loss(train/val) 0.16307/0.36836. Took 0.14 sec\n",
      "ACC: 0.546875, MCC: 0.2188190425877391\n",
      "Epoch 0, Loss(train/val) 0.48906/0.48066. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.46161/0.45319. Took 0.15 sec\n",
      "Epoch 2, Loss(train/val) 0.41825/0.41613. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.37970/0.39254. Took 0.15 sec\n",
      "Epoch 4, Loss(train/val) 0.36035/0.38157. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.34738/0.36770. Took 0.15 sec\n",
      "Epoch 6, Loss(train/val) 0.33496/0.37388. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.32366/0.39006. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.31490/0.39797. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.30184/0.38409. Took 0.16 sec\n",
      "Epoch 10, Loss(train/val) 0.29401/0.38885. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.28645/0.45201. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.28044/0.38467. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.28329/0.40872. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.28327/0.37273. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.27372/0.41673. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.27221/0.45906. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.26136/0.40953. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.26002/0.46308. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.25319/0.47848. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.25603/0.37515. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.25207/0.41930. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.24351/0.39434. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.24408/0.46425. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.24273/0.37327. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.24049/0.35498. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.24043/0.37698. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.22931/0.35227. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.22943/0.36617. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.22690/0.34370. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.22752/0.30814. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.22625/0.35069. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.21331/0.38424. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.23063/0.40496. Took 0.16 sec\n",
      "Epoch 34, Loss(train/val) 0.22660/0.37216. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.22382/0.43085. Took 0.15 sec\n",
      "Epoch 36, Loss(train/val) 0.21562/0.34594. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.23253/0.34161. Took 0.15 sec\n",
      "Epoch 38, Loss(train/val) 0.21597/0.32390. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.21522/0.40342. Took 0.16 sec\n",
      "Epoch 40, Loss(train/val) 0.21099/0.41911. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.20349/0.38649. Took 0.15 sec\n",
      "Epoch 42, Loss(train/val) 0.20067/0.43304. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.20730/0.34713. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.20034/0.33746. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.19397/0.38350. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.19917/0.42956. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.19061/0.39782. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.19181/0.39202. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.19895/0.41543. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.19377/0.33293. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.19314/0.39668. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.17836/0.40865. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.18084/0.37362. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.18049/0.41167. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.17133/0.39663. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.17197/0.39329. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.17207/0.38129. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.17068/0.36858. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.17347/0.36306. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.16341/0.35133. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.17243/0.35323. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.17020/0.37157. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.17102/0.36331. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.17069/0.39700. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.15643/0.40535. Took 0.15 sec\n",
      "Epoch 66, Loss(train/val) 0.16485/0.35858. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.16894/0.37081. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.17251/0.33743. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.16675/0.38777. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.15651/0.38075. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.15948/0.38040. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.16527/0.34303. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.15471/0.36850. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.15396/0.39517. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.14507/0.34988. Took 0.15 sec\n",
      "Epoch 76, Loss(train/val) 0.15343/0.39215. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.15886/0.38419. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.16462/0.36758. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.15371/0.38856. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.15172/0.39671. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.14709/0.35549. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.14101/0.37847. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.14401/0.37253. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.14833/0.37815. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.14941/0.34038. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.14337/0.36125. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.13690/0.34863. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.14323/0.36924. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.15498/0.35117. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.13904/0.34721. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.13797/0.35838. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.13691/0.35790. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.13815/0.35764. Took 0.15 sec\n",
      "Epoch 94, Loss(train/val) 0.13965/0.35944. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.14592/0.36129. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.14477/0.34428. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.13554/0.36490. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.14077/0.35880. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.13392/0.35754. Took 0.14 sec\n",
      "ACC: 0.6875, MCC: 0.44132821044702913\n",
      "Epoch 0, Loss(train/val) 0.49728/0.49168. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.47811/0.46320. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.45181/0.42157. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.42791/0.39821. Took 0.16 sec\n",
      "Epoch 4, Loss(train/val) 0.41385/0.38470. Took 0.15 sec\n",
      "Epoch 5, Loss(train/val) 0.40394/0.37758. Took 0.16 sec\n",
      "Epoch 6, Loss(train/val) 0.39972/0.38333. Took 0.15 sec\n",
      "Epoch 7, Loss(train/val) 0.38970/0.36496. Took 0.15 sec\n",
      "Epoch 8, Loss(train/val) 0.38649/0.37494. Took 0.15 sec\n",
      "Epoch 9, Loss(train/val) 0.37599/0.36207. Took 0.16 sec\n",
      "Epoch 10, Loss(train/val) 0.36665/0.37157. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.35242/0.36194. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.34287/0.35985. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.33337/0.35406. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.32408/0.35616. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.31007/0.35553. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.30273/0.37661. Took 0.15 sec\n",
      "Epoch 17, Loss(train/val) 0.30587/0.34623. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.28885/0.36221. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.27379/0.33463. Took 0.15 sec\n",
      "Epoch 20, Loss(train/val) 0.27151/0.34291. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.26637/0.34819. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.26724/0.34655. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.26150/0.33880. Took 0.16 sec\n",
      "Epoch 24, Loss(train/val) 0.25156/0.36251. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.24645/0.34893. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.24933/0.34188. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.23562/0.34434. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.24462/0.35322. Took 0.13 sec\n",
      "Epoch 29, Loss(train/val) 0.22754/0.34353. Took 0.16 sec\n",
      "Epoch 30, Loss(train/val) 0.22942/0.35549. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.22959/0.35410. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.22610/0.36052. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.22345/0.36140. Took 0.16 sec\n",
      "Epoch 34, Loss(train/val) 0.22096/0.36430. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.22156/0.36528. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.20700/0.36161. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.20336/0.36094. Took 0.16 sec\n",
      "Epoch 38, Loss(train/val) 0.20217/0.35852. Took 0.15 sec\n",
      "Epoch 39, Loss(train/val) 0.19550/0.35808. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.19482/0.35711. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.19557/0.36065. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.19091/0.35610. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.19273/0.36406. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.18981/0.35944. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.18565/0.36469. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.18412/0.36966. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.18490/0.36130. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.17785/0.35691. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.18765/0.36068. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.17103/0.36076. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.17660/0.36874. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.17195/0.36221. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.17128/0.36612. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.16296/0.37231. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.18536/0.37048. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.17439/0.37145. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.17683/0.36838. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.15534/0.36424. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.16450/0.36877. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.15721/0.37678. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.15909/0.37086. Took 0.15 sec\n",
      "Epoch 62, Loss(train/val) 0.15208/0.36974. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.15440/0.37275. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.15785/0.36829. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.16056/0.37700. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.14868/0.37064. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.15466/0.37576. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.14671/0.37146. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.15303/0.38296. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.15001/0.37452. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.14204/0.36305. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.14438/0.36100. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.15304/0.35808. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.14607/0.35846. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.14065/0.36024. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.13609/0.35965. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.13979/0.36362. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.13315/0.35277. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.13830/0.35952. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.13635/0.35519. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.13820/0.35821. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.13353/0.37509. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.12928/0.36490. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.13049/0.36693. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.12621/0.36597. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.12677/0.35730. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.13982/0.37677. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.12789/0.36303. Took 0.14 sec\n",
      "Epoch 89, Loss(train/val) 0.12723/0.37439. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.13068/0.36005. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.12518/0.37358. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.12081/0.35451. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.12665/0.37086. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.12904/0.35220. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.11844/0.34786. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.12664/0.35538. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.12387/0.36148. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.11910/0.37202. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.12719/0.36035. Took 0.14 sec\n",
      "ACC: 0.6875, MCC: 0.4172897660939783\n",
      "Epoch 0, Loss(train/val) 0.49226/0.47994. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.46808/0.45757. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.44560/0.44783. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.42865/0.42664. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.41453/0.42097. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.40595/0.42015. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.39490/0.39825. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.38636/0.37441. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.37279/0.35231. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.34675/0.31958. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.33198/0.27864. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.33217/0.29718. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.31725/0.27170. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.31951/0.26931. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.30339/0.26325. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.30488/0.27646. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.29890/0.28014. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.29842/0.29686. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.29531/0.28227. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.29574/0.25815. Took 0.15 sec\n",
      "Epoch 20, Loss(train/val) 0.27696/0.27113. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.26959/0.24813. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.28599/0.27652. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.26880/0.26782. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.26496/0.27449. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.26488/0.23958. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.26226/0.26440. Took 0.13 sec\n",
      "Epoch 27, Loss(train/val) 0.25649/0.24295. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.25298/0.26277. Took 0.13 sec\n",
      "Epoch 29, Loss(train/val) 0.25038/0.26049. Took 0.13 sec\n",
      "Epoch 30, Loss(train/val) 0.25134/0.23430. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.24444/0.23785. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.24367/0.26537. Took 0.13 sec\n",
      "Epoch 33, Loss(train/val) 0.24749/0.23207. Took 0.16 sec\n",
      "Epoch 34, Loss(train/val) 0.24167/0.22015. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.24251/0.22032. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.24045/0.19684. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.22152/0.26516. Took 0.17 sec\n",
      "Epoch 38, Loss(train/val) 0.22644/0.20041. Took 0.15 sec\n",
      "Epoch 39, Loss(train/val) 0.21582/0.22649. Took 0.15 sec\n",
      "Epoch 40, Loss(train/val) 0.22157/0.23985. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.20892/0.23718. Took 0.16 sec\n",
      "Epoch 42, Loss(train/val) 0.22386/0.24992. Took 0.15 sec\n",
      "Epoch 43, Loss(train/val) 0.20797/0.22601. Took 0.17 sec\n",
      "Epoch 44, Loss(train/val) 0.21112/0.24487. Took 0.15 sec\n",
      "Epoch 45, Loss(train/val) 0.20996/0.20214. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.20866/0.26561. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.21500/0.25405. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.20855/0.22282. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.20194/0.22565. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.20535/0.21232. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.20845/0.21061. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.20786/0.21780. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.20457/0.25951. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.20272/0.20356. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.18891/0.23959. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.19506/0.21338. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.18743/0.21459. Took 0.15 sec\n",
      "Epoch 58, Loss(train/val) 0.19654/0.22391. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.18967/0.21179. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.19201/0.22037. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.18014/0.29256. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.18695/0.16486. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.19241/0.29884. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.18768/0.22119. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.18901/0.22930. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.18290/0.27505. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) 0.17508/0.25012. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.16828/0.27272. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.17312/0.24294. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.17446/0.29224. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.17512/0.25967. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.17001/0.23957. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.16589/0.26864. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.16250/0.25801. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.16640/0.26906. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.16946/0.22825. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.17466/0.26704. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.16928/0.26241. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.16401/0.22884. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.16707/0.23356. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.15755/0.21693. Took 0.15 sec\n",
      "Epoch 82, Loss(train/val) 0.16145/0.21180. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.15797/0.21574. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.15503/0.24115. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.16203/0.20887. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.14933/0.22648. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.15536/0.24856. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.15288/0.25112. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.15348/0.21410. Took 0.15 sec\n",
      "Epoch 90, Loss(train/val) 0.16317/0.23270. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.15592/0.29016. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.15541/0.23041. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.15432/0.24498. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.15523/0.28083. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.16031/0.21221. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.14842/0.26124. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.14608/0.24018. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.14493/0.24805. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.14213/0.26076. Took 0.14 sec\n",
      "ACC: 0.65625, MCC: 0.32148654400651655\n",
      "Epoch 0, Loss(train/val) 0.49030/0.49283. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.46828/0.47656. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.44283/0.44261. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.41649/0.40578. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.39997/0.38515. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.38192/0.35490. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.36611/0.33689. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.35023/0.34153. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.33759/0.41001. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.32486/0.42836. Took 0.15 sec\n",
      "Epoch 10, Loss(train/val) 0.32231/0.42394. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.32221/0.47691. Took 0.15 sec\n",
      "Epoch 12, Loss(train/val) 0.31304/0.39176. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.30680/0.43978. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.30670/0.37017. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.29923/0.40066. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.29070/0.40290. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.28291/0.43274. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.28810/0.42081. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.27709/0.46322. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.28366/0.42538. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.28084/0.42779. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.28033/0.43532. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.27132/0.41031. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.26704/0.39509. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.25901/0.41251. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.24473/0.40973. Took 0.13 sec\n",
      "Epoch 27, Loss(train/val) 0.25240/0.43425. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.25216/0.40886. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.25124/0.40819. Took 0.16 sec\n",
      "Epoch 30, Loss(train/val) 0.25026/0.43463. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.23746/0.40941. Took 0.17 sec\n",
      "Epoch 32, Loss(train/val) 0.23858/0.41620. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.23236/0.43058. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.24423/0.41119. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.22548/0.42248. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.23647/0.43376. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.23568/0.38186. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.23247/0.39843. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.21833/0.36667. Took 0.16 sec\n",
      "Epoch 40, Loss(train/val) 0.24005/0.40574. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.24089/0.38682. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.22114/0.38824. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.22020/0.35045. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.21979/0.37182. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.21244/0.37664. Took 0.15 sec\n",
      "Epoch 46, Loss(train/val) 0.22319/0.36619. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.22494/0.37367. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.20511/0.37619. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.21314/0.35452. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.20460/0.38083. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.19534/0.36685. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.19694/0.37165. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.19553/0.38009. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.19636/0.38203. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.19436/0.36670. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.19632/0.37248. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.19348/0.36355. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.18691/0.36612. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.19300/0.36639. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.18218/0.35512. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.18868/0.34547. Took 0.15 sec\n",
      "Epoch 62, Loss(train/val) 0.17929/0.35113. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.18673/0.33018. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.18599/0.35521. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.18454/0.35004. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.17608/0.34059. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.17426/0.32412. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.16695/0.34018. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.17753/0.31601. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.18591/0.33745. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.16921/0.36180. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.16926/0.35525. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.16955/0.33714. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.16613/0.35179. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.16781/0.36186. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.16770/0.36211. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.17324/0.35051. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.15335/0.34981. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.16857/0.33377. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.16212/0.34277. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.16051/0.34169. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.18120/0.34537. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.16011/0.35346. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.14692/0.33495. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.15662/0.31140. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.14968/0.33584. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.15972/0.31770. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.15438/0.32509. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.15285/0.33202. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.14831/0.33465. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.14491/0.34413. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.14101/0.34032. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.14128/0.33840. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.14856/0.33250. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.14050/0.33841. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.14376/0.34440. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.14494/0.32669. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.14513/0.34863. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.14435/0.32270. Took 0.15 sec\n",
      "ACC: 0.640625, MCC: 0.2506422767984621\n",
      "Epoch 0, Loss(train/val) 0.48737/0.44830. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.46346/0.39992. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.43812/0.37236. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.41829/0.36752. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.40710/0.37275. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.39733/0.37316. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.38276/0.37109. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.37206/0.35322. Took 0.17 sec\n",
      "Epoch 8, Loss(train/val) 0.35605/0.34313. Took 0.16 sec\n",
      "Epoch 9, Loss(train/val) 0.33995/0.33161. Took 0.16 sec\n",
      "Epoch 10, Loss(train/val) 0.33978/0.32661. Took 0.17 sec\n",
      "Epoch 11, Loss(train/val) 0.33793/0.30184. Took 0.16 sec\n",
      "Epoch 12, Loss(train/val) 0.32182/0.29590. Took 0.15 sec\n",
      "Epoch 13, Loss(train/val) 0.33738/0.33034. Took 0.16 sec\n",
      "Epoch 14, Loss(train/val) 0.32423/0.30757. Took 0.15 sec\n",
      "Epoch 15, Loss(train/val) 0.31168/0.33563. Took 0.17 sec\n",
      "Epoch 16, Loss(train/val) 0.30284/0.28797. Took 0.16 sec\n",
      "Epoch 17, Loss(train/val) 0.30460/0.30058. Took 0.16 sec\n",
      "Epoch 18, Loss(train/val) 0.30216/0.31915. Took 0.16 sec\n",
      "Epoch 19, Loss(train/val) 0.28684/0.31806. Took 0.16 sec\n",
      "Epoch 20, Loss(train/val) 0.28524/0.31194. Took 0.16 sec\n",
      "Epoch 21, Loss(train/val) 0.27615/0.30990. Took 0.16 sec\n",
      "Epoch 22, Loss(train/val) 0.27679/0.31372. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.26887/0.31021. Took 0.16 sec\n",
      "Epoch 24, Loss(train/val) 0.26666/0.31589. Took 0.15 sec\n",
      "Epoch 25, Loss(train/val) 0.26680/0.30145. Took 0.16 sec\n",
      "Epoch 26, Loss(train/val) 0.26990/0.30362. Took 0.15 sec\n",
      "Epoch 27, Loss(train/val) 0.25773/0.30576. Took 0.17 sec\n",
      "Epoch 28, Loss(train/val) 0.25121/0.34517. Took 0.17 sec\n",
      "Epoch 29, Loss(train/val) 0.25232/0.32844. Took 0.19 sec\n",
      "Epoch 30, Loss(train/val) 0.25748/0.30819. Took 0.18 sec\n",
      "Epoch 31, Loss(train/val) 0.25080/0.32498. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.23567/0.34409. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.25508/0.31948. Took 0.17 sec\n",
      "Epoch 34, Loss(train/val) 0.24827/0.32660. Took 0.16 sec\n",
      "Epoch 35, Loss(train/val) 0.23504/0.34440. Took 0.15 sec\n",
      "Epoch 36, Loss(train/val) 0.23254/0.32434. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.22581/0.33160. Took 0.17 sec\n",
      "Epoch 38, Loss(train/val) 0.22716/0.33532. Took 0.15 sec\n",
      "Epoch 39, Loss(train/val) 0.24776/0.35617. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.23896/0.31812. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.22815/0.33628. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.22512/0.32672. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.22964/0.32005. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.21449/0.32155. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.22455/0.32938. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.21527/0.33531. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.21365/0.33346. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.21511/0.32466. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.19907/0.33907. Took 0.15 sec\n",
      "Epoch 50, Loss(train/val) 0.19995/0.33912. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.20021/0.34052. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.20248/0.32680. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) 0.20448/0.33044. Took 0.15 sec\n",
      "Epoch 54, Loss(train/val) 0.19299/0.32324. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.18843/0.31810. Took 0.15 sec\n",
      "Epoch 56, Loss(train/val) 0.19225/0.32310. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.18426/0.32392. Took 0.15 sec\n",
      "Epoch 58, Loss(train/val) 0.17928/0.33486. Took 0.14 sec\n",
      "Epoch 59, Loss(train/val) 0.17699/0.33496. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.17790/0.33109. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.17517/0.33857. Took 0.15 sec\n",
      "Epoch 62, Loss(train/val) 0.18146/0.32631. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.18140/0.32873. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.17416/0.31739. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.17949/0.32282. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.17232/0.32255. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.16631/0.30665. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.15842/0.32407. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.17065/0.31658. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.16856/0.32335. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.16898/0.32236. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.17503/0.32492. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.16426/0.31116. Took 0.15 sec\n",
      "Epoch 74, Loss(train/val) 0.15828/0.32260. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) 0.15944/0.32489. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.16943/0.32346. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.15995/0.32403. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.15354/0.32757. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.15228/0.32902. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.15250/0.33020. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.15319/0.31055. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.15364/0.31317. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) 0.15034/0.32550. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.15342/0.32374. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.14690/0.31704. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.14130/0.31441. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.14651/0.33105. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.13757/0.34125. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.13766/0.33597. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.13977/0.34171. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.14661/0.32846. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.13643/0.32182. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.13534/0.34092. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.13436/0.32244. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.13783/0.31786. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.13341/0.33600. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.13598/0.32580. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.12914/0.32584. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.13807/0.32625. Took 0.13 sec\n",
      "ACC: 0.71875, MCC: 0.4475057658924364\n",
      "Epoch 0, Loss(train/val) 0.49105/0.47226. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.46425/0.42473. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.43208/0.37655. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.41025/0.35086. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.39797/0.33701. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.39303/0.33298. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.38543/0.31830. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.38008/0.31966. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.37683/0.31597. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.36288/0.31326. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.35121/0.32273. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.33685/0.32617. Took 0.15 sec\n",
      "Epoch 12, Loss(train/val) 0.31942/0.32838. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.31696/0.34773. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.30937/0.33593. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.30163/0.35197. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.30393/0.34926. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.29196/0.34671. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.29062/0.33219. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.29055/0.29677. Took 0.15 sec\n",
      "Epoch 20, Loss(train/val) 0.28140/0.29775. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.27100/0.37056. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.28105/0.34392. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.27746/0.34077. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.25883/0.35040. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.26050/0.31596. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.25701/0.31537. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.26857/0.34453. Took 0.16 sec\n",
      "Epoch 28, Loss(train/val) 0.26258/0.36948. Took 0.13 sec\n",
      "Epoch 29, Loss(train/val) 0.24775/0.36560. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.25230/0.34105. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.24869/0.34188. Took 0.16 sec\n",
      "Epoch 32, Loss(train/val) 0.23648/0.33592. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.23487/0.35965. Took 0.17 sec\n",
      "Epoch 34, Loss(train/val) 0.23331/0.31607. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.23661/0.34986. Took 0.16 sec\n",
      "Epoch 36, Loss(train/val) 0.22437/0.34342. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.22784/0.37067. Took 0.16 sec\n",
      "Epoch 38, Loss(train/val) 0.22364/0.34777. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.21629/0.38628. Took 0.16 sec\n",
      "Epoch 40, Loss(train/val) 0.22209/0.35132. Took 0.15 sec\n",
      "Epoch 41, Loss(train/val) 0.22240/0.36797. Took 0.15 sec\n",
      "Epoch 42, Loss(train/val) 0.21329/0.40964. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.20750/0.37388. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.20526/0.36523. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.21015/0.37564. Took 0.15 sec\n",
      "Epoch 46, Loss(train/val) 0.20990/0.35146. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.20209/0.35209. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.20170/0.37560. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.20354/0.37635. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.20062/0.36387. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.19538/0.32011. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.19598/0.34862. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.19670/0.34777. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.19461/0.32922. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.19809/0.31438. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.19554/0.30769. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.19512/0.31806. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.19142/0.35038. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.19247/0.34942. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.18830/0.34958. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.18485/0.31925. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.18350/0.31687. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.17754/0.39196. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.18362/0.36255. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.18505/0.35298. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.17646/0.41552. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.17399/0.35530. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.17166/0.38063. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.17308/0.38484. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.16864/0.36466. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.17680/0.39536. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.17274/0.35183. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.16779/0.35568. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.16906/0.35331. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.15331/0.33289. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.16036/0.37201. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.16813/0.36503. Took 0.15 sec\n",
      "Epoch 78, Loss(train/val) 0.15876/0.36476. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.16180/0.33742. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.15635/0.33020. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.15174/0.32538. Took 0.15 sec\n",
      "Epoch 82, Loss(train/val) 0.15061/0.31415. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.14942/0.32928. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.14448/0.32295. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.14676/0.31878. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.13843/0.30822. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.15923/0.34888. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.14509/0.36448. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.13709/0.31729. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.14324/0.34517. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.13779/0.33213. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.13334/0.33347. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.13543/0.32196. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.13802/0.32808. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.13915/0.31079. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.13498/0.30789. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.12748/0.29640. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.12663/0.32368. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.13956/0.29471. Took 0.13 sec\n",
      "ACC: 0.625, MCC: 0.3166692820873667\n",
      "Epoch 0, Loss(train/val) 0.49010/0.48299. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.46644/0.45945. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.43639/0.44253. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.40927/0.43247. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.39382/0.42553. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.38521/0.41339. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.37779/0.40003. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.36503/0.38522. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.35526/0.38791. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.33080/0.37438. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.32855/0.35442. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.31178/0.35223. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.29534/0.33836. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.30061/0.39054. Took 0.16 sec\n",
      "Epoch 14, Loss(train/val) 0.32813/0.37527. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.29973/0.33634. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.29691/0.36466. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.28902/0.35020. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.27538/0.35050. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.27521/0.34460. Took 0.15 sec\n",
      "Epoch 20, Loss(train/val) 0.27384/0.36122. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.27622/0.36325. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.26571/0.35872. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.26805/0.35602. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.26680/0.36513. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.26478/0.35890. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.26478/0.35795. Took 0.13 sec\n",
      "Epoch 27, Loss(train/val) 0.26172/0.35746. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.25923/0.35369. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.25274/0.36458. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.24243/0.36078. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.24860/0.35424. Took 0.16 sec\n",
      "Epoch 32, Loss(train/val) 0.24781/0.35988. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.24367/0.34832. Took 0.17 sec\n",
      "Epoch 34, Loss(train/val) 0.23896/0.36114. Took 0.17 sec\n",
      "Epoch 35, Loss(train/val) 0.23634/0.34503. Took 0.15 sec\n",
      "Epoch 36, Loss(train/val) 0.24456/0.34965. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.24951/0.36777. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.23155/0.34372. Took 0.15 sec\n",
      "Epoch 39, Loss(train/val) 0.23019/0.35504. Took 0.15 sec\n",
      "Epoch 40, Loss(train/val) 0.22307/0.33673. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.22844/0.35309. Took 0.16 sec\n",
      "Epoch 42, Loss(train/val) 0.22757/0.34465. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.21656/0.35110. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.21689/0.35545. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.21995/0.35780. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.21198/0.36541. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.21204/0.35941. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.20551/0.34969. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.19809/0.34567. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.20891/0.33228. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.20495/0.35821. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.20175/0.34142. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.19692/0.33393. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.20475/0.33312. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.19707/0.32815. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.19131/0.33730. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.19038/0.33247. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.19435/0.32280. Took 0.14 sec\n",
      "Epoch 59, Loss(train/val) 0.19369/0.33156. Took 0.15 sec\n",
      "Epoch 60, Loss(train/val) 0.19144/0.32719. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.19440/0.33636. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.18729/0.34092. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.19246/0.31818. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.18476/0.32333. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.17865/0.33727. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.18413/0.32878. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.18031/0.32212. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.18510/0.33802. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.17572/0.33366. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.16867/0.33575. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.17656/0.33166. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.16752/0.31413. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.16397/0.32776. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.16031/0.31926. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.17125/0.33441. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.16598/0.30788. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.16133/0.32138. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.16349/0.31879. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.16339/0.32427. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.16608/0.33650. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.15876/0.32807. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.16231/0.31130. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.15407/0.33092. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.15243/0.34318. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.15740/0.33694. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.15493/0.32242. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.14941/0.33623. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.15315/0.32758. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.15209/0.32519. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.14711/0.32074. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.14893/0.32302. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.15004/0.33414. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.14546/0.34507. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.14754/0.33391. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.14669/0.30861. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.14356/0.31247. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.14110/0.30027. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.14633/0.29812. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.14991/0.32387. Took 0.14 sec\n",
      "ACC: 0.640625, MCC: 0.3354321472637219\n",
      "Epoch 0, Loss(train/val) 0.49194/0.48669. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.46931/0.46308. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.44141/0.42472. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.41624/0.39420. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.40120/0.37856. Took 0.16 sec\n",
      "Epoch 5, Loss(train/val) 0.39172/0.34780. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.37758/0.33210. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.36748/0.34057. Took 0.15 sec\n",
      "Epoch 8, Loss(train/val) 0.35068/0.30804. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.33769/0.30441. Took 0.15 sec\n",
      "Epoch 10, Loss(train/val) 0.32244/0.35499. Took 0.15 sec\n",
      "Epoch 11, Loss(train/val) 0.30938/0.33772. Took 0.16 sec\n",
      "Epoch 12, Loss(train/val) 0.30988/0.33604. Took 0.16 sec\n",
      "Epoch 13, Loss(train/val) 0.29595/0.35057. Took 0.24 sec\n",
      "Epoch 14, Loss(train/val) 0.28621/0.36001. Took 0.24 sec\n",
      "Epoch 15, Loss(train/val) 0.28375/0.37540. Took 0.23 sec\n",
      "Epoch 16, Loss(train/val) 0.28468/0.36243. Took 0.25 sec\n",
      "Epoch 17, Loss(train/val) 0.28053/0.35210. Took 0.21 sec\n",
      "Epoch 18, Loss(train/val) 0.28582/0.36708. Took 0.18 sec\n",
      "Epoch 19, Loss(train/val) 0.27037/0.38234. Took 0.16 sec\n",
      "Epoch 20, Loss(train/val) 0.26909/0.37181. Took 0.19 sec\n",
      "Epoch 21, Loss(train/val) 0.26068/0.39053. Took 0.17 sec\n",
      "Epoch 22, Loss(train/val) 0.26213/0.37629. Took 0.16 sec\n",
      "Epoch 23, Loss(train/val) 0.26114/0.38462. Took 0.20 sec\n",
      "Epoch 24, Loss(train/val) 0.25764/0.39275. Took 0.17 sec\n",
      "Epoch 25, Loss(train/val) 0.24977/0.38460. Took 0.17 sec\n",
      "Epoch 26, Loss(train/val) 0.25797/0.40561. Took 0.19 sec\n",
      "Epoch 27, Loss(train/val) 0.24685/0.41317. Took 0.17 sec\n",
      "Epoch 28, Loss(train/val) 0.24319/0.38355. Took 0.20 sec\n",
      "Epoch 29, Loss(train/val) 0.25645/0.37906. Took 0.16 sec\n",
      "Epoch 30, Loss(train/val) 0.24181/0.40014. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.24590/0.36585. Took 0.16 sec\n",
      "Epoch 32, Loss(train/val) 0.24078/0.40329. Took 0.17 sec\n",
      "Epoch 33, Loss(train/val) 0.23170/0.38843. Took 0.16 sec\n",
      "Epoch 34, Loss(train/val) 0.23385/0.37574. Took 0.16 sec\n",
      "Epoch 35, Loss(train/val) 0.23168/0.37798. Took 0.15 sec\n",
      "Epoch 36, Loss(train/val) 0.23191/0.35490. Took 0.17 sec\n",
      "Epoch 37, Loss(train/val) 0.22566/0.41501. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.22339/0.36796. Took 0.15 sec\n",
      "Epoch 39, Loss(train/val) 0.23030/0.36683. Took 0.15 sec\n",
      "Epoch 40, Loss(train/val) 0.22113/0.41814. Took 0.17 sec\n",
      "Epoch 41, Loss(train/val) 0.23038/0.41726. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.20854/0.36785. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.22214/0.37494. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.22660/0.40104. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.22777/0.38809. Took 0.15 sec\n",
      "Epoch 46, Loss(train/val) 0.20920/0.39086. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.21276/0.41497. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.20967/0.37013. Took 0.15 sec\n",
      "Epoch 49, Loss(train/val) 0.19963/0.38870. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.20112/0.41942. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.21786/0.38839. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.20356/0.37203. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.21206/0.37532. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.20060/0.35641. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.20154/0.40884. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.19668/0.34403. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.19816/0.36930. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.19231/0.38992. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.19038/0.38424. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.19436/0.38173. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.18497/0.39973. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.18070/0.41385. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.18844/0.39158. Took 0.15 sec\n",
      "Epoch 64, Loss(train/val) 0.18661/0.40516. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.17978/0.40997. Took 0.15 sec\n",
      "Epoch 66, Loss(train/val) 0.18896/0.39986. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.19317/0.40711. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.17822/0.40350. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.17176/0.39993. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.17465/0.38303. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.17863/0.38341. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.17205/0.37767. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.17424/0.36530. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.17392/0.37106. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.16380/0.37394. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.17065/0.37425. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.17458/0.37557. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.17574/0.38114. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.17161/0.36602. Took 0.15 sec\n",
      "Epoch 80, Loss(train/val) 0.16625/0.37851. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.16723/0.39000. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.16292/0.38131. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.16387/0.37478. Took 0.15 sec\n",
      "Epoch 84, Loss(train/val) 0.17471/0.39784. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.16481/0.36445. Took 0.15 sec\n",
      "Epoch 86, Loss(train/val) 0.16459/0.37962. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.17794/0.35775. Took 0.16 sec\n",
      "Epoch 88, Loss(train/val) 0.17227/0.36824. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.16174/0.34885. Took 0.15 sec\n",
      "Epoch 90, Loss(train/val) 0.15398/0.38026. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.15629/0.38218. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.15288/0.38919. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.15274/0.38089. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.14748/0.37590. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.15480/0.36181. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.15192/0.39699. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.14440/0.38508. Took 0.15 sec\n",
      "Epoch 98, Loss(train/val) 0.14801/0.38023. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.14640/0.36020. Took 0.14 sec\n",
      "ACC: 0.65625, MCC: 0.3110917000380287\n",
      "Epoch 0, Loss(train/val) 0.48942/0.46052. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.46077/0.41603. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.42932/0.36866. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.40375/0.33660. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.38984/0.32530. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.37900/0.32058. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.36707/0.35037. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.35377/0.35144. Took 0.16 sec\n",
      "Epoch 8, Loss(train/val) 0.34281/0.31941. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.33803/0.36123. Took 0.15 sec\n",
      "Epoch 10, Loss(train/val) 0.31811/0.33135. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.30890/0.34191. Took 0.16 sec\n",
      "Epoch 12, Loss(train/val) 0.31959/0.32822. Took 0.15 sec\n",
      "Epoch 13, Loss(train/val) 0.31277/0.31065. Took 0.24 sec\n",
      "Epoch 14, Loss(train/val) 0.30205/0.33708. Took 0.20 sec\n",
      "Epoch 15, Loss(train/val) 0.29281/0.33023. Took 0.21 sec\n",
      "Epoch 16, Loss(train/val) 0.30768/0.33634. Took 0.20 sec\n",
      "Epoch 17, Loss(train/val) 0.28574/0.36066. Took 0.20 sec\n",
      "Epoch 18, Loss(train/val) 0.28780/0.34169. Took 0.17 sec\n",
      "Epoch 19, Loss(train/val) 0.27724/0.34546. Took 0.17 sec\n",
      "Epoch 20, Loss(train/val) 0.27919/0.37156. Took 0.15 sec\n",
      "Epoch 21, Loss(train/val) 0.26079/0.35899. Took 0.18 sec\n",
      "Epoch 22, Loss(train/val) 0.26914/0.36142. Took 0.17 sec\n",
      "Epoch 23, Loss(train/val) 0.25978/0.35555. Took 0.16 sec\n",
      "Epoch 24, Loss(train/val) 0.25033/0.35378. Took 0.15 sec\n",
      "Epoch 25, Loss(train/val) 0.26038/0.35814. Took 0.18 sec\n",
      "Epoch 26, Loss(train/val) 0.25491/0.35731. Took 0.15 sec\n",
      "Epoch 27, Loss(train/val) 0.25706/0.34511. Took 0.16 sec\n",
      "Epoch 28, Loss(train/val) 0.25329/0.37317. Took 0.16 sec\n",
      "Epoch 29, Loss(train/val) 0.25466/0.36261. Took 0.20 sec\n",
      "Epoch 30, Loss(train/val) 0.24571/0.35864. Took 0.18 sec\n",
      "Epoch 31, Loss(train/val) 0.25017/0.36553. Took 0.19 sec\n",
      "Epoch 32, Loss(train/val) 0.23800/0.35191. Took 0.18 sec\n",
      "Epoch 33, Loss(train/val) 0.24293/0.37113. Took 0.17 sec\n",
      "Epoch 34, Loss(train/val) 0.23625/0.35216. Took 0.19 sec\n",
      "Epoch 35, Loss(train/val) 0.23448/0.35824. Took 0.19 sec\n",
      "Epoch 36, Loss(train/val) 0.23386/0.37703. Took 0.17 sec\n",
      "Epoch 37, Loss(train/val) 0.24096/0.38576. Took 0.17 sec\n",
      "Epoch 38, Loss(train/val) 0.23399/0.35045. Took 0.19 sec\n",
      "Epoch 39, Loss(train/val) 0.23510/0.36449. Took 0.17 sec\n",
      "Epoch 40, Loss(train/val) 0.22378/0.39772. Took 0.16 sec\n",
      "Epoch 41, Loss(train/val) 0.22553/0.38912. Took 0.16 sec\n",
      "Epoch 42, Loss(train/val) 0.22343/0.38218. Took 0.16 sec\n",
      "Epoch 43, Loss(train/val) 0.21627/0.39715. Took 0.17 sec\n",
      "Epoch 44, Loss(train/val) 0.21612/0.38627. Took 0.17 sec\n",
      "Epoch 45, Loss(train/val) 0.21532/0.39878. Took 0.15 sec\n",
      "Epoch 46, Loss(train/val) 0.22204/0.39330. Took 0.16 sec\n",
      "Epoch 47, Loss(train/val) 0.21712/0.37048. Took 0.17 sec\n",
      "Epoch 48, Loss(train/val) 0.21016/0.38905. Took 0.18 sec\n",
      "Epoch 49, Loss(train/val) 0.20926/0.38171. Took 0.15 sec\n",
      "Epoch 50, Loss(train/val) 0.20757/0.37308. Took 0.15 sec\n",
      "Epoch 51, Loss(train/val) 0.20341/0.37659. Took 0.15 sec\n",
      "Epoch 52, Loss(train/val) 0.20829/0.38454. Took 0.17 sec\n",
      "Epoch 53, Loss(train/val) 0.20553/0.37226. Took 0.16 sec\n",
      "Epoch 54, Loss(train/val) 0.19936/0.36326. Took 0.15 sec\n",
      "Epoch 55, Loss(train/val) 0.20893/0.39335. Took 0.17 sec\n",
      "Epoch 56, Loss(train/val) 0.19367/0.38174. Took 0.16 sec\n",
      "Epoch 57, Loss(train/val) 0.20422/0.39805. Took 0.18 sec\n",
      "Epoch 58, Loss(train/val) 0.19247/0.40185. Took 0.17 sec\n",
      "Epoch 59, Loss(train/val) 0.20517/0.37847. Took 0.17 sec\n",
      "Epoch 60, Loss(train/val) 0.18716/0.38681. Took 0.16 sec\n",
      "Epoch 61, Loss(train/val) 0.19480/0.39144. Took 0.16 sec\n",
      "Epoch 62, Loss(train/val) 0.20123/0.37535. Took 0.19 sec\n",
      "Epoch 63, Loss(train/val) 0.18831/0.39407. Took 0.17 sec\n",
      "Epoch 64, Loss(train/val) 0.18937/0.38769. Took 0.19 sec\n",
      "Epoch 65, Loss(train/val) 0.19298/0.37995. Took 0.17 sec\n",
      "Epoch 66, Loss(train/val) 0.19334/0.38173. Took 0.16 sec\n",
      "Epoch 67, Loss(train/val) 0.18412/0.38171. Took 0.16 sec\n",
      "Epoch 68, Loss(train/val) 0.18311/0.37432. Took 0.19 sec\n",
      "Epoch 69, Loss(train/val) 0.18714/0.38207. Took 0.16 sec\n",
      "Epoch 70, Loss(train/val) 0.18616/0.37227. Took 0.17 sec\n",
      "Epoch 71, Loss(train/val) 0.18766/0.35178. Took 0.16 sec\n",
      "Epoch 72, Loss(train/val) 0.18388/0.38075. Took 0.18 sec\n",
      "Epoch 73, Loss(train/val) 0.18945/0.36558. Took 0.16 sec\n",
      "Epoch 74, Loss(train/val) 0.18565/0.39142. Took 0.15 sec\n",
      "Epoch 75, Loss(train/val) 0.18374/0.35822. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.17853/0.35548. Took 0.17 sec\n",
      "Epoch 77, Loss(train/val) 0.17605/0.35319. Took 0.17 sec\n",
      "Epoch 78, Loss(train/val) 0.18565/0.34973. Took 0.15 sec\n",
      "Epoch 79, Loss(train/val) 0.17995/0.35562. Took 0.15 sec\n",
      "Epoch 80, Loss(train/val) 0.17888/0.36465. Took 0.15 sec\n",
      "Epoch 81, Loss(train/val) 0.17539/0.35358. Took 0.17 sec\n",
      "Epoch 82, Loss(train/val) 0.17604/0.35110. Took 0.16 sec\n",
      "Epoch 83, Loss(train/val) 0.17316/0.36692. Took 0.16 sec\n",
      "Epoch 84, Loss(train/val) 0.17761/0.35013. Took 0.18 sec\n",
      "Epoch 85, Loss(train/val) 0.17354/0.35012. Took 0.16 sec\n",
      "Epoch 86, Loss(train/val) 0.17219/0.37510. Took 0.16 sec\n",
      "Epoch 87, Loss(train/val) 0.16435/0.36507. Took 0.15 sec\n",
      "Epoch 88, Loss(train/val) 0.17739/0.36800. Took 0.17 sec\n",
      "Epoch 89, Loss(train/val) 0.17037/0.37409. Took 0.18 sec\n",
      "Epoch 90, Loss(train/val) 0.17716/0.36272. Took 0.17 sec\n",
      "Epoch 91, Loss(train/val) 0.16988/0.37860. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.16530/0.35618. Took 0.16 sec\n",
      "Epoch 93, Loss(train/val) 0.16429/0.36759. Took 0.15 sec\n",
      "Epoch 94, Loss(train/val) 0.16554/0.36313. Took 0.14 sec\n",
      "Epoch 95, Loss(train/val) 0.16669/0.39312. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.16049/0.38474. Took 0.15 sec\n",
      "Epoch 97, Loss(train/val) 0.16657/0.36542. Took 0.15 sec\n",
      "Epoch 98, Loss(train/val) 0.17361/0.34946. Took 0.15 sec\n",
      "Epoch 99, Loss(train/val) 0.17133/0.34631. Took 0.15 sec\n",
      "ACC: 0.78125, MCC: 0.5607843137254902\n",
      "Epoch 0, Loss(train/val) 0.48885/0.45911. Took 0.17 sec\n",
      "Epoch 1, Loss(train/val) 0.46409/0.38303. Took 0.16 sec\n",
      "Epoch 2, Loss(train/val) 0.42541/0.30849. Took 0.17 sec\n",
      "Epoch 3, Loss(train/val) 0.39885/0.28094. Took 0.15 sec\n",
      "Epoch 4, Loss(train/val) 0.38823/0.27986. Took 0.16 sec\n",
      "Epoch 5, Loss(train/val) 0.38199/0.27499. Took 0.16 sec\n",
      "Epoch 6, Loss(train/val) 0.37491/0.28150. Took 0.16 sec\n",
      "Epoch 7, Loss(train/val) 0.36928/0.27625. Took 0.17 sec\n",
      "Epoch 8, Loss(train/val) 0.36377/0.26671. Took 0.19 sec\n",
      "Epoch 9, Loss(train/val) 0.35887/0.25386. Took 0.16 sec\n",
      "Epoch 10, Loss(train/val) 0.34465/0.25120. Took 0.16 sec\n",
      "Epoch 11, Loss(train/val) 0.33511/0.27201. Took 0.16 sec\n",
      "Epoch 12, Loss(train/val) 0.33125/0.27172. Took 0.16 sec\n",
      "Epoch 13, Loss(train/val) 0.31063/0.27813. Took 0.19 sec\n",
      "Epoch 14, Loss(train/val) 0.30515/0.28136. Took 0.21 sec\n",
      "Epoch 15, Loss(train/val) 0.31437/0.27308. Took 0.18 sec\n",
      "Epoch 16, Loss(train/val) 0.30175/0.27835. Took 0.16 sec\n",
      "Epoch 17, Loss(train/val) 0.30122/0.26882. Took 0.18 sec\n",
      "Epoch 18, Loss(train/val) 0.29159/0.26179. Took 0.19 sec\n",
      "Epoch 19, Loss(train/val) 0.29123/0.24633. Took 0.18 sec\n",
      "Epoch 20, Loss(train/val) 0.28413/0.26758. Took 0.17 sec\n",
      "Epoch 21, Loss(train/val) 0.28515/0.27188. Took 0.17 sec\n",
      "Epoch 22, Loss(train/val) 0.28046/0.26553. Took 0.18 sec\n",
      "Epoch 23, Loss(train/val) 0.27713/0.23015. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.27596/0.22780. Took 0.15 sec\n",
      "Epoch 25, Loss(train/val) 0.27277/0.27800. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.26424/0.26856. Took 0.17 sec\n",
      "Epoch 27, Loss(train/val) 0.26135/0.23171. Took 0.16 sec\n",
      "Epoch 28, Loss(train/val) 0.26202/0.24897. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.26071/0.27784. Took 0.16 sec\n",
      "Epoch 30, Loss(train/val) 0.24592/0.27177. Took 0.19 sec\n",
      "Epoch 31, Loss(train/val) 0.26359/0.24353. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.25409/0.26686. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.25105/0.26033. Took 0.17 sec\n",
      "Epoch 34, Loss(train/val) 0.25569/0.24538. Took 0.16 sec\n",
      "Epoch 35, Loss(train/val) 0.24661/0.28567. Took 0.15 sec\n",
      "Epoch 36, Loss(train/val) 0.23224/0.28536. Took 0.17 sec\n",
      "Epoch 37, Loss(train/val) 0.23700/0.27030. Took 0.17 sec\n",
      "Epoch 38, Loss(train/val) 0.22798/0.22894. Took 0.17 sec\n",
      "Epoch 39, Loss(train/val) 0.23676/0.28397. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.23117/0.27610. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.22960/0.25696. Took 0.15 sec\n",
      "Epoch 42, Loss(train/val) 0.22849/0.23929. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.23080/0.25308. Took 0.17 sec\n",
      "Epoch 44, Loss(train/val) 0.22498/0.27078. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) 0.22119/0.25474. Took 0.17 sec\n",
      "Epoch 46, Loss(train/val) 0.21514/0.25247. Took 0.15 sec\n",
      "Epoch 47, Loss(train/val) 0.22336/0.26825. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.21901/0.24717. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.22364/0.27421. Took 0.15 sec\n",
      "Epoch 50, Loss(train/val) 0.22016/0.23970. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.22321/0.25417. Took 0.15 sec\n",
      "Epoch 52, Loss(train/val) 0.20888/0.23431. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) 0.20399/0.24213. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.20571/0.27439. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.20896/0.28442. Took 0.15 sec\n",
      "Epoch 56, Loss(train/val) 0.20176/0.24352. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.20422/0.28961. Took 0.18 sec\n",
      "Epoch 58, Loss(train/val) 0.20595/0.25249. Took 0.17 sec\n",
      "Epoch 59, Loss(train/val) 0.19567/0.23074. Took 0.16 sec\n",
      "Epoch 60, Loss(train/val) 0.20263/0.24498. Took 0.15 sec\n",
      "Epoch 61, Loss(train/val) 0.19757/0.28489. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.19366/0.25343. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.19641/0.24067. Took 0.15 sec\n",
      "Epoch 64, Loss(train/val) 0.19259/0.25452. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.19126/0.25386. Took 0.16 sec\n",
      "Epoch 66, Loss(train/val) 0.18955/0.26912. Took 0.18 sec\n",
      "Epoch 67, Loss(train/val) 0.18175/0.26127. Took 0.16 sec\n",
      "Epoch 68, Loss(train/val) 0.18134/0.25703. Took 0.15 sec\n",
      "Epoch 69, Loss(train/val) 0.18569/0.24463. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.18813/0.26043. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.18215/0.25120. Took 0.15 sec\n",
      "Epoch 72, Loss(train/val) 0.17825/0.26278. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.17729/0.25895. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.17571/0.25981. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.19709/0.26296. Took 0.15 sec\n",
      "Epoch 76, Loss(train/val) 0.17965/0.25282. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.18607/0.25907. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.17511/0.25279. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.17903/0.23425. Took 0.15 sec\n",
      "Epoch 80, Loss(train/val) 0.16804/0.26363. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.17312/0.25538. Took 0.15 sec\n",
      "Epoch 82, Loss(train/val) 0.17091/0.27591. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) 0.16558/0.28119. Took 0.15 sec\n",
      "Epoch 84, Loss(train/val) 0.16190/0.27616. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.16055/0.24293. Took 0.15 sec\n",
      "Epoch 86, Loss(train/val) 0.17220/0.24733. Took 0.15 sec\n",
      "Epoch 87, Loss(train/val) 0.16597/0.24371. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.16479/0.24421. Took 0.14 sec\n",
      "Epoch 89, Loss(train/val) 0.16080/0.28178. Took 0.15 sec\n",
      "Epoch 90, Loss(train/val) 0.16397/0.26977. Took 0.14 sec\n",
      "Epoch 91, Loss(train/val) 0.15994/0.28508. Took 0.15 sec\n",
      "Epoch 92, Loss(train/val) 0.16113/0.28208. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.15878/0.28090. Took 0.15 sec\n",
      "Epoch 94, Loss(train/val) 0.16173/0.27211. Took 0.14 sec\n",
      "Epoch 95, Loss(train/val) 0.16092/0.26480. Took 0.15 sec\n",
      "Epoch 96, Loss(train/val) 0.15968/0.25051. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.16546/0.30574. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.15614/0.27023. Took 0.14 sec\n",
      "Epoch 99, Loss(train/val) 0.15998/0.25340. Took 0.15 sec\n",
      "ACC: 0.71875, MCC: 0.4292324488398412\n",
      "Epoch 0, Loss(train/val) 0.48864/0.47656. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.46537/0.42874. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.43161/0.36887. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.40369/0.34161. Took 0.16 sec\n",
      "Epoch 4, Loss(train/val) 0.38555/0.32810. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.37715/0.32321. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.37202/0.31944. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.36347/0.31948. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.35890/0.32066. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.35340/0.32076. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.34459/0.31929. Took 0.15 sec\n",
      "Epoch 11, Loss(train/val) 0.33329/0.30665. Took 0.15 sec\n",
      "Epoch 12, Loss(train/val) 0.31970/0.28682. Took 0.16 sec\n",
      "Epoch 13, Loss(train/val) 0.30755/0.27704. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.30901/0.30803. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.30857/0.30323. Took 0.16 sec\n",
      "Epoch 16, Loss(train/val) 0.29741/0.29980. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.29417/0.28223. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.29237/0.30392. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.28022/0.26399. Took 0.17 sec\n",
      "Epoch 20, Loss(train/val) 0.26883/0.25889. Took 0.18 sec\n",
      "Epoch 21, Loss(train/val) 0.28630/0.26302. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.27543/0.26247. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.26674/0.26485. Took 0.18 sec\n",
      "Epoch 24, Loss(train/val) 0.25857/0.26310. Took 0.16 sec\n",
      "Epoch 25, Loss(train/val) 0.26987/0.27452. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.25437/0.29874. Took 0.15 sec\n",
      "Epoch 27, Loss(train/val) 0.26797/0.27119. Took 0.16 sec\n",
      "Epoch 28, Loss(train/val) 0.26334/0.23956. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.25283/0.23282. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.25357/0.22856. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.25083/0.22088. Took 0.16 sec\n",
      "Epoch 32, Loss(train/val) 0.24581/0.23359. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.25260/0.23038. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.24643/0.25920. Took 0.16 sec\n",
      "Epoch 35, Loss(train/val) 0.24734/0.24334. Took 0.16 sec\n",
      "Epoch 36, Loss(train/val) 0.24623/0.24304. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.23836/0.24203. Took 0.17 sec\n",
      "Epoch 38, Loss(train/val) 0.22938/0.23989. Took 0.15 sec\n",
      "Epoch 39, Loss(train/val) 0.22820/0.25036. Took 0.16 sec\n",
      "Epoch 40, Loss(train/val) 0.22920/0.25825. Took 0.15 sec\n",
      "Epoch 41, Loss(train/val) 0.22593/0.25640. Took 0.15 sec\n",
      "Epoch 42, Loss(train/val) 0.21807/0.26578. Took 0.15 sec\n",
      "Epoch 43, Loss(train/val) 0.21300/0.25075. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.21949/0.26706. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.22204/0.26486. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.22807/0.25548. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.21119/0.25415. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.21633/0.25486. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.21528/0.26136. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.21376/0.26054. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.20035/0.26588. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.21224/0.26183. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.21079/0.26963. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.20688/0.25777. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.20875/0.26107. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.21366/0.24921. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.21226/0.24236. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.20519/0.26422. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.19590/0.26789. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.19578/0.29149. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.19865/0.29651. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.19917/0.26822. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.20451/0.25775. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.19311/0.27306. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.18957/0.27547. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.19309/0.26558. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.18935/0.28160. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.20063/0.27859. Took 0.14 sec\n",
      "Epoch 69, Loss(train/val) 0.18911/0.27825. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.19193/0.32283. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.18767/0.31833. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.18912/0.26031. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.18862/0.32984. Took 0.15 sec\n",
      "Epoch 74, Loss(train/val) 0.18007/0.30169. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.17816/0.27071. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.17625/0.29188. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.17497/0.27548. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.17780/0.29171. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.17576/0.28731. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.18424/0.27861. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.18020/0.27598. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.17394/0.27344. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.16981/0.27453. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.16769/0.29340. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.16397/0.28235. Took 0.15 sec\n",
      "Epoch 86, Loss(train/val) 0.15563/0.27910. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.16587/0.27615. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.16422/0.28934. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.16767/0.28955. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.15702/0.27257. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.15715/0.28026. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.15273/0.26972. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.15917/0.28183. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.15631/0.29652. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.15021/0.27123. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.14843/0.27709. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.14872/0.28617. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.15053/0.30816. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.14499/0.30706. Took 0.14 sec\n",
      "ACC: 0.71875, MCC: 0.4032441137045824\n",
      "Epoch 0, Loss(train/val) 0.48799/0.48256. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.46045/0.44751. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.42404/0.40481. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.39455/0.36906. Took 0.16 sec\n",
      "Epoch 4, Loss(train/val) 0.37385/0.36349. Took 0.16 sec\n",
      "Epoch 5, Loss(train/val) 0.36673/0.34963. Took 0.17 sec\n",
      "Epoch 6, Loss(train/val) 0.35177/0.37335. Took 0.15 sec\n",
      "Epoch 7, Loss(train/val) 0.33955/0.36082. Took 0.16 sec\n",
      "Epoch 8, Loss(train/val) 0.33005/0.34939. Took 0.16 sec\n",
      "Epoch 9, Loss(train/val) 0.30926/0.35682. Took 0.18 sec\n",
      "Epoch 10, Loss(train/val) 0.31831/0.34066. Took 0.15 sec\n",
      "Epoch 11, Loss(train/val) 0.30565/0.50203. Took 0.15 sec\n",
      "Epoch 12, Loss(train/val) 0.31252/0.41924. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.29416/0.35253. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.29950/0.39231. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.28617/0.47781. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.28236/0.46221. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.27533/0.47293. Took 0.16 sec\n",
      "Epoch 18, Loss(train/val) 0.26967/0.48628. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.26880/0.49663. Took 0.15 sec\n",
      "Epoch 20, Loss(train/val) 0.27703/0.50169. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.27406/0.45707. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.27377/0.49753. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.26424/0.47401. Took 0.16 sec\n",
      "Epoch 24, Loss(train/val) 0.25974/0.46126. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.26236/0.47581. Took 0.17 sec\n",
      "Epoch 26, Loss(train/val) 0.25821/0.46839. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.24776/0.46634. Took 0.16 sec\n",
      "Epoch 28, Loss(train/val) 0.24325/0.46636. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.24184/0.45354. Took 0.16 sec\n",
      "Epoch 30, Loss(train/val) 0.23848/0.46422. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.24001/0.46575. Took 0.16 sec\n",
      "Epoch 32, Loss(train/val) 0.24715/0.45048. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.23543/0.45972. Took 0.17 sec\n",
      "Epoch 34, Loss(train/val) 0.24177/0.45207. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.23498/0.44470. Took 0.16 sec\n",
      "Epoch 36, Loss(train/val) 0.25401/0.47400. Took 0.17 sec\n",
      "Epoch 37, Loss(train/val) 0.23198/0.48762. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.24044/0.49336. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.23290/0.45262. Took 0.16 sec\n",
      "Epoch 40, Loss(train/val) 0.23366/0.46289. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.22602/0.42723. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.22140/0.45932. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.23195/0.42528. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.21868/0.45514. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.23495/0.45283. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.21945/0.43789. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.23183/0.44127. Took 0.15 sec\n",
      "Epoch 48, Loss(train/val) 0.22735/0.43587. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.20950/0.43713. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.20788/0.43419. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.22301/0.43283. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.23406/0.43995. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) 0.21782/0.43411. Took 0.15 sec\n",
      "Epoch 54, Loss(train/val) 0.21074/0.40479. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.19991/0.42949. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.21140/0.41738. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.19758/0.44420. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.19798/0.42261. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.20056/0.42409. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.19997/0.45356. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.20983/0.46492. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.20661/0.41931. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.20243/0.42155. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.20076/0.42915. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.20035/0.45339. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.19926/0.45213. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.20702/0.45669. Took 0.15 sec\n",
      "Epoch 68, Loss(train/val) 0.20181/0.44276. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.19319/0.45798. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.20215/0.45467. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.19003/0.45468. Took 0.15 sec\n",
      "Epoch 72, Loss(train/val) 0.20141/0.43693. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.19910/0.45477. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.20142/0.45379. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.19033/0.45408. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.18794/0.44121. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.19118/0.45916. Took 0.15 sec\n",
      "Epoch 78, Loss(train/val) 0.19352/0.45880. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.18364/0.46178. Took 0.15 sec\n",
      "Epoch 80, Loss(train/val) 0.18473/0.46181. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.17572/0.46110. Took 0.15 sec\n",
      "Epoch 82, Loss(train/val) 0.17298/0.46663. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) 0.18253/0.44669. Took 0.15 sec\n",
      "Epoch 84, Loss(train/val) 0.18075/0.42825. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.17707/0.44208. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.17101/0.44671. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.18454/0.46011. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.17473/0.42364. Took 0.14 sec\n",
      "Epoch 89, Loss(train/val) 0.16857/0.41663. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.17773/0.43818. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.17034/0.42518. Took 0.15 sec\n",
      "Epoch 92, Loss(train/val) 0.17412/0.42941. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.17330/0.45166. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.16864/0.47956. Took 0.14 sec\n",
      "Epoch 95, Loss(train/val) 0.17391/0.44329. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.17034/0.42320. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.16889/0.47425. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.17047/0.45626. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.16393/0.44834. Took 0.14 sec\n",
      "ACC: 0.71875, MCC: 0.43670601424896777\n",
      "Epoch 0, Loss(train/val) 0.49330/0.48660. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.46665/0.45405. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.42747/0.41378. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.39500/0.39865. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.37587/0.38713. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.35949/0.37468. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.34549/0.35763. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.32972/0.32532. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.32309/0.29947. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.31366/0.32540. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.31724/0.31159. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.31055/0.30355. Took 0.15 sec\n",
      "Epoch 12, Loss(train/val) 0.31028/0.31453. Took 0.15 sec\n",
      "Epoch 13, Loss(train/val) 0.29394/0.35768. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.29758/0.35260. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.29658/0.35247. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.28888/0.36298. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.27960/0.32632. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.28140/0.40024. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.26809/0.35772. Took 0.15 sec\n",
      "Epoch 20, Loss(train/val) 0.27020/0.47439. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.26326/0.40932. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.26234/0.43803. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.26352/0.42130. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.25542/0.43189. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.25685/0.44520. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.24067/0.44015. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.24419/0.44816. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.23939/0.45348. Took 0.13 sec\n",
      "Epoch 29, Loss(train/val) 0.23554/0.48511. Took 0.13 sec\n",
      "Epoch 30, Loss(train/val) 0.23729/0.49092. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.24571/0.48532. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.22868/0.48763. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.22325/0.48721. Took 0.16 sec\n",
      "Epoch 34, Loss(train/val) 0.22284/0.47577. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.22372/0.47606. Took 0.16 sec\n",
      "Epoch 36, Loss(train/val) 0.21522/0.48651. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.21620/0.48560. Took 0.15 sec\n",
      "Epoch 38, Loss(train/val) 0.21248/0.48079. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.22218/0.48244. Took 0.17 sec\n",
      "Epoch 40, Loss(train/val) 0.20185/0.48852. Took 0.15 sec\n",
      "Epoch 41, Loss(train/val) 0.20782/0.47834. Took 0.16 sec\n",
      "Epoch 42, Loss(train/val) 0.20033/0.46624. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.19853/0.48405. Took 0.16 sec\n",
      "Epoch 44, Loss(train/val) 0.21095/0.48224. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.20011/0.49300. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.19895/0.49060. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.19135/0.48594. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.18719/0.50565. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.20868/0.46516. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.19742/0.49002. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.19037/0.50642. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.19238/0.48419. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.18067/0.47165. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.17511/0.46927. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.18490/0.48190. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.18366/0.47150. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.19051/0.47877. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.18466/0.47336. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.17498/0.48881. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.17119/0.47864. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.17797/0.47804. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.16549/0.47269. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.16117/0.49752. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.16010/0.47786. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.16927/0.48862. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.16906/0.47447. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.15585/0.47271. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.15173/0.48674. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.16319/0.47674. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.15588/0.47240. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.15717/0.47517. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.15293/0.48404. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.14515/0.48638. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.14298/0.50249. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.14957/0.49673. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.13776/0.47397. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.15647/0.47321. Took 0.15 sec\n",
      "Epoch 78, Loss(train/val) 0.14001/0.48823. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.13967/0.49037. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.13798/0.49335. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.14406/0.53239. Took 0.15 sec\n",
      "Epoch 82, Loss(train/val) 0.13340/0.47563. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.13915/0.47747. Took 0.15 sec\n",
      "Epoch 84, Loss(train/val) 0.13299/0.48874. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.13055/0.49581. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.13694/0.50169. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.13121/0.50428. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.13110/0.48157. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.13269/0.47832. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.13207/0.47125. Took 0.14 sec\n",
      "Epoch 91, Loss(train/val) 0.12810/0.48975. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.12689/0.50015. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.12778/0.45720. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.13060/0.47186. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.11879/0.46448. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.11777/0.47306. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.12201/0.52128. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.13069/0.49963. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.11975/0.50737. Took 0.15 sec\n",
      "ACC: 0.734375, MCC: 0.48640923914333406\n",
      "Epoch 0, Loss(train/val) 0.49291/0.49624. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.46744/0.48960. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.43542/0.45293. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.40568/0.40530. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.38828/0.37330. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.37217/0.35688. Took 0.15 sec\n",
      "Epoch 6, Loss(train/val) 0.35406/0.34063. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.33702/0.34882. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.32101/0.33574. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.32136/0.31891. Took 0.15 sec\n",
      "Epoch 10, Loss(train/val) 0.31456/0.34979. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.31354/0.32241. Took 0.15 sec\n",
      "Epoch 12, Loss(train/val) 0.30626/0.32902. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.29978/0.33859. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.30228/0.37643. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.29957/0.33075. Took 0.17 sec\n",
      "Epoch 16, Loss(train/val) 0.29775/0.32472. Took 0.15 sec\n",
      "Epoch 17, Loss(train/val) 0.29442/0.34350. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.28774/0.32876. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.27639/0.35684. Took 0.16 sec\n",
      "Epoch 20, Loss(train/val) 0.27697/0.31980. Took 0.16 sec\n",
      "Epoch 21, Loss(train/val) 0.27655/0.30834. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.27773/0.29768. Took 0.15 sec\n",
      "Epoch 23, Loss(train/val) 0.26698/0.33266. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.26399/0.29961. Took 0.15 sec\n",
      "Epoch 25, Loss(train/val) 0.26408/0.27346. Took 0.17 sec\n",
      "Epoch 26, Loss(train/val) 0.26718/0.30932. Took 0.16 sec\n",
      "Epoch 27, Loss(train/val) 0.25868/0.26411. Took 0.17 sec\n",
      "Epoch 28, Loss(train/val) 0.24730/0.28147. Took 0.19 sec\n",
      "Epoch 29, Loss(train/val) 0.24429/0.25934. Took 0.17 sec\n",
      "Epoch 30, Loss(train/val) 0.24039/0.27811. Took 0.19 sec\n",
      "Epoch 31, Loss(train/val) 0.24451/0.26585. Took 0.17 sec\n",
      "Epoch 32, Loss(train/val) 0.23958/0.28319. Took 0.16 sec\n",
      "Epoch 33, Loss(train/val) 0.23582/0.29162. Took 0.18 sec\n",
      "Epoch 34, Loss(train/val) 0.22959/0.31684. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.22899/0.29924. Took 0.16 sec\n",
      "Epoch 36, Loss(train/val) 0.22275/0.29590. Took 0.16 sec\n",
      "Epoch 37, Loss(train/val) 0.23232/0.29873. Took 0.22 sec\n",
      "Epoch 38, Loss(train/val) 0.22165/0.29718. Took 0.15 sec\n",
      "Epoch 39, Loss(train/val) 0.22501/0.30774. Took 0.17 sec\n",
      "Epoch 40, Loss(train/val) 0.21461/0.29356. Took 0.16 sec\n",
      "Epoch 41, Loss(train/val) 0.21838/0.32363. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.20991/0.30675. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.20973/0.33674. Took 0.15 sec\n",
      "Epoch 44, Loss(train/val) 0.20131/0.31893. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) 0.21245/0.32028. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.20199/0.41465. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.19929/0.30233. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.20103/0.35810. Took 0.15 sec\n",
      "Epoch 49, Loss(train/val) 0.19970/0.32672. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.19118/0.33540. Took 0.17 sec\n",
      "Epoch 51, Loss(train/val) 0.19199/0.34012. Took 0.16 sec\n",
      "Epoch 52, Loss(train/val) 0.18633/0.31108. Took 0.15 sec\n",
      "Epoch 53, Loss(train/val) 0.19133/0.31627. Took 0.16 sec\n",
      "Epoch 54, Loss(train/val) 0.18362/0.37780. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.18555/0.31226. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.18841/0.34581. Took 0.15 sec\n",
      "Epoch 57, Loss(train/val) 0.19091/0.31879. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.17643/0.31203. Took 0.14 sec\n",
      "Epoch 59, Loss(train/val) 0.17495/0.35606. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.17630/0.31437. Took 0.15 sec\n",
      "Epoch 61, Loss(train/val) 0.17344/0.35195. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.16941/0.35306. Took 0.15 sec\n",
      "Epoch 63, Loss(train/val) 0.16223/0.36047. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.16414/0.31987. Took 0.15 sec\n",
      "Epoch 65, Loss(train/val) 0.17318/0.38066. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.15629/0.32573. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) 0.16388/0.38159. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.16537/0.39369. Took 0.15 sec\n",
      "Epoch 69, Loss(train/val) 0.17088/0.34639. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.15474/0.36616. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.15080/0.33895. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.14915/0.34681. Took 0.15 sec\n",
      "Epoch 73, Loss(train/val) 0.14735/0.34105. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.15082/0.32312. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) 0.14491/0.31927. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.14563/0.35689. Took 0.15 sec\n",
      "Epoch 77, Loss(train/val) 0.14232/0.34909. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.14221/0.36855. Took 0.15 sec\n",
      "Epoch 79, Loss(train/val) 0.14320/0.35491. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.13236/0.39944. Took 0.14 sec\n",
      "Epoch 81, Loss(train/val) 0.14234/0.35949. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.14190/0.38040. Took 0.15 sec\n",
      "Epoch 83, Loss(train/val) 0.14551/0.38524. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.13558/0.39113. Took 0.15 sec\n",
      "Epoch 85, Loss(train/val) 0.13135/0.42936. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.13117/0.38979. Took 0.15 sec\n",
      "Epoch 87, Loss(train/val) 0.13360/0.37673. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.13120/0.39215. Took 0.14 sec\n",
      "Epoch 89, Loss(train/val) 0.13240/0.37030. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.13956/0.37474. Took 0.14 sec\n",
      "Epoch 91, Loss(train/val) 0.13151/0.38050. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.13495/0.39643. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.13363/0.36305. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.13903/0.38109. Took 0.14 sec\n",
      "Epoch 95, Loss(train/val) 0.13127/0.37391. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.13438/0.39647. Took 0.15 sec\n",
      "Epoch 97, Loss(train/val) 0.13366/0.37230. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.12183/0.38555. Took 0.14 sec\n",
      "Epoch 99, Loss(train/val) 0.13078/0.36819. Took 0.13 sec\n",
      "ACC: 0.65625, MCC: 0.2966080766503938\n",
      "Epoch 0, Loss(train/val) 0.49649/0.48554. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.47695/0.44939. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.44498/0.40203. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.40621/0.37068. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.38249/0.35022. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.36617/0.34188. Took 0.15 sec\n",
      "Epoch 6, Loss(train/val) 0.35492/0.33400. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.32936/0.34701. Took 0.15 sec\n",
      "Epoch 8, Loss(train/val) 0.31835/0.34218. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.31028/0.30948. Took 0.15 sec\n",
      "Epoch 10, Loss(train/val) 0.30099/0.31583. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.29430/0.29451. Took 0.15 sec\n",
      "Epoch 12, Loss(train/val) 0.28353/0.33037. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.28039/0.31279. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.27865/0.31136. Took 0.15 sec\n",
      "Epoch 15, Loss(train/val) 0.26440/0.30423. Took 0.16 sec\n",
      "Epoch 16, Loss(train/val) 0.26628/0.32326. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.26348/0.28499. Took 0.17 sec\n",
      "Epoch 18, Loss(train/val) 0.27205/0.28987. Took 0.16 sec\n",
      "Epoch 19, Loss(train/val) 0.25826/0.30919. Took 0.15 sec\n",
      "Epoch 20, Loss(train/val) 0.25284/0.30501. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.24784/0.31738. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.23625/0.32612. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.24752/0.34001. Took 0.16 sec\n",
      "Epoch 24, Loss(train/val) 0.24552/0.30881. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.25176/0.33107. Took 0.16 sec\n",
      "Epoch 26, Loss(train/val) 0.26914/0.31799. Took 0.16 sec\n",
      "Epoch 27, Loss(train/val) 0.24401/0.31339. Took 0.16 sec\n",
      "Epoch 28, Loss(train/val) 0.23095/0.31979. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.22757/0.31433. Took 0.17 sec\n",
      "Epoch 30, Loss(train/val) 0.22671/0.31545. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.22584/0.31599. Took 0.16 sec\n",
      "Epoch 32, Loss(train/val) 0.22052/0.32167. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.21951/0.32643. Took 0.16 sec\n",
      "Epoch 34, Loss(train/val) 0.21661/0.30694. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.22194/0.32042. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.20863/0.33797. Took 0.16 sec\n",
      "Epoch 37, Loss(train/val) 0.21264/0.32815. Took 0.15 sec\n",
      "Epoch 38, Loss(train/val) 0.20908/0.33730. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.21019/0.32646. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.20664/0.32271. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.19963/0.33237. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.19841/0.33358. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.20342/0.35158. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.20661/0.31174. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.20325/0.33126. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.18986/0.32791. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.19271/0.32267. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.19767/0.35074. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.20577/0.33075. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.19819/0.32686. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.18775/0.34114. Took 0.15 sec\n",
      "Epoch 52, Loss(train/val) 0.19071/0.31542. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) 0.18397/0.32298. Took 0.15 sec\n",
      "Epoch 54, Loss(train/val) 0.18317/0.31927. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.18498/0.31950. Took 0.15 sec\n",
      "Epoch 56, Loss(train/val) 0.18654/0.31512. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.18673/0.30686. Took 0.16 sec\n",
      "Epoch 58, Loss(train/val) 0.18907/0.34886. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.19114/0.33222. Took 0.15 sec\n",
      "Epoch 60, Loss(train/val) 0.18654/0.32991. Took 0.15 sec\n",
      "Epoch 61, Loss(train/val) 0.18371/0.33116. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.17777/0.33438. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.18720/0.33409. Took 0.15 sec\n",
      "Epoch 64, Loss(train/val) 0.16433/0.35903. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.17301/0.34220. Took 0.20 sec\n",
      "Epoch 66, Loss(train/val) 0.17631/0.34759. Took 0.20 sec\n",
      "Epoch 67, Loss(train/val) 0.17493/0.35982. Took 0.22 sec\n",
      "Epoch 68, Loss(train/val) 0.15714/0.34296. Took 0.16 sec\n",
      "Epoch 69, Loss(train/val) 0.16911/0.36195. Took 0.15 sec\n",
      "Epoch 70, Loss(train/val) 0.16222/0.34753. Took 0.17 sec\n",
      "Epoch 71, Loss(train/val) 0.16664/0.36012. Took 0.16 sec\n",
      "Epoch 72, Loss(train/val) 0.16114/0.34571. Took 0.16 sec\n",
      "Epoch 73, Loss(train/val) 0.15891/0.33785. Took 0.15 sec\n",
      "Epoch 74, Loss(train/val) 0.16149/0.33704. Took 0.17 sec\n",
      "Epoch 75, Loss(train/val) 0.15502/0.34955. Took 0.15 sec\n",
      "Epoch 76, Loss(train/val) 0.15288/0.33385. Took 0.17 sec\n",
      "Epoch 77, Loss(train/val) 0.16180/0.34482. Took 0.16 sec\n",
      "Epoch 78, Loss(train/val) 0.15750/0.33343. Took 0.16 sec\n",
      "Epoch 79, Loss(train/val) 0.16240/0.32440. Took 0.15 sec\n",
      "Epoch 80, Loss(train/val) 0.15699/0.34471. Took 0.15 sec\n",
      "Epoch 81, Loss(train/val) 0.14659/0.35283. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.15593/0.34353. Took 0.15 sec\n",
      "Epoch 83, Loss(train/val) 0.14982/0.36086. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.15359/0.34239. Took 0.16 sec\n",
      "Epoch 85, Loss(train/val) 0.14774/0.33704. Took 0.15 sec\n",
      "Epoch 86, Loss(train/val) 0.15981/0.36344. Took 0.15 sec\n",
      "Epoch 87, Loss(train/val) 0.15937/0.38592. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.14568/0.33793. Took 0.15 sec\n",
      "Epoch 89, Loss(train/val) 0.14925/0.35357. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.14842/0.38212. Took 0.15 sec\n",
      "Epoch 91, Loss(train/val) 0.15226/0.34571. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.14739/0.37735. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.13538/0.37183. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.13939/0.36768. Took 0.17 sec\n",
      "Epoch 95, Loss(train/val) 0.14016/0.35476. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.14065/0.37419. Took 0.14 sec\n",
      "Epoch 97, Loss(train/val) 0.13683/0.37912. Took 0.15 sec\n",
      "Epoch 98, Loss(train/val) 0.13999/0.35768. Took 0.17 sec\n",
      "Epoch 99, Loss(train/val) 0.13473/0.32649. Took 0.14 sec\n",
      "ACC: 0.6875, MCC: 0.43064433753916403\n",
      "Epoch 0, Loss(train/val) 0.49135/0.47563. Took 0.17 sec\n",
      "Epoch 1, Loss(train/val) 0.46714/0.44575. Took 0.16 sec\n",
      "Epoch 2, Loss(train/val) 0.43948/0.40545. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.41152/0.36169. Took 0.16 sec\n",
      "Epoch 4, Loss(train/val) 0.38231/0.33977. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.36003/0.33472. Took 0.17 sec\n",
      "Epoch 6, Loss(train/val) 0.34111/0.33645. Took 0.15 sec\n",
      "Epoch 7, Loss(train/val) 0.33043/0.33008. Took 0.15 sec\n",
      "Epoch 8, Loss(train/val) 0.31616/0.33459. Took 0.15 sec\n",
      "Epoch 9, Loss(train/val) 0.31284/0.31892. Took 0.16 sec\n",
      "Epoch 10, Loss(train/val) 0.30262/0.33163. Took 0.16 sec\n",
      "Epoch 11, Loss(train/val) 0.29519/0.33242. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.28694/0.30926. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.28079/0.33495. Took 0.16 sec\n",
      "Epoch 14, Loss(train/val) 0.27361/0.33731. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.28700/0.33785. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.27913/0.29536. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.27375/0.31126. Took 0.16 sec\n",
      "Epoch 18, Loss(train/val) 0.26336/0.32532. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.26506/0.32668. Took 0.16 sec\n",
      "Epoch 20, Loss(train/val) 0.25929/0.32082. Took 0.15 sec\n",
      "Epoch 21, Loss(train/val) 0.25479/0.33280. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.25718/0.31221. Took 0.16 sec\n",
      "Epoch 23, Loss(train/val) 0.24833/0.30819. Took 0.17 sec\n",
      "Epoch 24, Loss(train/val) 0.23847/0.32003. Took 0.16 sec\n",
      "Epoch 25, Loss(train/val) 0.24004/0.30458. Took 0.17 sec\n",
      "Epoch 26, Loss(train/val) 0.23636/0.29818. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.24456/0.31814. Took 0.17 sec\n",
      "Epoch 28, Loss(train/val) 0.23348/0.30977. Took 0.16 sec\n",
      "Epoch 29, Loss(train/val) 0.22661/0.31755. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.22884/0.31746. Took 0.16 sec\n",
      "Epoch 31, Loss(train/val) 0.23276/0.33693. Took 0.20 sec\n",
      "Epoch 32, Loss(train/val) 0.22544/0.31061. Took 0.19 sec\n",
      "Epoch 33, Loss(train/val) 0.22158/0.31741. Took 0.17 sec\n",
      "Epoch 34, Loss(train/val) 0.21707/0.37569. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.21807/0.31733. Took 0.16 sec\n",
      "Epoch 36, Loss(train/val) 0.20485/0.32641. Took 0.17 sec\n",
      "Epoch 37, Loss(train/val) 0.22067/0.28536. Took 0.16 sec\n",
      "Epoch 38, Loss(train/val) 0.21750/0.34541. Took 0.15 sec\n",
      "Epoch 39, Loss(train/val) 0.21017/0.35256. Took 0.20 sec\n",
      "Epoch 40, Loss(train/val) 0.21190/0.33987. Took 0.18 sec\n",
      "Epoch 41, Loss(train/val) 0.20724/0.34951. Took 0.15 sec\n",
      "Epoch 42, Loss(train/val) 0.20424/0.36160. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.20659/0.42200. Took 0.15 sec\n",
      "Epoch 44, Loss(train/val) 0.21229/0.32225. Took 0.15 sec\n",
      "Epoch 45, Loss(train/val) 0.20210/0.35033. Took 0.15 sec\n",
      "Epoch 46, Loss(train/val) 0.20314/0.32857. Took 0.18 sec\n",
      "Epoch 47, Loss(train/val) 0.21234/0.32822. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.19600/0.32712. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.19499/0.36885. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.20200/0.39585. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.20060/0.32853. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.18871/0.32803. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.19104/0.39129. Took 0.15 sec\n",
      "Epoch 54, Loss(train/val) 0.18904/0.35078. Took 0.15 sec\n",
      "Epoch 55, Loss(train/val) 0.18666/0.36967. Took 0.15 sec\n",
      "Epoch 56, Loss(train/val) 0.18740/0.36730. Took 0.15 sec\n",
      "Epoch 57, Loss(train/val) 0.18258/0.39356. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.17397/0.39345. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.17659/0.40301. Took 0.15 sec\n",
      "Epoch 60, Loss(train/val) 0.17355/0.40479. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.16937/0.36913. Took 0.16 sec\n",
      "Epoch 62, Loss(train/val) 0.17847/0.34540. Took 0.15 sec\n",
      "Epoch 63, Loss(train/val) 0.17136/0.35814. Took 0.17 sec\n",
      "Epoch 64, Loss(train/val) 0.17497/0.38825. Took 0.16 sec\n",
      "Epoch 65, Loss(train/val) 0.16587/0.39409. Took 0.15 sec\n",
      "Epoch 66, Loss(train/val) 0.16137/0.39950. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) 0.16718/0.43458. Took 0.15 sec\n",
      "Epoch 68, Loss(train/val) 0.16056/0.40510. Took 0.15 sec\n",
      "Epoch 69, Loss(train/val) 0.16666/0.43846. Took 0.17 sec\n",
      "Epoch 70, Loss(train/val) 0.15266/0.40560. Took 0.15 sec\n",
      "Epoch 71, Loss(train/val) 0.15557/0.40495. Took 0.16 sec\n",
      "Epoch 72, Loss(train/val) 0.16483/0.42895. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.15719/0.42763. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.16088/0.42725. Took 0.15 sec\n",
      "Epoch 75, Loss(train/val) 0.16164/0.43575. Took 0.16 sec\n",
      "Epoch 76, Loss(train/val) 0.15641/0.41800. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.15703/0.41306. Took 0.16 sec\n",
      "Epoch 78, Loss(train/val) 0.15581/0.44153. Took 0.14 sec\n",
      "Epoch 79, Loss(train/val) 0.15780/0.40031. Took 0.15 sec\n",
      "Epoch 80, Loss(train/val) 0.15986/0.39526. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.16166/0.40726. Took 0.15 sec\n",
      "Epoch 82, Loss(train/val) 0.14998/0.46313. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.15401/0.45179. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.15124/0.46677. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.15455/0.42931. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.15886/0.41473. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.14316/0.45712. Took 0.17 sec\n",
      "Epoch 88, Loss(train/val) 0.14184/0.46538. Took 0.15 sec\n",
      "Epoch 89, Loss(train/val) 0.15218/0.43151. Took 0.15 sec\n",
      "Epoch 90, Loss(train/val) 0.15263/0.44879. Took 0.15 sec\n",
      "Epoch 91, Loss(train/val) 0.14786/0.45376. Took 0.15 sec\n",
      "Epoch 92, Loss(train/val) 0.14041/0.45518. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.13850/0.45767. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.13911/0.43123. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.13656/0.45271. Took 0.16 sec\n",
      "Epoch 96, Loss(train/val) 0.13909/0.45344. Took 0.14 sec\n",
      "Epoch 97, Loss(train/val) 0.13942/0.44221. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.13519/0.42443. Took 0.14 sec\n",
      "Epoch 99, Loss(train/val) 0.14228/0.44010. Took 0.16 sec\n",
      "ACC: 0.71875, MCC: 0.43393264597022163\n",
      "Epoch 0, Loss(train/val) 0.49463/0.47276. Took 0.16 sec\n",
      "Epoch 1, Loss(train/val) 0.47249/0.43126. Took 0.15 sec\n",
      "Epoch 2, Loss(train/val) 0.44081/0.38390. Took 0.15 sec\n",
      "Epoch 3, Loss(train/val) 0.40614/0.35479. Took 0.16 sec\n",
      "Epoch 4, Loss(train/val) 0.37447/0.34105. Took 0.16 sec\n",
      "Epoch 5, Loss(train/val) 0.35191/0.32832. Took 0.15 sec\n",
      "Epoch 6, Loss(train/val) 0.34652/0.32407. Took 0.16 sec\n",
      "Epoch 7, Loss(train/val) 0.33179/0.33875. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.34589/0.33417. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.32505/0.32049. Took 0.17 sec\n",
      "Epoch 10, Loss(train/val) 0.31277/0.31066. Took 0.17 sec\n",
      "Epoch 11, Loss(train/val) 0.30605/0.30761. Took 0.18 sec\n",
      "Epoch 12, Loss(train/val) 0.32309/0.30771. Took 0.19 sec\n",
      "Epoch 13, Loss(train/val) 0.31035/0.30297. Took 0.16 sec\n",
      "Epoch 14, Loss(train/val) 0.29789/0.30705. Took 0.16 sec\n",
      "Epoch 15, Loss(train/val) 0.30406/0.29263. Took 0.17 sec\n",
      "Epoch 16, Loss(train/val) 0.30012/0.27272. Took 0.16 sec\n",
      "Epoch 17, Loss(train/val) 0.30142/0.28877. Took 0.16 sec\n",
      "Epoch 18, Loss(train/val) 0.29248/0.36669. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.28631/0.28169. Took 0.15 sec\n",
      "Epoch 20, Loss(train/val) 0.28658/0.27665. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.28630/0.32397. Took 0.16 sec\n",
      "Epoch 22, Loss(train/val) 0.28608/0.28702. Took 0.15 sec\n",
      "Epoch 23, Loss(train/val) 0.27131/0.32152. Took 0.17 sec\n",
      "Epoch 24, Loss(train/val) 0.28250/0.32849. Took 0.15 sec\n",
      "Epoch 25, Loss(train/val) 0.27218/0.29493. Took 0.16 sec\n",
      "Epoch 26, Loss(train/val) 0.27197/0.29721. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.26967/0.29591. Took 0.17 sec\n",
      "Epoch 28, Loss(train/val) 0.26274/0.31075. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.26309/0.30616. Took 0.18 sec\n",
      "Epoch 30, Loss(train/val) 0.27357/0.26691. Took 0.20 sec\n",
      "Epoch 31, Loss(train/val) 0.25912/0.31332. Took 0.17 sec\n",
      "Epoch 32, Loss(train/val) 0.25640/0.30480. Took 0.19 sec\n",
      "Epoch 33, Loss(train/val) 0.26295/0.30895. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.26319/0.29185. Took 0.16 sec\n",
      "Epoch 35, Loss(train/val) 0.25720/0.28927. Took 0.17 sec\n",
      "Epoch 36, Loss(train/val) 0.24843/0.30958. Took 0.17 sec\n",
      "Epoch 37, Loss(train/val) 0.26491/0.29595. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.26264/0.30699. Took 0.15 sec\n",
      "Epoch 39, Loss(train/val) 0.26091/0.32313. Took 0.18 sec\n",
      "Epoch 40, Loss(train/val) 0.26965/0.33962. Took 0.19 sec\n",
      "Epoch 41, Loss(train/val) 0.26742/0.30390. Took 0.15 sec\n",
      "Epoch 42, Loss(train/val) 0.24724/0.28990. Took 0.15 sec\n",
      "Epoch 43, Loss(train/val) 0.24202/0.34000. Took 0.17 sec\n",
      "Epoch 44, Loss(train/val) 0.24987/0.32932. Took 0.15 sec\n",
      "Epoch 45, Loss(train/val) 0.24772/0.31663. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.24409/0.31644. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.23723/0.30149. Took 0.15 sec\n",
      "Epoch 48, Loss(train/val) 0.24494/0.30972. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.24065/0.33041. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.23288/0.32260. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.23868/0.31499. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.24133/0.30622. Took 0.15 sec\n",
      "Epoch 53, Loss(train/val) 0.24660/0.31678. Took 0.16 sec\n",
      "Epoch 54, Loss(train/val) 0.23775/0.30176. Took 0.15 sec\n",
      "Epoch 55, Loss(train/val) 0.23058/0.30554. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.23935/0.34272. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.24164/0.32040. Took 0.15 sec\n",
      "Epoch 58, Loss(train/val) 0.23388/0.29643. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.22818/0.32027. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.22420/0.40104. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.23640/0.41688. Took 0.15 sec\n",
      "Epoch 62, Loss(train/val) 0.22304/0.31735. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.22442/0.29498. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.21809/0.29546. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.21818/0.28756. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.21429/0.28617. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.21110/0.32266. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.21766/0.30236. Took 0.14 sec\n",
      "Epoch 69, Loss(train/val) 0.20693/0.31723. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.20750/0.30471. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.20655/0.30583. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.21201/0.30067. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.20846/0.32158. Took 0.15 sec\n",
      "Epoch 74, Loss(train/val) 0.20309/0.29976. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.20028/0.31476. Took 0.15 sec\n",
      "Epoch 76, Loss(train/val) 0.20728/0.28477. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.20061/0.27670. Took 0.15 sec\n",
      "Epoch 78, Loss(train/val) 0.20613/0.31392. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.20780/0.30253. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.20056/0.27426. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.19459/0.26682. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.19244/0.28238. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.20238/0.31294. Took 0.15 sec\n",
      "Epoch 84, Loss(train/val) 0.19661/0.25555. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.19372/0.26348. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.19680/0.24809. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.19096/0.28524. Took 0.16 sec\n",
      "Epoch 88, Loss(train/val) 0.19464/0.26718. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.20006/0.30588. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.22592/0.30457. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.21932/0.25669. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.18904/0.24011. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.19414/0.26933. Took 0.15 sec\n",
      "Epoch 94, Loss(train/val) 0.19412/0.29267. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.18823/0.28923. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.18905/0.27769. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.19524/0.28063. Took 0.15 sec\n",
      "Epoch 98, Loss(train/val) 0.18667/0.31028. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.18426/0.29486. Took 0.14 sec\n",
      "ACC: 0.609375, MCC: 0.21943699408049175\n",
      "Epoch 0, Loss(train/val) 0.49142/0.48408. Took 0.16 sec\n",
      "Epoch 1, Loss(train/val) 0.46678/0.45496. Took 0.15 sec\n",
      "Epoch 2, Loss(train/val) 0.43158/0.42207. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.39871/0.40403. Took 0.15 sec\n",
      "Epoch 4, Loss(train/val) 0.37768/0.39241. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.36213/0.39023. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.35608/0.37045. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.34664/0.38283. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.33290/0.36524. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.32644/0.36673. Took 0.15 sec\n",
      "Epoch 10, Loss(train/val) 0.32177/0.35155. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.31007/0.37460. Took 0.16 sec\n",
      "Epoch 12, Loss(train/val) 0.31221/0.38794. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.30915/0.38878. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.29722/0.42487. Took 0.15 sec\n",
      "Epoch 15, Loss(train/val) 0.29867/0.40857. Took 0.16 sec\n",
      "Epoch 16, Loss(train/val) 0.30749/0.40443. Took 0.15 sec\n",
      "Epoch 17, Loss(train/val) 0.30071/0.38988. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.29653/0.40268. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.29644/0.36838. Took 0.16 sec\n",
      "Epoch 20, Loss(train/val) 0.29249/0.39507. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.28828/0.40079. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.27993/0.41991. Took 0.16 sec\n",
      "Epoch 23, Loss(train/val) 0.28017/0.42202. Took 0.16 sec\n",
      "Epoch 24, Loss(train/val) 0.27292/0.42522. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.28007/0.42766. Took 0.16 sec\n",
      "Epoch 26, Loss(train/val) 0.27054/0.43693. Took 0.13 sec\n",
      "Epoch 27, Loss(train/val) 0.26979/0.42882. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.26376/0.43317. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.26763/0.43931. Took 0.19 sec\n",
      "Epoch 30, Loss(train/val) 0.25848/0.43685. Took 0.20 sec\n",
      "Epoch 31, Loss(train/val) 0.26037/0.43246. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.25736/0.44149. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.26272/0.44272. Took 0.17 sec\n",
      "Epoch 34, Loss(train/val) 0.25824/0.43004. Took 0.16 sec\n",
      "Epoch 35, Loss(train/val) 0.24933/0.43421. Took 0.15 sec\n",
      "Epoch 36, Loss(train/val) 0.24827/0.43772. Took 0.16 sec\n",
      "Epoch 37, Loss(train/val) 0.24974/0.44068. Took 0.16 sec\n",
      "Epoch 38, Loss(train/val) 0.24114/0.44230. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.24283/0.42784. Took 0.17 sec\n",
      "Epoch 40, Loss(train/val) 0.24006/0.44200. Took 0.15 sec\n",
      "Epoch 41, Loss(train/val) 0.22858/0.43436. Took 0.15 sec\n",
      "Epoch 42, Loss(train/val) 0.23350/0.42682. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.23699/0.43959. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.23629/0.43689. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) 0.23049/0.42765. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.23162/0.44057. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.22416/0.43819. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.23151/0.43334. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.21629/0.44194. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.21878/0.42870. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.22663/0.43670. Took 0.15 sec\n",
      "Epoch 52, Loss(train/val) 0.21543/0.43462. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.22091/0.43500. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.22950/0.42827. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.21548/0.43831. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.20704/0.44028. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.20905/0.43181. Took 0.15 sec\n",
      "Epoch 58, Loss(train/val) 0.20856/0.41911. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.20840/0.43212. Took 0.15 sec\n",
      "Epoch 60, Loss(train/val) 0.20512/0.43316. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.20669/0.43654. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.20273/0.42031. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.20691/0.41811. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.21191/0.42324. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.20501/0.42305. Took 0.16 sec\n",
      "Epoch 66, Loss(train/val) 0.20393/0.42901. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.20151/0.41164. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.20130/0.42937. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.20305/0.43200. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.19062/0.42797. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.19733/0.42780. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.19222/0.42648. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.19712/0.41024. Took 0.15 sec\n",
      "Epoch 74, Loss(train/val) 0.20253/0.42838. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.19326/0.43170. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.18928/0.41784. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.19159/0.42579. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.18854/0.41953. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.19543/0.42414. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.19290/0.41618. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.19980/0.41873. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.19121/0.42047. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.19121/0.41566. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.18644/0.42316. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.19104/0.40778. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.18400/0.43033. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.18153/0.39683. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.18344/0.39820. Took 0.14 sec\n",
      "Epoch 89, Loss(train/val) 0.18939/0.40617. Took 0.15 sec\n",
      "Epoch 90, Loss(train/val) 0.18005/0.39224. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.17704/0.38826. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.17759/0.39122. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.18281/0.38658. Took 0.15 sec\n",
      "Epoch 94, Loss(train/val) 0.18220/0.39944. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.17757/0.38859. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.17173/0.37281. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.17154/0.38963. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.17403/0.37652. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.16110/0.39744. Took 0.14 sec\n",
      "ACC: 0.765625, MCC: 0.5405421721320017\n",
      "Epoch 0, Loss(train/val) 0.49241/0.48660. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.46993/0.44426. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.43305/0.38991. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.39387/0.36744. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.37705/0.32960. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.36305/0.31849. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.35190/0.30316. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.34458/0.28084. Took 0.15 sec\n",
      "Epoch 8, Loss(train/val) 0.34082/0.28166. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.32861/0.28619. Took 0.15 sec\n",
      "Epoch 10, Loss(train/val) 0.33243/0.29039. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.32703/0.30076. Took 0.17 sec\n",
      "Epoch 12, Loss(train/val) 0.32090/0.30206. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.31253/0.26687. Took 0.16 sec\n",
      "Epoch 14, Loss(train/val) 0.31313/0.26433. Took 0.16 sec\n",
      "Epoch 15, Loss(train/val) 0.31451/0.28365. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.30514/0.36080. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.31391/0.32677. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.30925/0.36356. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.30288/0.28490. Took 0.18 sec\n",
      "Epoch 20, Loss(train/val) 0.30301/0.31920. Took 0.15 sec\n",
      "Epoch 21, Loss(train/val) 0.29898/0.27393. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.29757/0.27044. Took 0.15 sec\n",
      "Epoch 23, Loss(train/val) 0.29414/0.43917. Took 0.16 sec\n",
      "Epoch 24, Loss(train/val) 0.32450/0.40438. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.29782/0.40832. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.28851/0.40293. Took 0.16 sec\n",
      "Epoch 27, Loss(train/val) 0.28520/0.39869. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.28307/0.40239. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.27850/0.41780. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.28225/0.42073. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.27800/0.40716. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.27632/0.41013. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.26870/0.42209. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.26874/0.43786. Took 0.19 sec\n",
      "Epoch 35, Loss(train/val) 0.27146/0.43798. Took 0.15 sec\n",
      "Epoch 36, Loss(train/val) 0.26903/0.46030. Took 0.16 sec\n",
      "Epoch 37, Loss(train/val) 0.26153/0.46057. Took 0.15 sec\n",
      "Epoch 38, Loss(train/val) 0.27624/0.36880. Took 0.16 sec\n",
      "Epoch 39, Loss(train/val) 0.25951/0.41365. Took 0.15 sec\n",
      "Epoch 40, Loss(train/val) 0.26298/0.31320. Took 0.16 sec\n",
      "Epoch 41, Loss(train/val) 0.27915/0.47366. Took 0.18 sec\n",
      "Epoch 42, Loss(train/val) 0.25610/0.45457. Took 0.15 sec\n",
      "Epoch 43, Loss(train/val) 0.26181/0.42075. Took 0.15 sec\n",
      "Epoch 44, Loss(train/val) 0.26348/0.42605. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.25378/0.37499. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.25869/0.38040. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.25326/0.37456. Took 0.15 sec\n",
      "Epoch 48, Loss(train/val) 0.25187/0.44732. Took 0.15 sec\n",
      "Epoch 49, Loss(train/val) 0.25068/0.47697. Took 0.17 sec\n",
      "Epoch 50, Loss(train/val) 0.25167/0.45929. Took 0.14 sec\n",
      "Epoch 51, Loss(train/val) 0.24345/0.35924. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.25245/0.39012. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.24629/0.40316. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.24430/0.43737. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.24500/0.48250. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.23768/0.42945. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.23801/0.46686. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.23813/0.46374. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.23686/0.41014. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.24513/0.44888. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.22934/0.42464. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.23135/0.34410. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.23555/0.35084. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.22967/0.42757. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.23045/0.34603. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.22209/0.34241. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.22479/0.36691. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.21707/0.34845. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.20947/0.36182. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.21091/0.33900. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.21434/0.42247. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.21261/0.36296. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.21084/0.36502. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.21536/0.38037. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.22893/0.38736. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.20716/0.36068. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.20530/0.35481. Took 0.15 sec\n",
      "Epoch 78, Loss(train/val) 0.19839/0.36239. Took 0.14 sec\n",
      "Epoch 79, Loss(train/val) 0.20197/0.32798. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.20113/0.31668. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.20321/0.31759. Took 0.15 sec\n",
      "Epoch 82, Loss(train/val) 0.20442/0.33426. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) 0.19700/0.32387. Took 0.15 sec\n",
      "Epoch 84, Loss(train/val) 0.19761/0.39602. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.19634/0.44721. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.19040/0.30576. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.18792/0.33086. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.18791/0.36826. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.18315/0.34259. Took 0.15 sec\n",
      "Epoch 90, Loss(train/val) 0.18338/0.30732. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.18153/0.33900. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.18579/0.35499. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.18340/0.30204. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.18106/0.34807. Took 0.14 sec\n",
      "Epoch 95, Loss(train/val) 0.18308/0.36386. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.17807/0.30556. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.17902/0.33071. Took 0.16 sec\n",
      "Epoch 98, Loss(train/val) 0.17305/0.40812. Took 0.14 sec\n",
      "Epoch 99, Loss(train/val) 0.17974/0.39429. Took 0.16 sec\n",
      "ACC: 0.578125, MCC: 0.16840930802174117\n",
      "Epoch 0, Loss(train/val) 0.48706/0.49387. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.45615/0.47139. Took 0.17 sec\n",
      "Epoch 2, Loss(train/val) 0.41396/0.43593. Took 0.19 sec\n",
      "Epoch 3, Loss(train/val) 0.38453/0.42383. Took 0.17 sec\n",
      "Epoch 4, Loss(train/val) 0.37410/0.41157. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.36358/0.42286. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.35163/0.41407. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.34221/0.41070. Took 0.17 sec\n",
      "Epoch 8, Loss(train/val) 0.32953/0.41881. Took 0.17 sec\n",
      "Epoch 9, Loss(train/val) 0.32216/0.41195. Took 0.15 sec\n",
      "Epoch 10, Loss(train/val) 0.32084/0.40901. Took 0.18 sec\n",
      "Epoch 11, Loss(train/val) 0.31005/0.40361. Took 0.18 sec\n",
      "Epoch 12, Loss(train/val) 0.30414/0.39807. Took 0.16 sec\n",
      "Epoch 13, Loss(train/val) 0.30753/0.37646. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.30533/0.40491. Took 0.16 sec\n",
      "Epoch 15, Loss(train/val) 0.29647/0.39090. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.29619/0.38424. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.31090/0.39378. Took 0.16 sec\n",
      "Epoch 18, Loss(train/val) 0.30453/0.37675. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.29602/0.37765. Took 0.15 sec\n",
      "Epoch 20, Loss(train/val) 0.28494/0.36677. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.27382/0.37946. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.27565/0.37057. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.28466/0.37276. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.27985/0.36810. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.26675/0.37423. Took 0.17 sec\n",
      "Epoch 26, Loss(train/val) 0.27505/0.37125. Took 0.15 sec\n",
      "Epoch 27, Loss(train/val) 0.26917/0.38068. Took 0.17 sec\n",
      "Epoch 28, Loss(train/val) 0.26148/0.37768. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.26413/0.38339. Took 0.17 sec\n",
      "Epoch 30, Loss(train/val) 0.25324/0.36612. Took 0.16 sec\n",
      "Epoch 31, Loss(train/val) 0.25095/0.37657. Took 0.17 sec\n",
      "Epoch 32, Loss(train/val) 0.25272/0.39418. Took 0.22 sec\n",
      "Epoch 33, Loss(train/val) 0.25285/0.37358. Took 0.17 sec\n",
      "Epoch 34, Loss(train/val) 0.23884/0.34948. Took 0.18 sec\n",
      "Epoch 35, Loss(train/val) 0.24628/0.34605. Took 0.16 sec\n",
      "Epoch 36, Loss(train/val) 0.24131/0.37718. Took 0.17 sec\n",
      "Epoch 37, Loss(train/val) 0.24515/0.37359. Took 0.15 sec\n",
      "Epoch 38, Loss(train/val) 0.23947/0.38401. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.23604/0.37262. Took 0.19 sec\n",
      "Epoch 40, Loss(train/val) 0.24515/0.37537. Took 0.17 sec\n",
      "Epoch 41, Loss(train/val) 0.23207/0.38210. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.23713/0.37274. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.23505/0.36919. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.22448/0.34994. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.22684/0.36497. Took 0.16 sec\n",
      "Epoch 46, Loss(train/val) 0.22102/0.35868. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.23424/0.35434. Took 0.15 sec\n",
      "Epoch 48, Loss(train/val) 0.23107/0.36146. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.22172/0.35887. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.21896/0.36282. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.22210/0.37045. Took 0.15 sec\n",
      "Epoch 52, Loss(train/val) 0.21556/0.37059. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.21685/0.36899. Took 0.15 sec\n",
      "Epoch 54, Loss(train/val) 0.21699/0.35807. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.20879/0.38123. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.21353/0.35683. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.21244/0.41027. Took 0.15 sec\n",
      "Epoch 58, Loss(train/val) 0.20593/0.36993. Took 0.14 sec\n",
      "Epoch 59, Loss(train/val) 0.20021/0.39936. Took 0.17 sec\n",
      "Epoch 60, Loss(train/val) 0.20520/0.36270. Took 0.15 sec\n",
      "Epoch 61, Loss(train/val) 0.20392/0.35238. Took 0.16 sec\n",
      "Epoch 62, Loss(train/val) 0.21452/0.41563. Took 0.16 sec\n",
      "Epoch 63, Loss(train/val) 0.21576/0.36334. Took 0.15 sec\n",
      "Epoch 64, Loss(train/val) 0.21005/0.37730. Took 0.15 sec\n",
      "Epoch 65, Loss(train/val) 0.20108/0.35954. Took 0.16 sec\n",
      "Epoch 66, Loss(train/val) 0.19022/0.38240. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) 0.19726/0.36736. Took 0.16 sec\n",
      "Epoch 68, Loss(train/val) 0.19967/0.38997. Took 0.14 sec\n",
      "Epoch 69, Loss(train/val) 0.19244/0.36222. Took 0.16 sec\n",
      "Epoch 70, Loss(train/val) 0.19615/0.36801. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.19252/0.43163. Took 0.15 sec\n",
      "Epoch 72, Loss(train/val) 0.19614/0.36954. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.18501/0.41953. Took 0.15 sec\n",
      "Epoch 74, Loss(train/val) 0.19384/0.36163. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) 0.18716/0.37019. Took 0.15 sec\n",
      "Epoch 76, Loss(train/val) 0.18433/0.40305. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.18012/0.37379. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.17814/0.41465. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.18166/0.36548. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.18812/0.41715. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.17801/0.43198. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.18134/0.41694. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.19123/0.40452. Took 0.15 sec\n",
      "Epoch 84, Loss(train/val) 0.18056/0.36442. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.18168/0.38128. Took 0.16 sec\n",
      "Epoch 86, Loss(train/val) 0.17241/0.40957. Took 0.15 sec\n",
      "Epoch 87, Loss(train/val) 0.16954/0.39127. Took 0.16 sec\n",
      "Epoch 88, Loss(train/val) 0.17302/0.35722. Took 0.14 sec\n",
      "Epoch 89, Loss(train/val) 0.17938/0.35796. Took 0.16 sec\n",
      "Epoch 90, Loss(train/val) 0.17972/0.42257. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.16910/0.42377. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.18355/0.40942. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.18161/0.39179. Took 0.16 sec\n",
      "Epoch 94, Loss(train/val) 0.17521/0.42533. Took 0.15 sec\n",
      "Epoch 95, Loss(train/val) 0.16785/0.44861. Took 0.17 sec\n",
      "Epoch 96, Loss(train/val) 0.16265/0.44806. Took 0.15 sec\n",
      "Epoch 97, Loss(train/val) 0.16828/0.44583. Took 0.15 sec\n",
      "Epoch 98, Loss(train/val) 0.16284/0.44061. Took 0.14 sec\n",
      "Epoch 99, Loss(train/val) 0.16258/0.45529. Took 0.15 sec\n",
      "ACC: 0.703125, MCC: 0.4052867805690852\n",
      "Epoch 0, Loss(train/val) 0.49456/0.48995. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.47283/0.46835. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.43667/0.44232. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.40312/0.42233. Took 0.16 sec\n",
      "Epoch 4, Loss(train/val) 0.38188/0.40581. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.36881/0.39473. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.35678/0.37841. Took 0.15 sec\n",
      "Epoch 7, Loss(train/val) 0.34925/0.38006. Took 0.15 sec\n",
      "Epoch 8, Loss(train/val) 0.34400/0.38146. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.34319/0.34497. Took 0.18 sec\n",
      "Epoch 10, Loss(train/val) 0.33475/0.36452. Took 0.18 sec\n",
      "Epoch 11, Loss(train/val) 0.32661/0.34635. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.32537/0.37831. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.32054/0.33745. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.31867/0.35567. Took 0.15 sec\n",
      "Epoch 15, Loss(train/val) 0.30732/0.34084. Took 0.18 sec\n",
      "Epoch 16, Loss(train/val) 0.30988/0.34930. Took 0.18 sec\n",
      "Epoch 17, Loss(train/val) 0.30885/0.35359. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.30165/0.39703. Took 0.15 sec\n",
      "Epoch 19, Loss(train/val) 0.30262/0.33159. Took 0.17 sec\n",
      "Epoch 20, Loss(train/val) 0.29989/0.35233. Took 0.16 sec\n",
      "Epoch 21, Loss(train/val) 0.29554/0.38188. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.30002/0.31787. Took 0.15 sec\n",
      "Epoch 23, Loss(train/val) 0.29194/0.35223. Took 0.16 sec\n",
      "Epoch 24, Loss(train/val) 0.28563/0.36975. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.27785/0.32900. Took 0.16 sec\n",
      "Epoch 26, Loss(train/val) 0.28563/0.31120. Took 0.19 sec\n",
      "Epoch 27, Loss(train/val) 0.27843/0.31636. Took 0.17 sec\n",
      "Epoch 28, Loss(train/val) 0.27534/0.31602. Took 0.17 sec\n",
      "Epoch 29, Loss(train/val) 0.27302/0.31899. Took 0.18 sec\n",
      "Epoch 30, Loss(train/val) 0.26773/0.31241. Took 0.17 sec\n",
      "Epoch 31, Loss(train/val) 0.25796/0.31637. Took 0.16 sec\n",
      "Epoch 32, Loss(train/val) 0.26563/0.31698. Took 0.17 sec\n",
      "Epoch 33, Loss(train/val) 0.26564/0.35643. Took 0.17 sec\n",
      "Epoch 34, Loss(train/val) 0.26499/0.32847. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.26309/0.32724. Took 0.16 sec\n",
      "Epoch 36, Loss(train/val) 0.26455/0.32761. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.25411/0.32848. Took 0.16 sec\n",
      "Epoch 38, Loss(train/val) 0.25171/0.31767. Took 0.15 sec\n",
      "Epoch 39, Loss(train/val) 0.24962/0.33006. Took 0.16 sec\n",
      "Epoch 40, Loss(train/val) 0.24174/0.32029. Took 0.15 sec\n",
      "Epoch 41, Loss(train/val) 0.24239/0.36303. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.23986/0.34171. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.23782/0.31027. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.23924/0.31514. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.23171/0.31602. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.22995/0.30834. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.22759/0.30597. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.21535/0.31488. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.22712/0.30956. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.22338/0.28543. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.21856/0.30617. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.20650/0.29559. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.20563/0.29897. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.21143/0.29374. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.20908/0.30344. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.20809/0.31445. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.21455/0.30618. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.20678/0.31446. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.19653/0.31559. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.19787/0.30194. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.19964/0.30716. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.18486/0.30527. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.19162/0.30117. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.19465/0.29011. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.19774/0.30413. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.18977/0.29757. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.17888/0.29946. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.18530/0.29528. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.18232/0.29468. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.18103/0.30622. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.18260/0.29863. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.18659/0.31436. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.17749/0.30737. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.17738/0.29782. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.18087/0.29387. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.16713/0.29754. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.16582/0.28986. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.16818/0.29651. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.16962/0.30070. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.16403/0.30117. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.16777/0.30154. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.16083/0.29802. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.15644/0.30808. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.15500/0.28355. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.15889/0.28299. Took 0.15 sec\n",
      "Epoch 86, Loss(train/val) 0.16410/0.30190. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.15712/0.29271. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.15648/0.28879. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.16077/0.31366. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.16833/0.30185. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.15801/0.28993. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.15417/0.28552. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.15109/0.30002. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.15333/0.29640. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.15100/0.28803. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.15447/0.27377. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.14813/0.30534. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.14632/0.28459. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.14875/0.30252. Took 0.13 sec\n",
      "ACC: 0.640625, MCC: 0.29771284816973936\n",
      "Epoch 0, Loss(train/val) 0.50020/0.48635. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.48166/0.45186. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.44967/0.38745. Took 0.16 sec\n",
      "Epoch 3, Loss(train/val) 0.40986/0.33944. Took 0.17 sec\n",
      "Epoch 4, Loss(train/val) 0.38343/0.33174. Took 0.15 sec\n",
      "Epoch 5, Loss(train/val) 0.36127/0.32956. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.33847/0.31347. Took 0.16 sec\n",
      "Epoch 7, Loss(train/val) 0.32665/0.30880. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.32201/0.31645. Took 0.16 sec\n",
      "Epoch 9, Loss(train/val) 0.30122/0.30436. Took 0.16 sec\n",
      "Epoch 10, Loss(train/val) 0.29538/0.27972. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.29222/0.27207. Took 0.15 sec\n",
      "Epoch 12, Loss(train/val) 0.27815/0.29026. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.29472/0.32255. Took 0.16 sec\n",
      "Epoch 14, Loss(train/val) 0.28726/0.30712. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.27725/0.27174. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.26602/0.25628. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.27352/0.27205. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.26447/0.29490. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.25497/0.27489. Took 0.15 sec\n",
      "Epoch 20, Loss(train/val) 0.25597/0.28234. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.25579/0.30002. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.25971/0.27422. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.27637/0.30966. Took 0.16 sec\n",
      "Epoch 24, Loss(train/val) 0.26366/0.27768. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.26303/0.30395. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.23985/0.30989. Took 0.13 sec\n",
      "Epoch 27, Loss(train/val) 0.24601/0.30365. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.23927/0.26572. Took 0.13 sec\n",
      "Epoch 29, Loss(train/val) 0.25201/0.31594. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.24632/0.29239. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.23635/0.27813. Took 0.16 sec\n",
      "Epoch 32, Loss(train/val) 0.23686/0.29419. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.23096/0.28574. Took 0.16 sec\n",
      "Epoch 34, Loss(train/val) 0.22161/0.28919. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.23029/0.30733. Took 0.16 sec\n",
      "Epoch 36, Loss(train/val) 0.22719/0.30493. Took 0.16 sec\n",
      "Epoch 37, Loss(train/val) 0.23061/0.31908. Took 0.16 sec\n",
      "Epoch 38, Loss(train/val) 0.22559/0.31552. Took 0.15 sec\n",
      "Epoch 39, Loss(train/val) 0.22411/0.29085. Took 0.16 sec\n",
      "Epoch 40, Loss(train/val) 0.22737/0.31205. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.23406/0.32425. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.23602/0.26627. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.21605/0.30238. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.21480/0.30774. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.21199/0.31171. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.21056/0.31780. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.20525/0.30637. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.22022/0.31287. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.21147/0.30761. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.21051/0.30708. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.20319/0.29832. Took 0.15 sec\n",
      "Epoch 52, Loss(train/val) 0.20673/0.31906. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.21329/0.33013. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.20822/0.30494. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.20643/0.31007. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.20602/0.28507. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.20314/0.30733. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.20366/0.29224. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.20848/0.32996. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.19761/0.30434. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.19471/0.30690. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.18585/0.31316. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.19653/0.30246. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.18829/0.32412. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.18289/0.31339. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.18615/0.32096. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.18520/0.29543. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.18881/0.31594. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.18352/0.32166. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.18188/0.32762. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.17237/0.32865. Took 0.15 sec\n",
      "Epoch 72, Loss(train/val) 0.17529/0.30794. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.17500/0.31056. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.17358/0.32268. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.17480/0.33921. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.17688/0.31969. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.17452/0.31200. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.17282/0.31317. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.17169/0.31103. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.16856/0.31029. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.17639/0.34973. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.17159/0.31893. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.16200/0.30363. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.16381/0.28315. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.17090/0.30151. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.15965/0.30083. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.16194/0.29932. Took 0.15 sec\n",
      "Epoch 88, Loss(train/val) 0.15341/0.29832. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.16024/0.29829. Took 0.15 sec\n",
      "Epoch 90, Loss(train/val) 0.15627/0.29963. Took 0.14 sec\n",
      "Epoch 91, Loss(train/val) 0.15741/0.32337. Took 0.15 sec\n",
      "Epoch 92, Loss(train/val) 0.15348/0.32504. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.15528/0.30804. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.15669/0.30614. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.14861/0.28619. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.15908/0.30638. Took 0.15 sec\n",
      "Epoch 97, Loss(train/val) 0.15818/0.29338. Took 0.17 sec\n",
      "Epoch 98, Loss(train/val) 0.15931/0.30070. Took 0.16 sec\n",
      "Epoch 99, Loss(train/val) 0.15050/0.28820. Took 0.17 sec\n",
      "ACC: 0.703125, MCC: 0.3971160402518228\n",
      "Epoch 0, Loss(train/val) 0.48881/0.48608. Took 0.16 sec\n",
      "Epoch 1, Loss(train/val) 0.45866/0.45471. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.41175/0.42223. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.37742/0.41376. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.35921/0.39944. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.34589/0.34837. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.33660/0.39587. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.32375/0.34551. Took 0.15 sec\n",
      "Epoch 8, Loss(train/val) 0.31715/0.32113. Took 0.15 sec\n",
      "Epoch 9, Loss(train/val) 0.30367/0.33907. Took 0.19 sec\n",
      "Epoch 10, Loss(train/val) 0.30572/0.31946. Took 0.19 sec\n",
      "Epoch 11, Loss(train/val) 0.30577/0.34581. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.29470/0.31921. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.30961/0.36904. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.29675/0.33393. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.29029/0.25949. Took 0.17 sec\n",
      "Epoch 16, Loss(train/val) 0.29967/0.30915. Took 0.17 sec\n",
      "Epoch 17, Loss(train/val) 0.29133/0.34210. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.29570/0.35641. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.27647/0.30722. Took 0.16 sec\n",
      "Epoch 20, Loss(train/val) 0.28241/0.33127. Took 0.15 sec\n",
      "Epoch 21, Loss(train/val) 0.27556/0.31447. Took 0.18 sec\n",
      "Epoch 22, Loss(train/val) 0.26880/0.31237. Took 0.17 sec\n",
      "Epoch 23, Loss(train/val) 0.28923/0.33212. Took 0.16 sec\n",
      "Epoch 24, Loss(train/val) 0.27925/0.35883. Took 0.15 sec\n",
      "Epoch 25, Loss(train/val) 0.27618/0.32394. Took 0.16 sec\n",
      "Epoch 26, Loss(train/val) 0.26555/0.30031. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.26808/0.34809. Took 0.16 sec\n",
      "Epoch 28, Loss(train/val) 0.26784/0.39662. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.27821/0.41126. Took 0.17 sec\n",
      "Epoch 30, Loss(train/val) 0.27538/0.36888. Took 0.17 sec\n",
      "Epoch 31, Loss(train/val) 0.28319/0.42901. Took 0.19 sec\n",
      "Epoch 32, Loss(train/val) 0.29400/0.39042. Took 0.17 sec\n",
      "Epoch 33, Loss(train/val) 0.27778/0.40242. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.27199/0.40337. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.26899/0.43209. Took 0.17 sec\n",
      "Epoch 36, Loss(train/val) 0.27315/0.41896. Took 0.16 sec\n",
      "Epoch 37, Loss(train/val) 0.27070/0.38567. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.25435/0.39219. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.25655/0.38847. Took 0.16 sec\n",
      "Epoch 40, Loss(train/val) 0.26907/0.35723. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.27573/0.40692. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.25588/0.39390. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.25145/0.39076. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.24608/0.38892. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.24705/0.37387. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.25073/0.36872. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.24584/0.37256. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.24754/0.37738. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.23779/0.37528. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.23860/0.38635. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.23986/0.35991. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.24276/0.35567. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.24058/0.37168. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.22255/0.38202. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.23025/0.36924. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.22845/0.36610. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.21983/0.37495. Took 0.15 sec\n",
      "Epoch 58, Loss(train/val) 0.22682/0.38151. Took 0.15 sec\n",
      "Epoch 59, Loss(train/val) 0.22802/0.39161. Took 0.16 sec\n",
      "Epoch 60, Loss(train/val) 0.22688/0.36661. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.22697/0.40233. Took 0.15 sec\n",
      "Epoch 62, Loss(train/val) 0.22287/0.38867. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.22624/0.39947. Took 0.16 sec\n",
      "Epoch 64, Loss(train/val) 0.21668/0.42251. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.22783/0.34261. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.21501/0.40680. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) 0.22064/0.40281. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.21955/0.41253. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.21685/0.39327. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.21845/0.41148. Took 0.15 sec\n",
      "Epoch 71, Loss(train/val) 0.21085/0.40086. Took 0.15 sec\n",
      "Epoch 72, Loss(train/val) 0.20586/0.40375. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.20727/0.39343. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.20004/0.39745. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.20461/0.41054. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.19457/0.40416. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.20079/0.39951. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.20077/0.39795. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.20973/0.40921. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.19555/0.41080. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.19015/0.40744. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.19225/0.39995. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.19223/0.39730. Took 0.17 sec\n",
      "Epoch 84, Loss(train/val) 0.19083/0.40925. Took 0.15 sec\n",
      "Epoch 85, Loss(train/val) 0.18918/0.41100. Took 0.15 sec\n",
      "Epoch 86, Loss(train/val) 0.19256/0.39109. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.18906/0.40963. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.19176/0.41082. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.18562/0.40970. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.18622/0.39873. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.18608/0.41030. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.17496/0.40524. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.18204/0.41424. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.17652/0.39595. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.17696/0.40928. Took 0.15 sec\n",
      "Epoch 96, Loss(train/val) 0.17231/0.39681. Took 0.14 sec\n",
      "Epoch 97, Loss(train/val) 0.16863/0.40911. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.17020/0.40424. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.17476/0.40910. Took 0.14 sec\n",
      "ACC: 0.640625, MCC: 0.30686720460853334\n",
      "Epoch 0, Loss(train/val) 0.48757/0.48783. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.45275/0.47324. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.40571/0.46719. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.37660/0.46099. Took 0.15 sec\n",
      "Epoch 4, Loss(train/val) 0.35739/0.45083. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.34093/0.43031. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.32741/0.41535. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.31703/0.40752. Took 0.16 sec\n",
      "Epoch 8, Loss(train/val) 0.30880/0.39568. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.30703/0.39131. Took 0.15 sec\n",
      "Epoch 10, Loss(train/val) 0.29654/0.40085. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.29243/0.41344. Took 0.15 sec\n",
      "Epoch 12, Loss(train/val) 0.28611/0.39970. Took 0.21 sec\n",
      "Epoch 13, Loss(train/val) 0.28695/0.38927. Took 0.22 sec\n",
      "Epoch 14, Loss(train/val) 0.28418/0.37516. Took 0.22 sec\n",
      "Epoch 15, Loss(train/val) 0.28744/0.37990. Took 0.19 sec\n",
      "Epoch 16, Loss(train/val) 0.27641/0.41729. Took 0.16 sec\n",
      "Epoch 17, Loss(train/val) 0.27887/0.42892. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.27594/0.39310. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.26842/0.40807. Took 0.17 sec\n",
      "Epoch 20, Loss(train/val) 0.25732/0.40958. Took 0.15 sec\n",
      "Epoch 21, Loss(train/val) 0.26813/0.39652. Took 0.16 sec\n",
      "Epoch 22, Loss(train/val) 0.25183/0.39973. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.25814/0.40519. Took 0.16 sec\n",
      "Epoch 24, Loss(train/val) 0.25602/0.39293. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.24990/0.40292. Took 0.16 sec\n",
      "Epoch 26, Loss(train/val) 0.24903/0.40578. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.24731/0.40245. Took 0.19 sec\n",
      "Epoch 28, Loss(train/val) 0.23663/0.42665. Took 0.19 sec\n",
      "Epoch 29, Loss(train/val) 0.24671/0.41313. Took 0.16 sec\n",
      "Epoch 30, Loss(train/val) 0.22909/0.41945. Took 0.16 sec\n",
      "Epoch 31, Loss(train/val) 0.23394/0.42990. Took 0.16 sec\n",
      "Epoch 32, Loss(train/val) 0.23511/0.44015. Took 0.16 sec\n",
      "Epoch 33, Loss(train/val) 0.22976/0.41708. Took 0.20 sec\n",
      "Epoch 34, Loss(train/val) 0.22040/0.41736. Took 0.22 sec\n",
      "Epoch 35, Loss(train/val) 0.22228/0.43378. Took 0.18 sec\n",
      "Epoch 36, Loss(train/val) 0.21934/0.42221. Took 0.17 sec\n",
      "Epoch 37, Loss(train/val) 0.21457/0.42243. Took 0.16 sec\n",
      "Epoch 38, Loss(train/val) 0.21761/0.40407. Took 0.15 sec\n",
      "Epoch 39, Loss(train/val) 0.22075/0.38924. Took 0.18 sec\n",
      "Epoch 40, Loss(train/val) 0.21957/0.42386. Took 0.16 sec\n",
      "Epoch 41, Loss(train/val) 0.21060/0.41094. Took 0.16 sec\n",
      "Epoch 42, Loss(train/val) 0.21445/0.42180. Took 0.17 sec\n",
      "Epoch 43, Loss(train/val) 0.19990/0.41300. Took 0.17 sec\n",
      "Epoch 44, Loss(train/val) 0.21417/0.41717. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) 0.20115/0.43659. Took 0.15 sec\n",
      "Epoch 46, Loss(train/val) 0.19499/0.43277. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.19678/0.44980. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.20409/0.41861. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.19559/0.45355. Took 0.15 sec\n",
      "Epoch 50, Loss(train/val) 0.18939/0.44726. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.19152/0.43816. Took 0.16 sec\n",
      "Epoch 52, Loss(train/val) 0.18713/0.44260. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) 0.18982/0.44971. Took 0.15 sec\n",
      "Epoch 54, Loss(train/val) 0.19874/0.44714. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.19547/0.43957. Took 0.15 sec\n",
      "Epoch 56, Loss(train/val) 0.18506/0.46974. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.18567/0.47458. Took 0.15 sec\n",
      "Epoch 58, Loss(train/val) 0.18503/0.45677. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.18165/0.48359. Took 0.15 sec\n",
      "Epoch 60, Loss(train/val) 0.17706/0.47734. Took 0.14 sec\n",
      "Epoch 61, Loss(train/val) 0.18508/0.45402. Took 0.15 sec\n",
      "Epoch 62, Loss(train/val) 0.17423/0.44655. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.18228/0.47078. Took 0.15 sec\n",
      "Epoch 64, Loss(train/val) 0.17555/0.47005. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.17284/0.51721. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.17826/0.49816. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.18004/0.50496. Took 0.15 sec\n",
      "Epoch 68, Loss(train/val) 0.17343/0.48350. Took 0.14 sec\n",
      "Epoch 69, Loss(train/val) 0.17304/0.51188. Took 0.15 sec\n",
      "Epoch 70, Loss(train/val) 0.17445/0.48652. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.16857/0.48768. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.16655/0.50933. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.16253/0.50995. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.16088/0.49495. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) 0.16160/0.49389. Took 0.16 sec\n",
      "Epoch 76, Loss(train/val) 0.16132/0.51087. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.16489/0.51379. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.15683/0.51960. Took 0.14 sec\n",
      "Epoch 79, Loss(train/val) 0.16636/0.54026. Took 0.15 sec\n",
      "Epoch 80, Loss(train/val) 0.16116/0.51044. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.15817/0.51440. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.15648/0.49917. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.15253/0.49108. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.15669/0.51565. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.15294/0.50968. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.15437/0.48781. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.15079/0.51236. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.15375/0.50783. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.14274/0.49586. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.14811/0.53059. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.14187/0.51594. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.14752/0.49709. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.14462/0.50532. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.14425/0.47806. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.14339/0.49807. Took 0.15 sec\n",
      "Epoch 96, Loss(train/val) 0.14111/0.46663. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.14472/0.50455. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.13664/0.51646. Took 0.14 sec\n",
      "Epoch 99, Loss(train/val) 0.14377/0.52936. Took 0.15 sec\n",
      "ACC: 0.703125, MCC: 0.4278508737318931\n",
      "Epoch 0, Loss(train/val) 0.48636/0.49886. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.45374/0.48738. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.40909/0.46943. Took 0.15 sec\n",
      "Epoch 3, Loss(train/val) 0.38431/0.45293. Took 0.15 sec\n",
      "Epoch 4, Loss(train/val) 0.36836/0.45047. Took 0.15 sec\n",
      "Epoch 5, Loss(train/val) 0.35874/0.42272. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.34592/0.41358. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.34354/0.39094. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.33283/0.39004. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.33040/0.40518. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.31835/0.36029. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.31604/0.36200. Took 0.15 sec\n",
      "Epoch 12, Loss(train/val) 0.31928/0.39588. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.31297/0.38910. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.30013/0.34623. Took 0.15 sec\n",
      "Epoch 15, Loss(train/val) 0.28923/0.33511. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.28666/0.35760. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.28862/0.32876. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.29926/0.31415. Took 0.15 sec\n",
      "Epoch 19, Loss(train/val) 0.28577/0.31715. Took 0.15 sec\n",
      "Epoch 20, Loss(train/val) 0.27033/0.30899. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.28115/0.34974. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.27245/0.35830. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.26696/0.34478. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.26249/0.31345. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.26379/0.38831. Took 0.16 sec\n",
      "Epoch 26, Loss(train/val) 0.26071/0.37011. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.26943/0.37810. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.26455/0.37196. Took 0.13 sec\n",
      "Epoch 29, Loss(train/val) 0.25896/0.37778. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.25070/0.32961. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.25223/0.32333. Took 0.16 sec\n",
      "Epoch 32, Loss(train/val) 0.23739/0.34629. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.25693/0.37259. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.24029/0.31122. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.24659/0.33425. Took 0.17 sec\n",
      "Epoch 36, Loss(train/val) 0.23634/0.31613. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.24354/0.33379. Took 0.15 sec\n",
      "Epoch 38, Loss(train/val) 0.23705/0.34526. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.24204/0.35101. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.22733/0.34614. Took 0.15 sec\n",
      "Epoch 41, Loss(train/val) 0.22571/0.31171. Took 0.16 sec\n",
      "Epoch 42, Loss(train/val) 0.23105/0.30324. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.22541/0.30867. Took 0.15 sec\n",
      "Epoch 44, Loss(train/val) 0.23019/0.34132. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.22725/0.32794. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.22502/0.35924. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.22642/0.34396. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.21830/0.33572. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.21929/0.32697. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.22410/0.34866. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.21322/0.33084. Took 0.15 sec\n",
      "Epoch 52, Loss(train/val) 0.21077/0.34432. Took 0.16 sec\n",
      "Epoch 53, Loss(train/val) 0.21054/0.35915. Took 0.15 sec\n",
      "Epoch 54, Loss(train/val) 0.21628/0.33943. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.21335/0.30608. Took 0.15 sec\n",
      "Epoch 56, Loss(train/val) 0.20859/0.30274. Took 0.15 sec\n",
      "Epoch 57, Loss(train/val) 0.21507/0.34030. Took 0.17 sec\n",
      "Epoch 58, Loss(train/val) 0.21094/0.33485. Took 0.15 sec\n",
      "Epoch 59, Loss(train/val) 0.21702/0.32478. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.20379/0.29284. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.20731/0.33614. Took 0.15 sec\n",
      "Epoch 62, Loss(train/val) 0.20648/0.32130. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.20430/0.31653. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.20064/0.31964. Took 0.15 sec\n",
      "Epoch 65, Loss(train/val) 0.19560/0.32639. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.19450/0.32499. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.19707/0.30278. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.20023/0.31310. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.19473/0.32530. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.19442/0.34122. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.19268/0.30982. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.18747/0.32848. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.19934/0.34920. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.19316/0.32595. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) 0.19206/0.33834. Took 0.17 sec\n",
      "Epoch 76, Loss(train/val) 0.19125/0.32349. Took 0.17 sec\n",
      "Epoch 77, Loss(train/val) 0.18004/0.35807. Took 0.15 sec\n",
      "Epoch 78, Loss(train/val) 0.18726/0.32366. Took 0.17 sec\n",
      "Epoch 79, Loss(train/val) 0.19237/0.32822. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.18355/0.31224. Took 0.14 sec\n",
      "Epoch 81, Loss(train/val) 0.17525/0.31886. Took 0.15 sec\n",
      "Epoch 82, Loss(train/val) 0.18177/0.27879. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) 0.18073/0.35222. Took 0.15 sec\n",
      "Epoch 84, Loss(train/val) 0.18635/0.30766. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.19345/0.31193. Took 0.17 sec\n",
      "Epoch 86, Loss(train/val) 0.17206/0.32595. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.17543/0.32350. Took 0.15 sec\n",
      "Epoch 88, Loss(train/val) 0.17965/0.33603. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.19026/0.32227. Took 0.15 sec\n",
      "Epoch 90, Loss(train/val) 0.18971/0.30840. Took 0.14 sec\n",
      "Epoch 91, Loss(train/val) 0.17333/0.31825. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.17440/0.29513. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.17338/0.32032. Took 0.15 sec\n",
      "Epoch 94, Loss(train/val) 0.17062/0.32593. Took 0.14 sec\n",
      "Epoch 95, Loss(train/val) 0.17163/0.30777. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.16606/0.32444. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.16788/0.35498. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.17251/0.31780. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.16760/0.32507. Took 0.15 sec\n",
      "ACC: 0.625, MCC: 0.2519763153394848\n",
      "Epoch 0, Loss(train/val) 0.49549/0.48954. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.47120/0.47322. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.43395/0.46740. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.39513/0.46165. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.37533/0.45715. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.35215/0.40981. Took 0.15 sec\n",
      "Epoch 6, Loss(train/val) 0.34177/0.40557. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.33439/0.38938. Took 0.15 sec\n",
      "Epoch 8, Loss(train/val) 0.32385/0.36606. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.32069/0.37780. Took 0.15 sec\n",
      "Epoch 10, Loss(train/val) 0.30296/0.34989. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.30426/0.37414. Took 0.15 sec\n",
      "Epoch 12, Loss(train/val) 0.30735/0.38352. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.30261/0.35516. Took 0.16 sec\n",
      "Epoch 14, Loss(train/val) 0.29064/0.36177. Took 0.16 sec\n",
      "Epoch 15, Loss(train/val) 0.28476/0.37200. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.28155/0.34899. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.28576/0.34284. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.26999/0.39552. Took 0.15 sec\n",
      "Epoch 19, Loss(train/val) 0.27722/0.38789. Took 0.15 sec\n",
      "Epoch 20, Loss(train/val) 0.26393/0.39141. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.26194/0.38107. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.26442/0.36863. Took 0.15 sec\n",
      "Epoch 23, Loss(train/val) 0.25908/0.37226. Took 0.16 sec\n",
      "Epoch 24, Loss(train/val) 0.26573/0.36407. Took 0.15 sec\n",
      "Epoch 25, Loss(train/val) 0.25857/0.34936. Took 0.17 sec\n",
      "Epoch 26, Loss(train/val) 0.25690/0.36191. Took 0.16 sec\n",
      "Epoch 27, Loss(train/val) 0.24973/0.35218. Took 0.17 sec\n",
      "Epoch 28, Loss(train/val) 0.24969/0.36696. Took 0.17 sec\n",
      "Epoch 29, Loss(train/val) 0.25129/0.35332. Took 0.17 sec\n",
      "Epoch 30, Loss(train/val) 0.23456/0.35534. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.23959/0.35428. Took 0.16 sec\n",
      "Epoch 32, Loss(train/val) 0.23664/0.34649. Took 0.23 sec\n",
      "Epoch 33, Loss(train/val) 0.23995/0.35861. Took 0.17 sec\n",
      "Epoch 34, Loss(train/val) 0.23315/0.34823. Took 0.16 sec\n",
      "Epoch 35, Loss(train/val) 0.23181/0.35044. Took 0.19 sec\n",
      "Epoch 36, Loss(train/val) 0.22580/0.36078. Took 0.17 sec\n",
      "Epoch 37, Loss(train/val) 0.22990/0.36486. Took 0.16 sec\n",
      "Epoch 38, Loss(train/val) 0.22450/0.37349. Took 0.15 sec\n",
      "Epoch 39, Loss(train/val) 0.22528/0.34966. Took 0.18 sec\n",
      "Epoch 40, Loss(train/val) 0.22259/0.35257. Took 0.15 sec\n",
      "Epoch 41, Loss(train/val) 0.22701/0.35780. Took 0.16 sec\n",
      "Epoch 42, Loss(train/val) 0.22358/0.34508. Took 0.16 sec\n",
      "Epoch 43, Loss(train/val) 0.22758/0.37910. Took 0.18 sec\n",
      "Epoch 44, Loss(train/val) 0.22761/0.35405. Took 0.17 sec\n",
      "Epoch 45, Loss(train/val) 0.21494/0.32418. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.23229/0.35413. Took 0.15 sec\n",
      "Epoch 47, Loss(train/val) 0.20290/0.31734. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.21228/0.32553. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.20765/0.35009. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.21200/0.33619. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.21477/0.35739. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.20604/0.33417. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.20849/0.33732. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.20413/0.34223. Took 0.15 sec\n",
      "Epoch 55, Loss(train/val) 0.20957/0.31557. Took 0.15 sec\n",
      "Epoch 56, Loss(train/val) 0.20834/0.32306. Took 0.16 sec\n",
      "Epoch 57, Loss(train/val) 0.20147/0.33807. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.20709/0.33474. Took 0.14 sec\n",
      "Epoch 59, Loss(train/val) 0.19990/0.34221. Took 0.17 sec\n",
      "Epoch 60, Loss(train/val) 0.20090/0.33018. Took 0.16 sec\n",
      "Epoch 61, Loss(train/val) 0.20511/0.33405. Took 0.17 sec\n",
      "Epoch 62, Loss(train/val) 0.19673/0.33378. Took 0.16 sec\n",
      "Epoch 63, Loss(train/val) 0.19293/0.33328. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.18722/0.34379. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.19047/0.34543. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.19173/0.35965. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.18431/0.36549. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.18970/0.35586. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.18385/0.34140. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.18543/0.35043. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.19239/0.38165. Took 0.15 sec\n",
      "Epoch 72, Loss(train/val) 0.18871/0.36015. Took 0.16 sec\n",
      "Epoch 73, Loss(train/val) 0.18574/0.34900. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.18365/0.33654. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) 0.18184/0.33786. Took 0.15 sec\n",
      "Epoch 76, Loss(train/val) 0.17722/0.35568. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.18299/0.33845. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.18223/0.34590. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.18111/0.35337. Took 0.16 sec\n",
      "Epoch 80, Loss(train/val) 0.18671/0.33004. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.17946/0.34477. Took 0.15 sec\n",
      "Epoch 82, Loss(train/val) 0.18511/0.35870. Took 0.16 sec\n",
      "Epoch 83, Loss(train/val) 0.18058/0.36047. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.18034/0.34723. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.17752/0.35530. Took 0.16 sec\n",
      "Epoch 86, Loss(train/val) 0.17530/0.34680. Took 0.15 sec\n",
      "Epoch 87, Loss(train/val) 0.17767/0.33333. Took 0.15 sec\n",
      "Epoch 88, Loss(train/val) 0.16772/0.32728. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.16716/0.35846. Took 0.15 sec\n",
      "Epoch 90, Loss(train/val) 0.17866/0.32644. Took 0.16 sec\n",
      "Epoch 91, Loss(train/val) 0.18177/0.32711. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.17070/0.33967. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.16894/0.35440. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.16435/0.35779. Took 0.14 sec\n",
      "Epoch 95, Loss(train/val) 0.17268/0.34675. Took 0.16 sec\n",
      "Epoch 96, Loss(train/val) 0.17287/0.35759. Took 0.14 sec\n",
      "Epoch 97, Loss(train/val) 0.17585/0.34344. Took 0.16 sec\n",
      "Epoch 98, Loss(train/val) 0.16254/0.33340. Took 0.15 sec\n",
      "Epoch 99, Loss(train/val) 0.16373/0.30790. Took 0.16 sec\n",
      "ACC: 0.765625, MCC: 0.5305928383295753\n",
      "Epoch 0, Loss(train/val) 0.49151/0.47240. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.46634/0.42148. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.42797/0.37983. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.39467/0.36927. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.37732/0.36151. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.36061/0.35879. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.34505/0.35488. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.32981/0.33709. Took 0.17 sec\n",
      "Epoch 8, Loss(train/val) 0.32197/0.32816. Took 0.17 sec\n",
      "Epoch 9, Loss(train/val) 0.31545/0.32558. Took 0.15 sec\n",
      "Epoch 10, Loss(train/val) 0.30776/0.32032. Took 0.15 sec\n",
      "Epoch 11, Loss(train/val) 0.30816/0.31016. Took 0.16 sec\n",
      "Epoch 12, Loss(train/val) 0.30713/0.32422. Took 0.16 sec\n",
      "Epoch 13, Loss(train/val) 0.28967/0.30177. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.28508/0.30998. Took 0.15 sec\n",
      "Epoch 15, Loss(train/val) 0.27972/0.30365. Took 0.16 sec\n",
      "Epoch 16, Loss(train/val) 0.27253/0.29946. Took 0.15 sec\n",
      "Epoch 17, Loss(train/val) 0.27500/0.28662. Took 0.16 sec\n",
      "Epoch 18, Loss(train/val) 0.27297/0.27035. Took 0.16 sec\n",
      "Epoch 19, Loss(train/val) 0.26524/0.28305. Took 0.16 sec\n",
      "Epoch 20, Loss(train/val) 0.25774/0.30226. Took 0.15 sec\n",
      "Epoch 21, Loss(train/val) 0.25980/0.29713. Took 0.19 sec\n",
      "Epoch 22, Loss(train/val) 0.25835/0.28526. Took 0.20 sec\n",
      "Epoch 23, Loss(train/val) 0.25145/0.28442. Took 0.18 sec\n",
      "Epoch 24, Loss(train/val) 0.24823/0.26386. Took 0.18 sec\n",
      "Epoch 25, Loss(train/val) 0.24318/0.28020. Took 0.17 sec\n",
      "Epoch 26, Loss(train/val) 0.24131/0.25345. Took 0.15 sec\n",
      "Epoch 27, Loss(train/val) 0.24510/0.27637. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.23400/0.27304. Took 0.17 sec\n",
      "Epoch 29, Loss(train/val) 0.22747/0.27901. Took 0.19 sec\n",
      "Epoch 30, Loss(train/val) 0.22530/0.27833. Took 0.19 sec\n",
      "Epoch 31, Loss(train/val) 0.22157/0.28104. Took 0.17 sec\n",
      "Epoch 32, Loss(train/val) 0.21618/0.27767. Took 0.17 sec\n",
      "Epoch 33, Loss(train/val) 0.21705/0.28241. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.22062/0.27935. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.20868/0.26875. Took 0.17 sec\n",
      "Epoch 36, Loss(train/val) 0.20749/0.27023. Took 0.19 sec\n",
      "Epoch 37, Loss(train/val) 0.21405/0.27163. Took 0.22 sec\n",
      "Epoch 38, Loss(train/val) 0.21027/0.26230. Took 0.18 sec\n",
      "Epoch 39, Loss(train/val) 0.19924/0.27367. Took 0.20 sec\n",
      "Epoch 40, Loss(train/val) 0.21151/0.25476. Took 0.17 sec\n",
      "Epoch 41, Loss(train/val) 0.21731/0.25397. Took 0.18 sec\n",
      "Epoch 42, Loss(train/val) 0.20152/0.27779. Took 0.17 sec\n",
      "Epoch 43, Loss(train/val) 0.19841/0.27309. Took 0.17 sec\n",
      "Epoch 44, Loss(train/val) 0.19926/0.27838. Took 0.15 sec\n",
      "Epoch 45, Loss(train/val) 0.20304/0.27524. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.19961/0.27326. Took 0.15 sec\n",
      "Epoch 47, Loss(train/val) 0.19429/0.27206. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.18875/0.26689. Took 0.15 sec\n",
      "Epoch 49, Loss(train/val) 0.19295/0.26502. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.18793/0.26317. Took 0.17 sec\n",
      "Epoch 51, Loss(train/val) 0.18287/0.27296. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.17914/0.26521. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) 0.18063/0.26217. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.17786/0.27363. Took 0.15 sec\n",
      "Epoch 55, Loss(train/val) 0.18361/0.25674. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.18184/0.27471. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.18885/0.27066. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.17816/0.24487. Took 0.15 sec\n",
      "Epoch 59, Loss(train/val) 0.17721/0.28449. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.17462/0.26267. Took 0.14 sec\n",
      "Epoch 61, Loss(train/val) 0.17994/0.26853. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.17579/0.28143. Took 0.15 sec\n",
      "Epoch 63, Loss(train/val) 0.16554/0.27764. Took 0.15 sec\n",
      "Epoch 64, Loss(train/val) 0.17452/0.26843. Took 0.16 sec\n",
      "Epoch 65, Loss(train/val) 0.16880/0.27975. Took 0.15 sec\n",
      "Epoch 66, Loss(train/val) 0.16837/0.26078. Took 0.15 sec\n",
      "Epoch 67, Loss(train/val) 0.16705/0.28011. Took 0.15 sec\n",
      "Epoch 68, Loss(train/val) 0.16453/0.27207. Took 0.15 sec\n",
      "Epoch 69, Loss(train/val) 0.16139/0.27905. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.15684/0.28783. Took 0.15 sec\n",
      "Epoch 71, Loss(train/val) 0.15863/0.28282. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.15756/0.26728. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.15305/0.28818. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.15681/0.28458. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) 0.15956/0.28526. Took 0.15 sec\n",
      "Epoch 76, Loss(train/val) 0.15851/0.30417. Took 0.18 sec\n",
      "Epoch 77, Loss(train/val) 0.14977/0.29416. Took 0.15 sec\n",
      "Epoch 78, Loss(train/val) 0.15265/0.28403. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.15220/0.28020. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.14974/0.27708. Took 0.17 sec\n",
      "Epoch 81, Loss(train/val) 0.14301/0.27457. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.14599/0.28579. Took 0.16 sec\n",
      "Epoch 83, Loss(train/val) 0.14472/0.28252. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.14798/0.28565. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.14061/0.27850. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.14228/0.28578. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.14211/0.30677. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.14559/0.30342. Took 0.15 sec\n",
      "Epoch 89, Loss(train/val) 0.14055/0.29879. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.14448/0.31459. Took 0.14 sec\n",
      "Epoch 91, Loss(train/val) 0.14582/0.28370. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.15281/0.29301. Took 0.15 sec\n",
      "Epoch 93, Loss(train/val) 0.13972/0.28406. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.13070/0.29059. Took 0.14 sec\n",
      "Epoch 95, Loss(train/val) 0.13233/0.29577. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.14219/0.30138. Took 0.15 sec\n",
      "Epoch 97, Loss(train/val) 0.13894/0.29124. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.13518/0.28821. Took 0.16 sec\n",
      "Epoch 99, Loss(train/val) 0.12548/0.29724. Took 0.15 sec\n",
      "ACC: 0.640625, MCC: 0.28049997001672616\n",
      "Epoch 0, Loss(train/val) 0.49244/0.48679. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.47025/0.46088. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.43155/0.43132. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.39728/0.41337. Took 0.15 sec\n",
      "Epoch 4, Loss(train/val) 0.37348/0.40057. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.35851/0.38331. Took 0.15 sec\n",
      "Epoch 6, Loss(train/val) 0.34390/0.40148. Took 0.15 sec\n",
      "Epoch 7, Loss(train/val) 0.32616/0.35854. Took 0.15 sec\n",
      "Epoch 8, Loss(train/val) 0.32730/0.38986. Took 0.15 sec\n",
      "Epoch 9, Loss(train/val) 0.30254/0.31562. Took 0.16 sec\n",
      "Epoch 10, Loss(train/val) 0.29896/0.33686. Took 0.16 sec\n",
      "Epoch 11, Loss(train/val) 0.28802/0.31594. Took 0.16 sec\n",
      "Epoch 12, Loss(train/val) 0.28318/0.36897. Took 0.17 sec\n",
      "Epoch 13, Loss(train/val) 0.27101/0.37452. Took 0.20 sec\n",
      "Epoch 14, Loss(train/val) 0.27284/0.34949. Took 0.17 sec\n",
      "Epoch 15, Loss(train/val) 0.26169/0.33387. Took 0.17 sec\n",
      "Epoch 16, Loss(train/val) 0.26138/0.34629. Took 0.19 sec\n",
      "Epoch 17, Loss(train/val) 0.26933/0.31722. Took 0.17 sec\n",
      "Epoch 18, Loss(train/val) 0.26109/0.41026. Took 0.15 sec\n",
      "Epoch 19, Loss(train/val) 0.25660/0.40137. Took 0.16 sec\n",
      "Epoch 20, Loss(train/val) 0.27020/0.39339. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.25727/0.40915. Took 0.16 sec\n",
      "Epoch 22, Loss(train/val) 0.26742/0.39252. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.25934/0.31513. Took 0.17 sec\n",
      "Epoch 24, Loss(train/val) 0.25618/0.31913. Took 0.17 sec\n",
      "Epoch 25, Loss(train/val) 0.23929/0.31130. Took 0.16 sec\n",
      "Epoch 26, Loss(train/val) 0.23330/0.37648. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.25064/0.33402. Took 0.16 sec\n",
      "Epoch 28, Loss(train/val) 0.25075/0.36455. Took 0.19 sec\n",
      "Epoch 29, Loss(train/val) 0.23249/0.34334. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.23502/0.35610. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.23549/0.33787. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.22562/0.34946. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.23070/0.35696. Took 0.18 sec\n",
      "Epoch 34, Loss(train/val) 0.23837/0.35454. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.22962/0.38443. Took 0.17 sec\n",
      "Epoch 36, Loss(train/val) 0.22428/0.40339. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.22128/0.37799. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.22420/0.37941. Took 0.18 sec\n",
      "Epoch 39, Loss(train/val) 0.21992/0.40917. Took 0.17 sec\n",
      "Epoch 40, Loss(train/val) 0.22968/0.41687. Took 0.20 sec\n",
      "Epoch 41, Loss(train/val) 0.21479/0.38518. Took 0.16 sec\n",
      "Epoch 42, Loss(train/val) 0.24374/0.37140. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.23822/0.32778. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.20854/0.36800. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.21841/0.38485. Took 0.15 sec\n",
      "Epoch 46, Loss(train/val) 0.20719/0.34869. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.21475/0.34620. Took 0.16 sec\n",
      "Epoch 48, Loss(train/val) 0.20288/0.36455. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.20291/0.34266. Took 0.17 sec\n",
      "Epoch 50, Loss(train/val) 0.20348/0.34973. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.19944/0.37012. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.19522/0.36385. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) 0.21119/0.33272. Took 0.15 sec\n",
      "Epoch 54, Loss(train/val) 0.19944/0.35704. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.20547/0.34348. Took 0.15 sec\n",
      "Epoch 56, Loss(train/val) 0.20404/0.34645. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.21262/0.34880. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.19736/0.37088. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.19884/0.35076. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.19787/0.35683. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.19460/0.35094. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.19713/0.36226. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.19185/0.37880. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.18871/0.36255. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.18883/0.38741. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.18599/0.36723. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.18354/0.34510. Took 0.15 sec\n",
      "Epoch 68, Loss(train/val) 0.19107/0.38230. Took 0.15 sec\n",
      "Epoch 69, Loss(train/val) 0.19844/0.40308. Took 0.15 sec\n",
      "Epoch 70, Loss(train/val) 0.19106/0.40815. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.18676/0.38349. Took 0.15 sec\n",
      "Epoch 72, Loss(train/val) 0.18409/0.39536. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.17967/0.38493. Took 0.16 sec\n",
      "Epoch 74, Loss(train/val) 0.17484/0.39243. Took 0.17 sec\n",
      "Epoch 75, Loss(train/val) 0.18065/0.40368. Took 0.16 sec\n",
      "Epoch 76, Loss(train/val) 0.17856/0.37764. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.17383/0.37411. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.16612/0.39174. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.17416/0.41030. Took 0.16 sec\n",
      "Epoch 80, Loss(train/val) 0.17197/0.39488. Took 0.15 sec\n",
      "Epoch 81, Loss(train/val) 0.16689/0.40529. Took 0.17 sec\n",
      "Epoch 82, Loss(train/val) 0.16588/0.39986. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) 0.16782/0.40281. Took 0.15 sec\n",
      "Epoch 84, Loss(train/val) 0.16014/0.39305. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.17180/0.40077. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.17651/0.39361. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.16391/0.39209. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.16364/0.40897. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.16590/0.40715. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.15578/0.40721. Took 0.14 sec\n",
      "Epoch 91, Loss(train/val) 0.15972/0.41735. Took 0.17 sec\n",
      "Epoch 92, Loss(train/val) 0.16514/0.39317. Took 0.15 sec\n",
      "Epoch 93, Loss(train/val) 0.16169/0.39642. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.15597/0.37296. Took 0.14 sec\n",
      "Epoch 95, Loss(train/val) 0.16352/0.38163. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.15177/0.41895. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.16291/0.39284. Took 0.15 sec\n",
      "Epoch 98, Loss(train/val) 0.14941/0.40501. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.14228/0.42331. Took 0.14 sec\n",
      "ACC: 0.625, MCC: 0.22381412908589723\n",
      "Epoch 0, Loss(train/val) 0.49251/0.50026. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.47081/0.48533. Took 0.15 sec\n",
      "Epoch 2, Loss(train/val) 0.42698/0.44580. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.38836/0.40600. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.36304/0.39279. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.34766/0.37708. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.32919/0.38383. Took 0.16 sec\n",
      "Epoch 7, Loss(train/val) 0.32305/0.35936. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.30480/0.35298. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.29249/0.34866. Took 0.15 sec\n",
      "Epoch 10, Loss(train/val) 0.27735/0.38184. Took 0.16 sec\n",
      "Epoch 11, Loss(train/val) 0.28305/0.34464. Took 0.15 sec\n",
      "Epoch 12, Loss(train/val) 0.28383/0.35977. Took 0.15 sec\n",
      "Epoch 13, Loss(train/val) 0.27042/0.37899. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.26644/0.36208. Took 0.15 sec\n",
      "Epoch 15, Loss(train/val) 0.26691/0.35867. Took 0.17 sec\n",
      "Epoch 16, Loss(train/val) 0.26173/0.38411. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.26873/0.36298. Took 0.16 sec\n",
      "Epoch 18, Loss(train/val) 0.25119/0.34850. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.25117/0.38234. Took 0.16 sec\n",
      "Epoch 20, Loss(train/val) 0.24585/0.34099. Took 0.19 sec\n",
      "Epoch 21, Loss(train/val) 0.24462/0.35854. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.24076/0.35126. Took 0.15 sec\n",
      "Epoch 23, Loss(train/val) 0.24552/0.34547. Took 0.16 sec\n",
      "Epoch 24, Loss(train/val) 0.23676/0.35856. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.23550/0.34628. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.23358/0.33676. Took 0.19 sec\n",
      "Epoch 27, Loss(train/val) 0.23924/0.36256. Took 0.16 sec\n",
      "Epoch 28, Loss(train/val) 0.22094/0.34367. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.22950/0.34866. Took 0.17 sec\n",
      "Epoch 30, Loss(train/val) 0.22628/0.34623. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.22393/0.36030. Took 0.16 sec\n",
      "Epoch 32, Loss(train/val) 0.21543/0.35492. Took 0.18 sec\n",
      "Epoch 33, Loss(train/val) 0.21674/0.36041. Took 0.16 sec\n",
      "Epoch 34, Loss(train/val) 0.21155/0.37710. Took 0.17 sec\n",
      "Epoch 35, Loss(train/val) 0.20716/0.37663. Took 0.16 sec\n",
      "Epoch 36, Loss(train/val) 0.20771/0.37664. Took 0.16 sec\n",
      "Epoch 37, Loss(train/val) 0.20076/0.36922. Took 0.15 sec\n",
      "Epoch 38, Loss(train/val) 0.20209/0.37160. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.20623/0.36388. Took 0.17 sec\n",
      "Epoch 40, Loss(train/val) 0.19483/0.38028. Took 0.17 sec\n",
      "Epoch 41, Loss(train/val) 0.19092/0.35467. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.19978/0.35794. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.18926/0.35656. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.18662/0.35819. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.18367/0.35232. Took 0.15 sec\n",
      "Epoch 46, Loss(train/val) 0.18712/0.38779. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.17875/0.37539. Took 0.15 sec\n",
      "Epoch 48, Loss(train/val) 0.16802/0.38960. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.17281/0.39962. Took 0.16 sec\n",
      "Epoch 50, Loss(train/val) 0.16782/0.38557. Took 0.15 sec\n",
      "Epoch 51, Loss(train/val) 0.16413/0.40834. Took 0.15 sec\n",
      "Epoch 52, Loss(train/val) 0.16678/0.39077. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) 0.17032/0.37737. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.16269/0.39783. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.15890/0.39189. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.16148/0.37188. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.16619/0.37665. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.15444/0.39555. Took 0.14 sec\n",
      "Epoch 59, Loss(train/val) 0.15659/0.38364. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.15577/0.39813. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.14937/0.39897. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.14601/0.37883. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.14586/0.40007. Took 0.15 sec\n",
      "Epoch 64, Loss(train/val) 0.14988/0.41114. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.14866/0.40136. Took 0.17 sec\n",
      "Epoch 66, Loss(train/val) 0.14701/0.39652. Took 0.17 sec\n",
      "Epoch 67, Loss(train/val) 0.14534/0.42535. Took 0.15 sec\n",
      "Epoch 68, Loss(train/val) 0.13543/0.40731. Took 0.14 sec\n",
      "Epoch 69, Loss(train/val) 0.13858/0.35003. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.13910/0.35082. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.13961/0.38697. Took 0.15 sec\n",
      "Epoch 72, Loss(train/val) 0.14377/0.38334. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.13471/0.38492. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.13254/0.39263. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) 0.13407/0.40431. Took 0.17 sec\n",
      "Epoch 76, Loss(train/val) 0.13954/0.36926. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.13509/0.34228. Took 0.15 sec\n",
      "Epoch 78, Loss(train/val) 0.13130/0.39598. Took 0.14 sec\n",
      "Epoch 79, Loss(train/val) 0.13025/0.38375. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.12409/0.37928. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.12616/0.40274. Took 0.16 sec\n",
      "Epoch 82, Loss(train/val) 0.12556/0.39401. Took 0.15 sec\n",
      "Epoch 83, Loss(train/val) 0.12282/0.39764. Took 0.15 sec\n",
      "Epoch 84, Loss(train/val) 0.12236/0.38457. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.12110/0.39467. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.12341/0.39684. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.12753/0.39646. Took 0.15 sec\n",
      "Epoch 88, Loss(train/val) 0.12275/0.41137. Took 0.14 sec\n",
      "Epoch 89, Loss(train/val) 0.11813/0.39882. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.12821/0.42381. Took 0.15 sec\n",
      "Epoch 91, Loss(train/val) 0.11452/0.42803. Took 0.16 sec\n",
      "Epoch 92, Loss(train/val) 0.11617/0.39985. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.11198/0.39184. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.12242/0.42844. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.10850/0.35715. Took 0.15 sec\n",
      "Epoch 96, Loss(train/val) 0.11343/0.34716. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.12048/0.38009. Took 0.15 sec\n",
      "Epoch 98, Loss(train/val) 0.11331/0.38461. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.10614/0.38696. Took 0.14 sec\n",
      "ACC: 0.640625, MCC: 0.2511236011669613\n",
      "Epoch 0, Loss(train/val) 0.48942/0.48333. Took 0.16 sec\n",
      "Epoch 1, Loss(train/val) 0.46731/0.45171. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.43374/0.41968. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.40114/0.40897. Took 0.15 sec\n",
      "Epoch 4, Loss(train/val) 0.38587/0.38935. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.36759/0.36955. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.35954/0.36528. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.34365/0.32350. Took 0.17 sec\n",
      "Epoch 8, Loss(train/val) 0.33618/0.33996. Took 0.15 sec\n",
      "Epoch 9, Loss(train/val) 0.32212/0.31430. Took 0.17 sec\n",
      "Epoch 10, Loss(train/val) 0.31463/0.31531. Took 0.18 sec\n",
      "Epoch 11, Loss(train/val) 0.30715/0.31340. Took 0.15 sec\n",
      "Epoch 12, Loss(train/val) 0.29906/0.31463. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.29285/0.28889. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.28357/0.29129. Took 0.16 sec\n",
      "Epoch 15, Loss(train/val) 0.28037/0.31695. Took 0.16 sec\n",
      "Epoch 16, Loss(train/val) 0.28317/0.31638. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.27263/0.31959. Took 0.16 sec\n",
      "Epoch 18, Loss(train/val) 0.26667/0.32628. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.26270/0.33497. Took 0.16 sec\n",
      "Epoch 20, Loss(train/val) 0.25407/0.32963. Took 0.17 sec\n",
      "Epoch 21, Loss(train/val) 0.25290/0.29891. Took 0.17 sec\n",
      "Epoch 22, Loss(train/val) 0.24258/0.29883. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.24766/0.31107. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.24542/0.30870. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.23203/0.31311. Took 0.19 sec\n",
      "Epoch 26, Loss(train/val) 0.23233/0.33551. Took 0.16 sec\n",
      "Epoch 27, Loss(train/val) 0.24062/0.32188. Took 0.13 sec\n",
      "Epoch 28, Loss(train/val) 0.22207/0.33454. Took 0.13 sec\n",
      "Epoch 29, Loss(train/val) 0.22401/0.32554. Took 0.19 sec\n",
      "Epoch 30, Loss(train/val) 0.22772/0.35623. Took 0.21 sec\n",
      "Epoch 31, Loss(train/val) 0.21062/0.35332. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.20736/0.36285. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.21505/0.36032. Took 0.16 sec\n",
      "Epoch 34, Loss(train/val) 0.20836/0.35524. Took 0.19 sec\n",
      "Epoch 35, Loss(train/val) 0.19954/0.35510. Took 0.16 sec\n",
      "Epoch 36, Loss(train/val) 0.19726/0.34254. Took 0.19 sec\n",
      "Epoch 37, Loss(train/val) 0.20260/0.35167. Took 0.17 sec\n",
      "Epoch 38, Loss(train/val) 0.19622/0.34994. Took 0.19 sec\n",
      "Epoch 39, Loss(train/val) 0.19444/0.36342. Took 0.15 sec\n",
      "Epoch 40, Loss(train/val) 0.18212/0.35407. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.18782/0.36307. Took 0.18 sec\n",
      "Epoch 42, Loss(train/val) 0.18032/0.35708. Took 0.15 sec\n",
      "Epoch 43, Loss(train/val) 0.17826/0.36918. Took 0.15 sec\n",
      "Epoch 44, Loss(train/val) 0.18769/0.37991. Took 0.15 sec\n",
      "Epoch 45, Loss(train/val) 0.18113/0.36964. Took 0.15 sec\n",
      "Epoch 46, Loss(train/val) 0.16399/0.34599. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.16911/0.35641. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.18277/0.35823. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.16785/0.36150. Took 0.15 sec\n",
      "Epoch 50, Loss(train/val) 0.16303/0.36883. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.14945/0.37717. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.16311/0.39188. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.16025/0.36471. Took 0.15 sec\n",
      "Epoch 54, Loss(train/val) 0.16501/0.36690. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.15822/0.37234. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.15922/0.36800. Took 0.15 sec\n",
      "Epoch 57, Loss(train/val) 0.14795/0.37280. Took 0.15 sec\n",
      "Epoch 58, Loss(train/val) 0.14636/0.39496. Took 0.15 sec\n",
      "Epoch 59, Loss(train/val) 0.14417/0.39197. Took 0.15 sec\n",
      "Epoch 60, Loss(train/val) 0.13768/0.38866. Took 0.14 sec\n",
      "Epoch 61, Loss(train/val) 0.14793/0.39087. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.14552/0.36672. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.14762/0.36641. Took 0.15 sec\n",
      "Epoch 64, Loss(train/val) 0.14429/0.38662. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.14428/0.38536. Took 0.15 sec\n",
      "Epoch 66, Loss(train/val) 0.14276/0.39209. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) 0.13575/0.40098. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.13956/0.38579. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.14252/0.39109. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.13797/0.38952. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.14166/0.39845. Took 0.15 sec\n",
      "Epoch 72, Loss(train/val) 0.13525/0.40816. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.12741/0.39975. Took 0.16 sec\n",
      "Epoch 74, Loss(train/val) 0.13557/0.39290. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) 0.13279/0.40625. Took 0.15 sec\n",
      "Epoch 76, Loss(train/val) 0.13720/0.39414. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.12842/0.37517. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.13201/0.39787. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.12749/0.39743. Took 0.15 sec\n",
      "Epoch 80, Loss(train/val) 0.12585/0.39414. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.12486/0.39552. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.12524/0.38456. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.12080/0.38185. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.12505/0.39399. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.12654/0.36604. Took 0.15 sec\n",
      "Epoch 86, Loss(train/val) 0.11972/0.38624. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.11962/0.38705. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.11573/0.38252. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.11413/0.35883. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.11433/0.39299. Took 0.14 sec\n",
      "Epoch 91, Loss(train/val) 0.11707/0.36279. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.11492/0.36509. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.11688/0.37510. Took 0.15 sec\n",
      "Epoch 94, Loss(train/val) 0.12038/0.36234. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.11125/0.38290. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.11610/0.36105. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.11027/0.37135. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.11078/0.38959. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.10944/0.35908. Took 0.14 sec\n",
      "ACC: 0.65625, MCC: 0.3333333333333333\n",
      "Epoch 0, Loss(train/val) 0.49052/0.47351. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.46835/0.43120. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.43519/0.38713. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.40441/0.36395. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.38455/0.36131. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.37543/0.35087. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.35475/0.34091. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.34238/0.33908. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.31474/0.34445. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.32150/0.35058. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.29926/0.34023. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.29288/0.36170. Took 0.15 sec\n",
      "Epoch 12, Loss(train/val) 0.29455/0.34158. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.29010/0.34573. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.28567/0.31021. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.26926/0.34074. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.26672/0.33459. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.26084/0.34658. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.26643/0.34764. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.25698/0.33524. Took 0.16 sec\n",
      "Epoch 20, Loss(train/val) 0.25594/0.33451. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.24570/0.34267. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.24862/0.32930. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.23834/0.32827. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.24996/0.33814. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.24328/0.33333. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.23602/0.31995. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.24141/0.32380. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.23699/0.33661. Took 0.13 sec\n",
      "Epoch 29, Loss(train/val) 0.22910/0.32706. Took 0.13 sec\n",
      "Epoch 30, Loss(train/val) 0.22838/0.34192. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.22796/0.33294. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.23693/0.33541. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.23684/0.32869. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.23552/0.32879. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.22087/0.35737. Took 0.16 sec\n",
      "Epoch 36, Loss(train/val) 0.22392/0.33012. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.22048/0.33700. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.21344/0.35354. Took 0.15 sec\n",
      "Epoch 39, Loss(train/val) 0.22052/0.33991. Took 0.15 sec\n",
      "Epoch 40, Loss(train/val) 0.20568/0.32636. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.20813/0.33913. Took 0.16 sec\n",
      "Epoch 42, Loss(train/val) 0.20304/0.32778. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.20889/0.32833. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.19735/0.35267. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.20358/0.35972. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.19990/0.34449. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.19664/0.34529. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.20314/0.32629. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.19635/0.36823. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.19350/0.33350. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.19694/0.35125. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.19632/0.33190. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.18330/0.35353. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.18790/0.34519. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.17989/0.33697. Took 0.15 sec\n",
      "Epoch 56, Loss(train/val) 0.18995/0.31643. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.18142/0.31943. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.18533/0.31667. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.18163/0.33070. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.18117/0.31988. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.16597/0.36046. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.18438/0.32838. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.17808/0.35240. Took 0.15 sec\n",
      "Epoch 64, Loss(train/val) 0.17574/0.34724. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.17837/0.33465. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.17801/0.34558. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.16748/0.34054. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.17004/0.33256. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.16957/0.34274. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.16900/0.34423. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.16662/0.35434. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.16603/0.32931. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.16421/0.32669. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.16270/0.33319. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.15695/0.32006. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.16846/0.33023. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.15767/0.32016. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.16111/0.34717. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.15671/0.33652. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.16450/0.32975. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.15677/0.32031. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.15818/0.31440. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.15931/0.32684. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.16346/0.32560. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.15542/0.31476. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.15710/0.33825. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.15048/0.32138. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.15607/0.32156. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.15593/0.31754. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.14903/0.30423. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.15441/0.32356. Took 0.15 sec\n",
      "Epoch 92, Loss(train/val) 0.14931/0.32434. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.14877/0.29591. Took 0.15 sec\n",
      "Epoch 94, Loss(train/val) 0.14364/0.30772. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.14810/0.31427. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.14454/0.33988. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.15266/0.31711. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.15298/0.31458. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.15185/0.34273. Took 0.13 sec\n",
      "ACC: 0.71875, MCC: 0.4475057658924364\n",
      "Epoch 0, Loss(train/val) 0.48856/0.45520. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.45823/0.38250. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.41821/0.33551. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.39859/0.31433. Took 0.16 sec\n",
      "Epoch 4, Loss(train/val) 0.38645/0.29929. Took 0.16 sec\n",
      "Epoch 5, Loss(train/val) 0.37836/0.28586. Took 0.16 sec\n",
      "Epoch 6, Loss(train/val) 0.37231/0.27097. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.36803/0.25545. Took 0.16 sec\n",
      "Epoch 8, Loss(train/val) 0.35742/0.23826. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.35190/0.22555. Took 0.16 sec\n",
      "Epoch 10, Loss(train/val) 0.34505/0.22008. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.33602/0.23492. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.33796/0.21460. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.32163/0.21878. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.32026/0.21446. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.31253/0.21766. Took 0.16 sec\n",
      "Epoch 16, Loss(train/val) 0.30312/0.25610. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.28785/0.28868. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.28622/0.25294. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.28664/0.21556. Took 0.16 sec\n",
      "Epoch 20, Loss(train/val) 0.28338/0.29350. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.27616/0.25591. Took 0.16 sec\n",
      "Epoch 22, Loss(train/val) 0.26087/0.31904. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.26536/0.23364. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.26255/0.25651. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.26181/0.26556. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.24992/0.27715. Took 0.13 sec\n",
      "Epoch 27, Loss(train/val) 0.24728/0.34249. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.23973/0.30252. Took 0.13 sec\n",
      "Epoch 29, Loss(train/val) 0.25141/0.40524. Took 0.16 sec\n",
      "Epoch 30, Loss(train/val) 0.24958/0.27399. Took 0.13 sec\n",
      "Epoch 31, Loss(train/val) 0.24024/0.30531. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.23084/0.27329. Took 0.13 sec\n",
      "Epoch 33, Loss(train/val) 0.23340/0.29176. Took 0.16 sec\n",
      "Epoch 34, Loss(train/val) 0.22805/0.31861. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.22208/0.34582. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.23415/0.25876. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.23485/0.30082. Took 0.15 sec\n",
      "Epoch 38, Loss(train/val) 0.22331/0.32326. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.22007/0.29104. Took 0.17 sec\n",
      "Epoch 40, Loss(train/val) 0.21836/0.30083. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.21723/0.29889. Took 0.17 sec\n",
      "Epoch 42, Loss(train/val) 0.21062/0.33633. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.20786/0.28255. Took 0.15 sec\n",
      "Epoch 44, Loss(train/val) 0.21432/0.29480. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) 0.19687/0.29984. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.19803/0.35607. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.20241/0.30162. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.20069/0.36116. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.19818/0.35467. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.20744/0.34092. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.18225/0.33388. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.18492/0.35868. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.18181/0.35400. Took 0.15 sec\n",
      "Epoch 54, Loss(train/val) 0.17740/0.36851. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.18684/0.34536. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.18051/0.32894. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.17586/0.37813. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.17430/0.34382. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.18000/0.29933. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.17234/0.32964. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.16676/0.34973. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.17387/0.36117. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.17725/0.33830. Took 0.15 sec\n",
      "Epoch 64, Loss(train/val) 0.17817/0.34066. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.17057/0.33766. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.16763/0.35628. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.16079/0.36963. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.16915/0.33625. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.16335/0.37962. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.16228/0.38540. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.16323/0.30185. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.15200/0.35634. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.14703/0.36783. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.15551/0.34370. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.16001/0.36799. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.14928/0.34869. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.14991/0.35511. Took 0.15 sec\n",
      "Epoch 78, Loss(train/val) 0.14979/0.37212. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.14772/0.38680. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.14789/0.36672. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.14203/0.37405. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.15247/0.36258. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.14347/0.37078. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.14125/0.36028. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.14745/0.35910. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.14618/0.37253. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.14717/0.37192. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.13721/0.38687. Took 0.14 sec\n",
      "Epoch 89, Loss(train/val) 0.14212/0.35933. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.14611/0.36875. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.13701/0.35092. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.13662/0.35531. Took 0.15 sec\n",
      "Epoch 93, Loss(train/val) 0.13731/0.38283. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.13832/0.38519. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.12860/0.36173. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.13205/0.33497. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.13005/0.32364. Took 0.15 sec\n",
      "Epoch 98, Loss(train/val) 0.12602/0.38838. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.12632/0.37443. Took 0.14 sec\n",
      "ACC: 0.640625, MCC: 0.282494169258455\n",
      "Epoch 0, Loss(train/val) 0.49301/0.48291. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.46946/0.45020. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.42921/0.39887. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.39628/0.38705. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.37913/0.38226. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.36959/0.38192. Took 0.15 sec\n",
      "Epoch 6, Loss(train/val) 0.35837/0.38040. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.35074/0.37112. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.34394/0.37611. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.33521/0.36224. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.33274/0.37041. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.32968/0.37277. Took 0.15 sec\n",
      "Epoch 12, Loss(train/val) 0.34109/0.38230. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.35392/0.37544. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.32577/0.35357. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.31738/0.32816. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.31375/0.33928. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.30642/0.30954. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.30157/0.31544. Took 0.15 sec\n",
      "Epoch 19, Loss(train/val) 0.29370/0.31407. Took 0.15 sec\n",
      "Epoch 20, Loss(train/val) 0.29375/0.29748. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.29058/0.29970. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.28146/0.30958. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.28603/0.29808. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.27872/0.31087. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.28065/0.30951. Took 0.16 sec\n",
      "Epoch 26, Loss(train/val) 0.27370/0.32664. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.27339/0.32562. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.26350/0.34442. Took 0.13 sec\n",
      "Epoch 29, Loss(train/val) 0.26809/0.34018. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.26465/0.35334. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.26533/0.31510. Took 0.16 sec\n",
      "Epoch 32, Loss(train/val) 0.25410/0.31486. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.24878/0.31827. Took 0.16 sec\n",
      "Epoch 34, Loss(train/val) 0.24366/0.33088. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.24785/0.31377. Took 0.15 sec\n",
      "Epoch 36, Loss(train/val) 0.23658/0.30725. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.23353/0.31468. Took 0.15 sec\n",
      "Epoch 38, Loss(train/val) 0.23977/0.31461. Took 0.15 sec\n",
      "Epoch 39, Loss(train/val) 0.22903/0.32016. Took 0.16 sec\n",
      "Epoch 40, Loss(train/val) 0.23280/0.31971. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.23348/0.35472. Took 0.16 sec\n",
      "Epoch 42, Loss(train/val) 0.22209/0.31280. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.22870/0.31237. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.22661/0.31005. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.21502/0.33749. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.21621/0.33350. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.21080/0.32027. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.21254/0.29503. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.20002/0.31026. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.21517/0.31438. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.20754/0.30454. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.20602/0.29641. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) 0.20323/0.29849. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.19708/0.30530. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.19996/0.30916. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.19058/0.31439. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.20161/0.31436. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.19134/0.35958. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.19634/0.30626. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.19966/0.31195. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.19249/0.32182. Took 0.15 sec\n",
      "Epoch 62, Loss(train/val) 0.18975/0.35392. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.18965/0.36401. Took 0.13 sec\n",
      "Epoch 64, Loss(train/val) 0.19192/0.34448. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.18463/0.30704. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.17924/0.34044. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.18668/0.34300. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.18494/0.33926. Took 0.14 sec\n",
      "Epoch 69, Loss(train/val) 0.17508/0.32036. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.18178/0.31077. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.18149/0.32546. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.17421/0.32818. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.18479/0.32910. Took 0.15 sec\n",
      "Epoch 74, Loss(train/val) 0.17754/0.29811. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.16772/0.33792. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.18165/0.28920. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.16431/0.32689. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.16908/0.31330. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.16845/0.33744. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.17736/0.31248. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.17450/0.31241. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.17684/0.34736. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.18790/0.28964. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.16990/0.34105. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.16367/0.33615. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.16012/0.32788. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.16821/0.32966. Took 0.15 sec\n",
      "Epoch 88, Loss(train/val) 0.15906/0.33055. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.15545/0.33676. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.15980/0.32764. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.15913/0.33670. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.16435/0.29814. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.15629/0.31018. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.15431/0.30450. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.16024/0.29875. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.15520/0.35243. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.15677/0.31107. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.15005/0.35425. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.15442/0.32786. Took 0.14 sec\n",
      "ACC: 0.640625, MCC: 0.3522521434341141\n",
      "Epoch 0, Loss(train/val) 0.49059/0.48638. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.46609/0.46730. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.42514/0.42827. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.39409/0.39528. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.37093/0.38176. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.35319/0.38666. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.33937/0.34927. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.33584/0.36238. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.32675/0.33669. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.32047/0.35507. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.33430/0.29345. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.31743/0.35767. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.31988/0.32610. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.31140/0.33787. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.30899/0.35763. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.31448/0.35314. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.31872/0.36128. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.30668/0.33608. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.29718/0.33363. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.29877/0.35167. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.29362/0.34244. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.28298/0.35548. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.27868/0.41287. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.27926/0.39411. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.28405/0.31552. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.28256/0.51404. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.27291/0.34282. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.27524/0.37104. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.26111/0.33144. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.27103/0.47533. Took 0.16 sec\n",
      "Epoch 30, Loss(train/val) 0.27760/0.37075. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.26260/0.36944. Took 0.17 sec\n",
      "Epoch 32, Loss(train/val) 0.25462/0.43025. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.25764/0.39803. Took 0.17 sec\n",
      "Epoch 34, Loss(train/val) 0.26199/0.41583. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.25020/0.35246. Took 0.15 sec\n",
      "Epoch 36, Loss(train/val) 0.24330/0.43953. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.24345/0.43040. Took 0.16 sec\n",
      "Epoch 38, Loss(train/val) 0.24798/0.42092. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.24848/0.35552. Took 0.16 sec\n",
      "Epoch 40, Loss(train/val) 0.24471/0.35415. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.23968/0.32272. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.23715/0.40623. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.24310/0.44530. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.23169/0.38350. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.24056/0.43035. Took 0.15 sec\n",
      "Epoch 46, Loss(train/val) 0.23031/0.50393. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.23243/0.38472. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.22310/0.45823. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.22473/0.39541. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.22543/0.44414. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.22644/0.40347. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.23800/0.37209. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.22247/0.37735. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.22105/0.32323. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.22682/0.46043. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.22785/0.46687. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.21302/0.49967. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.22073/0.37364. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.21207/0.46006. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.21235/0.40455. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.21493/0.33559. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.21134/0.43852. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.21375/0.35217. Took 0.15 sec\n",
      "Epoch 64, Loss(train/val) 0.21132/0.37109. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.20450/0.34748. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.20381/0.33190. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.20282/0.37353. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.20087/0.36459. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.20404/0.35595. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.19671/0.38056. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.19868/0.33902. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.19586/0.33227. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.20086/0.32363. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.18368/0.32157. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.19199/0.32690. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.18988/0.33165. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.18994/0.33419. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.18356/0.32455. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.18903/0.32384. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.17731/0.34279. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.17877/0.32814. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.17807/0.31629. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.17749/0.32952. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.17328/0.34481. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.17971/0.35277. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.17495/0.32729. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.17911/0.30421. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.17237/0.30986. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.16715/0.34900. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.16449/0.32729. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.16367/0.32253. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.16572/0.34073. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.16364/0.30282. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.16555/0.31576. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.16363/0.34815. Took 0.15 sec\n",
      "Epoch 96, Loss(train/val) 0.16896/0.33155. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.16484/0.36087. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.16667/0.34099. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.16316/0.32943. Took 0.14 sec\n",
      "ACC: 0.65625, MCC: 0.314970394174356\n",
      "Epoch 0, Loss(train/val) 0.48906/0.47592. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.46371/0.44173. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.43055/0.41548. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.40095/0.39528. Took 0.15 sec\n",
      "Epoch 4, Loss(train/val) 0.38238/0.37132. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.36794/0.40932. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.35791/0.37473. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.33761/0.35693. Took 0.15 sec\n",
      "Epoch 8, Loss(train/val) 0.31985/0.31537. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.31307/0.32022. Took 0.15 sec\n",
      "Epoch 10, Loss(train/val) 0.29936/0.29285. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.29429/0.28905. Took 0.15 sec\n",
      "Epoch 12, Loss(train/val) 0.28598/0.28442. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.28259/0.29691. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.27266/0.30973. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.31012/0.35066. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.29960/0.30764. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.26898/0.27820. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.26144/0.29312. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.26153/0.30215. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.26124/0.29481. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.24860/0.29438. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.24661/0.29283. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.23599/0.28600. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.24141/0.29939. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.23806/0.29948. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.23692/0.28845. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.23134/0.27648. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.23472/0.27636. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.23129/0.27526. Took 0.16 sec\n",
      "Epoch 30, Loss(train/val) 0.21485/0.29501. Took 0.16 sec\n",
      "Epoch 31, Loss(train/val) 0.22381/0.29818. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.21957/0.28292. Took 0.16 sec\n",
      "Epoch 33, Loss(train/val) 0.21540/0.30477. Took 0.16 sec\n",
      "Epoch 34, Loss(train/val) 0.21089/0.29527. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.21236/0.30408. Took 0.16 sec\n",
      "Epoch 36, Loss(train/val) 0.21369/0.28313. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.20650/0.27912. Took 0.15 sec\n",
      "Epoch 38, Loss(train/val) 0.19984/0.27077. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.20126/0.27622. Took 0.16 sec\n",
      "Epoch 40, Loss(train/val) 0.20003/0.28405. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.20339/0.28183. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.20828/0.29644. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.20263/0.29479. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.20473/0.29118. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.19579/0.27531. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.19919/0.30342. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.18867/0.30203. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.18992/0.27546. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.18179/0.27945. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.18653/0.27901. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.18145/0.30240. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.17644/0.31091. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.17572/0.26564. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.17699/0.27358. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.17643/0.30829. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.17137/0.28624. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.17137/0.28000. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.16374/0.27983. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.16849/0.27598. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.16408/0.28007. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.16471/0.29068. Took 0.15 sec\n",
      "Epoch 62, Loss(train/val) 0.16654/0.27880. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.16681/0.32160. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.16563/0.29037. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.16249/0.28567. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.15743/0.28539. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.15362/0.30095. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.16109/0.28640. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.16223/0.28927. Took 0.15 sec\n",
      "Epoch 70, Loss(train/val) 0.14920/0.28868. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.16024/0.28431. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.15042/0.27626. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.14835/0.28481. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.15423/0.28906. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.14276/0.28671. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.14455/0.28897. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.14969/0.28608. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.14260/0.27717. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.14631/0.27983. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.14562/0.29873. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.14675/0.29041. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.13748/0.29311. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.14148/0.28872. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.13925/0.29364. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.13160/0.27814. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.13586/0.28330. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.14279/0.28313. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.13607/0.28422. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.13248/0.29886. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.13240/0.29322. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.13413/0.28509. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.12929/0.27953. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.13375/0.30124. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.12903/0.32375. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.12478/0.27502. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.12091/0.28189. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.12856/0.27210. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.12097/0.28859. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.12085/0.29184. Took 0.14 sec\n",
      "ACC: 0.640625, MCC: 0.26810248177031065\n",
      "Epoch 0, Loss(train/val) 0.48297/0.46299. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.45193/0.41901. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.41907/0.39541. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.39165/0.39342. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.37579/0.39457. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.36309/0.38937. Took 0.15 sec\n",
      "Epoch 6, Loss(train/val) 0.34866/0.38680. Took 0.15 sec\n",
      "Epoch 7, Loss(train/val) 0.33737/0.38548. Took 0.15 sec\n",
      "Epoch 8, Loss(train/val) 0.32436/0.37407. Took 0.15 sec\n",
      "Epoch 9, Loss(train/val) 0.32080/0.38217. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.30152/0.38532. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.29949/0.37598. Took 0.15 sec\n",
      "Epoch 12, Loss(train/val) 0.28942/0.36311. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.28836/0.37266. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.27687/0.37823. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.27159/0.40518. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.27860/0.39680. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.27148/0.40607. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.31128/0.40732. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.29807/0.39741. Took 0.16 sec\n",
      "Epoch 20, Loss(train/val) 0.29184/0.41244. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.26160/0.40224. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.25451/0.40753. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.24519/0.40456. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.24766/0.40790. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.24399/0.41245. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.24749/0.41719. Took 0.15 sec\n",
      "Epoch 27, Loss(train/val) 0.24429/0.41071. Took 0.16 sec\n",
      "Epoch 28, Loss(train/val) 0.23221/0.41275. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.23595/0.41810. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.22812/0.40538. Took 0.16 sec\n",
      "Epoch 31, Loss(train/val) 0.22814/0.39940. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.22537/0.40761. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.21459/0.40500. Took 0.17 sec\n",
      "Epoch 34, Loss(train/val) 0.20895/0.41698. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.21322/0.40790. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.20288/0.41516. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.20688/0.41755. Took 0.15 sec\n",
      "Epoch 38, Loss(train/val) 0.20249/0.42324. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.19775/0.40680. Took 0.15 sec\n",
      "Epoch 40, Loss(train/val) 0.20416/0.40940. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.18800/0.40548. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.18181/0.41431. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.18787/0.38887. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.20208/0.39367. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.19389/0.38791. Took 0.15 sec\n",
      "Epoch 46, Loss(train/val) 0.19013/0.35920. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.17285/0.36278. Took 0.15 sec\n",
      "Epoch 48, Loss(train/val) 0.19401/0.39107. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.19449/0.37033. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.17673/0.36946. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.18505/0.37383. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.17412/0.36580. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.17730/0.39809. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.17759/0.38262. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.17459/0.39166. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.16882/0.39069. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.16907/0.39171. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.16396/0.41571. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.16705/0.39709. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.16151/0.39572. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.15562/0.40039. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.16787/0.38046. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.15731/0.38716. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.15916/0.36819. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.16076/0.39182. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.14906/0.39789. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.14900/0.39797. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.15175/0.36085. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.14807/0.38007. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.14987/0.37367. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.13969/0.35656. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.14687/0.36765. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.14237/0.38059. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.14446/0.39970. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.13899/0.38599. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.14136/0.38583. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.13529/0.38627. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.13691/0.38979. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.13013/0.38500. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.13863/0.40226. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.14352/0.38178. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.13553/0.39795. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.13897/0.40047. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.12837/0.39761. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.12854/0.38864. Took 0.15 sec\n",
      "Epoch 86, Loss(train/val) 0.12278/0.40581. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.12764/0.36320. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.13344/0.38143. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.12365/0.40816. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.12869/0.39891. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.12476/0.38681. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.12966/0.39255. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.12935/0.39093. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.13101/0.39440. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.12413/0.39630. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.11436/0.40062. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.12011/0.40385. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.12502/0.39786. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.12086/0.39475. Took 0.14 sec\n",
      "ACC: 0.609375, MCC: 0.24343352255809222\n",
      "Epoch 0, Loss(train/val) 0.49238/0.49102. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.46430/0.47125. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.43259/0.45104. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.40314/0.43054. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.38217/0.41980. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.36532/0.41545. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.35521/0.41268. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.34602/0.40710. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.33934/0.39328. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.32962/0.39754. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.32127/0.42838. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.31676/0.40976. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.30522/0.40911. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.31842/0.40962. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.29829/0.40307. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.30209/0.39624. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.28598/0.41372. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.28696/0.40231. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.28244/0.40764. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.28198/0.41731. Took 0.15 sec\n",
      "Epoch 20, Loss(train/val) 0.28012/0.41510. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.27394/0.40823. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.27762/0.40744. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.26935/0.41619. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.26151/0.41225. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.26860/0.40435. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.25746/0.40729. Took 0.13 sec\n",
      "Epoch 27, Loss(train/val) 0.25395/0.41628. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.24755/0.39644. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.23819/0.40768. Took 0.13 sec\n",
      "Epoch 30, Loss(train/val) 0.24049/0.41113. Took 0.13 sec\n",
      "Epoch 31, Loss(train/val) 0.23717/0.40232. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.24178/0.41821. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.24491/0.39219. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.23378/0.41064. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.22812/0.40595. Took 0.16 sec\n",
      "Epoch 36, Loss(train/val) 0.22733/0.41050. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.21166/0.40427. Took 0.15 sec\n",
      "Epoch 38, Loss(train/val) 0.22064/0.39600. Took 0.15 sec\n",
      "Epoch 39, Loss(train/val) 0.21508/0.40173. Took 0.16 sec\n",
      "Epoch 40, Loss(train/val) 0.21233/0.36934. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.22229/0.38891. Took 0.16 sec\n",
      "Epoch 42, Loss(train/val) 0.21671/0.39200. Took 0.16 sec\n",
      "Epoch 43, Loss(train/val) 0.20943/0.39991. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.20815/0.38827. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.20825/0.39799. Took 0.15 sec\n",
      "Epoch 46, Loss(train/val) 0.20312/0.36391. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.19899/0.36192. Took 0.15 sec\n",
      "Epoch 48, Loss(train/val) 0.20438/0.39756. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.20013/0.40386. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.19276/0.40832. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.19545/0.42064. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.19763/0.38585. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.19992/0.36430. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.19879/0.37963. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.18598/0.36534. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.18267/0.34314. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.18205/0.34787. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.18168/0.35800. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.17999/0.32988. Took 0.15 sec\n",
      "Epoch 60, Loss(train/val) 0.18045/0.38384. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.17483/0.34079. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.17738/0.31934. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.18329/0.32560. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.17387/0.33427. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.16812/0.33306. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.16992/0.34932. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.16618/0.33090. Took 0.15 sec\n",
      "Epoch 68, Loss(train/val) 0.17155/0.32338. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.16535/0.35751. Took 0.15 sec\n",
      "Epoch 70, Loss(train/val) 0.15787/0.37487. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.15311/0.34690. Took 0.15 sec\n",
      "Epoch 72, Loss(train/val) 0.14811/0.36372. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.15598/0.36969. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.14763/0.34789. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.14663/0.32024. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.14111/0.35088. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.14694/0.35993. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.15027/0.37845. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.13826/0.37350. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.13272/0.33287. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.13651/0.37155. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.13765/0.35647. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) 0.13859/0.36219. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.13464/0.36593. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.13390/0.36982. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.13186/0.35012. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.13871/0.37485. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.12490/0.38355. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.12830/0.32444. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.13213/0.35324. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.12684/0.33564. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.12919/0.35090. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.12363/0.35547. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.12125/0.34200. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.12039/0.32517. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.12121/0.39343. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.12132/0.38272. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.11805/0.36902. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.11792/0.37051. Took 0.13 sec\n",
      "ACC: 0.75, MCC: 0.49265895172303803\n",
      "Epoch 0, Loss(train/val) 0.49244/0.47685. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.46176/0.42997. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.42667/0.37506. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.39100/0.33881. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.36687/0.32625. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.35141/0.31048. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.34890/0.31782. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.33981/0.31500. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.32292/0.31359. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.32207/0.31271. Took 0.15 sec\n",
      "Epoch 10, Loss(train/val) 0.31302/0.30665. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.30112/0.30969. Took 0.15 sec\n",
      "Epoch 12, Loss(train/val) 0.29598/0.30901. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.30617/0.25984. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.30897/0.31826. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.28702/0.29599. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.27325/0.30203. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.27697/0.31377. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.26871/0.30716. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.26026/0.28979. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.27462/0.29147. Took 0.15 sec\n",
      "Epoch 21, Loss(train/val) 0.27056/0.28313. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.27016/0.30894. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.25511/0.28209. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.25534/0.28762. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.26502/0.30722. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.25305/0.29510. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.23331/0.26978. Took 0.16 sec\n",
      "Epoch 28, Loss(train/val) 0.24730/0.29929. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.23641/0.27922. Took 0.16 sec\n",
      "Epoch 30, Loss(train/val) 0.23644/0.30100. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.24941/0.30218. Took 0.16 sec\n",
      "Epoch 32, Loss(train/val) 0.24582/0.31176. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.22930/0.28388. Took 0.17 sec\n",
      "Epoch 34, Loss(train/val) 0.22256/0.30535. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.22587/0.28535. Took 0.16 sec\n",
      "Epoch 36, Loss(train/val) 0.21702/0.30893. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.21710/0.28432. Took 0.16 sec\n",
      "Epoch 38, Loss(train/val) 0.21223/0.29990. Took 0.15 sec\n",
      "Epoch 39, Loss(train/val) 0.20833/0.27119. Took 0.17 sec\n",
      "Epoch 40, Loss(train/val) 0.21630/0.29982. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.19787/0.30597. Took 0.15 sec\n",
      "Epoch 42, Loss(train/val) 0.19943/0.30641. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.20024/0.31594. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.19962/0.30624. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.20165/0.29562. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.19545/0.28938. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.18693/0.29019. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.18743/0.30267. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.18969/0.28342. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.18437/0.29301. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.18287/0.28808. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.18413/0.27399. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.19127/0.30025. Took 0.15 sec\n",
      "Epoch 54, Loss(train/val) 0.18394/0.29779. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.17286/0.29619. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.17431/0.29853. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.16956/0.29754. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.17225/0.30253. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.17297/0.30084. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.15857/0.28481. Took 0.14 sec\n",
      "Epoch 61, Loss(train/val) 0.17200/0.30182. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.16155/0.28659. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.15994/0.30056. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.15695/0.29630. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.16008/0.29692. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.16349/0.30166. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) 0.15931/0.29679. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.16195/0.29351. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.15843/0.29373. Took 0.15 sec\n",
      "Epoch 70, Loss(train/val) 0.15026/0.29938. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.14930/0.30123. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.14551/0.29783. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.15318/0.30177. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.14781/0.29804. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.15231/0.29117. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.14348/0.30522. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.14173/0.30309. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.14425/0.31756. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.15030/0.32243. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.14610/0.31656. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.14332/0.33092. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.14196/0.30406. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.13793/0.31506. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.13250/0.29966. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.13785/0.29802. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.13740/0.31497. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.12440/0.29746. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.13782/0.30148. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.12861/0.30149. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.12987/0.30866. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.12744/0.29148. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.12870/0.30804. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.12957/0.29845. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.12570/0.30705. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.13048/0.31464. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.14722/0.30577. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.12451/0.29659. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.12501/0.29525. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.12889/0.30917. Took 0.14 sec\n",
      "ACC: 0.640625, MCC: 0.2805550872420795\n",
      "Epoch 0, Loss(train/val) 0.49139/0.49022. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.46497/0.46891. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.43170/0.42740. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.39921/0.41138. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.37928/0.39739. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.36112/0.38620. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.35005/0.37605. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.33769/0.37549. Took 0.15 sec\n",
      "Epoch 8, Loss(train/val) 0.32887/0.38494. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.32322/0.36417. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.31901/0.36003. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.31512/0.38041. Took 0.15 sec\n",
      "Epoch 12, Loss(train/val) 0.31208/0.35953. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.30486/0.35450. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.30252/0.36438. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.29727/0.34282. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.30982/0.36393. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.29687/0.33247. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.29477/0.34425. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.29026/0.35644. Took 0.16 sec\n",
      "Epoch 20, Loss(train/val) 0.28444/0.33333. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.27695/0.36118. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.28496/0.44984. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.29577/0.36593. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.27481/0.31316. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.27303/0.34406. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.25931/0.31318. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.25294/0.32538. Took 0.16 sec\n",
      "Epoch 28, Loss(train/val) 0.25967/0.29858. Took 0.13 sec\n",
      "Epoch 29, Loss(train/val) 0.25496/0.39092. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.26255/0.30161. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.25915/0.37915. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.26030/0.38931. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.26834/0.36601. Took 0.16 sec\n",
      "Epoch 34, Loss(train/val) 0.25352/0.34210. Took 0.16 sec\n",
      "Epoch 35, Loss(train/val) 0.24501/0.34311. Took 0.16 sec\n",
      "Epoch 36, Loss(train/val) 0.24802/0.28485. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.25702/0.32760. Took 0.16 sec\n",
      "Epoch 38, Loss(train/val) 0.24564/0.32855. Took 0.15 sec\n",
      "Epoch 39, Loss(train/val) 0.23744/0.28568. Took 0.16 sec\n",
      "Epoch 40, Loss(train/val) 0.24149/0.35600. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.23970/0.31621. Took 0.16 sec\n",
      "Epoch 42, Loss(train/val) 0.23359/0.30397. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.23528/0.30363. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.22087/0.28110. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.21736/0.27249. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.22739/0.32441. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.23114/0.33431. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.22124/0.29180. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.23817/0.39371. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.24821/0.33361. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.22710/0.27961. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.22159/0.28490. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.21893/0.32450. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.20676/0.28437. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.22177/0.28387. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.21502/0.28189. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.21266/0.26676. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.21024/0.30184. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.20563/0.27905. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.21104/0.27159. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.21118/0.29864. Took 0.15 sec\n",
      "Epoch 62, Loss(train/val) 0.21484/0.28820. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.21024/0.27000. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.20968/0.29392. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.19762/0.29536. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.19539/0.29358. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.20377/0.27910. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.20877/0.28589. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.20171/0.26461. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.19865/0.27905. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.19316/0.27057. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.20218/0.29248. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.18565/0.31831. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.18557/0.28136. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.18902/0.28181. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.18465/0.32696. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.18254/0.28734. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.18328/0.34427. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.19220/0.28484. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.18200/0.29204. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.18487/0.26685. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.18614/0.28623. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.18580/0.31475. Took 0.15 sec\n",
      "Epoch 84, Loss(train/val) 0.18290/0.33448. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.17549/0.27807. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.18009/0.28893. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.17119/0.30605. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.17459/0.29099. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.17215/0.31109. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.16597/0.31651. Took 0.15 sec\n",
      "Epoch 91, Loss(train/val) 0.16218/0.31552. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.16262/0.29287. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.16506/0.30564. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.16796/0.30322. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.15993/0.33052. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.15988/0.33499. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.16796/0.28868. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.16794/0.28969. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.16844/0.29401. Took 0.14 sec\n",
      "ACC: 0.578125, MCC: 0.16511700362686718\n",
      "Epoch 0, Loss(train/val) 0.49064/0.49484. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.46397/0.47777. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.42497/0.45794. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.38952/0.44352. Took 0.15 sec\n",
      "Epoch 4, Loss(train/val) 0.36552/0.42376. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.35240/0.42167. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.35088/0.41123. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.33776/0.37337. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.34461/0.38313. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.33341/0.37954. Took 0.15 sec\n",
      "Epoch 10, Loss(train/val) 0.32997/0.38414. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.32616/0.38293. Took 0.15 sec\n",
      "Epoch 12, Loss(train/val) 0.32941/0.42096. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.31801/0.37215. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.31156/0.36277. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.31193/0.38576. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.30458/0.38837. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.30681/0.40313. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.29717/0.40847. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.30367/0.41153. Took 0.15 sec\n",
      "Epoch 20, Loss(train/val) 0.27642/0.39902. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.28250/0.39716. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.27917/0.39195. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.26940/0.38615. Took 0.16 sec\n",
      "Epoch 24, Loss(train/val) 0.27355/0.40057. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.27441/0.39395. Took 0.16 sec\n",
      "Epoch 26, Loss(train/val) 0.26778/0.39671. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.25725/0.39777. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.25661/0.38315. Took 0.13 sec\n",
      "Epoch 29, Loss(train/val) 0.25048/0.40775. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.26468/0.39134. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.25214/0.42339. Took 0.16 sec\n",
      "Epoch 32, Loss(train/val) 0.24218/0.39787. Took 0.16 sec\n",
      "Epoch 33, Loss(train/val) 0.24712/0.40472. Took 0.16 sec\n",
      "Epoch 34, Loss(train/val) 0.24549/0.39580. Took 0.16 sec\n",
      "Epoch 35, Loss(train/val) 0.23884/0.40145. Took 0.15 sec\n",
      "Epoch 36, Loss(train/val) 0.23827/0.39067. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.22396/0.39548. Took 0.15 sec\n",
      "Epoch 38, Loss(train/val) 0.21436/0.39063. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.21746/0.39029. Took 0.16 sec\n",
      "Epoch 40, Loss(train/val) 0.22912/0.38590. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.20954/0.39360. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.21511/0.38576. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.21808/0.40103. Took 0.15 sec\n",
      "Epoch 44, Loss(train/val) 0.21259/0.37238. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.20272/0.38192. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.19332/0.38891. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.19697/0.38103. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.19798/0.37772. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.19530/0.38738. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.18861/0.37502. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.18342/0.37649. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.17533/0.35324. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.18938/0.38576. Took 0.15 sec\n",
      "Epoch 54, Loss(train/val) 0.18441/0.34983. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.17941/0.35984. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.16959/0.36672. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.17840/0.37129. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.17055/0.36278. Took 0.14 sec\n",
      "Epoch 59, Loss(train/val) 0.17015/0.36847. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.17249/0.36915. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.15874/0.36937. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.16535/0.35240. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.16983/0.35614. Took 0.15 sec\n",
      "Epoch 64, Loss(train/val) 0.16724/0.36354. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.16284/0.36491. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.16036/0.33884. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.15936/0.35549. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.15015/0.36145. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.15032/0.36107. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.15149/0.35341. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.15376/0.34894. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.15419/0.36120. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.14863/0.39173. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.14497/0.36931. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.14120/0.38214. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.15175/0.36673. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.14669/0.38983. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.13770/0.34754. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.14068/0.36643. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.14088/0.34777. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.13777/0.32821. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.14128/0.34037. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) 0.14470/0.38155. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.13443/0.35243. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.13177/0.35161. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.13515/0.37366. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.13702/0.36331. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.13493/0.37846. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.13907/0.35563. Took 0.15 sec\n",
      "Epoch 90, Loss(train/val) 0.13339/0.36748. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.13098/0.39552. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.12761/0.35524. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.12957/0.33850. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.12681/0.36148. Took 0.14 sec\n",
      "Epoch 95, Loss(train/val) 0.12719/0.35355. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.12682/0.34722. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.11962/0.35881. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.12649/0.36098. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.12442/0.37484. Took 0.14 sec\n",
      "ACC: 0.671875, MCC: 0.3228319989860621\n",
      "Epoch 0, Loss(train/val) 0.49369/0.49028. Took 0.16 sec\n",
      "Epoch 1, Loss(train/val) 0.47241/0.47579. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.43331/0.46724. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.39439/0.45199. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.37333/0.41011. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.35673/0.41856. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.35111/0.38245. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.34422/0.39413. Took 0.15 sec\n",
      "Epoch 8, Loss(train/val) 0.32732/0.41297. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.32453/0.39841. Took 0.15 sec\n",
      "Epoch 10, Loss(train/val) 0.31024/0.38515. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.30431/0.40150. Took 0.16 sec\n",
      "Epoch 12, Loss(train/val) 0.30677/0.38017. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.30370/0.40170. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.30243/0.40550. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.29260/0.39457. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.29261/0.40536. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.29241/0.33270. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.28176/0.40215. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.28207/0.35874. Took 0.16 sec\n",
      "Epoch 20, Loss(train/val) 0.26962/0.38550. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.26616/0.37938. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.26203/0.36257. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.25512/0.35306. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.24364/0.38125. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.25196/0.37759. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.23739/0.37589. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.24410/0.38382. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.23300/0.37365. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.22603/0.36644. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.24054/0.38586. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.22568/0.35768. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.22984/0.37773. Took 0.16 sec\n",
      "Epoch 33, Loss(train/val) 0.22158/0.38646. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.22625/0.35367. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.21949/0.38450. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.23141/0.39969. Took 0.16 sec\n",
      "Epoch 37, Loss(train/val) 0.21399/0.37506. Took 0.16 sec\n",
      "Epoch 38, Loss(train/val) 0.21688/0.41843. Took 0.16 sec\n",
      "Epoch 39, Loss(train/val) 0.21438/0.36960. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.21821/0.38506. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.21316/0.39417. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.20436/0.39503. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.20734/0.43733. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.19987/0.38395. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.20488/0.39708. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.18787/0.40255. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.20082/0.41490. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.19722/0.41001. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.19198/0.36804. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.19694/0.37898. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.19838/0.37182. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.19162/0.37063. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.19029/0.35523. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.18087/0.34876. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.19506/0.35002. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.18898/0.37898. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.18192/0.35273. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.18020/0.38947. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.18037/0.36040. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.18086/0.32740. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.17911/0.36300. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.18165/0.39202. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.17250/0.39378. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.16963/0.34625. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.16257/0.34787. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.16971/0.34051. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.16426/0.33486. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.16424/0.36773. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.17602/0.32737. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.15812/0.38470. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.15927/0.33453. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.16461/0.35287. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.16784/0.31256. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.14974/0.36699. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.16641/0.35712. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.15841/0.33185. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.15721/0.33376. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.14970/0.33903. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.15674/0.29216. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.15065/0.30624. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.16118/0.35142. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.15260/0.29385. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.15077/0.31354. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.14663/0.30265. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.13747/0.30614. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.14774/0.28446. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.15142/0.32012. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.14335/0.35871. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.14674/0.32312. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.14160/0.30254. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.14816/0.33465. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.14213/0.32432. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.14983/0.32102. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.14061/0.30945. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.13728/0.29354. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.14530/0.34554. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.13472/0.30602. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.13724/0.30316. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.13606/0.31930. Took 0.14 sec\n",
      "ACC: 0.59375, MCC: 0.24019223070763068\n",
      "Epoch 0, Loss(train/val) 0.49281/0.48704. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.46826/0.46417. Took 0.14 sec\n",
      "Epoch 2, Loss(train/val) 0.43553/0.43052. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.41146/0.41198. Took 0.17 sec\n",
      "Epoch 4, Loss(train/val) 0.39691/0.40350. Took 0.19 sec\n",
      "Epoch 5, Loss(train/val) 0.38292/0.34453. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.37102/0.34277. Took 0.15 sec\n",
      "Epoch 7, Loss(train/val) 0.35773/0.33877. Took 0.15 sec\n",
      "Epoch 8, Loss(train/val) 0.35985/0.39722. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.34243/0.39899. Took 0.17 sec\n",
      "Epoch 10, Loss(train/val) 0.33417/0.39948. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.32652/0.39534. Took 0.15 sec\n",
      "Epoch 12, Loss(train/val) 0.31395/0.39028. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.31401/0.45875. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.30111/0.42318. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.29149/0.46254. Took 0.16 sec\n",
      "Epoch 16, Loss(train/val) 0.29326/0.42998. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.29671/0.40260. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.29318/0.42224. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.28018/0.40861. Took 0.15 sec\n",
      "Epoch 20, Loss(train/val) 0.27991/0.41167. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.27045/0.40569. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.27098/0.42814. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.25792/0.39112. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.26791/0.42935. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.26237/0.40606. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.25094/0.39162. Took 0.13 sec\n",
      "Epoch 27, Loss(train/val) 0.25855/0.41074. Took 0.16 sec\n",
      "Epoch 28, Loss(train/val) 0.24611/0.40789. Took 0.13 sec\n",
      "Epoch 29, Loss(train/val) 0.24829/0.40386. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.23764/0.41565. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.24313/0.41351. Took 0.16 sec\n",
      "Epoch 32, Loss(train/val) 0.23474/0.41035. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.23717/0.39710. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.23911/0.43946. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.23117/0.42851. Took 0.16 sec\n",
      "Epoch 36, Loss(train/val) 0.22686/0.41930. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.23012/0.43981. Took 0.16 sec\n",
      "Epoch 38, Loss(train/val) 0.22486/0.44663. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.21882/0.42785. Took 0.16 sec\n",
      "Epoch 40, Loss(train/val) 0.21732/0.43675. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.21772/0.43626. Took 0.15 sec\n",
      "Epoch 42, Loss(train/val) 0.22416/0.44199. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.22919/0.44702. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.21770/0.43460. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.21460/0.43792. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.22486/0.42829. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.20861/0.43594. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.21547/0.43381. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.19798/0.43855. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.20271/0.41460. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.20787/0.43168. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.20995/0.43173. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.19321/0.42394. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.20877/0.41753. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.21063/0.43263. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.20204/0.41646. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.21352/0.41469. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.21660/0.41516. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.19898/0.42019. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.18402/0.41930. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.18338/0.40910. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.19097/0.41267. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.18838/0.41512. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.18853/0.43135. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.19244/0.43573. Took 0.15 sec\n",
      "Epoch 66, Loss(train/val) 0.17598/0.44495. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.18049/0.42123. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.16917/0.42510. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.18575/0.43244. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.17255/0.44171. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.18175/0.42104. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.17441/0.42717. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.17530/0.42177. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.17213/0.41774. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.17621/0.41884. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.17260/0.39851. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.17331/0.42146. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.17344/0.40743. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.17200/0.42358. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.17501/0.40298. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.17123/0.41717. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.16640/0.39482. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.16344/0.42472. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.16713/0.41686. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.14822/0.41947. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.16053/0.41576. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.15952/0.42740. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.15820/0.42645. Took 0.14 sec\n",
      "Epoch 89, Loss(train/val) 0.15512/0.42708. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.15790/0.42036. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.15506/0.42536. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.15059/0.43166. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.15101/0.40671. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.15151/0.43006. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.15227/0.41952. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.15635/0.43728. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.15931/0.41614. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.14815/0.42520. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.15405/0.43235. Took 0.15 sec\n",
      "ACC: 0.65625, MCC: 0.30980392156862746\n",
      "Epoch 0, Loss(train/val) 0.48965/0.47989. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.46621/0.45271. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.43920/0.42027. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.40439/0.38873. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.37687/0.36051. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.36554/0.33633. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.35018/0.32441. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.33629/0.38771. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.33624/0.37953. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.31233/0.42254. Took 0.15 sec\n",
      "Epoch 10, Loss(train/val) 0.31442/0.38284. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.29946/0.39762. Took 0.15 sec\n",
      "Epoch 12, Loss(train/val) 0.30954/0.39811. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.29508/0.38677. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.28228/0.41726. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.27426/0.39431. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.27973/0.31738. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.29837/0.32205. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.28328/0.39705. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.28759/0.35944. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.26832/0.35107. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.26714/0.37131. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.27172/0.32334. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.26049/0.35698. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.26160/0.36768. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.26967/0.28304. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.26340/0.31949. Took 0.13 sec\n",
      "Epoch 27, Loss(train/val) 0.24921/0.29362. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.25815/0.27540. Took 0.13 sec\n",
      "Epoch 29, Loss(train/val) 0.25925/0.29218. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.24971/0.28898. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.25385/0.31422. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.23940/0.33394. Took 0.16 sec\n",
      "Epoch 33, Loss(train/val) 0.23847/0.32934. Took 0.16 sec\n",
      "Epoch 34, Loss(train/val) 0.23590/0.34412. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.24336/0.35958. Took 0.15 sec\n",
      "Epoch 36, Loss(train/val) 0.23257/0.33448. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.23841/0.35644. Took 0.16 sec\n",
      "Epoch 38, Loss(train/val) 0.22604/0.38122. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.22280/0.36254. Took 0.16 sec\n",
      "Epoch 40, Loss(train/val) 0.22116/0.32733. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.22976/0.33762. Took 0.16 sec\n",
      "Epoch 42, Loss(train/val) 0.23308/0.34820. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.22205/0.33598. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.22369/0.37206. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.22085/0.35877. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.20501/0.34751. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.22356/0.31308. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.21042/0.34002. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.21199/0.30515. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.20473/0.29730. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.20443/0.30998. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.20223/0.31255. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.21300/0.29548. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.20505/0.31135. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.20055/0.36039. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.20590/0.35809. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.19708/0.34969. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.19353/0.35535. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.20555/0.34025. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.20140/0.37506. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.20663/0.36994. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.19596/0.35677. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.19762/0.40529. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.19532/0.40141. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.18561/0.38350. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.19024/0.36953. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.18143/0.36839. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.18834/0.35938. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.18814/0.34590. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.18776/0.38479. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.18354/0.37218. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.18001/0.35669. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.18304/0.44473. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.17846/0.43010. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.17278/0.42059. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.18432/0.40126. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.18363/0.44710. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.17977/0.43105. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.17396/0.39272. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.17225/0.37568. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.17829/0.37219. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.17062/0.36198. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.17279/0.35374. Took 0.15 sec\n",
      "Epoch 84, Loss(train/val) 0.17301/0.35585. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.16418/0.36609. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.16651/0.39490. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.17722/0.33428. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.17648/0.38166. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.16158/0.33167. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.16967/0.33257. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.15870/0.30983. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.16199/0.33853. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.15859/0.33564. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.16292/0.32958. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.15718/0.36295. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.16672/0.35089. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.15700/0.30500. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.15199/0.32069. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.15373/0.38989. Took 0.14 sec\n",
      "ACC: 0.640625, MCC: 0.3747838900064599\n",
      "Epoch 0, Loss(train/val) 0.49457/0.50776. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.47443/0.52195. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.44913/0.50336. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.42153/0.45815. Took 0.15 sec\n",
      "Epoch 4, Loss(train/val) 0.40186/0.43641. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.38803/0.42266. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.37495/0.41313. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.35850/0.38413. Took 0.15 sec\n",
      "Epoch 8, Loss(train/val) 0.34616/0.37689. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.33582/0.34398. Took 0.15 sec\n",
      "Epoch 10, Loss(train/val) 0.31986/0.33027. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.31335/0.31577. Took 0.15 sec\n",
      "Epoch 12, Loss(train/val) 0.30899/0.36228. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.30039/0.32053. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.30437/0.35422. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.29060/0.33176. Took 0.16 sec\n",
      "Epoch 16, Loss(train/val) 0.29464/0.30900. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.28539/0.31385. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.29110/0.35209. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.29039/0.32287. Took 0.15 sec\n",
      "Epoch 20, Loss(train/val) 0.26713/0.32261. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.27513/0.31253. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.26181/0.32222. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.26999/0.31585. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.25632/0.33094. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.26207/0.32308. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.25484/0.33014. Took 0.15 sec\n",
      "Epoch 27, Loss(train/val) 0.25019/0.32760. Took 0.16 sec\n",
      "Epoch 28, Loss(train/val) 0.24071/0.33009. Took 0.16 sec\n",
      "Epoch 29, Loss(train/val) 0.24337/0.34330. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.24638/0.30787. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.23979/0.32231. Took 0.17 sec\n",
      "Epoch 32, Loss(train/val) 0.24200/0.29866. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.23298/0.31119. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.24744/0.31458. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.23742/0.32823. Took 0.15 sec\n",
      "Epoch 36, Loss(train/val) 0.23249/0.34559. Took 0.13 sec\n",
      "Epoch 37, Loss(train/val) 0.24276/0.30696. Took 0.15 sec\n",
      "Epoch 38, Loss(train/val) 0.23378/0.32136. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.22545/0.32510. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.22207/0.32324. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.22379/0.30082. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.23363/0.34523. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.23018/0.32592. Took 0.15 sec\n",
      "Epoch 44, Loss(train/val) 0.22460/0.32759. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.21379/0.32756. Took 0.15 sec\n",
      "Epoch 46, Loss(train/val) 0.22922/0.33221. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.24248/0.34546. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.21921/0.33125. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.23339/0.29095. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.21223/0.33182. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.21997/0.29922. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.21566/0.31360. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.20635/0.35281. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.20473/0.31007. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.20034/0.31955. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.21123/0.31451. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.19727/0.28603. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.20276/0.32427. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.20465/0.30636. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.20394/0.30196. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.19903/0.30042. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.19841/0.31920. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.20229/0.30875. Took 0.15 sec\n",
      "Epoch 64, Loss(train/val) 0.19311/0.34826. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.19833/0.36320. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.18939/0.34915. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.19272/0.32464. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.19874/0.30274. Took 0.14 sec\n",
      "Epoch 69, Loss(train/val) 0.18695/0.32131. Took 0.15 sec\n",
      "Epoch 70, Loss(train/val) 0.18551/0.28675. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.19327/0.29473. Took 0.15 sec\n",
      "Epoch 72, Loss(train/val) 0.19964/0.26982. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.17961/0.33805. Took 0.15 sec\n",
      "Epoch 74, Loss(train/val) 0.19166/0.30386. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.18488/0.32673. Took 0.16 sec\n",
      "Epoch 76, Loss(train/val) 0.18585/0.30897. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.17180/0.32237. Took 0.17 sec\n",
      "Epoch 78, Loss(train/val) 0.17615/0.32452. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.17724/0.31710. Took 0.15 sec\n",
      "Epoch 80, Loss(train/val) 0.18898/0.33569. Took 0.15 sec\n",
      "Epoch 81, Loss(train/val) 0.17451/0.30977. Took 0.17 sec\n",
      "Epoch 82, Loss(train/val) 0.17976/0.31325. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) 0.17112/0.33460. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.16846/0.33716. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.16746/0.31610. Took 0.17 sec\n",
      "Epoch 86, Loss(train/val) 0.17070/0.31404. Took 0.16 sec\n",
      "Epoch 87, Loss(train/val) 0.16822/0.35589. Took 0.15 sec\n",
      "Epoch 88, Loss(train/val) 0.18145/0.30889. Took 0.14 sec\n",
      "Epoch 89, Loss(train/val) 0.16818/0.33753. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.17692/0.33509. Took 0.14 sec\n",
      "Epoch 91, Loss(train/val) 0.16575/0.34784. Took 0.15 sec\n",
      "Epoch 92, Loss(train/val) 0.16502/0.34175. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.15632/0.34316. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.16732/0.34352. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.15421/0.32271. Took 0.17 sec\n",
      "Epoch 96, Loss(train/val) 0.16697/0.34242. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.15311/0.33207. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.16254/0.28709. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.16008/0.34657. Took 0.15 sec\n",
      "ACC: 0.71875, MCC: 0.44810278287677535\n",
      "Epoch 0, Loss(train/val) 0.49250/0.48712. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.47284/0.47057. Took 0.15 sec\n",
      "Epoch 2, Loss(train/val) 0.44562/0.44893. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.41232/0.43028. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.38498/0.41047. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.36520/0.38447. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.35194/0.38545. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.33728/0.38836. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.33166/0.36585. Took 0.17 sec\n",
      "Epoch 9, Loss(train/val) 0.31938/0.38912. Took 0.17 sec\n",
      "Epoch 10, Loss(train/val) 0.31256/0.33051. Took 0.17 sec\n",
      "Epoch 11, Loss(train/val) 0.30727/0.36494. Took 0.16 sec\n",
      "Epoch 12, Loss(train/val) 0.30272/0.32421. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.29709/0.33954. Took 0.18 sec\n",
      "Epoch 14, Loss(train/val) 0.29327/0.35012. Took 0.16 sec\n",
      "Epoch 15, Loss(train/val) 0.28307/0.34010. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.28387/0.33278. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.28524/0.27421. Took 0.17 sec\n",
      "Epoch 18, Loss(train/val) 0.27815/0.34857. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.28464/0.27844. Took 0.15 sec\n",
      "Epoch 20, Loss(train/val) 0.28616/0.33052. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.28871/0.33241. Took 0.17 sec\n",
      "Epoch 22, Loss(train/val) 0.29694/0.29231. Took 0.16 sec\n",
      "Epoch 23, Loss(train/val) 0.26724/0.24992. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.27228/0.32062. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.26854/0.30801. Took 0.17 sec\n",
      "Epoch 26, Loss(train/val) 0.26343/0.32606. Took 0.15 sec\n",
      "Epoch 27, Loss(train/val) 0.26448/0.28467. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.26405/0.32943. Took 0.16 sec\n",
      "Epoch 29, Loss(train/val) 0.26415/0.30138. Took 0.19 sec\n",
      "Epoch 30, Loss(train/val) 0.26990/0.32073. Took 0.17 sec\n",
      "Epoch 31, Loss(train/val) 0.25073/0.32152. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.24666/0.33473. Took 0.16 sec\n",
      "Epoch 33, Loss(train/val) 0.25341/0.33081. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.24293/0.29130. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.23754/0.36960. Took 0.17 sec\n",
      "Epoch 36, Loss(train/val) 0.24626/0.31486. Took 0.19 sec\n",
      "Epoch 37, Loss(train/val) 0.23815/0.31578. Took 0.16 sec\n",
      "Epoch 38, Loss(train/val) 0.23656/0.29426. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.23495/0.33615. Took 0.17 sec\n",
      "Epoch 40, Loss(train/val) 0.23903/0.31974. Took 0.15 sec\n",
      "Epoch 41, Loss(train/val) 0.23769/0.29848. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.23707/0.28196. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.22536/0.31046. Took 0.16 sec\n",
      "Epoch 44, Loss(train/val) 0.23411/0.26982. Took 0.15 sec\n",
      "Epoch 45, Loss(train/val) 0.21823/0.25667. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.22559/0.30920. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.23213/0.27244. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.22639/0.27907. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.22608/0.29721. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.22287/0.26003. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.22356/0.28880. Took 0.15 sec\n",
      "Epoch 52, Loss(train/val) 0.21761/0.29503. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.21987/0.27428. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.21952/0.29740. Took 0.15 sec\n",
      "Epoch 55, Loss(train/val) 0.21886/0.29998. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.20908/0.28597. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.21662/0.32962. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.21284/0.29214. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.21045/0.31332. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.21591/0.30378. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.20300/0.29848. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.20534/0.29726. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.20568/0.30603. Took 0.15 sec\n",
      "Epoch 64, Loss(train/val) 0.21027/0.30934. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.20607/0.34648. Took 0.15 sec\n",
      "Epoch 66, Loss(train/val) 0.20843/0.32465. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.19942/0.33078. Took 0.16 sec\n",
      "Epoch 68, Loss(train/val) 0.20570/0.28540. Took 0.14 sec\n",
      "Epoch 69, Loss(train/val) 0.20917/0.27911. Took 0.15 sec\n",
      "Epoch 70, Loss(train/val) 0.21028/0.29850. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.20120/0.32058. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.19866/0.31417. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.19347/0.31334. Took 0.15 sec\n",
      "Epoch 74, Loss(train/val) 0.19384/0.27845. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.19890/0.32972. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.19353/0.33131. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.19538/0.33852. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.19745/0.30347. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.20485/0.28915. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.18329/0.30118. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.19067/0.32058. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.19219/0.29123. Took 0.14 sec\n",
      "Epoch 83, Loss(train/val) 0.18017/0.27978. Took 0.15 sec\n",
      "Epoch 84, Loss(train/val) 0.18801/0.29830. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.18477/0.30381. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.18669/0.28648. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.17292/0.28268. Took 0.15 sec\n",
      "Epoch 88, Loss(train/val) 0.17618/0.30742. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.17901/0.25310. Took 0.15 sec\n",
      "Epoch 90, Loss(train/val) 0.17898/0.27026. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.17330/0.27974. Took 0.15 sec\n",
      "Epoch 92, Loss(train/val) 0.17894/0.32618. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.17563/0.31295. Took 0.15 sec\n",
      "Epoch 94, Loss(train/val) 0.17143/0.26190. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.17768/0.33027. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.17956/0.30810. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.17360/0.31660. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.17482/0.27515. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.18239/0.31232. Took 0.14 sec\n",
      "ACC: 0.75, MCC: 0.49206349206349204\n",
      "Epoch 0, Loss(train/val) 0.49232/0.48539. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.47133/0.44739. Took 0.15 sec\n",
      "Epoch 2, Loss(train/val) 0.44237/0.37560. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.41677/0.31573. Took 0.15 sec\n",
      "Epoch 4, Loss(train/val) 0.39653/0.29392. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.38164/0.27372. Took 0.15 sec\n",
      "Epoch 6, Loss(train/val) 0.35860/0.27087. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.34179/0.30505. Took 0.15 sec\n",
      "Epoch 8, Loss(train/val) 0.32328/0.33548. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.31034/0.42581. Took 0.18 sec\n",
      "Epoch 10, Loss(train/val) 0.31254/0.38080. Took 0.17 sec\n",
      "Epoch 11, Loss(train/val) 0.30207/0.39581. Took 0.16 sec\n",
      "Epoch 12, Loss(train/val) 0.28469/0.30158. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.31350/0.36353. Took 0.16 sec\n",
      "Epoch 14, Loss(train/val) 0.28594/0.35513. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.27664/0.35751. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.27615/0.33513. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.27671/0.33277. Took 0.16 sec\n",
      "Epoch 18, Loss(train/val) 0.27221/0.34916. Took 0.16 sec\n",
      "Epoch 19, Loss(train/val) 0.26433/0.38459. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.27204/0.41281. Took 0.15 sec\n",
      "Epoch 21, Loss(train/val) 0.27345/0.40571. Took 0.16 sec\n",
      "Epoch 22, Loss(train/val) 0.26164/0.37797. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.26232/0.38899. Took 0.17 sec\n",
      "Epoch 24, Loss(train/val) 0.25536/0.38763. Took 0.16 sec\n",
      "Epoch 25, Loss(train/val) 0.25775/0.41640. Took 0.16 sec\n",
      "Epoch 26, Loss(train/val) 0.25078/0.41053. Took 0.15 sec\n",
      "Epoch 27, Loss(train/val) 0.27095/0.37809. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.25598/0.36603. Took 0.16 sec\n",
      "Epoch 29, Loss(train/val) 0.24934/0.39211. Took 0.21 sec\n",
      "Epoch 30, Loss(train/val) 0.25964/0.36152. Took 0.21 sec\n",
      "Epoch 31, Loss(train/val) 0.23917/0.39608. Took 0.22 sec\n",
      "Epoch 32, Loss(train/val) 0.24302/0.37978. Took 0.24 sec\n",
      "Epoch 33, Loss(train/val) 0.24098/0.39507. Took 0.24 sec\n",
      "Epoch 34, Loss(train/val) 0.25083/0.39931. Took 0.19 sec\n",
      "Epoch 35, Loss(train/val) 0.24800/0.39027. Took 0.17 sec\n",
      "Epoch 36, Loss(train/val) 0.23898/0.37172. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.23306/0.32790. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.22988/0.37979. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.23721/0.37918. Took 0.16 sec\n",
      "Epoch 40, Loss(train/val) 0.23292/0.36057. Took 0.16 sec\n",
      "Epoch 41, Loss(train/val) 0.22688/0.34590. Took 0.13 sec\n",
      "Epoch 42, Loss(train/val) 0.21450/0.37110. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.23756/0.35384. Took 0.16 sec\n",
      "Epoch 44, Loss(train/val) 0.22971/0.31847. Took 0.17 sec\n",
      "Epoch 45, Loss(train/val) 0.21928/0.36915. Took 0.15 sec\n",
      "Epoch 46, Loss(train/val) 0.21569/0.37009. Took 0.16 sec\n",
      "Epoch 47, Loss(train/val) 0.22338/0.38210. Took 0.17 sec\n",
      "Epoch 48, Loss(train/val) 0.21718/0.33782. Took 0.15 sec\n",
      "Epoch 49, Loss(train/val) 0.21855/0.37385. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.21788/0.36585. Took 0.15 sec\n",
      "Epoch 51, Loss(train/val) 0.21410/0.34264. Took 0.16 sec\n",
      "Epoch 52, Loss(train/val) 0.21242/0.35910. Took 0.17 sec\n",
      "Epoch 53, Loss(train/val) 0.20178/0.32287. Took 0.15 sec\n",
      "Epoch 54, Loss(train/val) 0.21551/0.36708. Took 0.15 sec\n",
      "Epoch 55, Loss(train/val) 0.20257/0.33650. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.21207/0.35824. Took 0.15 sec\n",
      "Epoch 57, Loss(train/val) 0.20263/0.34132. Took 0.16 sec\n",
      "Epoch 58, Loss(train/val) 0.20429/0.37705. Took 0.15 sec\n",
      "Epoch 59, Loss(train/val) 0.20570/0.36044. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.20418/0.33372. Took 0.16 sec\n",
      "Epoch 61, Loss(train/val) 0.19716/0.35849. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.19540/0.33739. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.19195/0.35918. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.19203/0.35778. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.19483/0.35450. Took 0.15 sec\n",
      "Epoch 66, Loss(train/val) 0.21324/0.37154. Took 0.15 sec\n",
      "Epoch 67, Loss(train/val) 0.19405/0.36858. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.19493/0.36997. Took 0.14 sec\n",
      "Epoch 69, Loss(train/val) 0.19770/0.36774. Took 0.15 sec\n",
      "Epoch 70, Loss(train/val) 0.19208/0.36991. Took 0.15 sec\n",
      "Epoch 71, Loss(train/val) 0.18360/0.40425. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.19013/0.36071. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.18232/0.37398. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.18353/0.37114. Took 0.15 sec\n",
      "Epoch 75, Loss(train/val) 0.18230/0.38042. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.18477/0.36718. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.17896/0.34913. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.18127/0.38373. Took 0.14 sec\n",
      "Epoch 79, Loss(train/val) 0.19145/0.34805. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.19456/0.36551. Took 0.14 sec\n",
      "Epoch 81, Loss(train/val) 0.18351/0.36642. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.17413/0.36930. Took 0.15 sec\n",
      "Epoch 83, Loss(train/val) 0.17465/0.37400. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.17921/0.40094. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.18455/0.37372. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.19066/0.39197. Took 0.15 sec\n",
      "Epoch 87, Loss(train/val) 0.20954/0.35768. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.18882/0.38897. Took 0.15 sec\n",
      "Epoch 89, Loss(train/val) 0.18191/0.40416. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.17767/0.40681. Took 0.14 sec\n",
      "Epoch 91, Loss(train/val) 0.17601/0.38536. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.17926/0.38831. Took 0.15 sec\n",
      "Epoch 93, Loss(train/val) 0.17147/0.39293. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.17011/0.36744. Took 0.15 sec\n",
      "Epoch 95, Loss(train/val) 0.17215/0.40384. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.18285/0.39364. Took 0.15 sec\n",
      "Epoch 97, Loss(train/val) 0.17848/0.38020. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.18087/0.41493. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.18054/0.39607. Took 0.13 sec\n",
      "ACC: 0.640625, MCC: 0.20339007194925068\n",
      "Epoch 0, Loss(train/val) 0.49532/0.46557. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.47862/0.42654. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.45141/0.39512. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.41892/0.38295. Took 0.15 sec\n",
      "Epoch 4, Loss(train/val) 0.39534/0.38165. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.37791/0.38580. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.36641/0.36942. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.34917/0.37765. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.34450/0.34219. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.32324/0.37615. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.31836/0.37225. Took 0.15 sec\n",
      "Epoch 11, Loss(train/val) 0.33050/0.30474. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.35517/0.36257. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.31756/0.37595. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.31782/0.38332. Took 0.15 sec\n",
      "Epoch 15, Loss(train/val) 0.29647/0.29304. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.29923/0.32324. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.28457/0.33934. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.28158/0.33389. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.28598/0.32254. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.28432/0.30979. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.28355/0.32667. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.27297/0.30158. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.27367/0.29679. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.27184/0.30255. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.25604/0.30734. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.26762/0.29200. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.25452/0.29351. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.25635/0.29354. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.26104/0.29379. Took 0.16 sec\n",
      "Epoch 30, Loss(train/val) 0.24835/0.29859. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.25525/0.30146. Took 0.16 sec\n",
      "Epoch 32, Loss(train/val) 0.23985/0.29432. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.24767/0.30162. Took 0.17 sec\n",
      "Epoch 34, Loss(train/val) 0.24093/0.28376. Took 0.16 sec\n",
      "Epoch 35, Loss(train/val) 0.24567/0.27336. Took 0.15 sec\n",
      "Epoch 36, Loss(train/val) 0.23198/0.28963. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.24282/0.28458. Took 0.16 sec\n",
      "Epoch 38, Loss(train/val) 0.23697/0.30972. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.24066/0.29856. Took 0.16 sec\n",
      "Epoch 40, Loss(train/val) 0.22347/0.29649. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.22331/0.28933. Took 0.15 sec\n",
      "Epoch 42, Loss(train/val) 0.22276/0.28552. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.22662/0.29308. Took 0.18 sec\n",
      "Epoch 44, Loss(train/val) 0.22008/0.28488. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.23209/0.29516. Took 0.15 sec\n",
      "Epoch 46, Loss(train/val) 0.21967/0.30977. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.22728/0.28517. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.20760/0.28537. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.21083/0.29493. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.21002/0.28137. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.21773/0.27299. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.21041/0.28902. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) 0.21397/0.27806. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.19165/0.29759. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.21152/0.28206. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.20749/0.28920. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.20720/0.28455. Took 0.15 sec\n",
      "Epoch 58, Loss(train/val) 0.20122/0.27950. Took 0.14 sec\n",
      "Epoch 59, Loss(train/val) 0.19386/0.28165. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.20156/0.30166. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.20666/0.27404. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.19811/0.27028. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.19657/0.27730. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.19433/0.27963. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.19357/0.29340. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.18834/0.29167. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.19585/0.28545. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.19143/0.29131. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.18882/0.29047. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.18518/0.29016. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.17350/0.29673. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.18175/0.28374. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.17465/0.28488. Took 0.15 sec\n",
      "Epoch 74, Loss(train/val) 0.17813/0.27859. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.18158/0.27050. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.18380/0.29943. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.16668/0.27198. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.17060/0.27317. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.17718/0.27539. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.17520/0.27595. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.16968/0.26820. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.16432/0.28087. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.17506/0.28787. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.17154/0.27488. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.18350/0.30665. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.17206/0.27394. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.16448/0.28724. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.17211/0.28448. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.16982/0.27833. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.17432/0.30070. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.16667/0.28633. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.16390/0.27464. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.16310/0.28123. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.16180/0.28373. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.15478/0.27562. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.16277/0.27253. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.15571/0.29145. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.15864/0.27566. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.16176/0.30136. Took 0.14 sec\n",
      "ACC: 0.65625, MCC: 0.35468319119889385\n",
      "Epoch 0, Loss(train/val) 0.49170/0.49296. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.47201/0.48313. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.44028/0.49754. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.41229/0.50098. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.39917/0.49144. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.38495/0.45937. Took 0.17 sec\n",
      "Epoch 6, Loss(train/val) 0.36944/0.45017. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.35378/0.41777. Took 0.15 sec\n",
      "Epoch 8, Loss(train/val) 0.34045/0.44982. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.32099/0.40890. Took 0.16 sec\n",
      "Epoch 10, Loss(train/val) 0.31177/0.45472. Took 0.15 sec\n",
      "Epoch 11, Loss(train/val) 0.30688/0.42084. Took 0.15 sec\n",
      "Epoch 12, Loss(train/val) 0.29900/0.42527. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.28869/0.44138. Took 0.16 sec\n",
      "Epoch 14, Loss(train/val) 0.30574/0.43814. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.30109/0.41460. Took 0.16 sec\n",
      "Epoch 16, Loss(train/val) 0.29299/0.38414. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.28352/0.40628. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.27942/0.36803. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.27518/0.40745. Took 0.16 sec\n",
      "Epoch 20, Loss(train/val) 0.28317/0.43990. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.26792/0.42052. Took 0.16 sec\n",
      "Epoch 22, Loss(train/val) 0.26395/0.41953. Took 0.15 sec\n",
      "Epoch 23, Loss(train/val) 0.27630/0.34017. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.25972/0.41350. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.26039/0.40973. Took 0.18 sec\n",
      "Epoch 26, Loss(train/val) 0.26819/0.39908. Took 0.16 sec\n",
      "Epoch 27, Loss(train/val) 0.26416/0.35015. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.26781/0.38144. Took 0.15 sec\n",
      "Epoch 29, Loss(train/val) 0.24960/0.42130. Took 0.18 sec\n",
      "Epoch 30, Loss(train/val) 0.24806/0.42624. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.25591/0.35339. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.25166/0.35348. Took 0.17 sec\n",
      "Epoch 33, Loss(train/val) 0.25515/0.36878. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.25032/0.33866. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.24938/0.35592. Took 0.16 sec\n",
      "Epoch 36, Loss(train/val) 0.23854/0.36909. Took 0.13 sec\n",
      "Epoch 37, Loss(train/val) 0.24626/0.37351. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.23309/0.37684. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.23845/0.36760. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.22113/0.37394. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.23603/0.36839. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.22807/0.36900. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.21965/0.37038. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.22025/0.37959. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.21082/0.37533. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.21858/0.36412. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.20879/0.36025. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.21686/0.37361. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.20551/0.37053. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.20639/0.34569. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.20910/0.33487. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.20226/0.34270. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.19974/0.36992. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.20767/0.36285. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.20004/0.36100. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.20961/0.32739. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.22703/0.37989. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.21825/0.39890. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.21545/0.38237. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.19273/0.38283. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.19692/0.35516. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.19359/0.35992. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.19191/0.36365. Took 0.15 sec\n",
      "Epoch 64, Loss(train/val) 0.18272/0.38616. Took 0.15 sec\n",
      "Epoch 65, Loss(train/val) 0.18969/0.33483. Took 0.17 sec\n",
      "Epoch 66, Loss(train/val) 0.18573/0.36310. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) 0.18135/0.35258. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.17248/0.34893. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.17684/0.34563. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.17806/0.35112. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.17449/0.35334. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.17510/0.36586. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.17866/0.34971. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.16842/0.35955. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.16499/0.35950. Took 0.15 sec\n",
      "Epoch 76, Loss(train/val) 0.17652/0.35699. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.17029/0.35335. Took 0.15 sec\n",
      "Epoch 78, Loss(train/val) 0.17357/0.35837. Took 0.14 sec\n",
      "Epoch 79, Loss(train/val) 0.17148/0.34444. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.16487/0.38578. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.18242/0.34137. Took 0.15 sec\n",
      "Epoch 82, Loss(train/val) 0.16450/0.33549. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.16501/0.36656. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.16470/0.38181. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.15863/0.36726. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.16872/0.36493. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.16867/0.35321. Took 0.15 sec\n",
      "Epoch 88, Loss(train/val) 0.15737/0.35890. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.16821/0.34291. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.16530/0.35398. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.16951/0.37007. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.16158/0.35969. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.15099/0.37860. Took 0.15 sec\n",
      "Epoch 94, Loss(train/val) 0.14577/0.37530. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.15760/0.36667. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.14741/0.36471. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.15686/0.35342. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.14402/0.36404. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.15366/0.33236. Took 0.14 sec\n",
      "ACC: 0.515625, MCC: 0.09061004703659373\n",
      "Epoch 0, Loss(train/val) 0.49620/0.49319. Took 0.16 sec\n",
      "Epoch 1, Loss(train/val) 0.48341/0.47450. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.45813/0.43177. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.42685/0.42144. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.40531/0.38717. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.38120/0.35620. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.35630/0.30302. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.33971/0.33194. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.32288/0.35827. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.31068/0.40556. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.31271/0.42737. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.32820/0.49721. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.31870/0.39969. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.31213/0.36877. Took 0.16 sec\n",
      "Epoch 14, Loss(train/val) 0.30380/0.45493. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.28719/0.49265. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.29291/0.42382. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.28609/0.44291. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.27252/0.47905. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.26909/0.46187. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.27592/0.47072. Took 0.15 sec\n",
      "Epoch 21, Loss(train/val) 0.27733/0.45080. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.27338/0.45659. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.25688/0.46121. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.26965/0.46489. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.24981/0.43198. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.28422/0.46142. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.26733/0.46274. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.23440/0.45002. Took 0.18 sec\n",
      "Epoch 29, Loss(train/val) 0.24280/0.45447. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.25290/0.44838. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.26071/0.40736. Took 0.16 sec\n",
      "Epoch 32, Loss(train/val) 0.26958/0.46139. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.24605/0.46491. Took 0.16 sec\n",
      "Epoch 34, Loss(train/val) 0.24386/0.45694. Took 0.17 sec\n",
      "Epoch 35, Loss(train/val) 0.24532/0.47122. Took 0.16 sec\n",
      "Epoch 36, Loss(train/val) 0.22477/0.45146. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.23441/0.44671. Took 0.16 sec\n",
      "Epoch 38, Loss(train/val) 0.23391/0.46214. Took 0.15 sec\n",
      "Epoch 39, Loss(train/val) 0.22971/0.44098. Took 0.16 sec\n",
      "Epoch 40, Loss(train/val) 0.23722/0.44564. Took 0.16 sec\n",
      "Epoch 41, Loss(train/val) 0.22900/0.44892. Took 0.16 sec\n",
      "Epoch 42, Loss(train/val) 0.22346/0.46818. Took 0.15 sec\n",
      "Epoch 43, Loss(train/val) 0.23296/0.43440. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.23753/0.45681. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.22796/0.45828. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.21615/0.44340. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.22025/0.43425. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.20493/0.42152. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.21059/0.43975. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.21204/0.43709. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.20662/0.46157. Took 0.15 sec\n",
      "Epoch 52, Loss(train/val) 0.19930/0.45389. Took 0.14 sec\n",
      "Epoch 53, Loss(train/val) 0.20700/0.46253. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.22088/0.46725. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.19493/0.45831. Took 0.15 sec\n",
      "Epoch 56, Loss(train/val) 0.19803/0.45127. Took 0.14 sec\n",
      "Epoch 57, Loss(train/val) 0.20602/0.46078. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.19823/0.46404. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.20541/0.45726. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.19117/0.46326. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.18756/0.46684. Took 0.15 sec\n",
      "Epoch 62, Loss(train/val) 0.18670/0.47300. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.18365/0.45855. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.19243/0.44831. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.18694/0.45801. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.18461/0.47555. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.19188/0.44816. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.19004/0.46010. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.18548/0.45982. Took 0.15 sec\n",
      "Epoch 70, Loss(train/val) 0.18720/0.46732. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.18346/0.46425. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.18320/0.46223. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.18151/0.46157. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.16842/0.44764. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.17295/0.44282. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.17348/0.44664. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.16520/0.45069. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.17656/0.46036. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.18323/0.45934. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.17963/0.44075. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.19423/0.39872. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.20044/0.44447. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.17202/0.45549. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.17776/0.45112. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.17636/0.44445. Took 0.15 sec\n",
      "Epoch 86, Loss(train/val) 0.16921/0.44299. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.17954/0.46006. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.17779/0.46032. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.16792/0.44972. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.17153/0.44025. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.16774/0.45378. Took 0.12 sec\n",
      "Epoch 92, Loss(train/val) 0.16917/0.44241. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.16299/0.45317. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.16589/0.46215. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.15154/0.48122. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.15650/0.46635. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.16212/0.47772. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.15324/0.45979. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.15940/0.46161. Took 0.13 sec\n",
      "ACC: 0.640625, MCC: 0.23746520388551606\n",
      "Epoch 0, Loss(train/val) 0.49473/0.48937. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.47615/0.46751. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.44347/0.44347. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.41091/0.42555. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.39254/0.41539. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.37535/0.40513. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.35866/0.39061. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.33828/0.34646. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.32197/0.31121. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.32241/0.33370. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.30913/0.31456. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.30804/0.31292. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.28935/0.33555. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.28650/0.33118. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.28699/0.32378. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.27742/0.33879. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.26366/0.35757. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.27046/0.37761. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.24873/0.34089. Took 0.16 sec\n",
      "Epoch 19, Loss(train/val) 0.25363/0.33401. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.25413/0.33892. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.24725/0.33391. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.24168/0.35824. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.24049/0.35238. Took 0.16 sec\n",
      "Epoch 24, Loss(train/val) 0.23590/0.37940. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.23795/0.40792. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.23752/0.35636. Took 0.13 sec\n",
      "Epoch 27, Loss(train/val) 0.22964/0.40093. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.22533/0.39481. Took 0.13 sec\n",
      "Epoch 29, Loss(train/val) 0.22810/0.37215. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.22009/0.38357. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.21978/0.40012. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.21684/0.42944. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.22015/0.38023. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.21821/0.38509. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.21061/0.37182. Took 0.17 sec\n",
      "Epoch 36, Loss(train/val) 0.20517/0.42376. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.19848/0.44630. Took 0.16 sec\n",
      "Epoch 38, Loss(train/val) 0.21501/0.41075. Took 0.16 sec\n",
      "Epoch 39, Loss(train/val) 0.20024/0.36450. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.19116/0.45113. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.19459/0.40947. Took 0.17 sec\n",
      "Epoch 42, Loss(train/val) 0.18844/0.39214. Took 0.15 sec\n",
      "Epoch 43, Loss(train/val) 0.20033/0.41064. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.18295/0.40204. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) 0.18283/0.40967. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.19363/0.40561. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.19172/0.36586. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.18942/0.42342. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.18813/0.41788. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.19977/0.38416. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.18215/0.41482. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.18430/0.42116. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.17237/0.41880. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.18113/0.39681. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.17677/0.41842. Took 0.13 sec\n",
      "Epoch 56, Loss(train/val) 0.17327/0.36559. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.18254/0.35022. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.17636/0.40085. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.18077/0.37063. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.17569/0.38548. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.16545/0.37263. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.16953/0.40433. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.17827/0.41799. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.16263/0.38999. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.16179/0.42845. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.17072/0.40535. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.17214/0.36833. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.17039/0.35476. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.15929/0.36514. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.16272/0.37099. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.15819/0.42769. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.16811/0.33895. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.16767/0.43109. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.16107/0.42426. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.17303/0.38073. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.16518/0.43475. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.15656/0.42064. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.15689/0.34819. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.14963/0.42044. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.15964/0.41110. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.15432/0.39631. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.15846/0.39546. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.15229/0.39472. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.15435/0.38097. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.15164/0.38725. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.15122/0.36273. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.14383/0.36730. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.14743/0.38345. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.15515/0.36368. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.14806/0.39816. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.14164/0.38139. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.15151/0.38270. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.15591/0.37779. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.13694/0.40329. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.14298/0.40671. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.13642/0.40159. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.13920/0.40811. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.13757/0.35167. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.14610/0.40087. Took 0.14 sec\n",
      "ACC: 0.703125, MCC: 0.4052867805690852\n",
      "Epoch 0, Loss(train/val) 0.49452/0.49045. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.47853/0.47507. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.45016/0.44925. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.41766/0.43761. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.39989/0.43352. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.38260/0.40603. Took 0.13 sec\n",
      "Epoch 6, Loss(train/val) 0.36261/0.36358. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.33761/0.33637. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.32005/0.33854. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.31396/0.34105. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.31691/0.31147. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.30318/0.33644. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.30430/0.33490. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.29910/0.34134. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.29548/0.32425. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.27976/0.31192. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.28438/0.31937. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.27777/0.36879. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.29096/0.33106. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.27055/0.30986. Took 0.16 sec\n",
      "Epoch 20, Loss(train/val) 0.26894/0.30848. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.26778/0.35749. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.26781/0.39175. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.26130/0.33336. Took 0.16 sec\n",
      "Epoch 24, Loss(train/val) 0.25663/0.35393. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.25820/0.32175. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.25217/0.30735. Took 0.13 sec\n",
      "Epoch 27, Loss(train/val) 0.25014/0.30616. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.24315/0.31574. Took 0.13 sec\n",
      "Epoch 29, Loss(train/val) 0.24578/0.30904. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.24599/0.34748. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.22005/0.31091. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.23655/0.30880. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.22863/0.32540. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.22630/0.35101. Took 0.16 sec\n",
      "Epoch 35, Loss(train/val) 0.21801/0.31790. Took 0.17 sec\n",
      "Epoch 36, Loss(train/val) 0.22603/0.31441. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.21417/0.32348. Took 0.16 sec\n",
      "Epoch 38, Loss(train/val) 0.21486/0.32653. Took 0.17 sec\n",
      "Epoch 39, Loss(train/val) 0.21386/0.32280. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.20639/0.37011. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.20782/0.35717. Took 0.16 sec\n",
      "Epoch 42, Loss(train/val) 0.21141/0.31993. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.19776/0.35777. Took 0.15 sec\n",
      "Epoch 44, Loss(train/val) 0.20355/0.35303. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.19742/0.33646. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.19321/0.35794. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.19351/0.34929. Took 0.15 sec\n",
      "Epoch 48, Loss(train/val) 0.19374/0.33196. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.19421/0.31543. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.18359/0.34787. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.18598/0.32996. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.18081/0.32265. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.17822/0.37551. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.17940/0.33465. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.17157/0.32423. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.17396/0.35883. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.15803/0.32912. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.16217/0.36321. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.17016/0.35464. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.17396/0.34256. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.16126/0.36903. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.17050/0.31999. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.17344/0.31905. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.16679/0.33855. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.14565/0.33667. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.15490/0.32169. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.14999/0.33404. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.14384/0.34379. Took 0.14 sec\n",
      "Epoch 69, Loss(train/val) 0.14780/0.36688. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.14451/0.36234. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.16477/0.37191. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.16025/0.34438. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.14177/0.35097. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.14462/0.34853. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.13748/0.33485. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.14132/0.35282. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.14280/0.33562. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.13914/0.32336. Took 0.15 sec\n",
      "Epoch 79, Loss(train/val) 0.13643/0.33724. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.13890/0.33683. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.13864/0.30866. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.13655/0.33561. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.13171/0.36792. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.13963/0.38566. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.13215/0.35816. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.14065/0.36612. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.12802/0.34284. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.12448/0.36109. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.13442/0.33500. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.13174/0.32867. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.12601/0.32725. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.11471/0.32304. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.12096/0.33935. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.11874/0.32636. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.12481/0.33031. Took 0.15 sec\n",
      "Epoch 96, Loss(train/val) 0.12058/0.29474. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.11921/0.33292. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.11852/0.32568. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.11663/0.31936. Took 0.14 sec\n",
      "ACC: 0.59375, MCC: 0.1883201896480698\n",
      "Epoch 0, Loss(train/val) 0.48953/0.48394. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.46411/0.45840. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.42893/0.42588. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.40363/0.40346. Took 0.15 sec\n",
      "Epoch 4, Loss(train/val) 0.38242/0.40628. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.37106/0.39637. Took 0.16 sec\n",
      "Epoch 6, Loss(train/val) 0.36383/0.39142. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.35991/0.36771. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.35409/0.37783. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.34771/0.36485. Took 0.15 sec\n",
      "Epoch 10, Loss(train/val) 0.33693/0.35333. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.33702/0.35806. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.33215/0.35163. Took 0.17 sec\n",
      "Epoch 13, Loss(train/val) 0.32264/0.34919. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.31964/0.35107. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.31441/0.35741. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.31206/0.35442. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.30735/0.34157. Took 0.16 sec\n",
      "Epoch 18, Loss(train/val) 0.30268/0.36502. Took 0.16 sec\n",
      "Epoch 19, Loss(train/val) 0.30374/0.35706. Took 0.16 sec\n",
      "Epoch 20, Loss(train/val) 0.29865/0.34945. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.29195/0.35079. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.29976/0.35538. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.28968/0.36575. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.28570/0.36424. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.28254/0.37512. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.27711/0.35979. Took 0.15 sec\n",
      "Epoch 27, Loss(train/val) 0.27462/0.35685. Took 0.16 sec\n",
      "Epoch 28, Loss(train/val) 0.27524/0.36888. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.27431/0.36998. Took 0.16 sec\n",
      "Epoch 30, Loss(train/val) 0.26948/0.36293. Took 0.17 sec\n",
      "Epoch 31, Loss(train/val) 0.27034/0.35002. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.26521/0.36056. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.26673/0.38685. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.26482/0.35305. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.26508/0.34542. Took 0.15 sec\n",
      "Epoch 36, Loss(train/val) 0.25825/0.37229. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.26096/0.37233. Took 0.15 sec\n",
      "Epoch 38, Loss(train/val) 0.25795/0.38548. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.25788/0.37209. Took 0.15 sec\n",
      "Epoch 40, Loss(train/val) 0.25531/0.37330. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.25799/0.36599. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.25102/0.39376. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.25566/0.38232. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.25698/0.37816. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.24929/0.38419. Took 0.15 sec\n",
      "Epoch 46, Loss(train/val) 0.25393/0.37012. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.24815/0.35603. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.25102/0.38554. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.25218/0.37892. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.24068/0.38853. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.23582/0.38473. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.24345/0.39358. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.24251/0.37999. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.24093/0.35968. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.23910/0.40284. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.23731/0.39492. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.23494/0.36361. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.23610/0.38779. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.23187/0.36868. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.23099/0.40025. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.23406/0.40118. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.23143/0.38301. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.22865/0.40894. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.22793/0.38027. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.22321/0.40144. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.22352/0.39865. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.22415/0.40486. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.22437/0.37797. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.22853/0.36516. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.21645/0.40947. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.20923/0.39652. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.21158/0.42948. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.21158/0.40327. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.21766/0.36676. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.21693/0.36557. Took 0.15 sec\n",
      "Epoch 76, Loss(train/val) 0.21386/0.37347. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.20968/0.39146. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.21404/0.35543. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.20929/0.37021. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.20000/0.37300. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.20741/0.34478. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.19694/0.37096. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.19595/0.38064. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.19945/0.38766. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.19325/0.39131. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.19589/0.38188. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.20015/0.38323. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.18846/0.36563. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.19127/0.36722. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.19252/0.37041. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.18230/0.38404. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.18643/0.37657. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.18492/0.37542. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.17329/0.39352. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.18062/0.35860. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.18064/0.37639. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.17897/0.37211. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.18100/0.38039. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.17533/0.38963. Took 0.14 sec\n",
      "ACC: 0.640625, MCC: 0.2965909994776427\n",
      "Epoch 0, Loss(train/val) 0.48895/0.47896. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.46657/0.45083. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.43512/0.41648. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.40993/0.39996. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.39094/0.39216. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.37312/0.38870. Took 0.15 sec\n",
      "Epoch 6, Loss(train/val) 0.36635/0.39119. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.35886/0.38869. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.35525/0.37699. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.35001/0.38111. Took 0.16 sec\n",
      "Epoch 10, Loss(train/val) 0.35231/0.38841. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.33587/0.38255. Took 0.15 sec\n",
      "Epoch 12, Loss(train/val) 0.33234/0.39012. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.33596/0.39124. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.32902/0.37947. Took 0.15 sec\n",
      "Epoch 15, Loss(train/val) 0.32350/0.37983. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.32726/0.38875. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.32147/0.38617. Took 0.16 sec\n",
      "Epoch 18, Loss(train/val) 0.31654/0.38767. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.30923/0.39928. Took 0.16 sec\n",
      "Epoch 20, Loss(train/val) 0.30513/0.42047. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.29952/0.43877. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.29596/0.50817. Took 0.15 sec\n",
      "Epoch 23, Loss(train/val) 0.29306/0.48805. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.28541/0.49918. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.29027/0.46205. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.28075/0.43468. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.28270/0.40401. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.27871/0.43279. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.28234/0.42611. Took 0.16 sec\n",
      "Epoch 30, Loss(train/val) 0.27333/0.38317. Took 0.16 sec\n",
      "Epoch 31, Loss(train/val) 0.27025/0.37988. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.27313/0.39246. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.26890/0.37003. Took 0.17 sec\n",
      "Epoch 34, Loss(train/val) 0.26329/0.46474. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.27059/0.44130. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.25869/0.36908. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.25753/0.38219. Took 0.15 sec\n",
      "Epoch 38, Loss(train/val) 0.25509/0.48844. Took 0.15 sec\n",
      "Epoch 39, Loss(train/val) 0.25604/0.38999. Took 0.16 sec\n",
      "Epoch 40, Loss(train/val) 0.25713/0.47205. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.26252/0.36992. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.25785/0.38867. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.25368/0.42297. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.26213/0.38823. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.25065/0.31955. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.25125/0.34414. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.24462/0.36205. Took 0.15 sec\n",
      "Epoch 48, Loss(train/val) 0.23877/0.35297. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.24614/0.37619. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.24104/0.36305. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.23392/0.35334. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.22855/0.36003. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.23057/0.34631. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.23176/0.35273. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.22672/0.37520. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.24433/0.39397. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.23684/0.39597. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.23169/0.37967. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.22827/0.41842. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.21669/0.36572. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.22435/0.40014. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.22507/0.37520. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.22179/0.38942. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.22354/0.45336. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.22577/0.38248. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.22702/0.35646. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.22467/0.38768. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.22114/0.40791. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.21417/0.36881. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.21570/0.37785. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.21128/0.37916. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.21553/0.42164. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.20496/0.34887. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.20559/0.35528. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.20886/0.31433. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.20338/0.34458. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.19803/0.33177. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.20322/0.34736. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.20105/0.32973. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.19183/0.34300. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.20437/0.32636. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.19461/0.31564. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.20274/0.32753. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.19128/0.31689. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.19023/0.32520. Took 0.13 sec\n",
      "Epoch 86, Loss(train/val) 0.19841/0.33672. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.19023/0.35257. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.19553/0.32022. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.18241/0.28534. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.18671/0.29556. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.19135/0.30853. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.19256/0.33571. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.18449/0.34019. Took 0.13 sec\n",
      "Epoch 94, Loss(train/val) 0.19284/0.30072. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.18354/0.29790. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.17758/0.30130. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.18470/0.33657. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.18549/0.28848. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.18032/0.30319. Took 0.14 sec\n",
      "ACC: 0.640625, MCC: 0.2825430298229483\n",
      "Epoch 0, Loss(train/val) 0.49290/0.48518. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.47056/0.45828. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.43392/0.40457. Took 0.14 sec\n",
      "Epoch 3, Loss(train/val) 0.40172/0.37176. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.38662/0.34222. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.37195/0.32585. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.36217/0.33329. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.35912/0.32233. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.35460/0.33508. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.34698/0.34232. Took 0.15 sec\n",
      "Epoch 10, Loss(train/val) 0.34168/0.36637. Took 0.15 sec\n",
      "Epoch 11, Loss(train/val) 0.33386/0.39638. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.33418/0.34304. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.33327/0.40585. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.33391/0.36289. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.32024/0.41610. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.32503/0.35027. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.32308/0.41695. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.31076/0.38578. Took 0.15 sec\n",
      "Epoch 19, Loss(train/val) 0.30152/0.40664. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.29540/0.34112. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.28834/0.39404. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.29119/0.34568. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.29524/0.41924. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.28613/0.42261. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.27979/0.42733. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.27201/0.37367. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.27215/0.34566. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.26560/0.36537. Took 0.13 sec\n",
      "Epoch 29, Loss(train/val) 0.25747/0.34361. Took 0.16 sec\n",
      "Epoch 30, Loss(train/val) 0.25559/0.34659. Took 0.16 sec\n",
      "Epoch 31, Loss(train/val) 0.25422/0.36688. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.24728/0.35302. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.24083/0.34121. Took 0.18 sec\n",
      "Epoch 34, Loss(train/val) 0.24115/0.32437. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.23813/0.35388. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.23383/0.34298. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.23350/0.35891. Took 0.15 sec\n",
      "Epoch 38, Loss(train/val) 0.22165/0.35782. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.21815/0.32330. Took 0.16 sec\n",
      "Epoch 40, Loss(train/val) 0.21911/0.38871. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.21626/0.37401. Took 0.15 sec\n",
      "Epoch 42, Loss(train/val) 0.21898/0.36220. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.20861/0.38021. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.20848/0.37611. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.20837/0.41964. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.20705/0.36278. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.20814/0.36504. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.20983/0.36158. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.20109/0.37397. Took 0.15 sec\n",
      "Epoch 50, Loss(train/val) 0.19889/0.38474. Took 0.14 sec\n",
      "Epoch 51, Loss(train/val) 0.18965/0.36040. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.19799/0.38216. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.19170/0.35224. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.19010/0.33210. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.18608/0.39256. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.17619/0.37593. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.17893/0.38376. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.17430/0.35791. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.17870/0.35916. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.17625/0.35099. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.18111/0.37762. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.17668/0.34972. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.17255/0.35094. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.16473/0.36929. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.17087/0.39417. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.16734/0.38643. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.16095/0.38800. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.16202/0.38224. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.16922/0.39200. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.16422/0.38816. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.16064/0.38505. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.16027/0.36010. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.15732/0.38272. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.15988/0.37182. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.15350/0.38722. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.15957/0.38257. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.15340/0.35602. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.15111/0.35120. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.14063/0.40956. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.14930/0.37208. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.14159/0.37788. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.14682/0.38669. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.14437/0.38575. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.13913/0.38381. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.14997/0.36529. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.14891/0.40244. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.14055/0.36506. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.14819/0.37786. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.14094/0.37725. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.13650/0.39527. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.14030/0.39018. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.14721/0.41552. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.13819/0.39624. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.15354/0.41539. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.14392/0.38985. Took 0.12 sec\n",
      "Epoch 96, Loss(train/val) 0.13915/0.41081. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.13039/0.40743. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.12890/0.42339. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.13330/0.43845. Took 0.13 sec\n",
      "ACC: 0.546875, MCC: 0.08222643447147887\n",
      "Epoch 0, Loss(train/val) 0.49293/0.49120. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.46805/0.47589. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.43440/0.46646. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.39756/0.46607. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.37938/0.45408. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.36331/0.45315. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.35445/0.44576. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.34410/0.43718. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.33625/0.42132. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.33782/0.44995. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.33084/0.43162. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.31897/0.46908. Took 0.15 sec\n",
      "Epoch 12, Loss(train/val) 0.31386/0.46701. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.30344/0.45964. Took 0.16 sec\n",
      "Epoch 14, Loss(train/val) 0.30300/0.44579. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.29172/0.43054. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.28141/0.45029. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.28578/0.38374. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.28365/0.43641. Took 0.15 sec\n",
      "Epoch 19, Loss(train/val) 0.27899/0.41125. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.26595/0.41016. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.26390/0.36765. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.27782/0.37362. Took 0.15 sec\n",
      "Epoch 23, Loss(train/val) 0.29303/0.38156. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.28338/0.38718. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.27467/0.38171. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.27155/0.37569. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.25985/0.37957. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.26326/0.37921. Took 0.13 sec\n",
      "Epoch 29, Loss(train/val) 0.25569/0.37646. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.26158/0.40712. Took 0.13 sec\n",
      "Epoch 31, Loss(train/val) 0.24713/0.39547. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.25235/0.39513. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.24691/0.38181. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.24309/0.38257. Took 0.17 sec\n",
      "Epoch 35, Loss(train/val) 0.24427/0.41542. Took 0.16 sec\n",
      "Epoch 36, Loss(train/val) 0.24257/0.38104. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.22914/0.38448. Took 0.15 sec\n",
      "Epoch 38, Loss(train/val) 0.23106/0.39986. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.23639/0.40070. Took 0.17 sec\n",
      "Epoch 40, Loss(train/val) 0.23523/0.38346. Took 0.16 sec\n",
      "Epoch 41, Loss(train/val) 0.21951/0.38827. Took 0.15 sec\n",
      "Epoch 42, Loss(train/val) 0.21834/0.38752. Took 0.15 sec\n",
      "Epoch 43, Loss(train/val) 0.21897/0.38819. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.21103/0.39483. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.21884/0.39079. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.21885/0.40120. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.21021/0.37952. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.21481/0.39946. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.22071/0.40443. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.21796/0.41763. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.22611/0.38182. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.20797/0.42510. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.20771/0.39432. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.21504/0.39471. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.20978/0.40230. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.19383/0.37546. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.19581/0.38841. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.19738/0.38698. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.20587/0.38406. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.19027/0.38794. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.19593/0.37661. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.19401/0.36567. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.20014/0.38233. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.18880/0.37166. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.20101/0.37543. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.18769/0.37217. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.19260/0.38716. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.17922/0.39844. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.18203/0.38825. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.18506/0.39973. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.18141/0.39850. Took 0.15 sec\n",
      "Epoch 72, Loss(train/val) 0.19618/0.38014. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.17579/0.37954. Took 0.15 sec\n",
      "Epoch 74, Loss(train/val) 0.17469/0.37039. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.17567/0.38070. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.17211/0.37276. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.18641/0.37393. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.17900/0.39378. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.17912/0.36626. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.16921/0.38769. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.17689/0.39719. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.17035/0.39070. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.16829/0.38305. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.16185/0.38776. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.17245/0.36865. Took 0.15 sec\n",
      "Epoch 86, Loss(train/val) 0.16581/0.37011. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.16114/0.37741. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.16184/0.39126. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.17057/0.39669. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.15880/0.37154. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.16202/0.40659. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.16854/0.36738. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.16061/0.40937. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.16465/0.42039. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.15585/0.44125. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.16985/0.39083. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.16474/0.39810. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.16395/0.42803. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.16288/0.41433. Took 0.14 sec\n",
      "ACC: 0.6875, MCC: 0.33062326126679026\n",
      "Epoch 0, Loss(train/val) 0.49350/0.48190. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.47103/0.44143. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.43536/0.39410. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.39670/0.37605. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.37781/0.35166. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.36752/0.34757. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.35376/0.34599. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.34207/0.35012. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.33886/0.35065. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.33042/0.34293. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.32344/0.33900. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.32046/0.35318. Took 0.16 sec\n",
      "Epoch 12, Loss(train/val) 0.31398/0.34903. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.30621/0.35019. Took 0.16 sec\n",
      "Epoch 14, Loss(train/val) 0.30202/0.34243. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.30546/0.35944. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.29512/0.32978. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.29346/0.34935. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.28851/0.34366. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.28085/0.34028. Took 0.15 sec\n",
      "Epoch 20, Loss(train/val) 0.27770/0.32549. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.27731/0.34105. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.26297/0.33700. Took 0.15 sec\n",
      "Epoch 23, Loss(train/val) 0.26262/0.34340. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.26625/0.34332. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.26727/0.36330. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.25973/0.34180. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.25892/0.35142. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.25216/0.33265. Took 0.13 sec\n",
      "Epoch 29, Loss(train/val) 0.25628/0.35989. Took 0.16 sec\n",
      "Epoch 30, Loss(train/val) 0.24827/0.36587. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.24884/0.34875. Took 0.16 sec\n",
      "Epoch 32, Loss(train/val) 0.23480/0.34416. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.23626/0.34663. Took 0.17 sec\n",
      "Epoch 34, Loss(train/val) 0.23874/0.34764. Took 0.16 sec\n",
      "Epoch 35, Loss(train/val) 0.23840/0.35178. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.23259/0.31302. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.22834/0.33966. Took 0.15 sec\n",
      "Epoch 38, Loss(train/val) 0.23023/0.33451. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.22904/0.33569. Took 0.16 sec\n",
      "Epoch 40, Loss(train/val) 0.22982/0.36689. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.22656/0.32274. Took 0.16 sec\n",
      "Epoch 42, Loss(train/val) 0.22189/0.33998. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.23132/0.35650. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.22834/0.37684. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.22224/0.36646. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.20978/0.35049. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.20337/0.37343. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.22304/0.33953. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.22101/0.33296. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.22310/0.33957. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.21093/0.33138. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.21118/0.32836. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.20573/0.32670. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.21121/0.36618. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.20621/0.34220. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.20505/0.32822. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.20097/0.32361. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.20731/0.31452. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.19846/0.34158. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.19262/0.32020. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.20417/0.32284. Took 0.15 sec\n",
      "Epoch 62, Loss(train/val) 0.19569/0.33571. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.19903/0.33339. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.19200/0.33356. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.19161/0.33189. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.18641/0.32739. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) 0.19407/0.33241. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.17275/0.32979. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.18202/0.32186. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.19054/0.32087. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.17757/0.33678. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.18352/0.34068. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.17946/0.32271. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.17538/0.31242. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.17695/0.31539. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.17661/0.31148. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.17467/0.31756. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.17969/0.31765. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.17114/0.31767. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.16698/0.30172. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.17060/0.33591. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.17529/0.31462. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.17297/0.30313. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.16712/0.30291. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.17361/0.29124. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.16483/0.31909. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.16423/0.31681. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.15885/0.30270. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.15626/0.30869. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.15836/0.34009. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.16121/0.32020. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.15921/0.31439. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.17041/0.29763. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.16191/0.30510. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.14895/0.30294. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.15767/0.31598. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.14549/0.30494. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.15077/0.30582. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.14375/0.30482. Took 0.14 sec\n",
      "ACC: 0.625, MCC: 0.24828653090964817\n",
      "Epoch 0, Loss(train/val) 0.49278/0.48844. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.46828/0.47001. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.43517/0.44471. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.39968/0.42519. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.37766/0.40525. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.36412/0.39592. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.35496/0.39080. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.34659/0.36808. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.34143/0.36237. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.33541/0.35524. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.33347/0.35215. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.33230/0.35180. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.32588/0.35622. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.31646/0.35012. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.31396/0.34981. Took 0.15 sec\n",
      "Epoch 15, Loss(train/val) 0.31272/0.35514. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.31306/0.35512. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.30284/0.34650. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.29489/0.34722. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.29760/0.34827. Took 0.15 sec\n",
      "Epoch 20, Loss(train/val) 0.28727/0.34847. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.29546/0.33962. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.28514/0.35111. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.28916/0.34263. Took 0.14 sec\n",
      "Epoch 24, Loss(train/val) 0.27873/0.35480. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.28399/0.37527. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.29682/0.35028. Took 0.13 sec\n",
      "Epoch 27, Loss(train/val) 0.28814/0.34687. Took 0.16 sec\n",
      "Epoch 28, Loss(train/val) 0.27291/0.32972. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.26151/0.33895. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.26912/0.35316. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.26189/0.33128. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.26018/0.33939. Took 0.13 sec\n",
      "Epoch 33, Loss(train/val) 0.25412/0.32307. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.25303/0.33181. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.24196/0.32263. Took 0.16 sec\n",
      "Epoch 36, Loss(train/val) 0.24976/0.34548. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.24369/0.33606. Took 0.17 sec\n",
      "Epoch 38, Loss(train/val) 0.24313/0.33254. Took 0.17 sec\n",
      "Epoch 39, Loss(train/val) 0.24469/0.33941. Took 0.15 sec\n",
      "Epoch 40, Loss(train/val) 0.23792/0.35068. Took 0.15 sec\n",
      "Epoch 41, Loss(train/val) 0.23689/0.35173. Took 0.15 sec\n",
      "Epoch 42, Loss(train/val) 0.23051/0.35337. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.23347/0.33826. Took 0.16 sec\n",
      "Epoch 44, Loss(train/val) 0.23136/0.36027. Took 0.14 sec\n",
      "Epoch 45, Loss(train/val) 0.23238/0.35361. Took 0.16 sec\n",
      "Epoch 46, Loss(train/val) 0.23158/0.34716. Took 0.14 sec\n",
      "Epoch 47, Loss(train/val) 0.22102/0.34152. Took 0.15 sec\n",
      "Epoch 48, Loss(train/val) 0.21344/0.35667. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.21697/0.33981. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.21317/0.33081. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.21681/0.34168. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.21789/0.33295. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.21740/0.34847. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.21115/0.35491. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.21018/0.35731. Took 0.15 sec\n",
      "Epoch 56, Loss(train/val) 0.20692/0.34865. Took 0.12 sec\n",
      "Epoch 57, Loss(train/val) 0.19968/0.34646. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.20230/0.35301. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.19835/0.36117. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.20256/0.35788. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.19882/0.35561. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.20249/0.35950. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.19276/0.35168. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.19179/0.35774. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.19825/0.36236. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.18914/0.36164. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.18927/0.35762. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.19059/0.36215. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.18865/0.37338. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.18707/0.37557. Took 0.14 sec\n",
      "Epoch 71, Loss(train/val) 0.18259/0.36074. Took 0.15 sec\n",
      "Epoch 72, Loss(train/val) 0.19010/0.35936. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.18057/0.35956. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.17817/0.36126. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.18236/0.36547. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.17934/0.38660. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.18214/0.36779. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.18418/0.36905. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.17451/0.37894. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.17343/0.37439. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.17099/0.38995. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.17132/0.39322. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.16219/0.38349. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.16691/0.37485. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.17029/0.37623. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.16163/0.39464. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.15945/0.38120. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.16388/0.39855. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.15634/0.40558. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.16489/0.39441. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.16903/0.38851. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.15491/0.38122. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.15611/0.37691. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.15727/0.38161. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.15258/0.38726. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.15618/0.38798. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.15238/0.38793. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.15432/0.38849. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.14624/0.38948. Took 0.14 sec\n",
      "ACC: 0.640625, MCC: 0.27967281717839076\n",
      "Epoch 0, Loss(train/val) 0.49060/0.48757. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.46034/0.46640. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.42931/0.43953. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.40337/0.42675. Took 0.15 sec\n",
      "Epoch 4, Loss(train/val) 0.38559/0.41030. Took 0.14 sec\n",
      "Epoch 5, Loss(train/val) 0.36954/0.39081. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.35861/0.38679. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.35325/0.39706. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.34738/0.37761. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.34234/0.37366. Took 0.15 sec\n",
      "Epoch 10, Loss(train/val) 0.33746/0.37784. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.33160/0.36508. Took 0.15 sec\n",
      "Epoch 12, Loss(train/val) 0.32119/0.35178. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.31421/0.34865. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.31260/0.35590. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.31127/0.36760. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.30544/0.36040. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.29809/0.36494. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.29580/0.36865. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.28890/0.37405. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.29153/0.38124. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.28723/0.37570. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.28777/0.39545. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.28089/0.39330. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.27877/0.39673. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.27706/0.40235. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.27181/0.40441. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.26456/0.41994. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.26516/0.40537. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.26427/0.40869. Took 0.14 sec\n",
      "Epoch 30, Loss(train/val) 0.25948/0.41317. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.24871/0.41352. Took 0.16 sec\n",
      "Epoch 32, Loss(train/val) 0.24781/0.40966. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.25968/0.39900. Took 0.16 sec\n",
      "Epoch 34, Loss(train/val) 0.24720/0.38709. Took 0.17 sec\n",
      "Epoch 35, Loss(train/val) 0.23953/0.38857. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.25053/0.39783. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.24414/0.40467. Took 0.16 sec\n",
      "Epoch 38, Loss(train/val) 0.23378/0.42170. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.23300/0.40234. Took 0.16 sec\n",
      "Epoch 40, Loss(train/val) 0.23170/0.38775. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.23146/0.39635. Took 0.16 sec\n",
      "Epoch 42, Loss(train/val) 0.23048/0.40862. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.22431/0.41913. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.22059/0.40893. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.21746/0.39565. Took 0.13 sec\n",
      "Epoch 46, Loss(train/val) 0.21193/0.41131. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.21956/0.39807. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.21338/0.39549. Took 0.14 sec\n",
      "Epoch 49, Loss(train/val) 0.20535/0.41392. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.20823/0.41896. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.20641/0.44019. Took 0.15 sec\n",
      "Epoch 52, Loss(train/val) 0.21129/0.40236. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.20852/0.42200. Took 0.15 sec\n",
      "Epoch 54, Loss(train/val) 0.19856/0.43021. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.20136/0.41901. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.20041/0.39790. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.20125/0.40400. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.19756/0.43376. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.19746/0.39368. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.19969/0.39666. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.19664/0.39226. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.18796/0.40310. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.18761/0.40057. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.18740/0.40312. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.17936/0.40979. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.18390/0.43201. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.18493/0.45714. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.18800/0.45507. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.18565/0.37954. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.18035/0.40422. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.17773/0.41893. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.17161/0.40221. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.17998/0.42549. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.17612/0.37454. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.17193/0.38835. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.17731/0.39243. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.17012/0.41926. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.17185/0.39594. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.16783/0.46401. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.16834/0.37880. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.17052/0.39421. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.16911/0.45550. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.17242/0.39408. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.16914/0.41684. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.16951/0.43899. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.15969/0.38706. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.16317/0.44840. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.16251/0.40358. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.15766/0.38943. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.16378/0.44534. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.16386/0.46777. Took 0.15 sec\n",
      "Epoch 92, Loss(train/val) 0.16364/0.45986. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.16030/0.43136. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.15777/0.47021. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.16186/0.47575. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.16267/0.43124. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.16096/0.39962. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.15658/0.38588. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.15642/0.41642. Took 0.14 sec\n",
      "ACC: 0.515625, MCC: 0.11617858011292062\n",
      "Epoch 0, Loss(train/val) 0.48966/0.50694. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.46560/0.50514. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.44039/0.47298. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.41145/0.42126. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.38963/0.39408. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.37348/0.38914. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.36490/0.37461. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.35860/0.36064. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.34637/0.37367. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.34286/0.33510. Took 0.15 sec\n",
      "Epoch 10, Loss(train/val) 0.33538/0.37488. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.33098/0.36950. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.32492/0.37234. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.32264/0.34341. Took 0.16 sec\n",
      "Epoch 14, Loss(train/val) 0.32058/0.34943. Took 0.15 sec\n",
      "Epoch 15, Loss(train/val) 0.31284/0.33826. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.32001/0.31168. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.31685/0.33373. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.30887/0.38636. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.30688/0.36338. Took 0.15 sec\n",
      "Epoch 20, Loss(train/val) 0.30443/0.33709. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.30550/0.33909. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.30152/0.34342. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.29132/0.35852. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.30193/0.35480. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.28409/0.33174. Took 0.16 sec\n",
      "Epoch 26, Loss(train/val) 0.29613/0.38020. Took 0.13 sec\n",
      "Epoch 27, Loss(train/val) 0.28883/0.33529. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.28648/0.37514. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.30462/0.36365. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.28416/0.33560. Took 0.16 sec\n",
      "Epoch 31, Loss(train/val) 0.28394/0.34455. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.27086/0.33855. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.28350/0.40442. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.27349/0.39089. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.27530/0.39349. Took 0.16 sec\n",
      "Epoch 36, Loss(train/val) 0.28132/0.38891. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.26994/0.33673. Took 0.16 sec\n",
      "Epoch 38, Loss(train/val) 0.26460/0.34244. Took 0.16 sec\n",
      "Epoch 39, Loss(train/val) 0.26049/0.33533. Took 0.15 sec\n",
      "Epoch 40, Loss(train/val) 0.25366/0.34821. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.25350/0.32635. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.25629/0.33737. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.24640/0.33022. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.25225/0.34258. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.24863/0.37207. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.24330/0.42776. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.25297/0.40988. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.24094/0.38140. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.23765/0.35528. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.23362/0.38500. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.23552/0.40034. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.22940/0.36648. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.24320/0.33863. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.22318/0.39908. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.22589/0.38683. Took 0.15 sec\n",
      "Epoch 56, Loss(train/val) 0.22720/0.39047. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.21509/0.34303. Took 0.15 sec\n",
      "Epoch 58, Loss(train/val) 0.21924/0.35102. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.21400/0.35465. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.21122/0.40016. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.20907/0.35585. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.22820/0.36505. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.21225/0.35161. Took 0.15 sec\n",
      "Epoch 64, Loss(train/val) 0.20588/0.36559. Took 0.14 sec\n",
      "Epoch 65, Loss(train/val) 0.21243/0.39226. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.20375/0.37917. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.19688/0.37619. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.20732/0.37366. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.20149/0.41142. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.20026/0.33523. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.18821/0.37398. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.20328/0.32166. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.20549/0.35103. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.19255/0.37361. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.18848/0.41370. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.20165/0.36469. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.18966/0.38242. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.18797/0.34780. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.19062/0.30757. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.20433/0.38682. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.19364/0.36989. Took 0.13 sec\n",
      "Epoch 82, Loss(train/val) 0.18369/0.40533. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.17379/0.42250. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.17833/0.38985. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.18204/0.33745. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.18470/0.36942. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.17065/0.38091. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.17282/0.28642. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.18274/0.42049. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.17822/0.39899. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.17148/0.38673. Took 0.15 sec\n",
      "Epoch 92, Loss(train/val) 0.17049/0.39223. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.17249/0.34707. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.17128/0.38681. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.16666/0.38427. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.16652/0.40041. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.16437/0.37339. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.15906/0.35609. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.15992/0.35227. Took 0.14 sec\n",
      "ACC: 0.609375, MCC: 0.2809057653515085\n",
      "Epoch 0, Loss(train/val) 0.49433/0.47838. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.47675/0.45739. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.45236/0.44334. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.42209/0.43289. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.40020/0.40415. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.38647/0.38823. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.37149/0.37187. Took 0.15 sec\n",
      "Epoch 7, Loss(train/val) 0.36801/0.35909. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.35067/0.34154. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.34428/0.33236. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.33566/0.33816. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.32509/0.33656. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.31607/0.30235. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.30924/0.29016. Took 0.16 sec\n",
      "Epoch 14, Loss(train/val) 0.30612/0.29514. Took 0.15 sec\n",
      "Epoch 15, Loss(train/val) 0.30114/0.29316. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.29837/0.29796. Took 0.15 sec\n",
      "Epoch 17, Loss(train/val) 0.29852/0.29905. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.28280/0.25766. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.29022/0.29425. Took 0.15 sec\n",
      "Epoch 20, Loss(train/val) 0.28965/0.29000. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.28620/0.27089. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.26931/0.28668. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.26614/0.25222. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.26772/0.25935. Took 0.16 sec\n",
      "Epoch 25, Loss(train/val) 0.26230/0.26159. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.26902/0.27877. Took 0.13 sec\n",
      "Epoch 27, Loss(train/val) 0.26216/0.25341. Took 0.16 sec\n",
      "Epoch 28, Loss(train/val) 0.25901/0.30149. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.25749/0.27284. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.25484/0.30604. Took 0.13 sec\n",
      "Epoch 31, Loss(train/val) 0.24924/0.27549. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.25453/0.29854. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.24285/0.29087. Took 0.16 sec\n",
      "Epoch 34, Loss(train/val) 0.23308/0.27420. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.23613/0.26903. Took 0.16 sec\n",
      "Epoch 36, Loss(train/val) 0.22674/0.28399. Took 0.17 sec\n",
      "Epoch 37, Loss(train/val) 0.22547/0.30209. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.23828/0.29506. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.22575/0.28976. Took 0.16 sec\n",
      "Epoch 40, Loss(train/val) 0.22542/0.27472. Took 0.15 sec\n",
      "Epoch 41, Loss(train/val) 0.22675/0.30775. Took 0.16 sec\n",
      "Epoch 42, Loss(train/val) 0.22098/0.28996. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.21844/0.30159. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.21367/0.29080. Took 0.15 sec\n",
      "Epoch 45, Loss(train/val) 0.21588/0.27909. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.20764/0.30319. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.20363/0.33249. Took 0.15 sec\n",
      "Epoch 48, Loss(train/val) 0.20167/0.34155. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.19742/0.32162. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.20604/0.32288. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.19900/0.31511. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.20875/0.30471. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.19456/0.29190. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.18945/0.31638. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.18683/0.32474. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.18852/0.31816. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.18095/0.32911. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.18095/0.31824. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.18651/0.31199. Took 0.13 sec\n",
      "Epoch 60, Loss(train/val) 0.19091/0.32269. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.17757/0.32292. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.17889/0.31852. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.18365/0.31398. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.18014/0.30247. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.18089/0.31847. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.17286/0.30619. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.17091/0.32271. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.17138/0.33224. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.16538/0.31418. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.16795/0.31716. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.16461/0.30880. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.16770/0.33092. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.15828/0.32671. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.15961/0.31801. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.15991/0.32534. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.15361/0.33169. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.15202/0.30649. Took 0.15 sec\n",
      "Epoch 78, Loss(train/val) 0.15435/0.33645. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.15239/0.31481. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.14687/0.33993. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.15294/0.33329. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.15021/0.33254. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.15529/0.31491. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.14781/0.31893. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.14405/0.32339. Took 0.15 sec\n",
      "Epoch 86, Loss(train/val) 0.15394/0.31900. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.15037/0.31458. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.13705/0.29046. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.14774/0.31741. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.13373/0.32265. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.13634/0.29733. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.13564/0.34167. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.14843/0.29489. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.14375/0.30912. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.14069/0.31472. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.13841/0.30161. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.14715/0.34058. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.13920/0.32338. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.13545/0.34551. Took 0.14 sec\n",
      "ACC: 0.6875, MCC: 0.35644472409976224\n",
      "Epoch 0, Loss(train/val) 0.49407/0.47508. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.47440/0.44070. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.44721/0.40813. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.41912/0.38403. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.39716/0.37992. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.38298/0.37798. Took 0.15 sec\n",
      "Epoch 6, Loss(train/val) 0.36529/0.37138. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.36100/0.35450. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.35888/0.32552. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.34322/0.31537. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.33771/0.31440. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.32526/0.31019. Took 0.14 sec\n",
      "Epoch 12, Loss(train/val) 0.32359/0.32286. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.30534/0.31721. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.29255/0.31962. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.29436/0.32138. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.29718/0.31322. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.28194/0.32785. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.29269/0.33190. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.26929/0.32725. Took 0.15 sec\n",
      "Epoch 20, Loss(train/val) 0.26454/0.33323. Took 0.15 sec\n",
      "Epoch 21, Loss(train/val) 0.27001/0.34380. Took 0.14 sec\n",
      "Epoch 22, Loss(train/val) 0.26903/0.36425. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.26599/0.36104. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.26764/0.36447. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.26066/0.35889. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.25137/0.35898. Took 0.13 sec\n",
      "Epoch 27, Loss(train/val) 0.24882/0.35817. Took 0.16 sec\n",
      "Epoch 28, Loss(train/val) 0.24323/0.35524. Took 0.16 sec\n",
      "Epoch 29, Loss(train/val) 0.24354/0.36210. Took 0.13 sec\n",
      "Epoch 30, Loss(train/val) 0.23053/0.34494. Took 0.13 sec\n",
      "Epoch 31, Loss(train/val) 0.23617/0.34132. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.22970/0.33963. Took 0.13 sec\n",
      "Epoch 33, Loss(train/val) 0.23579/0.35519. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.23252/0.35079. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.23091/0.37412. Took 0.16 sec\n",
      "Epoch 36, Loss(train/val) 0.23172/0.35605. Took 0.16 sec\n",
      "Epoch 37, Loss(train/val) 0.21757/0.36361. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.22808/0.36308. Took 0.15 sec\n",
      "Epoch 39, Loss(train/val) 0.22911/0.36598. Took 0.17 sec\n",
      "Epoch 40, Loss(train/val) 0.22401/0.37313. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.23224/0.36687. Took 0.17 sec\n",
      "Epoch 42, Loss(train/val) 0.22653/0.36726. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.21642/0.40439. Took 0.15 sec\n",
      "Epoch 44, Loss(train/val) 0.21504/0.35541. Took 0.15 sec\n",
      "Epoch 45, Loss(train/val) 0.20488/0.37589. Took 0.16 sec\n",
      "Epoch 46, Loss(train/val) 0.21100/0.38051. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.19878/0.39715. Took 0.15 sec\n",
      "Epoch 48, Loss(train/val) 0.20157/0.39242. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.20130/0.40332. Took 0.15 sec\n",
      "Epoch 50, Loss(train/val) 0.19420/0.38520. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.20555/0.39802. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.20289/0.38837. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.19857/0.38313. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.19106/0.38391. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.21253/0.40049. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.19869/0.38497. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.18987/0.39133. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.19379/0.37531. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.20333/0.39974. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.18641/0.38529. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.18485/0.37259. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.18302/0.37846. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.17895/0.39138. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.19005/0.38405. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.17897/0.38375. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.18685/0.38212. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.18368/0.38964. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.16769/0.37737. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.17520/0.37385. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.17933/0.36884. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.16901/0.37244. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.16763/0.39023. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.16501/0.37688. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.18477/0.36235. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.19086/0.32454. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.18141/0.35148. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.17470/0.35836. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.17712/0.35627. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.16545/0.38589. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.17003/0.38582. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.16108/0.38304. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.16983/0.40801. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.16759/0.39184. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.16002/0.41611. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.15901/0.41952. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.16162/0.42008. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.15749/0.39387. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.15746/0.38338. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.15105/0.36773. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.16165/0.36277. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.14964/0.39951. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.15438/0.42151. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.15987/0.45059. Took 0.15 sec\n",
      "Epoch 94, Loss(train/val) 0.16348/0.44657. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.16544/0.41694. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.15579/0.43708. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.14792/0.40158. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.14624/0.41899. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.14395/0.42810. Took 0.13 sec\n",
      "ACC: 0.671875, MCC: 0.34908762763709134\n",
      "Epoch 0, Loss(train/val) 0.49435/0.48814. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.47719/0.47099. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.44928/0.45313. Took 0.15 sec\n",
      "Epoch 3, Loss(train/val) 0.42164/0.44964. Took 0.16 sec\n",
      "Epoch 4, Loss(train/val) 0.40191/0.44421. Took 0.16 sec\n",
      "Epoch 5, Loss(train/val) 0.39072/0.44412. Took 0.15 sec\n",
      "Epoch 6, Loss(train/val) 0.38432/0.41577. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.36967/0.43458. Took 0.16 sec\n",
      "Epoch 8, Loss(train/val) 0.36069/0.40026. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.35724/0.40997. Took 0.16 sec\n",
      "Epoch 10, Loss(train/val) 0.33959/0.39298. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.33690/0.38482. Took 0.15 sec\n",
      "Epoch 12, Loss(train/val) 0.33190/0.39495. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.32151/0.38435. Took 0.13 sec\n",
      "Epoch 14, Loss(train/val) 0.31619/0.41290. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.33240/0.37448. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.31579/0.39875. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.32242/0.38028. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.30569/0.37264. Took 0.15 sec\n",
      "Epoch 19, Loss(train/val) 0.31032/0.38679. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.30564/0.37650. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.29764/0.38329. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.29219/0.37009. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.28777/0.38024. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.29381/0.39743. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.28250/0.37256. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.27817/0.36791. Took 0.14 sec\n",
      "Epoch 27, Loss(train/val) 0.27487/0.39425. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.27124/0.37585. Took 0.13 sec\n",
      "Epoch 29, Loss(train/val) 0.27754/0.37411. Took 0.16 sec\n",
      "Epoch 30, Loss(train/val) 0.26178/0.38946. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.26862/0.39016. Took 0.16 sec\n",
      "Epoch 32, Loss(train/val) 0.25857/0.39322. Took 0.16 sec\n",
      "Epoch 33, Loss(train/val) 0.25570/0.38128. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.25437/0.40430. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.25742/0.40697. Took 0.16 sec\n",
      "Epoch 36, Loss(train/val) 0.25622/0.39289. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.24729/0.39856. Took 0.16 sec\n",
      "Epoch 38, Loss(train/val) 0.24625/0.39699. Took 0.16 sec\n",
      "Epoch 39, Loss(train/val) 0.24581/0.40694. Took 0.15 sec\n",
      "Epoch 40, Loss(train/val) 0.24817/0.39517. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.24764/0.39440. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.23903/0.40303. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.24193/0.36973. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.23659/0.40332. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.23938/0.40896. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.23303/0.40125. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.24125/0.40702. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.22629/0.41884. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.21973/0.41512. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.22451/0.41988. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.22212/0.40128. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.22297/0.42095. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.21831/0.39972. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.21276/0.41562. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.20891/0.40520. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.20915/0.40883. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.20954/0.41470. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.21849/0.42224. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.20174/0.42716. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.21269/0.40785. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.21261/0.42369. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.19932/0.40633. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.19834/0.43632. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.20558/0.42790. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.19684/0.41688. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.19586/0.40708. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.19681/0.41302. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.19621/0.42100. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.19807/0.40385. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.19572/0.41471. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.18864/0.39557. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.19486/0.42134. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.18771/0.40080. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.19315/0.42375. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.19500/0.42410. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.17906/0.41966. Took 0.14 sec\n",
      "Epoch 77, Loss(train/val) 0.18101/0.42391. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.17751/0.42586. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.18110/0.43319. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.18646/0.42130. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.17711/0.42065. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.17466/0.41706. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.18358/0.42029. Took 0.15 sec\n",
      "Epoch 84, Loss(train/val) 0.17931/0.41184. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.17739/0.42715. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.16758/0.41117. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.16975/0.42043. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.16426/0.39274. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.16383/0.41440. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.16078/0.40185. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.16336/0.40166. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.15447/0.40836. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.16846/0.40280. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.15587/0.41452. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.16361/0.41141. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.16232/0.38517. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.16050/0.41217. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.16520/0.41301. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.15763/0.40515. Took 0.14 sec\n",
      "ACC: 0.6875, MCC: 0.40451991747794525\n",
      "Epoch 0, Loss(train/val) 0.49713/0.48973. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.48589/0.46877. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.46610/0.42679. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.43701/0.38547. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.41119/0.36937. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.39529/0.36397. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.38267/0.32642. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.36865/0.39405. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.36624/0.36661. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.34774/0.32231. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.34099/0.31769. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.32353/0.36515. Took 0.15 sec\n",
      "Epoch 12, Loss(train/val) 0.32835/0.43021. Took 0.16 sec\n",
      "Epoch 13, Loss(train/val) 0.33112/0.43577. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.32586/0.40454. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.31622/0.37436. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.30387/0.43837. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.30655/0.41851. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.29255/0.44565. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.30010/0.41575. Took 0.16 sec\n",
      "Epoch 20, Loss(train/val) 0.29391/0.41506. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.28427/0.42859. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.28405/0.42328. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.27874/0.43037. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.27673/0.43911. Took 0.14 sec\n",
      "Epoch 25, Loss(train/val) 0.26842/0.44377. Took 0.14 sec\n",
      "Epoch 26, Loss(train/val) 0.27992/0.40996. Took 0.15 sec\n",
      "Epoch 27, Loss(train/val) 0.26941/0.36500. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.28640/0.32532. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.27283/0.43728. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.26972/0.41744. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.26085/0.42429. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.25431/0.42519. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.25620/0.44122. Took 0.18 sec\n",
      "Epoch 34, Loss(train/val) 0.25925/0.43315. Took 0.16 sec\n",
      "Epoch 35, Loss(train/val) 0.24425/0.43041. Took 0.15 sec\n",
      "Epoch 36, Loss(train/val) 0.25013/0.42555. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.25177/0.41747. Took 0.16 sec\n",
      "Epoch 38, Loss(train/val) 0.23845/0.43837. Took 0.15 sec\n",
      "Epoch 39, Loss(train/val) 0.23981/0.42308. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.23989/0.41069. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.23722/0.42574. Took 0.16 sec\n",
      "Epoch 42, Loss(train/val) 0.24060/0.43733. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.24569/0.38479. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.23570/0.42070. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.22281/0.41697. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.22906/0.42625. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.22751/0.41770. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.22325/0.42134. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.22652/0.40023. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.22612/0.42272. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.23349/0.38039. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.22117/0.43174. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.21887/0.41389. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.22569/0.39990. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.21400/0.39667. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.21345/0.43451. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.22691/0.44434. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.21463/0.41482. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.20974/0.42650. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.20922/0.42362. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.19692/0.43383. Took 0.13 sec\n",
      "Epoch 62, Loss(train/val) 0.19199/0.42517. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.19451/0.43629. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.20104/0.40328. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.18979/0.39117. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.20290/0.45486. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.19080/0.42580. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.19437/0.41123. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.19346/0.42723. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.18378/0.42291. Took 0.15 sec\n",
      "Epoch 71, Loss(train/val) 0.18155/0.40124. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.18391/0.40634. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.18300/0.44243. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.19053/0.43397. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.18497/0.40028. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.17675/0.42906. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.17546/0.41132. Took 0.15 sec\n",
      "Epoch 78, Loss(train/val) 0.16965/0.41412. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.17610/0.35425. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.17712/0.37432. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.17780/0.35348. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.17956/0.36804. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.17846/0.38478. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.16931/0.40338. Took 0.14 sec\n",
      "Epoch 85, Loss(train/val) 0.17040/0.37995. Took 0.15 sec\n",
      "Epoch 86, Loss(train/val) 0.16094/0.39846. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.15664/0.38070. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.16448/0.42981. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.15402/0.38345. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.14822/0.38181. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.15416/0.39711. Took 0.15 sec\n",
      "Epoch 92, Loss(train/val) 0.15724/0.43381. Took 0.14 sec\n",
      "Epoch 93, Loss(train/val) 0.15180/0.37462. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.15437/0.38659. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.14291/0.43534. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.14569/0.40911. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.15528/0.40567. Took 0.15 sec\n",
      "Epoch 98, Loss(train/val) 0.14834/0.41491. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.13525/0.40449. Took 0.14 sec\n",
      "ACC: 0.453125, MCC: 0.1111111111111111\n",
      "Epoch 0, Loss(train/val) 0.49526/0.49187. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.47802/0.48300. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.45162/0.46300. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.41930/0.44616. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.39687/0.42470. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.38144/0.41002. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.36980/0.40742. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.36045/0.41685. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.34286/0.46507. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.34151/0.39827. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.32550/0.46207. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.31866/0.39879. Took 0.15 sec\n",
      "Epoch 12, Loss(train/val) 0.30919/0.48386. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.32240/0.43966. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.29764/0.47868. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.29873/0.46943. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.29108/0.35239. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.27965/0.34507. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.28052/0.47632. Took 0.15 sec\n",
      "Epoch 19, Loss(train/val) 0.27689/0.39955. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.27430/0.37413. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.26058/0.42690. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.25730/0.40111. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.26118/0.43491. Took 0.16 sec\n",
      "Epoch 24, Loss(train/val) 0.26024/0.50274. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.27107/0.34488. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.25602/0.45613. Took 0.13 sec\n",
      "Epoch 27, Loss(train/val) 0.24479/0.39887. Took 0.16 sec\n",
      "Epoch 28, Loss(train/val) 0.24919/0.37426. Took 0.13 sec\n",
      "Epoch 29, Loss(train/val) 0.23714/0.36183. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.23348/0.37639. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.23668/0.37656. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.23080/0.38908. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.23284/0.33249. Took 0.16 sec\n",
      "Epoch 34, Loss(train/val) 0.22537/0.33616. Took 0.16 sec\n",
      "Epoch 35, Loss(train/val) 0.21940/0.37834. Took 0.15 sec\n",
      "Epoch 36, Loss(train/val) 0.23240/0.37713. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.22211/0.39970. Took 0.16 sec\n",
      "Epoch 38, Loss(train/val) 0.22212/0.37938. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.20986/0.39212. Took 0.17 sec\n",
      "Epoch 40, Loss(train/val) 0.20704/0.43132. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.21650/0.38401. Took 0.15 sec\n",
      "Epoch 42, Loss(train/val) 0.20528/0.33802. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.21057/0.41183. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.20863/0.32716. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.21178/0.38427. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.19963/0.40194. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.19922/0.37805. Took 0.15 sec\n",
      "Epoch 48, Loss(train/val) 0.19170/0.34807. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.19546/0.35882. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.19656/0.34915. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.20162/0.37719. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.19359/0.28257. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.19011/0.33354. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.19820/0.36887. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.19339/0.30592. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.18600/0.36978. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.17921/0.33874. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.17963/0.30777. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.17689/0.32039. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.18147/0.33446. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.17972/0.40127. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.18598/0.28021. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.16911/0.33962. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.16580/0.32572. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.16977/0.30589. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.16731/0.30077. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.16569/0.29002. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.15820/0.31724. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.15819/0.28535. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.16751/0.29975. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.16160/0.29678. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.15924/0.31761. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.16328/0.28333. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.15249/0.35229. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) 0.17421/0.27517. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.15966/0.37242. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.16616/0.29885. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.17718/0.45272. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.16119/0.32770. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.14874/0.33133. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.15013/0.39895. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.14956/0.36358. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.14766/0.34225. Took 0.16 sec\n",
      "Epoch 84, Loss(train/val) 0.15686/0.39427. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.14525/0.31553. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.14909/0.29566. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.14958/0.39036. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.15212/0.36933. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.14671/0.29152. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.14368/0.34201. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.14325/0.27181. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.14863/0.30736. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.14377/0.32040. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.14239/0.36099. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.14261/0.30020. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.14295/0.28168. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.14068/0.31991. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.13973/0.33103. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.13731/0.32081. Took 0.15 sec\n",
      "ACC: 0.671875, MCC: 0.33435877499548305\n",
      "Epoch 0, Loss(train/val) 0.49423/0.48648. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.47322/0.45692. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.44022/0.42120. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.41180/0.40764. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.39430/0.40818. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.38149/0.40863. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.37295/0.40482. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.36319/0.39570. Took 0.15 sec\n",
      "Epoch 8, Loss(train/val) 0.35883/0.40105. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.36052/0.39946. Took 0.15 sec\n",
      "Epoch 10, Loss(train/val) 0.35117/0.39895. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.34620/0.40355. Took 0.15 sec\n",
      "Epoch 12, Loss(train/val) 0.33517/0.40358. Took 0.14 sec\n",
      "Epoch 13, Loss(train/val) 0.33725/0.39006. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.32975/0.36415. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.36091/0.37284. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.33001/0.39619. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.32236/0.37916. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.31956/0.37842. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.30693/0.32950. Took 0.15 sec\n",
      "Epoch 20, Loss(train/val) 0.30603/0.33506. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.30986/0.33026. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.29557/0.31631. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.28282/0.31699. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.28807/0.31593. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.28240/0.33729. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.27880/0.33094. Took 0.15 sec\n",
      "Epoch 27, Loss(train/val) 0.27094/0.33625. Took 0.16 sec\n",
      "Epoch 28, Loss(train/val) 0.26796/0.33724. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.26339/0.33942. Took 0.16 sec\n",
      "Epoch 30, Loss(train/val) 0.27050/0.34244. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.25980/0.33670. Took 0.16 sec\n",
      "Epoch 32, Loss(train/val) 0.25544/0.32221. Took 0.15 sec\n",
      "Epoch 33, Loss(train/val) 0.25144/0.33450. Took 0.16 sec\n",
      "Epoch 34, Loss(train/val) 0.24842/0.33314. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.24682/0.33634. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.24213/0.35011. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.22837/0.36763. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.23530/0.37437. Took 0.13 sec\n",
      "Epoch 39, Loss(train/val) 0.23156/0.35352. Took 0.15 sec\n",
      "Epoch 40, Loss(train/val) 0.23144/0.35119. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.21570/0.37586. Took 0.14 sec\n",
      "Epoch 42, Loss(train/val) 0.22866/0.36040. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.22092/0.36145. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.22083/0.35068. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.21518/0.35379. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.21023/0.36691. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.20047/0.37173. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.20041/0.38527. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.19833/0.38100. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.20372/0.36255. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.19632/0.36942. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.20278/0.38049. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.18215/0.37209. Took 0.13 sec\n",
      "Epoch 54, Loss(train/val) 0.19298/0.37814. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.19784/0.39452. Took 0.15 sec\n",
      "Epoch 56, Loss(train/val) 0.17960/0.40996. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.18114/0.39615. Took 0.13 sec\n",
      "Epoch 58, Loss(train/val) 0.18981/0.38745. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.19389/0.38984. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.18172/0.38403. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.18123/0.38490. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.18436/0.35940. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.17492/0.38620. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.17006/0.36891. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.17628/0.39038. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.16435/0.39575. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.16106/0.37435. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.16275/0.38777. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.15495/0.39733. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.16557/0.40441. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.15751/0.39322. Took 0.16 sec\n",
      "Epoch 72, Loss(train/val) 0.15282/0.38134. Took 0.14 sec\n",
      "Epoch 73, Loss(train/val) 0.16789/0.39957. Took 0.15 sec\n",
      "Epoch 74, Loss(train/val) 0.16881/0.37189. Took 0.14 sec\n",
      "Epoch 75, Loss(train/val) 0.16909/0.36670. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.15496/0.37139. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.15982/0.39008. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.15147/0.38557. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.14970/0.37690. Took 0.15 sec\n",
      "Epoch 80, Loss(train/val) 0.15136/0.37881. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.14978/0.38109. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.15347/0.37514. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.14345/0.38282. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.15051/0.37835. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.14127/0.36057. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.14501/0.38662. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.12892/0.38623. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.13176/0.37280. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.13012/0.36799. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.13313/0.37185. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.13712/0.40064. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.15053/0.41533. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.13784/0.39625. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.13108/0.40874. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.13148/0.41607. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.13643/0.38425. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.12700/0.39523. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.12867/0.39656. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.13482/0.39200. Took 0.14 sec\n",
      "ACC: 0.625, MCC: 0.24305875451990117\n",
      "Epoch 0, Loss(train/val) 0.49586/0.48778. Took 0.16 sec\n",
      "Epoch 1, Loss(train/val) 0.47552/0.46087. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.44439/0.39852. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.41223/0.34957. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.38821/0.32777. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.37593/0.32574. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.36940/0.31071. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.36038/0.30290. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.35605/0.34753. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.35706/0.30582. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.35828/0.31795. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.34705/0.38247. Took 0.15 sec\n",
      "Epoch 12, Loss(train/val) 0.34019/0.45375. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.34095/0.44152. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.33507/0.47277. Took 0.13 sec\n",
      "Epoch 15, Loss(train/val) 0.32717/0.45985. Took 0.13 sec\n",
      "Epoch 16, Loss(train/val) 0.31892/0.46369. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.32376/0.48204. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.31461/0.48055. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.30718/0.50530. Took 0.13 sec\n",
      "Epoch 20, Loss(train/val) 0.30459/0.51340. Took 0.14 sec\n",
      "Epoch 21, Loss(train/val) 0.29541/0.51478. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.29167/0.50753. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.28507/0.41972. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.28782/0.52323. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.28162/0.51324. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.27262/0.47769. Took 0.13 sec\n",
      "Epoch 27, Loss(train/val) 0.26289/0.50863. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.26514/0.45877. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.27050/0.52912. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.25052/0.52638. Took 0.13 sec\n",
      "Epoch 31, Loss(train/val) 0.25183/0.52290. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.24307/0.52362. Took 0.13 sec\n",
      "Epoch 33, Loss(train/val) 0.24652/0.51339. Took 0.16 sec\n",
      "Epoch 34, Loss(train/val) 0.23757/0.49123. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.23692/0.49517. Took 0.17 sec\n",
      "Epoch 36, Loss(train/val) 0.23132/0.49375. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.22288/0.43268. Took 0.15 sec\n",
      "Epoch 38, Loss(train/val) 0.22624/0.45686. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.21738/0.43882. Took 0.16 sec\n",
      "Epoch 40, Loss(train/val) 0.21846/0.47616. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.21179/0.36763. Took 0.17 sec\n",
      "Epoch 42, Loss(train/val) 0.21249/0.45151. Took 0.15 sec\n",
      "Epoch 43, Loss(train/val) 0.20624/0.39475. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.20295/0.42005. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.20644/0.42540. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.20377/0.43018. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.20077/0.39332. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.19430/0.38303. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.19420/0.38305. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.19721/0.36223. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.18615/0.43896. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.18726/0.45874. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.18673/0.41609. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.18772/0.39406. Took 0.14 sec\n",
      "Epoch 55, Loss(train/val) 0.18242/0.43355. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.17167/0.40515. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.17072/0.39461. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.17337/0.48323. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.18729/0.44139. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.17367/0.41217. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.17431/0.45142. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.17688/0.42643. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.17147/0.44424. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.16792/0.45002. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.16008/0.45566. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.16715/0.42956. Took 0.14 sec\n",
      "Epoch 67, Loss(train/val) 0.16014/0.44233. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.16583/0.44969. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.17409/0.39615. Took 0.13 sec\n",
      "Epoch 70, Loss(train/val) 0.16257/0.39394. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.15084/0.41740. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.15398/0.40676. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.15347/0.44984. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.15966/0.45952. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.15216/0.43215. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.15192/0.47097. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.15319/0.46363. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.15023/0.45805. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.14830/0.48549. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.13732/0.48331. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.14709/0.46700. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.14273/0.45799. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.14084/0.49275. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.13077/0.46892. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.13756/0.44927. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.13789/0.45066. Took 0.14 sec\n",
      "Epoch 87, Loss(train/val) 0.14167/0.45698. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.14102/0.44379. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.13541/0.44821. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.14367/0.41732. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.12982/0.44840. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.13416/0.43410. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.13254/0.45375. Took 0.15 sec\n",
      "Epoch 94, Loss(train/val) 0.12840/0.45220. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.12971/0.43746. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.13479/0.35089. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.13086/0.44440. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.12159/0.39335. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.12453/0.41290. Took 0.14 sec\n",
      "ACC: 0.53125, MCC: 0.06825406626599889\n",
      "Epoch 0, Loss(train/val) 0.49358/0.49239. Took 0.14 sec\n",
      "Epoch 1, Loss(train/val) 0.47345/0.47458. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.44080/0.43105. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.40906/0.40508. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.39393/0.39883. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.38281/0.40121. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.37276/0.40680. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.36866/0.39872. Took 0.15 sec\n",
      "Epoch 8, Loss(train/val) 0.36333/0.39104. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.35874/0.38474. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.35289/0.39594. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.34871/0.36793. Took 0.16 sec\n",
      "Epoch 12, Loss(train/val) 0.33794/0.40386. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.33628/0.39611. Took 0.16 sec\n",
      "Epoch 14, Loss(train/val) 0.32672/0.38334. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.31624/0.39767. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.31219/0.39261. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.31121/0.41669. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.29912/0.41931. Took 0.15 sec\n",
      "Epoch 19, Loss(train/val) 0.29415/0.45903. Took 0.14 sec\n",
      "Epoch 20, Loss(train/val) 0.29395/0.43083. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.29467/0.43200. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.28294/0.43006. Took 0.13 sec\n",
      "Epoch 23, Loss(train/val) 0.29310/0.48745. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.28205/0.48407. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.27860/0.46925. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.27717/0.42163. Took 0.13 sec\n",
      "Epoch 27, Loss(train/val) 0.26976/0.38353. Took 0.16 sec\n",
      "Epoch 28, Loss(train/val) 0.27078/0.47444. Took 0.14 sec\n",
      "Epoch 29, Loss(train/val) 0.25640/0.44830. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.25484/0.45571. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.26518/0.41635. Took 0.17 sec\n",
      "Epoch 32, Loss(train/val) 0.25519/0.40437. Took 0.17 sec\n",
      "Epoch 33, Loss(train/val) 0.24014/0.42080. Took 0.14 sec\n",
      "Epoch 34, Loss(train/val) 0.25480/0.40888. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.25406/0.43529. Took 0.16 sec\n",
      "Epoch 36, Loss(train/val) 0.24863/0.39893. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.23701/0.41225. Took 0.15 sec\n",
      "Epoch 38, Loss(train/val) 0.23431/0.40965. Took 0.15 sec\n",
      "Epoch 39, Loss(train/val) 0.23061/0.40900. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.22416/0.42506. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.23169/0.41388. Took 0.15 sec\n",
      "Epoch 42, Loss(train/val) 0.22141/0.39457. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.22687/0.40847. Took 0.13 sec\n",
      "Epoch 44, Loss(train/val) 0.22004/0.42432. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.21487/0.41401. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.21085/0.39440. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.21355/0.38117. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.20003/0.41215. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.20152/0.40663. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.20907/0.40319. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.18993/0.38652. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.19198/0.37981. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.19204/0.39609. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.18770/0.40176. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.18869/0.37880. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.18285/0.39746. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.18737/0.38581. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.18226/0.40214. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.18740/0.38502. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.18669/0.39275. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.18040/0.39020. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.18608/0.41258. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.18492/0.38073. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.17231/0.42077. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.17367/0.42512. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.16877/0.38853. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.17046/0.41621. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.16768/0.36969. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.15763/0.41485. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.15819/0.40398. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.16330/0.38225. Took 0.15 sec\n",
      "Epoch 72, Loss(train/val) 0.15662/0.41252. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.15982/0.43801. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.16136/0.42438. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.15976/0.41004. Took 0.15 sec\n",
      "Epoch 76, Loss(train/val) 0.15436/0.42391. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.15474/0.38877. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.15948/0.41001. Took 0.14 sec\n",
      "Epoch 79, Loss(train/val) 0.15768/0.42462. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.14635/0.40006. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.14892/0.39678. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.13949/0.41175. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.13836/0.41500. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.13833/0.39393. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.13856/0.39167. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.14373/0.36256. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.14880/0.39568. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.13794/0.39603. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.12918/0.38932. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.14001/0.39857. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.13104/0.37800. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.12794/0.40186. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.13599/0.38938. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.13823/0.40323. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.13494/0.38560. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.13390/0.35969. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.12553/0.41540. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.12473/0.40511. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.12945/0.40974. Took 0.14 sec\n",
      "ACC: 0.578125, MCC: 0.28137670960041816\n",
      "Epoch 0, Loss(train/val) 0.49315/0.46936. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.47133/0.41174. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.43747/0.33546. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.40329/0.28007. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.38418/0.26386. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.36804/0.25858. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.35695/0.26677. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.35197/0.27271. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.34766/0.26640. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.33707/0.27652. Took 0.13 sec\n",
      "Epoch 10, Loss(train/val) 0.33159/0.27953. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.32601/0.29229. Took 0.15 sec\n",
      "Epoch 12, Loss(train/val) 0.31815/0.27609. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.31121/0.30722. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.30309/0.28180. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.30418/0.30215. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.29229/0.30274. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.28426/0.30431. Took 0.14 sec\n",
      "Epoch 18, Loss(train/val) 0.28778/0.31454. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.27929/0.30901. Took 0.15 sec\n",
      "Epoch 20, Loss(train/val) 0.27936/0.31106. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.26631/0.30463. Took 0.16 sec\n",
      "Epoch 22, Loss(train/val) 0.27305/0.31202. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.26262/0.30780. Took 0.13 sec\n",
      "Epoch 24, Loss(train/val) 0.26464/0.29517. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.27027/0.30334. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.27338/0.28793. Took 0.13 sec\n",
      "Epoch 27, Loss(train/val) 0.26161/0.29354. Took 0.13 sec\n",
      "Epoch 28, Loss(train/val) 0.25190/0.27888. Took 0.13 sec\n",
      "Epoch 29, Loss(train/val) 0.25048/0.31348. Took 0.16 sec\n",
      "Epoch 30, Loss(train/val) 0.25287/0.31371. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.24155/0.29603. Took 0.14 sec\n",
      "Epoch 32, Loss(train/val) 0.24756/0.26707. Took 0.16 sec\n",
      "Epoch 33, Loss(train/val) 0.24557/0.28181. Took 0.18 sec\n",
      "Epoch 34, Loss(train/val) 0.24462/0.27392. Took 0.17 sec\n",
      "Epoch 35, Loss(train/val) 0.24025/0.27364. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.24308/0.27718. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.23894/0.29474. Took 0.16 sec\n",
      "Epoch 38, Loss(train/val) 0.22840/0.29028. Took 0.14 sec\n",
      "Epoch 39, Loss(train/val) 0.24460/0.28247. Took 0.17 sec\n",
      "Epoch 40, Loss(train/val) 0.22545/0.28825. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.22306/0.28688. Took 0.15 sec\n",
      "Epoch 42, Loss(train/val) 0.23068/0.29725. Took 0.13 sec\n",
      "Epoch 43, Loss(train/val) 0.23901/0.27792. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.22349/0.29351. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.22130/0.28953. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.21785/0.29266. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.21361/0.28843. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.21569/0.28872. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.21442/0.29127. Took 0.13 sec\n",
      "Epoch 50, Loss(train/val) 0.20993/0.30107. Took 0.14 sec\n",
      "Epoch 51, Loss(train/val) 0.21432/0.27980. Took 0.13 sec\n",
      "Epoch 52, Loss(train/val) 0.22187/0.28612. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.20647/0.29519. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.21833/0.30807. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.21135/0.28769. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.20582/0.30122. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.20229/0.31218. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.20419/0.30358. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.20053/0.30377. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.21175/0.28376. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.20430/0.27088. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.21094/0.30721. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.20705/0.31289. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.21115/0.30983. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.18840/0.30768. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.19315/0.32349. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.18645/0.30723. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.19985/0.30399. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.18912/0.31742. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.19248/0.31620. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.19386/0.30525. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.19018/0.30050. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.18572/0.32254. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.17737/0.31157. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.18871/0.31506. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.18036/0.31347. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.18296/0.31632. Took 0.13 sec\n",
      "Epoch 78, Loss(train/val) 0.17682/0.28947. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.18207/0.29488. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.17914/0.29176. Took 0.12 sec\n",
      "Epoch 81, Loss(train/val) 0.17740/0.30761. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.17903/0.29233. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.17598/0.29273. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.17379/0.30019. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.16908/0.30471. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.17261/0.30226. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.16881/0.28645. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.16573/0.29172. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.16044/0.28385. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.15973/0.29026. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.16795/0.28511. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.15995/0.29681. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.16075/0.29188. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.16280/0.28285. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.16012/0.29052. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.16926/0.30308. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.16043/0.29225. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.15684/0.29486. Took 0.14 sec\n",
      "Epoch 99, Loss(train/val) 0.15506/0.29219. Took 0.14 sec\n",
      "ACC: 0.59375, MCC: 0.18670576735092864\n",
      "Epoch 0, Loss(train/val) 0.49499/0.49289. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.47549/0.47129. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.44673/0.42895. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.41547/0.39296. Took 0.13 sec\n",
      "Epoch 4, Loss(train/val) 0.39259/0.38042. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.37544/0.37524. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.36191/0.36829. Took 0.14 sec\n",
      "Epoch 7, Loss(train/val) 0.35479/0.35881. Took 0.13 sec\n",
      "Epoch 8, Loss(train/val) 0.34284/0.36547. Took 0.14 sec\n",
      "Epoch 9, Loss(train/val) 0.33715/0.36467. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.32918/0.38429. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.32655/0.38316. Took 0.15 sec\n",
      "Epoch 12, Loss(train/val) 0.31736/0.38088. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.31064/0.37642. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.31211/0.37058. Took 0.15 sec\n",
      "Epoch 15, Loss(train/val) 0.29691/0.40294. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.29247/0.38430. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.28885/0.39756. Took 0.13 sec\n",
      "Epoch 18, Loss(train/val) 0.27779/0.38018. Took 0.13 sec\n",
      "Epoch 19, Loss(train/val) 0.27551/0.38482. Took 0.15 sec\n",
      "Epoch 20, Loss(train/val) 0.27089/0.37921. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.27243/0.39082. Took 0.13 sec\n",
      "Epoch 22, Loss(train/val) 0.27169/0.37702. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.26623/0.37954. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.26448/0.39122. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.25173/0.37721. Took 0.13 sec\n",
      "Epoch 26, Loss(train/val) 0.26031/0.38898. Took 0.13 sec\n",
      "Epoch 27, Loss(train/val) 0.25220/0.37342. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.24260/0.37244. Took 0.13 sec\n",
      "Epoch 29, Loss(train/val) 0.23555/0.36824. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.24080/0.37764. Took 0.15 sec\n",
      "Epoch 31, Loss(train/val) 0.23088/0.38293. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.24272/0.38878. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.23459/0.37993. Took 0.16 sec\n",
      "Epoch 34, Loss(train/val) 0.23359/0.37265. Took 0.14 sec\n",
      "Epoch 35, Loss(train/val) 0.24010/0.36588. Took 0.17 sec\n",
      "Epoch 36, Loss(train/val) 0.22228/0.36932. Took 0.15 sec\n",
      "Epoch 37, Loss(train/val) 0.23349/0.37239. Took 0.15 sec\n",
      "Epoch 38, Loss(train/val) 0.21880/0.37278. Took 0.16 sec\n",
      "Epoch 39, Loss(train/val) 0.21522/0.37713. Took 0.15 sec\n",
      "Epoch 40, Loss(train/val) 0.21229/0.38779. Took 0.14 sec\n",
      "Epoch 41, Loss(train/val) 0.20846/0.37704. Took 0.16 sec\n",
      "Epoch 42, Loss(train/val) 0.20181/0.36760. Took 0.15 sec\n",
      "Epoch 43, Loss(train/val) 0.20447/0.37995. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.20758/0.36481. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.20498/0.36231. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.19345/0.36394. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.19973/0.35985. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.20445/0.37553. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.19765/0.37124. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.18674/0.37055. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.18957/0.36312. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.19405/0.35497. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.19559/0.36787. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.19131/0.38891. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.19793/0.36824. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.18784/0.35809. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.18430/0.36172. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.18282/0.36500. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.17646/0.36751. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.17816/0.36415. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.17091/0.35715. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.17712/0.36881. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.16236/0.36519. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.16874/0.34209. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.16613/0.35777. Took 0.13 sec\n",
      "Epoch 66, Loss(train/val) 0.16122/0.35129. Took 0.15 sec\n",
      "Epoch 67, Loss(train/val) 0.17496/0.35159. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.17311/0.34109. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.16892/0.35079. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.16200/0.36503. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.17037/0.36895. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.15577/0.36406. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.16154/0.35187. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.15699/0.37505. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.15385/0.36022. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.15798/0.35097. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.15681/0.33778. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.16452/0.35760. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.15776/0.35774. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.15122/0.35274. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.15403/0.34708. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.14768/0.35237. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.15518/0.34388. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.15365/0.34669. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.16749/0.39112. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.15734/0.36697. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.15077/0.38605. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.14332/0.37279. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.14861/0.37659. Took 0.13 sec\n",
      "Epoch 90, Loss(train/val) 0.15098/0.35858. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.14792/0.36229. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.14086/0.35875. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.15273/0.34786. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.15055/0.36078. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.14073/0.34278. Took 0.14 sec\n",
      "Epoch 96, Loss(train/val) 0.13448/0.34369. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.15239/0.35033. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.13973/0.34167. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.13984/0.35345. Took 0.14 sec\n",
      "ACC: 0.703125, MCC: 0.3333333333333333\n",
      "Epoch 0, Loss(train/val) 0.49527/0.49990. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.47716/0.47206. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.44465/0.42003. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.41350/0.38996. Took 0.15 sec\n",
      "Epoch 4, Loss(train/val) 0.38935/0.37088. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.37040/0.36107. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.36110/0.35263. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.34689/0.35240. Took 0.14 sec\n",
      "Epoch 8, Loss(train/val) 0.33479/0.35660. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.32662/0.34714. Took 0.15 sec\n",
      "Epoch 10, Loss(train/val) 0.32636/0.33572. Took 0.14 sec\n",
      "Epoch 11, Loss(train/val) 0.31399/0.34608. Took 0.15 sec\n",
      "Epoch 12, Loss(train/val) 0.31869/0.35293. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.30736/0.35016. Took 0.15 sec\n",
      "Epoch 14, Loss(train/val) 0.29679/0.36969. Took 0.16 sec\n",
      "Epoch 15, Loss(train/val) 0.29241/0.35584. Took 0.14 sec\n",
      "Epoch 16, Loss(train/val) 0.28129/0.34129. Took 0.13 sec\n",
      "Epoch 17, Loss(train/val) 0.28216/0.34114. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.28456/0.34295. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.27112/0.33308. Took 0.15 sec\n",
      "Epoch 20, Loss(train/val) 0.27150/0.33867. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.25921/0.35024. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.27320/0.33024. Took 0.14 sec\n",
      "Epoch 23, Loss(train/val) 0.26675/0.32349. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.25638/0.35175. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.25546/0.36442. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.25771/0.37061. Took 0.15 sec\n",
      "Epoch 27, Loss(train/val) 0.24694/0.36951. Took 0.14 sec\n",
      "Epoch 28, Loss(train/val) 0.24314/0.36730. Took 0.13 sec\n",
      "Epoch 29, Loss(train/val) 0.23870/0.36322. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.23258/0.35249. Took 0.13 sec\n",
      "Epoch 31, Loss(train/val) 0.24070/0.38096. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.23865/0.37673. Took 0.14 sec\n",
      "Epoch 33, Loss(train/val) 0.24610/0.36661. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.23404/0.37811. Took 0.15 sec\n",
      "Epoch 35, Loss(train/val) 0.23838/0.37552. Took 0.16 sec\n",
      "Epoch 36, Loss(train/val) 0.22951/0.36338. Took 0.16 sec\n",
      "Epoch 37, Loss(train/val) 0.24172/0.37027. Took 0.14 sec\n",
      "Epoch 38, Loss(train/val) 0.22752/0.37217. Took 0.16 sec\n",
      "Epoch 39, Loss(train/val) 0.22589/0.38610. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.22736/0.39322. Took 0.13 sec\n",
      "Epoch 41, Loss(train/val) 0.20612/0.40250. Took 0.16 sec\n",
      "Epoch 42, Loss(train/val) 0.20148/0.38500. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.21485/0.37714. Took 0.16 sec\n",
      "Epoch 44, Loss(train/val) 0.20604/0.37664. Took 0.13 sec\n",
      "Epoch 45, Loss(train/val) 0.20531/0.38166. Took 0.14 sec\n",
      "Epoch 46, Loss(train/val) 0.19099/0.38594. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.19704/0.36535. Took 0.14 sec\n",
      "Epoch 48, Loss(train/val) 0.19917/0.38034. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.18869/0.38344. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.19182/0.38722. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.19395/0.38883. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.18762/0.37599. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.18749/0.35807. Took 0.15 sec\n",
      "Epoch 54, Loss(train/val) 0.20275/0.35731. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.19105/0.37858. Took 0.14 sec\n",
      "Epoch 56, Loss(train/val) 0.18871/0.39181. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.18999/0.38218. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.18460/0.39770. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.18036/0.37855. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.17981/0.37220. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.17642/0.38584. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.16630/0.41118. Took 0.14 sec\n",
      "Epoch 63, Loss(train/val) 0.18075/0.40514. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.16503/0.41556. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.16980/0.40593. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.17436/0.39139. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.16272/0.38837. Took 0.13 sec\n",
      "Epoch 68, Loss(train/val) 0.16161/0.41257. Took 0.13 sec\n",
      "Epoch 69, Loss(train/val) 0.16040/0.40918. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.16473/0.39720. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.15893/0.39030. Took 0.13 sec\n",
      "Epoch 72, Loss(train/val) 0.16663/0.37352. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.15582/0.38853. Took 0.13 sec\n",
      "Epoch 74, Loss(train/val) 0.16224/0.37293. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.15507/0.38364. Took 0.13 sec\n",
      "Epoch 76, Loss(train/val) 0.16298/0.38847. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.15889/0.38351. Took 0.15 sec\n",
      "Epoch 78, Loss(train/val) 0.15038/0.39467. Took 0.13 sec\n",
      "Epoch 79, Loss(train/val) 0.15443/0.39090. Took 0.13 sec\n",
      "Epoch 80, Loss(train/val) 0.15084/0.38105. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.14542/0.38248. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.15905/0.40723. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.15213/0.38053. Took 0.13 sec\n",
      "Epoch 84, Loss(train/val) 0.14320/0.39583. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.15144/0.40362. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.14538/0.37487. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.14164/0.38008. Took 0.13 sec\n",
      "Epoch 88, Loss(train/val) 0.14142/0.37350. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.15165/0.37840. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.13542/0.38956. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.14199/0.37947. Took 0.13 sec\n",
      "Epoch 92, Loss(train/val) 0.13955/0.38338. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.13747/0.39174. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.13724/0.38323. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.13756/0.37313. Took 0.13 sec\n",
      "Epoch 96, Loss(train/val) 0.13435/0.38617. Took 0.14 sec\n",
      "Epoch 97, Loss(train/val) 0.13880/0.39099. Took 0.14 sec\n",
      "Epoch 98, Loss(train/val) 0.13904/0.38757. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.14512/0.39661. Took 0.14 sec\n",
      "ACC: 0.609375, MCC: 0.3392414539297282\n",
      "Epoch 0, Loss(train/val) 0.49574/0.48559. Took 0.15 sec\n",
      "Epoch 1, Loss(train/val) 0.47789/0.45967. Took 0.13 sec\n",
      "Epoch 2, Loss(train/val) 0.44567/0.41540. Took 0.13 sec\n",
      "Epoch 3, Loss(train/val) 0.40829/0.38378. Took 0.14 sec\n",
      "Epoch 4, Loss(train/val) 0.38341/0.36871. Took 0.13 sec\n",
      "Epoch 5, Loss(train/val) 0.36624/0.35935. Took 0.14 sec\n",
      "Epoch 6, Loss(train/val) 0.35614/0.35061. Took 0.13 sec\n",
      "Epoch 7, Loss(train/val) 0.34459/0.34499. Took 0.15 sec\n",
      "Epoch 8, Loss(train/val) 0.33431/0.32890. Took 0.13 sec\n",
      "Epoch 9, Loss(train/val) 0.33069/0.31539. Took 0.14 sec\n",
      "Epoch 10, Loss(train/val) 0.32862/0.29854. Took 0.13 sec\n",
      "Epoch 11, Loss(train/val) 0.31675/0.30479. Took 0.13 sec\n",
      "Epoch 12, Loss(train/val) 0.31054/0.32109. Took 0.13 sec\n",
      "Epoch 13, Loss(train/val) 0.30289/0.31144. Took 0.14 sec\n",
      "Epoch 14, Loss(train/val) 0.29921/0.31434. Took 0.14 sec\n",
      "Epoch 15, Loss(train/val) 0.29248/0.31058. Took 0.15 sec\n",
      "Epoch 16, Loss(train/val) 0.29210/0.30086. Took 0.14 sec\n",
      "Epoch 17, Loss(train/val) 0.28474/0.31049. Took 0.15 sec\n",
      "Epoch 18, Loss(train/val) 0.27302/0.42980. Took 0.14 sec\n",
      "Epoch 19, Loss(train/val) 0.26942/0.37050. Took 0.15 sec\n",
      "Epoch 20, Loss(train/val) 0.26686/0.42039. Took 0.13 sec\n",
      "Epoch 21, Loss(train/val) 0.25233/0.40520. Took 0.15 sec\n",
      "Epoch 22, Loss(train/val) 0.25217/0.31503. Took 0.15 sec\n",
      "Epoch 23, Loss(train/val) 0.24816/0.34851. Took 0.15 sec\n",
      "Epoch 24, Loss(train/val) 0.24328/0.36506. Took 0.13 sec\n",
      "Epoch 25, Loss(train/val) 0.22883/0.44780. Took 0.15 sec\n",
      "Epoch 26, Loss(train/val) 0.24277/0.32647. Took 0.13 sec\n",
      "Epoch 27, Loss(train/val) 0.24446/0.30695. Took 0.15 sec\n",
      "Epoch 28, Loss(train/val) 0.23710/0.42063. Took 0.13 sec\n",
      "Epoch 29, Loss(train/val) 0.23298/0.43335. Took 0.15 sec\n",
      "Epoch 30, Loss(train/val) 0.22871/0.34836. Took 0.14 sec\n",
      "Epoch 31, Loss(train/val) 0.23285/0.34067. Took 0.15 sec\n",
      "Epoch 32, Loss(train/val) 0.22922/0.34764. Took 0.13 sec\n",
      "Epoch 33, Loss(train/val) 0.21855/0.37742. Took 0.15 sec\n",
      "Epoch 34, Loss(train/val) 0.21461/0.33856. Took 0.16 sec\n",
      "Epoch 35, Loss(train/val) 0.22118/0.49528. Took 0.14 sec\n",
      "Epoch 36, Loss(train/val) 0.22477/0.31757. Took 0.14 sec\n",
      "Epoch 37, Loss(train/val) 0.20826/0.29864. Took 0.17 sec\n",
      "Epoch 38, Loss(train/val) 0.20857/0.31930. Took 0.15 sec\n",
      "Epoch 39, Loss(train/val) 0.21267/0.33771. Took 0.14 sec\n",
      "Epoch 40, Loss(train/val) 0.20431/0.32696. Took 0.15 sec\n",
      "Epoch 41, Loss(train/val) 0.19637/0.33126. Took 0.15 sec\n",
      "Epoch 42, Loss(train/val) 0.19899/0.33032. Took 0.14 sec\n",
      "Epoch 43, Loss(train/val) 0.20225/0.35528. Took 0.14 sec\n",
      "Epoch 44, Loss(train/val) 0.19318/0.36257. Took 0.15 sec\n",
      "Epoch 45, Loss(train/val) 0.19246/0.36144. Took 0.16 sec\n",
      "Epoch 46, Loss(train/val) 0.19036/0.36524. Took 0.13 sec\n",
      "Epoch 47, Loss(train/val) 0.19053/0.31811. Took 0.13 sec\n",
      "Epoch 48, Loss(train/val) 0.19736/0.39468. Took 0.13 sec\n",
      "Epoch 49, Loss(train/val) 0.18984/0.32632. Took 0.14 sec\n",
      "Epoch 50, Loss(train/val) 0.18395/0.29951. Took 0.13 sec\n",
      "Epoch 51, Loss(train/val) 0.18725/0.32302. Took 0.14 sec\n",
      "Epoch 52, Loss(train/val) 0.18025/0.31515. Took 0.13 sec\n",
      "Epoch 53, Loss(train/val) 0.18217/0.32876. Took 0.14 sec\n",
      "Epoch 54, Loss(train/val) 0.17911/0.32921. Took 0.13 sec\n",
      "Epoch 55, Loss(train/val) 0.17370/0.32756. Took 0.15 sec\n",
      "Epoch 56, Loss(train/val) 0.16913/0.33906. Took 0.13 sec\n",
      "Epoch 57, Loss(train/val) 0.17773/0.35546. Took 0.14 sec\n",
      "Epoch 58, Loss(train/val) 0.17954/0.33988. Took 0.13 sec\n",
      "Epoch 59, Loss(train/val) 0.16243/0.37987. Took 0.14 sec\n",
      "Epoch 60, Loss(train/val) 0.16605/0.36255. Took 0.13 sec\n",
      "Epoch 61, Loss(train/val) 0.16859/0.32407. Took 0.14 sec\n",
      "Epoch 62, Loss(train/val) 0.15904/0.35731. Took 0.13 sec\n",
      "Epoch 63, Loss(train/val) 0.16966/0.37054. Took 0.14 sec\n",
      "Epoch 64, Loss(train/val) 0.17445/0.29889. Took 0.13 sec\n",
      "Epoch 65, Loss(train/val) 0.16154/0.33216. Took 0.14 sec\n",
      "Epoch 66, Loss(train/val) 0.15762/0.33934. Took 0.13 sec\n",
      "Epoch 67, Loss(train/val) 0.15622/0.37748. Took 0.14 sec\n",
      "Epoch 68, Loss(train/val) 0.15355/0.29197. Took 0.14 sec\n",
      "Epoch 69, Loss(train/val) 0.15429/0.31438. Took 0.14 sec\n",
      "Epoch 70, Loss(train/val) 0.15080/0.33416. Took 0.13 sec\n",
      "Epoch 71, Loss(train/val) 0.15848/0.32269. Took 0.14 sec\n",
      "Epoch 72, Loss(train/val) 0.14990/0.35588. Took 0.13 sec\n",
      "Epoch 73, Loss(train/val) 0.14360/0.33813. Took 0.14 sec\n",
      "Epoch 74, Loss(train/val) 0.15597/0.29994. Took 0.13 sec\n",
      "Epoch 75, Loss(train/val) 0.14021/0.29907. Took 0.14 sec\n",
      "Epoch 76, Loss(train/val) 0.15593/0.33352. Took 0.13 sec\n",
      "Epoch 77, Loss(train/val) 0.15448/0.36659. Took 0.14 sec\n",
      "Epoch 78, Loss(train/val) 0.14440/0.34090. Took 0.14 sec\n",
      "Epoch 79, Loss(train/val) 0.14366/0.31397. Took 0.14 sec\n",
      "Epoch 80, Loss(train/val) 0.14379/0.30595. Took 0.13 sec\n",
      "Epoch 81, Loss(train/val) 0.13803/0.31342. Took 0.14 sec\n",
      "Epoch 82, Loss(train/val) 0.13840/0.32299. Took 0.13 sec\n",
      "Epoch 83, Loss(train/val) 0.13965/0.31569. Took 0.14 sec\n",
      "Epoch 84, Loss(train/val) 0.14612/0.36060. Took 0.13 sec\n",
      "Epoch 85, Loss(train/val) 0.15111/0.33632. Took 0.14 sec\n",
      "Epoch 86, Loss(train/val) 0.14088/0.32714. Took 0.13 sec\n",
      "Epoch 87, Loss(train/val) 0.13755/0.32603. Took 0.14 sec\n",
      "Epoch 88, Loss(train/val) 0.13289/0.30012. Took 0.13 sec\n",
      "Epoch 89, Loss(train/val) 0.13880/0.29799. Took 0.14 sec\n",
      "Epoch 90, Loss(train/val) 0.13912/0.32853. Took 0.13 sec\n",
      "Epoch 91, Loss(train/val) 0.13403/0.31813. Took 0.14 sec\n",
      "Epoch 92, Loss(train/val) 0.13798/0.31842. Took 0.13 sec\n",
      "Epoch 93, Loss(train/val) 0.13229/0.35739. Took 0.14 sec\n",
      "Epoch 94, Loss(train/val) 0.14011/0.33907. Took 0.13 sec\n",
      "Epoch 95, Loss(train/val) 0.14272/0.34461. Took 0.15 sec\n",
      "Epoch 96, Loss(train/val) 0.13523/0.35457. Took 0.13 sec\n",
      "Epoch 97, Loss(train/val) 0.12487/0.33517. Took 0.13 sec\n",
      "Epoch 98, Loss(train/val) 0.12304/0.32942. Took 0.13 sec\n",
      "Epoch 99, Loss(train/val) 0.12352/0.35191. Took 0.14 sec\n",
      "ACC: 0.8125, MCC: 0.6017521614967438\n"
     ]
    }
   ],
   "source": [
    "## 실행 파일\n",
    "args.data_list = os.listdir(\"./data/kdd17/ourpped\")\n",
    "\n",
    "\n",
    "with open(args.save_file_path + '\\\\' + 'CONV_ATTBILSTM_result_t.csv', 'w', encoding='utf-8', newline='') as f:\n",
    "    wr = csv.writer(f)\n",
    "    wr.writerow([\"model\", \"stock\", \"entire_exp_time\",  \"avg_test_ACC\", \"avg_test_MCC\"])\n",
    "\n",
    "    for data in args.data_list:\n",
    "        \n",
    "        stock = data.split('.')[0]\n",
    "\n",
    "        est = time.time()\n",
    "        setattr(args, 'symbol', stock)\n",
    "        args.new_file_path = args.save_file_path + '\\\\' + \"CONV_ATTBILSTM_\" + args.symbol\n",
    "        os.makedirs(args.new_file_path)\n",
    "        \n",
    "        \n",
    "        csv_read = stock_csv_read(data,args.x_frames,args.y_frames)\n",
    "        split_data_list = csv_read.cv_split()\n",
    "        \n",
    "        ACC_cv = []\n",
    "        for i, data in enumerate(split_data_list):\n",
    "            args.split_file_path = args.new_file_path + \"\\\\\" + str(i) +\"th_iter\"\n",
    "            os.makedirs(args.split_file_path)\n",
    "\n",
    "            # 0번째에 index 1번째에 stock 1개가 input으로 들어감\n",
    "            trainset = StockDataset(data[0])\n",
    "            valset = StockDataset(data[1])\n",
    "            testset = StockDataset(data[2])\n",
    "        \n",
    "\n",
    "            partition = {'train': trainset, 'val': valset, 'test': testset}\n",
    "\n",
    "\n",
    "            setting, result = experiment(partition, args)\n",
    "            eet = time.time()\n",
    "            entire_exp_time = eet - est\n",
    "\n",
    "            fig = plt.figure()\n",
    "            plt.plot(result['train_losses'])\n",
    "            plt.plot(result['val_losses'])\n",
    "            plt.legend(['train_losses', 'val_losses'], fontsize=15)\n",
    "            plt.xlabel('epoch', fontsize=15)\n",
    "            plt.ylabel('loss', fontsize=15)\n",
    "            plt.grid()\n",
    "            plt.savefig(args.split_file_path + '\\\\' + str(args.symbol) + '_fig' + '.png')\n",
    "            plt.close(fig)\n",
    "            ACC_cv.append(result['ACC'])\n",
    "        ACC_cv_ar = np.array(ACC_cv)\n",
    "        acc_avg = np.mean(ACC_cv_ar)\n",
    "        acc_std = np.std(ACC_cv_ar)\n",
    "\n",
    "        wr.writerow([\"CONV_BILSTM_ATTENTION\", args.symbol, entire_exp_time, acc_avg, acc_std, result['MCC']])\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "interpreter": {
   "hash": "ff4208fb53146a003fd3ddce22903cec0cd243c3b14a4aec7cc1b5c53908f821"
  },
  "kernelspec": {
   "display_name": "py38_64",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
